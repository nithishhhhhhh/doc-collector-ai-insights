====================================================================================================
MASTER DOCUMENTATION COLLECTION
====================================================================================================
Combined documentation from: animejs, modal, bootstrap
Total sites: 3
Combined size: 2.7 MB
Generated: /Users/pandujakkampudi/Desktop/Project1/doc-collector-ai-insights
====================================================================================================

====================================================================================================
DOCUMENTATION SITE: ANIMEJS
Size: 0.4 MB
====================================================================================================

=== ANIMEJS DOCUMENTATION COLLECTION ===
Generated: /Users/pandujakkampudi/Desktop/Project1/doc-collector-ai-insights
Source: Documentation scraper
============================================================

=== DOC: 001_onenter.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onenter
ScrollObserver

Callbacks
Since 4.0.0
onEnter
Triggers a function every time the
enter
threshold
is met.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
entered =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onEnter
:
() =>
$value.
textContent
= ++entered,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
entered
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
ScrollObserver callbacks
onEnterForward

=== DOC: 002_animatable-methods.txt ===
URL: https://animejs.com/documentation/animatable/animatable-methods
Animatable
Since 4.0.0
Animatable methods
Triggers animations attached to the animatable properties.
Animation methods are available on an Animatable instance
Object
.
const
animatable =
createAnimatable
(target, parameters);
┌─────────────────────┐
animatable.│
x
(
100
)               │
animatable.│
y
(
50
,
500
,
'out(2)'
) ├─
Methods
animatable.│
revert
()             │
└─────────────────────┘
In this section
Getters
Setters
revert()
Previous
Next
Animatable settings
Getters

=== DOC: 003_pad-start.txt ===
URL: https://animejs.com/documentation/utilities/pad-start
Utilities
Since 4.0.0
padStart()
V4
Pads a
Number
from the start with a string until the result reaches a given length or creates a padding
Function
with pre-defined
totalLength
and
padString
parameters.
const
paddedValue = utils.
padStart
(value, totalLength, padString);
const
padderFunction = utils.
padStart
(totalLength, padString);
Parameters
Name
Accepts
value
(opt)
String
/
Number
totalLength
Number
padString
String
Returns
A
String
if a value is provided, otherwise a
chain-able utility
Function
to pad numbers from the start:
const
padTo5WithZeros = utils.
padStart
(
5
,
'0'
);
padTo5WithZeros
(
'123'
);
// '00123'
padTo5WithZeros
(
78
);
// '00078'
padTo5WithZeros
(
'1234'
);
// '01234'
const
roundAndPad = utils.
round
(
2
).
padStart
(
5
,
'0'
);
// Round to 2 decimal places then pad to 5 characters
roundAndPad
(
12.345
);
// '12.35'
roundAndPad
(
7.8
);
// '07.80'
import
{ animate, utils }
from
'animejs'
;
animate
(
'.value'
, {
innerHTML
:
10000
,
modifier
: utils.
round
(
0
).
padStart
(
6
,
'-'
),
duration
:
100000
,
ease
:
'linear'
,
});
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
roundPad()
padEnd()

=== DOC: 004_setters.txt ===
URL: https://animejs.com/documentation/animatable/animatable-methods/setters
Animatable

Methods
Since 4.0.0
Setters
Every animatable properties defined in the animatable parameters are transformed into methods and accessible on the animatable object.
When calling a method with at least one argument, the method acts as a setter, and returns the animatable instance, allowing chaining methods calls.
animatable.
property
(value, duration, easing);
Parameters
Name
Type
Description
value
Number
|
Array
<
Number
>
Defines the new value of the animatable to animate to
duration
(opt)
Number
Optional new transition duration in ms
easing
(opt)
ease
Optional new easing function of the animation
Returns
The animatable object itself, allowing for chaining of multiple property setter calls:
animatable.
x
(
100
).
y
(
200
);
// Animate x to 100 and y to 200 in 500ms
import
{ createAnimatable, utils }
from
'animejs'
;
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
$demo = $demos.
querySelector
(
'.docs-demo.is-active'
);
let
bounds = $demo.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $demo.
getBoundingClientRect
();
const
circle =
createAnimatable
(
'.circle'
, {
x
:
0
,
y
:
0
,
backgroundColor
:
0
,
ease
:
'outExpo'
,
});
const
rgb = [
164
,
255
,
79
];
// Sets new durations and easings
circle.
x
(
0
,
500
,
'out(2)'
);
circle.
y
(
0
,
500
,
'out(3)'
);
circle.
backgroundColor
(rgb,
250
);
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
hw = width /
2
;
const
hh = height /
2
;
const
x = utils.
clamp
(e.
clientX
- left - hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- top - hh, -hh, hh);
rgb[
0
] = utils.
mapRange
(x, -hw, hw,
0
,
164
);
rgb[
2
] = utils.
mapRange
(x, -hw, hw,
79
,
255
);
circle.
x
(x).
y
(y).
backgroundColor
(rgb);
// Update values
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"large centered row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
span
class
=
"label"
>
Move cursor around
</
span
>
</
div
>
Previous
Next
Getters
revert()

=== DOC: 005_playbackease.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/playbackease
Timeline

Playback settings
Since 4.0.0
playbackEase
V4
Applies and easing function to the entire playback of the timeline.
0
──────────playbackEase──────────›
1
A ──ease──› B ──ease──› C ──ease──› D
Accepts
ease
Default
null
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
playbackEase
=
'inOut'
;
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
({
playbackEase
:
'inOut(3)'
,
// this ease is applied across all children
})
.
add
(
'.circle'
, {
x
:
'15rem'
,
ease
:
'out(1)'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
,
ease
:
'out(2)'
})
.
add
(
'.square'
, {
x
:
'15rem'
,
ease
:
'out(3)'
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
playbackRate
Timeline callbacks

=== DOC: 006_color-function-value.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/color-function-value
Animation

Tween value types
Since 4.0.0
Color function value
WAAPI
The CSS
color
()
function can be animated with the
WAAPI
animate
()
method.
Accepts
Any
valid CSS color space syntax
is supported
import
{ waapi }
from
'animejs'
;
waapi.
animate
(
'.circle'
,  {
backgroundColor
:
'color(display-p3 1.0 0.267 0.267 / 1.0)'
,
});
<
div
class
=
"large justified row"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
Previous
Next
Color value
CSS variable

=== DOC: 007_array-of-targets.txt ===
URL: https://animejs.com/documentation/animation/targets/array-of-targets
Animation

Targets
Since 1.0.0
Array of targets
Targets multiple valid
Targets
simultaneously by grouping them inside an
Array
.
Any types of targets can be grouped together
Accepts
An
Array
of
Targets
import
{ animate, utils }
from
'animejs'
;
const
[ $log ] = utils.$(
'.demo code'
);
const
vector2D = {
x
:
0
,
y
:
0
};
animate
([vector2D,
'.square'
], {
x
:
'17rem'
,
modifier
: utils.
roundPad
(
2
).
padStart
(
5
,
'0'
),
onRender
:
() =>
$log.
textContent
=
JSON
.
stringify
(vector2D),
});
<
pre
class
=
"row large centered"
>
<
code
>
{"x":"0"}
</
code
>
</
pre
>
<
div
class
=
"row medium"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
JavaScript Objects
Animatable properties

=== DOC: 008_animatable-properties.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties
Animation
Since 1.0.0
Animatable properties
Define which properties of the
Targets
can be animated.
Animatable properties are defined in the parameters
Object
of the
animate
()
function.
animate
(
'.square'
, {
┌──────────────────┐
│
translateX
:
100
, │
│
scale
:
2
,        ├─
Animatable
Properties
│
opacity
:
.5
,     │
└──────────────────┘
duration
:
400
,
delay
:
250
,
ease
:
'out(3)'
,
loop
:
3
,
alternate
:
true
,
autoplay
:
false
,
onBegin
:
() =>
{},
onLoop
:
() =>
{},
onUpdate
:
() =>
{},
});
In this section
CSS Properties
CSS transforms
CSS Variables
JS Object properties
HTML Attributes
SVG Attributes
Previous
Next
Targets
CSS Properties

=== DOC: 009_wrap.txt ===
URL: https://animejs.com/documentation/utilities/wrap
Utilities
Since 4.0.0
wrap()
V4
Wraps a
Number
between a range defined with
min
and
max
values or creates a wrapping
Function
with pre-defined
min
and
max
parameters.
const
wrappedValue = utils.
wrap
(value, min, max);
const
wrapperFunction = utils.
wrap
(min, max);
Parameters
Name
Accepts
value
(opt)
Number
min
Number
max
Number
Returns
A
Number
if a value is provided, otherwise a
chain-able utility
Function
to wrap numbers between the specified
min
and
max
values:
const
wrapBetween0and100 = utils.
wrap
(
0
,
100
);
wrapBetween0and100
(
105
);
// 5
wrapBetween0and100
(
220
);
// 20
wrapBetween0and100
(-
15
);
// 85
const
wrapAndRound = utils.
wrap
(
0
,
100
).
round
(
2
);
// Wrap then round to 2 decimal places
wrapAndRound
(
105.7523
);
// 5.75
wrapAndRound
(
220.2514
);
// 20.25
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'1turn'
,
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
animate
(
'.wrapped'
, {
rotate
:
'1turn'
,
modifier
: utils.
wrap
(-
.25
,
.25
),
// Used as a modifier
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock wrapped"
>
</
div
>
<
div
class
=
"label"
>
wrapped [-.25,.25]
</
div
>
</
div
>
</
div
>
Previous
Next
snap()
mapRange()

=== DOC: 010_animateinview.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/animateinview
Draggable

Methods
Since 4.0.0
animateInView()
Animate the draggable inside the viewport if positioned outside of the container.
Parameters
Name
Type
Description
duration
(opt)
Number
The duration of the animation (default
350
)
gap
(opt)
Boolean
How much extra distance from the edges of the container the draggable should be animated to
ease
(opt)
ease
The easing function applied to the animation (default
InOutQuad
Returns
The draggable itself
import
{ createDraggable }
from
'animejs'
;
const
[ $animateInView ] = utils.$(
'.animate-button'
);
const
draggable =
createDraggable
(
'.square'
, {
container
:
'.grid'
,
});
const
animateInView
= (
) => {
draggable.
animateInView
(
400
,
16
);
}
// Set the draggable position outside the container
draggable.
x
= -
24
;
draggable.
y
=
72
;
$animateInView.
addEventListener
(
'click'
, animateInView);
<
div
class
=
"medium padded show-bounds grid square-grid animate-in-view"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button animate-button"
>
Animate in view
</
button
>
</
fieldset
>
</
div
>
Previous
Next
setY()
scrollInView()

=== DOC: 011_revert.txt ===
URL: https://animejs.com/documentation/scope/scope-methods/revert
Scope

Methods
Since 4.0.0
revert()
Reverts all Anime.js objects that have been declared inside a Scope and call the constructors cleanup functions if needed.
Returns
The Scope itself
import
{ utils, stagger, createScope, createTimeline }
from
'animejs'
;
const
[ $button1, $button2 ] = utils.$(
'.revert'
);
function
onMouseEnter
(
) {
animate
(
this
, {
scale
:
2
,
duration
:
250
}) }
function
onMouseLeave
(
) {
animate
(
this
, {
scale
:
1
,
duration
:
750
}) }
const
scopeConstructor
= scope => {
const
circles = utils.$(
'.circle'
);
circles.
forEach
(
(
$circle, i
) =>
{
animate
($circle, {
opacity
:
.25
,
loop
:
true
,
alternate
:
true
,
duration
:
500
,
delay
: i *
100
,
ease
:
'inOut(3)'
,
});
$circle.
addEventListener
(
'mouseenter'
, onMouseEnter);
$circle.
addEventListener
(
'mouseleave'
, onMouseLeave);
});
// Cleanup function to take care of removing event listeners on revert
return
() =>
{
circles.
forEach
($circle => {
// Anime.js instances are automatically reverted by the Scope
$circle.
removeEventListener
(
'mouseenter'
, onMouseEnter);
$circle.
removeEventListener
(
'mouseleave'
, onMouseLeave);
});
}
}
const
scope1 =
createScope
({
root
:
'.row-1'
}).
add
(scopeConstructor);
const
scope2 =
createScope
({
root
:
'.row-2'
}).
add
(scopeConstructor);
const
revertScope1
= (
) => scope1.
revert
();
const
revertScope2
= (
) => scope2.
revert
();
$button1.
addEventListener
(
'click'
, revertScope1);
$button2.
addEventListener
(
'click'
, revertScope2);
<
div
class
=
"medium justified row row-1"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium justified row row-2"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button revert"
>
Revert row 1
</
button
>
<
button
class
=
"button revert"
>
Revert row 2
</
button
>
</
fieldset
>
</
div
>
Previous
Next
add()
refresh()

=== DOC: 012_api-differences-with-native-waapi.txt ===
URL: https://animejs.com/documentation/web-animation-api/api-differences-with-native-waapi
Web Animation API
Since 4.0.0
API differences with native WAAPI
This chapter covers all major differences between the native Web Animation API
element.
animate
()
syntax and Anime.js
waapi.
animate
(element)
syntax.
Anime.js
waapi.
animate
(
┌────────────┐
│
'.square'
, ├─
Targets
└────────────┘
{
┌──────────────────┐
│
x
:
100
,          │
│
y
:
50
,           ├─
Keyframes
Values
│
opacity
:
.5
,     │
└──────────────────┘
┌──────────────────┐
│
loop
:
3
,         │
│
alternate
:
true
, ├─
Playback
Settings
│
ease
:
'out'
,     │
└──────────────────┘
});
WAAPI
const
$square =
document
.
querySelector
(
'.square'
);
┌────────────┐
│ $square    ├─
Targets
└────────────┘
.
animate
({
┌──────────────────────────┐
│
translate
:
'100px 50px'
, ├─
Keyframes
Values
│
opacity
:
.5
,             │
└──────────────────────────┘
}, {
┌──────────────────────────┐
│
ieterations
:
4
,          │
│
direction
:
'alternate'
,  ├─
Playback
Settings
│
easing
:
'ease-out'
,      │
└──────────────────────────┘
});
In this section
iterations
direction
easing
finished
Previous
Next
Improvements to the Web Animation API
iterations

=== DOC: 013_mapto.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters/mapto
Draggable

Axes parameters
Since 4.0.0
mapTo
Maps the axis value to a different property of the element.
Accepts
String
Default
null
import
{ createDraggable, utils }
from
'animejs'
;
utils.
set
(
'.square'
, {
z
:
100
});
createDraggable
(
'.square'
, {
x
: {
mapTo
:
'rotateY'
},
y
: {
mapTo
:
'z'
},
});
<
div
class
=
"large grid centered perspective square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
modifier
Draggable settings

=== DOC: 014_timeline-playback-settings.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings
Timeline
Since 2.0.0
Timeline playback settings
Specify the timings and behaviours of a timeline.
Timeline playback settings are defined directly in the
createTimeline
()
parameters
Object
.
createTimeline
({
┌───────────────────┐
│
defaults
: {       │
│
ease
:
'out(3)'
, │
│
duration
:
500
,  │
│ },                ├─
Playback
Settings
│
loop
:
3
,          │
│
alternate
:
true
,  │
│
autoplay
:
false
,  │
└───────────────────┘
onBegin
:
() =>
{},
onLoop
:
() =>
{},
onUpdate
:
() =>
{},
});
In this section
defaults
delay
loop
loopDelay
alternate
reversed
autoplay
frameRate
playbackRate
playbackEase
Previous
Next
Time position
defaults

=== DOC: 015_scope-properties.txt ===
URL: https://animejs.com/documentation/scope/scope-properties
Scope
Since 4.0.0
Scope properties
const
scope =
createScope
();
┌────────┐
scope.│methods │
scope.│root    ├─
Properties
scope.│matches │
└────────┘
Name
Description
data
An object used to store variables associated with the scope. Every properties added to it are cleared when the scope is reverted (
Object
)
defaults
Gets the default parameters for this scope (
Object
)
root
Gets the root element for DOM operations in this scope (
Document
|
HTMLElement
)
constructors
Gets the array of constructor functions added to this scope (
Array
<
Function
>
)
revertConstructors
Gets the array of revert constructor functions (
Array
<
Function
>
)
revertibles
Gets the array of revertible objects created within this scope (
Array
<
Tickable
|
Animatable
|
Draggable
|
ScrollObserver
|
Scope
>
)
methods
Gets the object containing methods added to this scope (
Object
)
matches
Gets the object containing current media query match results (
Object
)
mediaQueryLists
Gets the object containing MediaQueryList objects for this scope (
Object
)
Previous
Next
Scope methods
Stagger

=== DOC: 016_duration.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/duration
Timer

Playback settings
Since 4.0.0
duration
Defines the duration in milliseconds of the timer.
Setting
0
to a duration completes the timer instantly upon play.
Accepts
A
Number
equal to or greater than
0
Duration values higher than
1e12
are clamped internally to
1e12
(Or approximatively 32 years).
Default
Infinity
import
{ createTimer, utils }
from
'animejs'
;
const
[ $time ] = utils.$(
'.time'
);
createTimer
({
duration
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
delay
loop

=== DOC: 017_update.txt ===
URL: https://animejs.com/documentation/engine/engine-methods/update
Engine

Methods
Since 4.0.0
update()
Manually ticks the engine when
engine.
useDefaultMainLoop
is set to false.
engine.
useDefaultMainLoop
=
false
;
engine.
update
();
// Manual update call
Useful for integrating Anime.js in projects with existing animation loops, such as
Three.js
or game engines.
Returns
Engine
import
{ engine, createTimeline, utils }
from
'animejs'
;
// Prevents Anime.js from using its own loop
engine.
useDefaultMainLoop
=
false
;
const
[ $container ] = utils.$(
'.container'
);
const
color = utils.
get
($container,
'color'
);
const
{ width, height } = $container.
getBoundingClientRect
();
// Three.js setup, note that the global THREE object is defined globally
const
renderer =
new
THREE
.
WebGLRenderer
({
alpha
:
true
});
const
scene =
new
THREE
.
Scene
();
const
camera =
new
THREE
.
PerspectiveCamera
(
65
, width / height,
0.1
,
20
);
const
geometry =
new
THREE
.
BoxGeometry
(
1
,
1
,
1
);
const
material =
new
THREE
.
MeshBasicMaterial
({ color,
wireframe
:
true
});
renderer.
setSize
(width, height);
renderer.
setPixelRatio
(
window
.
devicePixelRatio
);
$container.
appendChild
(renderer.
domElement
);
camera.
position
.
z
=
5
;
function
createAnimatedCube
(
) {
const
cube =
new
THREE
.
Mesh
(geometry, material);
const
x = utils.
random
(-
10
,
10
,
2
);
const
y = utils.
random
(-
5
,
5
,
2
);
const
z = [-
10
,
7
];
const
r
= (
) => utils.
random
(-
Math
.
PI
*
2
,
Math
.
PI
*
2
,
3
);
const
duration =
4000
;
createTimeline
({
delay
: utils.
random
(
0
, duration),
defaults
: {
loop
:
true
, duration,
ease
:
'inSine'
, },
})
.
add
(cube.
position
, { x, y, z },
0
)
.
add
(cube.
rotation
, {
x
: r,
y
: r,
z
: r },
0
)
.
init
();
scene.
add
(cube);
}
for
(
let
i =
0
; i <
40
; i++) {
createAnimatedCube
();
}
function
render
(
) {
engine.
update
();
// Manually update Anime.js engine
renderer.
render
(scene, camera);
// Render Three.js scene
}
// Calls the builtin Three.js animation loop
renderer.
setAnimationLoop
(render);
<
div
class
=
"container large grid square-grid"
>
</
div
>
Previous
Next
Engine methods
pause()

=== DOC: 018_add-constructor-function.txt ===
URL: https://animejs.com/documentation/scope/add-constructor-function
Scope
Since 4.0.0
Add constructor function
A constructor function is called inside the Scope's context immediately after being passed as a callback of the Scope's
add
()
method.
The Scope registers and keeps track of all animations, timers, timelines, animatables, draggables, onScrolls, and even other scopes declared inside the constructor function.
scope.
add
(constructorFunction);
Constructor function argument
Name
Type
self
The current Scope instance
Returns
(optional)
A cleanup
Function
called when the Scope is reverted or when a media query changes.
import
{ utils, animate, createScope, createDraggable }
from
'animejs'
;
createScope
({
mediaQueries
: {
isSmall
:
'(max-width: 200px)'
},
defaults
: {
ease
:
'linear'
},
})
.
add
(
self
=>
{
/* Media queries state are accessible on the matches property */
const
{ isSmall } = self.
matches
;
/* The $() utility method is also scoped */
const
[ $square ] = utils.$(
'.square'
);
if
(self.
matches
.
isSmall
) {
/* Only animate the square when the iframe is small */
animate
($square, {
rotate
:
360
,
loop
:
true
,
});
}
else
{
/* Only create the draggable when the iframe is large enough */
$square.
classList
.
add
(
'draggable'
);
createDraggable
($square, {
container
:
document
.
body
,
});
}
return
() =>
{
/* Removes the class 'draggable' when the scope reverts itself */
$square.
classList
.
remove
(
'draggable'
);
}
});
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
Scope
Register method function

=== DOC: 019_alternate.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/alternate
Animation

Playback settings
Since 4.0.0
alternate
V4
Defines if the direction of the animation alternates on each iteration when the
loop
parameter is set to
true
or superior to
1
.
Accepts
Boolean
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
alternate
=
true
;
import
{ animate }
from
'animejs'
;
animate
(
'.dir-normal'
, {
x
:
'17rem'
,
alternate
:
false
,
// Default
loop
:
1
,
});
animate
(
'.dir-alternate'
, {
x
:
'17rem'
,
alternate
:
true
,
loop
:
1
,
// Required to see the second iteration
});
animate
(
'.dir-alternate-reverse'
, {
x
:
'17rem'
,
alternate
:
true
,
reversed
:
true
,
loop
:
1
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle dir-normal"
>
</
div
>
<
div
class
=
"padded label"
>
alternate: false
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle dir-alternate"
>
</
div
>
<
div
class
=
"padded label"
>
alternate: true
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle dir-alternate-reverse"
>
</
div
>
<
div
class
=
"padded label"
>
alternate: true, reversed: true
</
div
>
</
div
>
Previous
Next
loopDelay
reversed

=== DOC: 020_onleavebackward.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onleavebackward
ScrollObserver

Callbacks
Since 4.0.0
onLeaveBackward
Triggers a function every time the
leave
threshold
is met by scrolling backward.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
exits =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onLeaveBackward
:
() =>
$value.
textContent
= ++exits,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
exits
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onLeaveForward
onUpdate

=== DOC: 021_timer-methods.txt ===
URL: https://animejs.com/documentation/timer/timer-methods
Timer
Since 4.0.0
Timer methods
Provide control over the timing, behaviour and progression of a timer.
Timer methods are available on a Timer instance
Object
.
const
timer =
createTimer
(parameters);
┌──────────┐
timer.│
pause
()   │
timer.│
play
()    ├─
Methods
timer.│
restart
() │
└──────────┘
In this section
play()
reverse()
pause()
restart()
alternate()
resume()
complete()
cancel()
revert()
seek()
stretch()
Previous
Next
Timer callbacks
play()

=== DOC: 022_ongrab.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/ongrab
Draggable

Callbacks
Since 4.0.0
onGrab
Executes a function when the element is grabbed.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
grabs =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onGrab
:
() =>
$value.
textContent
= ++grabs
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
grabs
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
Draggable callbacks
onDrag

=== DOC: 023_timeline-positions-staggering.txt ===
URL: https://animejs.com/documentation/stagger/timeline-positions-staggering
Stagger
Since 4.0.0
Timeline positions staggering
V4
The timeline
add
()
position argument accepts function-based values, enabling the use of the stagger function returned by the
stagger
()
method when positioning a multi-target animation.
This results in each target having creating its own animation to a staggered position, increasing by a set number of milliseconds for each subsequent target.
Callbacks defined on the staggered animation are also staggered and are called for every target.
The
start
property of the
stagger
()
parameter object allows to define the starting value of the stagger, and accepts the same values as the timeline
add
()
position argument.
import
{ createTimeline, stagger, utils }
from
'animejs'
;
const
tl =
createTimeline
();
const
onComplete
= (
{ targets }
) => {
utils.
set
(targets, {
color
:
'var(--hex-red)'
});
}
tl
.
add
(
'.circle'
, {
x
:
'15rem'
, onComplete })
.
label
(
'circle completes'
)
.
add
([
'.triangle'
,
'.square'
], {
x
:
'15rem'
,
onComplete,
// Callbacks are aslo staggered
},
stagger
(
500
, {
start
:
'circle completes-=500'
}));
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Values staggering
Stagger value types

=== DOC: 024_time-position.txt ===
URL: https://animejs.com/documentation/timeline/time-position
Timeline
Since 2.0.0
Time position
Specifies the time at which a timeline child is inserted into a timeline.
If no position is defined, the child will be positioned at the end of the timeline.
The time position is defined as the last parameter of the following methods:
timeline.
add
(target, animationParameters, position);
timeline.
add
(timerParameters, position);
timeline.
call
(callbackFunction, position);
timeline.
sync
(labelName, position);
timeline.
label
(labelName, position);
Time position types
Type
Example
Description
Absolute
500
Position the element at exactly 100ms in the timeline
Addition
'+=100'
Position the element 100ms after the last element
Subtraction
'-=100'
Position the element 100ms before the last element end
Multiplier
'*=.5'
Position the element at half of the total element duration
Previous end
position
'<'
Position the element at the end position of the previous element
Previous start
position
'<<'
Position the element at the start position of the previous element
Combined
'<<+=250'
Position the element 250ms after the beginning position of the previous element
Label
'My Label'
Position the element at the
'My Label'
element
Stagger
stagger
(
10
)
Stagger the elements position by
10
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
()
.
label
(
'start'
,
0
)
.
add
(
'.square'
, {
x
:
'15rem'
,
duration
:
500
,
},
500
)
.
add
(
'.circle'
, {
x
:
'15rem'
,
duration
:
500
,
},
'start'
)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
500
,
},
'<-=250'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Call functions
Timeline playback settings

=== DOC: 025_revert.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/revert
Timer

Methods
Since 4.0.0
revert()
Cancels the timer, sets its
currentTime
to
0
and reverts the linked
onScroll
()
instance if necessary.
Use
.
revert
()
when you want to completely stop and destroy an timer.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $playButton ] = utils.$(
'.play'
);
const
[ $revertButton ] = utils.$(
'.revert'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
playTimer
= (
) => timer.
play
();
const
revertTimer
= (
) => {
timer.
revert
();
$time.
innerHTML
= timer.
currentTime
}
$playButton.
addEventListener
(
'click'
, playTimer);
$revertButton.
addEventListener
(
'click'
, revertTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button play"
>
Play
</
button
>
<
button
class
=
"button revert"
>
Revert
</
button
>
</
fieldset
>
</
div
>
Previous
Next
cancel()
seek()

=== DOC: 026_lerp.txt ===
URL: https://animejs.com/documentation/utilities/lerp
Utilities
Since 4.0.0
lerp()
V4
Performs a linear interpolation between two values.
The closer the amount is to
1
, the closer the result is to the
end
value.
The
utils.
lerp
()
function is
frame rate independent
.
const
lerped = utils.
lerp
(start, end, amount);
Parameters
Name
Accepts
start
Number
end
Number
amount
Number
[
0
-
1
]
Returns
Number
utils.
lerp
(
0
,
100
,
0
);
// 0
utils.
lerp
(
0
,
100
,
0.5
);
// 50
utils.
lerp
(
0
,
100
,
1
);
// 100
import
{ animate, createTimer, utils }
from
'animejs'
;
const
[ $input ] = utils.$(
'.input'
);
const
[ $lerped ] = utils.$(
'.lerped'
);
const
[ $lerped15fps ] = utils.$(
'.lerped-15'
);
animate
($input, {
rotate
:
'1000turn'
,
modifier
: utils.
snap
(
.25
),
duration
:
4000000
,
loop
:
true
,
ease
:
'linear'
,
});
const
loop =
createTimer
({
onUpdate
:
clock
=>
{
const
sourceRotate = utils.
get
($input,
'rotate'
,
false
);
const
lerpedRotate = utils.
get
($lerped,
'rotate'
,
false
);
utils.
set
($lerped, {
rotate
: utils.
lerp
(lerpedRotate, sourceRotate,
.075
) +
'turn'
});
}
});
const
loop15fps =
createTimer
({
frameRate
:
15
,
onUpdate
:
clock
=>
{
const
sourceRotate = utils.
get
($input,
'rotate'
,
false
);
const
lerpedRotate = utils.
get
($lerped15fps,
'rotate'
,
false
);
utils.
set
($lerped15fps, {
rotate
: utils.
lerp
(lerpedRotate, sourceRotate,
.0725
, clock) +
'turn'
});
}
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock input"
>
</
div
>
<
div
class
=
"label"
>
input
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock lerped"
>
</
div
>
<
div
class
=
"label"
>
lerped
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock lerped-15"
>
</
div
>
<
div
class
=
"label"
>
lerped 15fps
</
div
>
</
div
>
</
div
>
Previous
Next
sync()
round()

=== DOC: 027_revert.txt ===
URL: https://animejs.com/documentation/animatable/animatable-methods/revert
Animatable

Methods
Since 4.0.0
revert()
Reverts all the animatable properties to their original values and cleanup the CSS inline styles.
Use
revert
()
when you want to completely stop and destroy an animatable.
Returns
The animatable itself
Can be chained with other animatable methods.
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
$demo = $demos.
querySelector
(
'.docs-demo.is-active'
);
const
[ $revertButton ] = utils.$(
'.revert'
);
let
bounds = $demo.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $demo.
getBoundingClientRect
();
const
circles =
createAnimatable
(
'.circle'
, {
x
:
stagger
(
50
, {
from
:
'center'
,
start
:
100
}),
y
:
stagger
(
200
, {
from
:
'center'
,
start
:
200
}),
ease
:
'out(4)'
,
});
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
hw = width /
2
;
const
hh = height /
2
;
const
x = utils.
clamp
(e.
clientX
- left - hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- top - hh, -hh, hh);
circles.
x
(x).
y
(y);
}
const
revertAnimatable
= (
) => {
window
.
removeEventListener
(
'mousemove'
, onMouseMove);
circles.
revert
();
}
$revertButton.
addEventListener
(
'click'
, revertAnimatable);
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"large centered row"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button revert"
>
Revert
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Setters
Animatable properties

=== DOC: 028_engine-properties.txt ===
URL: https://animejs.com/documentation/engine/engine-properties
Engine
Since 4.0.0
Engine properties
import
{ engine }
from
'animejs'
;
┌───────────────────────┐
engine.│deltaTime              │
engine.│useDefaultMainLoop     ├─
Properties
engine.│pauseOnDocumentHidden  │
└───────────────────────┘
Name
Description
timeUnit
Gets and sets the unit of time to use for time-related values like
duration
and
delay
(
'ms'
|
's'
)
currentTime
Gets the current time of the engine (
Number
)
deltaTime
Gets the time elapsed since the last frame (
Number
)
precision
Gets and sets how many decimal places to round string values to during an animation (
Number
)
speed
Gets or sets the global playback rate for all animations (
Number
)
fps
Gets or sets the global frame rate for all animations (
Number
)
useDefaultMainLoop
Gets or sets whether the engine uses its default main loop (
Boolean
)
pauseOnDocumentHidden
Gets or sets whether the engine pauses when the tab is hidden (
Boolean
)
Previous
Next
Engine methods
Engine defaults

=== DOC: 029_playback-loopdelay.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/playback-loopdelay
Timer

Playback settings
Since 4.0.0
loopDelay
Defines the delay in milliseconds between loops.
Accepts
A
Number
equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loopDelay
=
500
;
import
{ createTimer, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
const
[ $time ] = utils.$(
'.time'
);
let
loops =
0
;
createTimer
({
loop
:
true
,
loopDelay
:
750
,
duration
:
250
,
onLoop
:
() =>
$loops.
innerHTML
= ++loops,
onUpdate
:
self
=>
$time.
innerHTML
= utils.
clamp
(self.
iterationCurrentTime
,
0
,
250
)
});
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops count
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
loop
alternate

=== DOC: 030_duration.txt ===
URL: https://animejs.com/documentation/animatable/animatable-settings/duration
Animatable

Settings
Since 4.0.0
duration
Specifies the duration in milliseconds for the transition to the animated value of the property.
Accepts
A
Number
equal to or greater than
0
A
Function based value
that returns a
Number
equal to or greater than
0
Default
1000
import
{ createAnimatable, utils, stagger }
from
'animejs'
;
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
$demo = $demos.
querySelector
(
'.docs-demo.is-active'
);
let
bounds = $demo.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $demo.
getBoundingClientRect
();
const
circles =
createAnimatable
(
'.circle'
, {
x
:
0
,
// Imediatly set the value without animation
y
:
stagger
(
200
, {
from
:
'center'
,
start
:
200
}),
ease
:
'out(4)'
,
});
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
hw = width /
2
;
const
hh = height /
2
;
const
x = utils.
clamp
(e.
clientX
- left - hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- top - hh, -hh, hh);
circles.
x
(x).
y
(y);
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"medium centered row"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"small centered row"
>
<
span
class
=
"label"
>
<
br
>
<
br
>
<
br
>
Move cursor around
</
span
>
</
div
>
Previous
Next
unit
ease

=== DOC: 031_scope.txt ===
URL: https://animejs.com/documentation/scope
Scope
V4
Anime.js instances declared inside a Scope can react to media queries, use custom root elements, share default parameters, and be reverted in batch, streamlining work in responsive and component-based environments.
Scopes are created using the
createScope
()
function.
import
{ createScope }
from
'animejs'
;
const
scope =
createScope
(parameters);
Parameters
Name
Accepts
parameters
(opt)
Scope parameters
Returns
Scope
import
{ animate, utils, createScope }
from
'animejs'
;
createScope
({
mediaQueries
: {
isSmall
:
'(max-width: 200px)'
,
reduceMotion
:
'(prefers-reduced-motion)'
,
}
})
.
add
(
self
=>
{
const
{ isSmall, reduceMotion } = self.
matches
;
if
(isSmall) {
utils.
set
(
'.square'
, {
scale
:
.5
});
}
animate
(
'.square'
, {
x
: isSmall ?
0
: [
'-35vw'
,
'35vw'
],
y
: isSmall ? [
'-40vh'
,
'40vh'
] :
0
,
loop
:
true
,
alternate
:
true
,
duration
: reduceMotion ?
0
: isSmall ?
750
:
1250
});
});
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
In this section
Add constructor function
Register method function
Parameters
Methods
Properties
Previous
Next
ScrollObserver
Add constructor function

=== DOC: 032_get.txt ===
URL: https://animejs.com/documentation/utilities/get
Utilities
Since 2.0.0
get()
Returns the current value of a target's property, with optional unit conversion or removal.
const
value = utils.
get
(target, property, unit);
Parameters
Name
Accepts
Description
target
Targets
The targeted element
property
String
A valid property name of the target
unit
(opt)
String
|
Boolean
Strip the unit if set to
false
or convert the unit if a valid unit
String
is passed
Returns
The returned property value type or the following types if the conditions are met:
Type
Condition
String
The target is an
HTMLElement
or
SVGElement
and the
unit
parameter is not set to
false
or set to a valid unit
String
Number
The target is an
HTMLElement
or
SVGElement
and the
unit
parameter set to
false
import
{ animate, utils }
from
'animejs'
;
const
[ $raw, $rem, $num ] = utils.$(
'.value'
);
const
[ $sq1, $sq2, $sq3 ] = utils.$(
'.square'
);
const
getValues
= (
) => {
// Return the raw parsed value (string with px)
$raw.
textContent
= utils.
get
($sq1,
'x'
);
// Return the converted value with unit (string with rem)
$rem.
textContent
= utils.
get
($sq2,
'x'
,
'rem'
);
// Return the raw value with its unit removed (number)
$num.
textContent
= utils.
get
($sq3,
'x'
,
false
);
}
animate
(
'.square'
, {
x
:
270
,
loop
:
true
,
alternate
:
true
,
onUpdate
: getValues
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
<
span
class
=
"raw value"
>
</
span
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
<
span
class
=
"rem value"
>
</
span
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
<
span
class
=
"num value"
>
</
span
>
</
div
>
</
div
>
Previous
Next
$()
set()

=== DOC: 033_remove.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/remove
Timeline

Methods
Since 4.0.0
remove()
V4
Removes animations, timers, timelines, targets or specific tween properties from the timeline.
The timeline will pauses automatically if all targets, animations, timers and timelines are removed.
Removing items from a timeline doesn't affect its duration. If you need to change the shape and duration of the timeline, you should create a new timeline instead.
Removing animations, timers or timelines
timeline.
remove
([animation, timer, timeline]);
Parameter
Accepts
object
Animation
|
Timer
|
Timeline
position
(opt)
Time position
Removing targets
timeline.
remove
(targets);
Parameter
Accepts
targets
Targets
Removing targets properties
timeline.
remove
(targets, propertyName);
Parameter
Accepts
targets
Targets
propertyName
A valid
Animatable properties
String
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $removeA, $removeB, $removeC ] = utils.$(
'.button'
);
const
animation =
animate
(
'.circle'
, {
x
:
'15rem'
,
scale
: [
1
,
.5
,
1
] });
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
})
.
sync
(animation)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
rotate
:
360
},
100
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
200
);
const
removeAnimation
= (
) => tl.
remove
(animation);
const
removeTarget
= (
) => tl.
remove
(
'.square'
);
const
removeRotate
= (
) => tl.
remove
(
'.triangle'
,
'rotate'
);
$removeA.
addEventListener
(
'click'
, removeAnimation);
$removeB.
addEventListener
(
'click'
, removeTarget);
$removeC.
addEventListener
(
'click'
, removeRotate);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Remove anim
</
button
>
<
button
class
=
"button"
>
Remove target
</
button
>
<
button
class
=
"button"
>
remove tween
</
button
>
</
fieldset
>
</
div
>
Previous
Next
label()
call()

=== DOC: 034_easing.txt ===
URL: https://animejs.com/documentation/web-animation-api/api-differences-with-native-waapi/easing
Web Animation API

API differences
Since 4.0.0
easing
The
easing
parameter is replaced by the
ease
parameter and accepts any easing
Function
.
The default easing is
'out(2)'
instead of
'linear'
.
On top of all the built-in WAAPI easing values, Anime.js offers a shorter syntax, and allow configuring the power of the
'out'
,
'in'
and
'inOut'
eases.
easing
ease
'ease-out'
'out'
|
'out(power)'
'ease-in'
'in'
|
'in(power)'
'ease-in-out'
'inOut'
|
'inOut(power)'
'cubic-bezier(x1, y1, x2, y2)'
'cubicBezier(x1, y1, x2, y2)'
Syntax comparison
Anime.js
waapi.
animate
(
'.square'
, {
x
:
100
,
ease
: eases.
outElastic
(
1.25
,
.1
)
});
WAAPI equivalent
const
targets =
document
.
querySelectorAll
(
'.square'
);
targets.
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
'100px'
,
}, {
fill
:
'forwards'
,
duration
:
1000
,
easing
:
'linear(0, 0.0874, 0.2047, 0.3429, 0.4929, 0.6464, 0.7961, 0.9357, 1.06, 1.1656, 1.25, 1.3122, 1.3521, 1.371, 1.3706, 1.3536, 1.3227, 1.2812, 1.2323, 1.1793, 1.125, 1.0721, 1.0227, 0.9788, 0.9415, 0.9116, 0.8896, 0.8755, 0.8688, 0.869, 0.875, 0.8859, 0.9006, 0.9179, 0.9366, 0.9558, 0.9745, 0.992, 1.0075, 1.0207, 1.0313, 1.039, 1.044, 1.0464, 1.0463, 1.0442, 1.0403, 1.0351, 1.029, 1.0224, 1.0156, 1.009, 1.0028, 0.9973, 0.9927, 0.989, 0.9862, 0.9844, 0.9836, 0.9844, 0.9857, 0.9876, 0.9897, 0.9921, 0.9945, 0.9968, 0.999, 1.0009, 1.0026, 1.0039, 1.0049, 1.0055, 1.0058, 1.0055, 1.005, 1.0044, 1.0036, 1.0028, 1.002, 1.0011, 1.0004, 0.9997, 0.9991, 0.9986, 0.9983, 0.9981, 0.998, 0.9982, 0.9984, 0.9987, 0.999, 0.9993, 0.9996, 0.9999, 1.0001, 1.0003, 1)'
})
});
Accepts
Any valid
easing
String
name or
Function
import
{ waapi, stagger }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
translate
:
'17rem'
,
ease
:
'inOut(6)'
,
delay
:
stagger
(
100
)
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
direction
finished

=== DOC: 035_scrollobserver-thresholds.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-thresholds
ScrollObserver
Since 4.0.0
ScrollObserver thresholds
Determines the points at which actions are triggered based on the scrolling position of a target element within a container.
Thresholds are defined with the
enter
and
leave
properties of the
onScroll
()
parameters
Object
.
animate
(
'.square'
, {
x
:
100
,
autoplay
:
onScroll
({
container
:
'.container'
,
target
:
'.section'
,
axis
:
'y'
,
┌──────────────────────────┐
│
enter
:
'bottom top'
,     ├─
Thresholds
│
leave
:
'top bottom'
,     │
└──────────────────────────┘
sync
:
true
,
onEnter
:
() =>
{},
onLeave
:
() =>
{},
onUpdate
:
() =>
{},
})
});
The conditions that determine when an element enters or leaves the viewport are specified by comparing two pairs of values: the target and container
start
and
end
values.
┌────────────────────────────────┐-
Container
Start
│                                │
│
Container
│
│                                │
│          ┌──────────┐----------│-
Target
Start
│          │          │          │
│          │
Target
│          │
└────────────────────────────────┘-
Container
End
│          │
└──────────┘------------
Target
End
Different syntaxes
Conditions can be written with the following syntaxes:
Object
onScroll
({
// Enters when the top of the target meets the bottom of the container
enter
: {
target
:
'top'
,
container
:
'bottom'
},
// Leaves when the bottom of the target meets the top of the container
leave
: {
target
:
'bottom'
,
container
:
'top'
}
});
Container value String
The container value can be passed directly and the target value defaults to
'start'
for enter and
'end'
for leave.
onScroll
({
// Enters when the top of the target meets the bottom of the container
enter
:
'bottom'
,
// Leaves when the bottom of the target meets the top of the container
leave
:
'top'
});
Container and target value shorthand String
onScroll
({
// Enters when the bottom of the container meets the top of the target
enter
:
'bottom top'
,
// Leaves when the top of the container meets the bottom of the target
leave
:
'top bottom'
,
});
Default enter
'end start'
Default leave
'start end'
In this section
Numeric values
Positions shorthands
Relative position values
Min max
Previous
Next
ScrollObserver settings
Numeric values

=== DOC: 036_morphto.txt ===
URL: https://animejs.com/documentation/svg/morphto
SVG
Since 4.0.0
morphTo()
Creates a morphing animation from one SVG shape to another by passing the
morphTo
()
function to the
d
property of a
SVGPathElement
or to the
points
property of a
SVGPolylineElement
or a
SVGPolygonElement
.
An optional
precision
parameter can be set to configure the amount of points generated to morph the two shapes.
If the precision parameter is set
0
, now points extrapolation is generated.
svg.
morphTo
(shapeTarget, precision);
Parameters
Name
Accepts
shapeTarget
CSS selector
|
SVGPathElement
|
SVGPolylineElement
|
SVGPolygonElement
precision=.33
(opt)
A
Number
between
0
and
1
Returns
An
Array
containing the shape's starting and final
String
values
import
{ animate, svg, utils }
from
'animejs'
;
const
[ $path1, $path2 ] = utils.$(
'polygon'
);
function
animateRandomPoints
(
) {
// Update the points attribute on #path-2
utils.
set
($path2, {
points
:
generatePoints
() });
// Morph the points of #path-1 into #path-2
animate
($path1, {
points
: svg.
morphTo
($path2),
ease
:
'inOutCirc'
,
duration
:
500
,
onComplete
: animateRandomPoints
});
}
// Start the animation
animateRandomPoints
();
// A function to generate random points on #path-2 on each iteration
// For demo purpose only
function
generatePoints
(
) {
const
total = utils.
random
(
4
,
64
);
const
r1 = utils.
random
(
4
,
56
);
const
r2 =
56
;
const
isOdd
= n => n %
2
;
let
points =
''
;
for
(
let
i =
0
, l =
isOdd
(total) ? total +
1
: total; i < l; i++) {
const
r =
isOdd
(i) ? r1 : r2;
const
a = (
2
*
Math
.
PI
* i / l) -
Math
.
PI
/
2
;
const
x =
152
+ utils.
round
(r *
Math
.
cos
(a),
0
);
const
y =
56
+ utils.
round
(r *
Math
.
sin
(a),
0
);
points +=
`
${x}
,
${y}
`
;
}
return
points;
}
<
svg
viewBox
=
"0 0 304 112"
>
<
g
stroke-width
=
"2"
stroke
=
"currentColor"
stroke-linejoin
=
"round"
fill
=
"none"
fill-rule
=
"evenodd"
>
<
polygon
id
=
"path-1"
points
=
"152,4 170,38 204,56 170,74 152,108 134,74 100,56 134,38"
>
</
polygon
>
<
polygon
style
=
"opacity: 0"
id
=
"path-2"
points
=
"152,4 170,38 204,56 170,74 152,108 134,74 100,56 134,38"
>
</
polygon
>
</
g
>
</
svg
>
Previous
Next
SVG
createDrawable()

=== DOC: 037_deg-to-rad.txt ===
URL: https://animejs.com/documentation/utilities/deg-to-rad
Utilities
Since 4.0.0
degToRad()
V4
Converts degrees into radians.
const
radians = utils.
degToRad
(degrees);
Parameters
Name
Accepts
degrees
(opt)
Number
Returns
A
Number
if degrees are provided, otherwise a
chain-able utility
Function
to convert degrees to radians:
const
degToRad = utils.
degToRad
();
degToRad
(
360
);
// 6.283185307179586
const
roundDegToRad = utils.
degToRad
().
round
(
2
);
// Convert degrees to radians then round to 2 decimal places
roundDegToRad
(
180
);
// 3.14
roundDegToRad
(
90
);
// 1.57
import
{ animate, createAnimatable, utils }
from
'animejs'
;
const
radAnimatable =
createAnimatable
(
'.rad'
, {
rotate
: {
unit
:
'rad'
,
duration
:
0
},
});
const
[ $deg ] = utils.$(
'.deg'
);
const
degAnimation =
animate
($deg, {
rotate
:
'360deg'
,
ease
:
'linear'
,
loop
:
true
,
onUpdate
:
() =>
{
const
degrees = utils.
get
($deg,
'rotate'
,
false
);
radAnimatable.
rotate
(utils.
degToRad
(degrees));
}
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock deg"
>
</
div
>
<
div
class
=
"label"
>
degrees
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock rad"
>
</
div
>
<
div
class
=
"label"
>
radians
</
div
>
</
div
>
</
div
>
Previous
Next
padEnd()
radToDeg()

=== DOC: 038_engine-defaults.txt ===
URL: https://animejs.com/documentation/engine/engine-defaults
Engine
Since 4.0.0
Engine defaults
Defines the global defaults properties used by all
Timer
,
Animation
and
Timeline
instances.
All default properties are available on the
defaults
Object
of
engine
.
import
{ engine }
from
'animejs'
;
engine.
engine
.
defaults
.
duration
=
500
;
Name
Accepts
playbackEase
Easing name
String
| Easing
Function
playbackRate
Number
frameRate
Number
loop
Number
|
Boolean
reversed
Boolean
alternate
Boolean
autoplay
Boolean
duration
Number
|
Function
delay
Number
|
Function
composition
Composition types
String
|
Function
ease
Easing name
String
| Easing
Function
loopDelay
Number
modifier
Modifier
Function
onBegin
Callback
Function
onUpdate
Callback
Function
onRender
Callback
Function
onLoop
Callback
Function
onComplete
Callback
Function
onPause
Callback
Function
Previous
Engine properties

=== DOC: 039_eased-scroll.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes/eased-scroll
ScrollObserver

Synchronisation modes
Since 4.0.0
Eased scroll
Applies an easing function to the synchronised playback progress of the linked object relative to the scroll position.
Accepts
ease
import
{ animate, stagger, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'12rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
delay
:
stagger
(
100
, {
from
:
'last'
}),
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
'inOutCirc'
,
debug
:
true
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Smooth scroll
ScrollObserver callbacks

=== DOC: 040_onupdate.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/onupdate
Timer

Callbacks
Since 4.0.0
onUpdate
Executes a function on every frames of a running timer at the specified
frameRate
.
Accepts
A
Function
whose first argument returns the timer itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onUpdate
=
self
=>
console
.
log
(self.
id
);
import
{ createTimer, utils }
from
'animejs'
;
const
[ $updates ] = utils.$(
'.updates'
);
const
[ $time ] = utils.$(
'.time'
);
let
updates =
0
;
createTimer
({
onUpdate
:
self
=>
{
$updates.
innerHTML
= ++updates;
$time.
innerHTML
= self.
currentTime
;
}
});
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"updates value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
onComplete
onLoop

=== DOC: 041_sync.txt ===
URL: https://animejs.com/documentation/utilities/sync
Utilities
Since 4.0.0
sync()
V4
Execute a callback function in sync with the engine loop.
utils.
sync
(
function
);
Parameters
Name
Accepts
callback
Function
Returns
Timer
import
{ animate, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $speed ] = utils.$(
'.speed'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loop
:
true
,
alternate
:
true
,
playbackRate
:
1
,
});
const
updateSpeed
= (
) => {
const
{ value } = $range;
$speed.
innerHTML
= utils.
roundPad
(+value,
2
);
utils.
sync
(
() =>
animation.
speed
= value);
}
$range.
addEventListener
(
'input'
, updateSpeed);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
speed
</
span
>
<
span
class
=
"speed value"
>
1.00
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
5
value
=
1
step
=
.01
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
shuffle()
lerp()

=== DOC: 042_tween-parameters.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters
Animation
Since 1.0.0
Tween parameters
Configure values, timings, and behaviors of animated properties.
Tween parameters can be specified
globally
for all properties directly with the other animation parameters, or
locally
for a specific property using an
Object
.
All animatable properties inherit the
global
parameters, which can be overridden
locally
for a specific tween.
animate
(
'.square'
, {
x
: {
┌───────────────────┐
│
to
:
100
,        │
│
delay
:
0
,       ├─
Local
Tween
Parameters
│
ease
:
'inOut(4)'
│
└───────────────────┘
},
scale
:
1
,
opacity
:
.5
,
┌───────────────────┐
│
duration
:
400
,    │
│
delay
:
250
,       ├─
Global
Tween
Parameters
│
ease
:
'out(3)'
,   │
└───────────────────┘
loop
:
3
,
alternate
:
true
,
});
In this section
to
from
delay
duration
ease
composition
modifier
Previous
Next
Tween value types
to

=== DOC: 043_add-timers.txt ===
URL: https://animejs.com/documentation/timeline/add-timers
Timeline
Since 4.0.0
Add timers
V4
Timers can be added to a timeline using the
add
()
method or the
sync
()
method.
Timer creation
Creates and adds a timer directly to the timeline using the
add
()
method.
timeline.
add
(parameters, position);
Parameters
Name
Accepts
parameters
An
Object
of
Timer playback settings
and
Timer callbacks
position
(opt)
Time position
Timer synchronisation
Synchronises an existing timer with the
sync
()
method.
timeline.
sync
(timer, position);
Parameters
Name
Accepts
timer
Timer
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, createTimer, utils }
from
'animejs'
;
const
[ $timer01, $timer02, $timer03 ] = utils.$(
'.timer'
);
const
timer1 =
createTimer
({
duration
:
1500
,
onUpdate
:
self
=>
$timer01.
innerHTML
= self.
currentTime
,
});
const
tl =
createTimeline
()
.
sync
(timer1)
.
add
({
duration
:
500
,
onUpdate
:
self
=>
$timer02.
innerHTML
= self.
currentTime
,
})
.
add
({
onUpdate
:
self
=>
$timer03.
innerHTML
= self.
currentTime
,
duration
:
1000
});
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
timer 01
</
span
>
<
span
class
=
"timer value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
timer 02
</
span
>
<
span
class
=
"timer value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
timer 03
</
span
>
<
span
class
=
"timer value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
Timeline
Add animations

=== DOC: 044_direction.txt ===
URL: https://animejs.com/documentation/web-animation-api/api-differences-with-native-waapi/direction
Web Animation API

API differences
Since 4.0.0
direction
The
direction
parameter is replaced by two separate parameters:
reversed
and
alternate
.
direction
reversed
alternate
Effect
'forward'
false
false
Play forward
'reverse'
true
false
Play backward
'alternate'
false
true
Alternate on loop
'alternate-reverse'
true
true
Start in reverse and alternate on loop
Syntax comparison
Anime.js
waapi.
animate
(
'.square'
, {
x
:
100
,
reversed
:
true
,
alternate
:
true
,
loop
:
3
});
WAAPI equivalent
const
targets =
document
.
querySelectorAll
(
'.square'
);
targets.
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
'100px'
,
}, {
fill
:
'forwards'
,
duration
:
1000
,
direction
:
'alternate-reverse'
,
iterations
:
4
})
});
Accepts
Boolean
import
{ waapi, stagger }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
translate
:
'17rem'
,
reversed
:
true
,
delay
:
stagger
(
100
)
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
iterations
easing

=== DOC: 045_dragspeed.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/dragspeed
Draggable

Settings
Since 4.0.0
dragSpeed
Specifies a value that affects the dragging speed of the element. The higher the value, the faster the element moves.
0
prevents the element from being dragged, and values less than
0
invert the drag movement.
Accepts
A
Number
A
Function
that returns a
Number
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
1
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
dragSpeed
:
2
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
dragSpeed
:
.5
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
releaseEase
scrollThreshold

=== DOC: 046_javascript-objects.txt ===
URL: https://animejs.com/documentation/animation/targets/javascript-objects
Animation

Targets
Since 1.0.0
JavaScript Objects
JS
Targets one or multiple JavaScript
Object
.
Accepts
Object
Instance of
Class
import
{ animate, utils }
from
'animejs'
;
const
[ $log ] = utils.$(
'code'
);
const
vector2D = {
x
:
0
,
y
:
0
};
animate
(vector2D, {
x
:
100
,
y
:
150
,
modifier
: utils.
round
(
0
),
onUpdate
:
() =>
$log.
textContent
=
JSON
.
stringify
(vector2D),
});
<
pre
class
=
"row large centered"
>
<
code
>
{"x":0,"y":0}
</
code
>
</
pre
>
Previous
Next
DOM Elements
Array of targets

=== DOC: 047_time-staggering.txt ===
URL: https://animejs.com/documentation/stagger/time-staggering
Stagger
Since 2.0.0
Time staggering
Tween's time related properties like
delay
and
duration
accepts Function-based values, enabling the use of the stagger function returned by the
stagger
()
method in multi-target animations.
This results in each target tween having different timings, increasing by a set number of milliseconds for each subsequent target.
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'17rem'
,
delay
:
stagger
(
100
),
duration
:
stagger
(
200
, {
start
:
500
}),
loop
:
true
,
alternate
:
true
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
delay: 0ms;
&nbsp;
&nbsp;
&nbsp;
duration: 500ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
delay: 100ms; duration: 700ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
delay: 200ms; duration: 900ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
delay: 300ms; duration: 1100ms
</
div
>
</
div
>
Previous
Next
Stagger
Values staggering

=== DOC: 048_onafterresize.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onafterresize
Draggable

Callbacks
Since 4.0.0
onAfterResize
Executes a function after either the container or the dragged target sizes change and the draggable values have been updated.
This can be used to update the position of the dragged element if the container size has changed.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
resizes =
0
;
const
draggable =
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onAfterResize
:
self
=>
{
$value.
textContent
= ++resizes;
self.
animateInView
(
1000
,
30
);
}
});
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
resizes
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onResize
Draggable methods

=== DOC: 049_engine.txt ===
URL: https://animejs.com/documentation/engine
Engine
V4
Drives and synchronises all
Animation
,
Timer
, and
Timeline
instances.
import
{ engine }
from
'animejs'
;
In this section
Parameters
Methods
Properties
Engine defaults
Previous
Next
Web Animation API
Engine parameters

=== DOC: 050_color-value.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/color-value
Animation

Tween value types
Since 1.0.0
Color value
Color values in the following formats can be parsed and used as values for animatable color properties.
Accepts
Format
Syntax
HEX
'#F44'
|
'#FF4444'
HEXA
'#F443'
|
'#FF444433'
RGB
'rgb(255, 168, 40)'
RGBA
'rgba(255, 168, 40, .2)'
HSL
'hsl(255, 168, 40)'
HSLA
'hsla(255, 168, 40, .2)'
String name
WAAPI
'red'
|
'aqua'
import
{ animate }
from
'animejs'
;
animate
(
'.hex'
,  {
background
:
'#FF4B4B'
,
});
animate
(
'.rgb'
,  {
background
:
'rgb(255, 168, 40)'
,
});
animate
(
'.hsl'
,  {
background
:
'hsl(44, 100%, 59%)'
,
});
animate
(
'.hexa'
, {
background
:
'#FF4B4B33'
,
});
animate
(
'.rgba'
, {
background
:
'rgba(255, 168, 40, .2)'
,
});
animate
(
'.hsla'
, {
background
:
'hsla(44, 100%, 59%, .2)'
,
});
<
div
class
=
"large justified row"
>
<
div
class
=
"circle hex"
>
</
div
>
<
div
class
=
"circle rgb"
>
</
div
>
<
div
class
=
"circle hsl"
>
</
div
>
<
div
class
=
"circle hexa"
>
</
div
>
<
div
class
=
"circle rgba"
>
</
div
>
<
div
class
=
"circle hsla"
>
</
div
>
</
div
>
Previous
Next
Relative value
Color function value

=== DOC: 051_defaults.txt ===
URL: https://animejs.com/documentation/scope/scope-parameters/defaults
Scope

Parameters
Since 4.0.0
defaults
Defines the Scope defaults properties which are then used for all
Timer
,
Animation
and
Timeline
created within that scope.
Accepts
An
Object
with the following optional properties:
Name
Accepts
playbackEase
Easing name
String
| Easing
Function
playbackRate
Number
frameRate
Number
loop
Number
|
Boolean
reversed
Boolean
alternate
Boolean
autoplay
Boolean
duration
Number
|
Function
delay
Number
|
Function
composition
Composition types
String
|
Function
ease
Easing name
String
| Easing
Function
loopDelay
Number
modifier
Modifier
Function
onBegin
Callback
Function
onUpdate
Callback
Function
onRender
Callback
Function
onLoop
Callback
Function
onComplete
Callback
Function
import
{ createScope, animate }
from
'animejs'
;
const
rows = utils.$(
'.row'
);
rows.
forEach
(
(
$row, i
) =>
{
createScope
({
root
: $row,
defaults
: {
ease
:
`out(
${
1
+ i}
)`
}
})
.
add
(
() =>
{
animate
(
'.square'
, {
x
:
'17rem'
,
loop
:
true
,
alternate
:
true
});
});
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
scope 1
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
scope 2
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
scope 3
</
div
>
</
div
>
Previous
Next
root
mediaQueries

=== DOC: 052_default-units.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/default-units
Web Animation API

Improvements to WAAPI
Since 4.0.0
Default units
If no unit is specified for properties that expect a unit, like
width
for example, the resulting animation will use the default browser unit for a set of commonly used properties:
Syntax comparison
Anime.js
waapi.
animate
(
'.circle'
, {
x
:
100
,
y
:
50
,
width
:
150
,
height
:
80
,
});
WAAPI equivalent
const
$el =
document
.
querySelector
(
'.circle'
);
$el.
animate
({
translate
:
'100px 50px'
,
width
:
'150px'
,
height
:
'80px'
,
}, {
duration
:
1000
,
easing
:
'ease-out'
,
}).
finished
.
then
(
() =>
{
$el.
style
.
translate
=
'100px'
;
});
Properties that automatically adds default units
Name
Default Unit
x
'px'
y
'px'
z
'px'
translateX
'px'
translateY
'px'
translateZ
'px'
rotate
'deg'
rotateX
'deg'
rotateY
'deg'
rotateZ
'deg'
skew
'deg'
skewX
'deg'
skewY
'deg'
perspective
'px'
width
'px'
height
'px'
margin
'px'
padding
'px'
top
'px'
right
'px'
bottom
'px'
left
'px'
borderWidth
'px'
fontSize
'px'
borderRadius
'px'
import
{ waapi }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
opacity
:
.5
,
x
:
250
,
rotate
:
45
,
width
:
40
,
height
:
40
,
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Multi-targets animation
Function based values

=== DOC: 053_timeunit-seconds-milliseconds.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters/timeunit-seconds-milliseconds
Engine

Parameters
Since 4.0.0
timeUnit (seconds / milliseconds)
Configures the unit of time to use for time-related values like
duration
and
delay
.
The currently defined default duration is automatically adjusted to the newly specified time unit.
engine.
timeUnit
=
's'
;
// Change the time unit globally to seconds
console
.
log
(engine.
engine
.
defaults
.
duration
);
// -> Returns 1
Accepts
's'
to use seconds
'ms'
to use milliseconds
Default
'ms'
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $timeS ] = utils.$(
'.time-s'
);
const
[ $timeMs ] = utils.$(
'.time-ms'
);
const
[ $ms, $s ] = utils.$(
'.toggle'
);
const
secondsTimer =
createTimer
({
duration
:
1
,
loop
:
true
,
onUpdate
:
self
=>
$timeS.
innerHTML
= utils.
roundPad
(self.
iterationCurrentTime
,
2
)
});
const
millisecondsTimer =
createTimer
({
duration
:
1000
,
loop
:
true
,
onUpdate
:
self
=>
$timeMs.
innerHTML
= utils.
roundPad
(self.
iterationCurrentTime
,
2
)
});
const
toggleSetting
= (
) => {
const
isUsingSeconds = engine.
timeUnit
===
's'
;
engine.
timeUnit
= isUsingSeconds ?
'ms'
:
's'
;
$ms.
disabled
= isUsingSeconds;
$s.
disabled
= !isUsingSeconds;
}
$ms.
addEventListener
(
'click'
, toggleSetting);
$s.
addEventListener
(
'click'
, toggleSetting);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
duration: 1
</
span
>
<
span
class
=
"time-s value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
duration: 1000
</
span
>
<
span
class
=
"time-ms value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button toggle"
disabled
>
milliseconds
</
button
>
<
button
class
=
"button toggle"
>
seconds
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Engine parameters
speed

=== DOC: 054_stagger-modifier.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-modifier
Stagger

Parameters
Since 2.0.0
Stagger modifier
Defines a function that modify the returned staggered value.
Accepts
A
Function
with the following parameters:
Parameters
Names
Description
value
The current animated numerical value
Must returns
Number
|
String
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
boxShadow
: [
{
to
:
stagger
([
1
,
.25
], {
modifier
:
v
=>
`0 0
${v *
30
}
px
${v *
20
}
px currentColor`
,
from
:
'center'
})
},
{
to
:
0
},
],
delay
:
stagger
(
100
, {
from
:
'center'
}),
loop
:
true
});
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Stagger grid axis

=== DOC: 055_refresh.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/refresh
Draggable

Methods
Since 4.0.0
refresh()
Re-compute every parameter defined using a function and re-calculate all internal values.
Refreshable parameters
snap
container
containerPadding
containerFriction
dragSpeed
scrollSpeed
scrollThreshold
minVelocity
maxVelocity
velocityMultiplier
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $refreshButton ] = utils.$(
'.refresh'
);
const
draggable =
createDraggable
(
'.square'
, {
snap
:
() =>
utils.
random
(
0
,
32
,
0
),
dragSpeed
:
() =>
utils.
random
(
.5
,
1.5
,
1
),
});
const
refreshDraggable
= (
) => draggable.
refresh
();
$refreshButton.
addEventListener
(
'click'
, refreshDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button refresh"
>
Refresh
</
button
>
</
fieldset
>
</
div
>
Previous
Next
revert()
Draggable properties

=== DOC: 056_snap.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters/snap
Draggable

Axes parameters
Since 4.0.0
snap
Rounds the final value of either both axes or one specific axis to the nearest specified increment.
If an
Array
is provided as the increment, it selects the closest value from the array.
Accepts
Number
Array
<
Number
>
A
Function
that returns any if the above
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
0
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
snap
:
56
,
// Global to both x and y
x
: {
snap
: [
0
,
200
] },
// Specific to x
});
<
div
class
=
"large grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
y
modifier

=== DOC: 057_onupdate.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onupdate
ScrollObserver

Callbacks
Since 4.0.0
onUpdate
Triggers a function every time the linked object progress updates during scroll synchronisation.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
updates =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
.5
,
debug
:
true
,
onUpdate
:
() =>
$value.
textContent
= ++updates,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onLeaveBackward
onSyncComplete

=== DOC: 058_releasemass.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/releasemass
Draggable

Settings
Since 4.0.0
releaseMass
Specifies the mass applied to the dragged element after release. Affects the speed, movement distance and bounciness of the dragged element. Lower values result in faster movement.
releaseMass
has no effect if a spring is passed to the
releaseEase
parameter and is overridden by the spring
mass
value.
Accepts
A
Number
between
0
and
1000
Default
1
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
releaseMass
:
.1
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
releaseMass
:
10
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
releaseContainerFriction
releaseStiffness

=== DOC: 059_link.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-methods/link
ScrollObserver

Methods
Since 4.0.0
link()
Connects an
Animation
,
Timer
or
Timeline
to a
ScrollObserver
instance.
This is equivalent to defining an
onScroll
()
instance on the
autoplay
parameter.
Only one object can be linked at a time, every call to
link
()
overrides the previously linked object.
Accepts
Animation
|
Timer
|
Timeline
Returns
The ScrollObserver itself
import
{ animate, onScroll }
from
'animejs'
;
const
animation =
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
});
const
scrollObserver =
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
});
scrollObserver.
link
(animation);
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
ScrollObserver methods
refresh()

=== DOC: 060_animatable-settings.txt ===
URL: https://animejs.com/documentation/animatable/animatable-settings
Animatable
Since 4.0.0
Animatable settings
Animatables properties settings are specified globally to all properties on the parameters object, or specifically to a property by passing an object.
createAnimatable
(targets, {
x
: {
┌──────────────────┐
│
unit
:
'rem'
,   │
│
duration
:
400
, ├─
Specific
Property
Settings
│
ease
:
'out(4)'
│
└──────────────────┘
},
y
:
200
,
rotate
:
1000
,
┌──────────────────┐
│
ease
:
'out(2)'
,  ├─
Global
Properties
Settings
└──────────────────┘
});
In this section
unit
duration
ease
modifier
Previous
Next
Animatable
unit

=== DOC: 061_stagger-reversed.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-reversed
Stagger

Parameters
Since 2.0.0
Stagger reversed
Defines if the stagger should operate in reverse.
Accepts
Boolean
Default
false
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
translateX
:
'17rem'
,
delay
:
stagger
(
100
, {
reversed
:
true
}),
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"label padded"
>
delay: 300ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"label padded"
>
delay: 200ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"label padded"
>
delay: 100ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"label padded"
>
delay: 0ms
</
div
>
</
div
>
Previous
Next
Stagger from
Stagger ease

=== DOC: 062_rad-to-deg.txt ===
URL: https://animejs.com/documentation/utilities/rad-to-deg
Utilities
Since 4.0.0
radToDeg()
V4
Converts radians into degrees.
const
degrees = utils.
radToDeg
(radians);
Parameters
Name
Accepts
radians
(opt)
Number
Returns
A
Number
if radians are provided, otherwise a
chain-able utility
Function
to convert radians to degrees:
const
radToDeg = utils.
radToDeg
();
radToDeg
(
1.7453292519943295
);
// 100
radToDeg
(
Math
.
PI
);
// 180
const
roundRadToDeg = utils.
radToDeg
().
round
(
2
);
// Convert radians to degrees then round to 2 decimal places
roundRadToDeg
(
Math
.
PI
/
7
);
// 25.71
import
{ animate, createAnimatable, utils }
from
'animejs'
;
const
degAnimatable =
createAnimatable
(
'.deg'
, {
rotate
: {
unit
:
'deg'
,
duration
:
0
}
});
const
[ $rad ] = utils.$(
'.rad'
);
const
degAnimation =
animate
($rad, {
rotate
: (
Math
.
PI
*
2
) +
'rad'
,
ease
:
'linear'
,
loop
:
true
,
onUpdate
:
() =>
{
const
radians = utils.
get
($rad,
'rotate'
,
false
);
degAnimatable.
rotate
(utils.
radToDeg
(radians));
}
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock rad"
>
</
div
>
<
div
class
=
"label"
>
radians
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock deg"
>
</
div
>
<
div
class
=
"label"
>
degrees
</
div
>
</
div
>
</
div
>
Previous
Next
degToRad()
Chain-able utility functions

=== DOC: 063_then.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/then
Animation

Callbacks
Since 4.0.0
then()
V4
Returns a
Promise
that resolves and execute a callback when the animation completes.
The
then
()
method can be directly inlined like this:
animate
(target, {
x
:
100
,
duration
:
500
}).
then
(callback);
Or used in an
async
/
await
context:
async
function
waitForAnimationToComplete
(
) {
return
animate
(target, {
x
:
100
,
duration
:
500
,
});
}
const
asyncAnimation =
await
waitForAnimationToComplete
();
Parameters
Name
Type
callback
A
Function
whose first argument returns the animation itself
Returns
Promise
import
{ animate }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
delay
:
500
,
});
animation.
then
(
() =>
$value.
textContent
=
'fulfilled'
);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
promise status
</
span
>
<
span
class
=
"value"
>
pending
</
span
>
</
pre
>
</
div
>
Previous
Next
onPause
Animation methods

=== DOC: 064_container.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/container
Draggable

Settings
Since 4.0.0
container
Specifies the container of the draggable element, preventing it from being dragged outside of the defined boundaries.
Accepts
CSS Selector
String
to target an
HTMLElement
HTMLElement
Array
<
Number
>
(
[top, right, bottom, left]
)
A
Function
that returns
Array
<
Number
>
(
[top, right, bottom, left]
)
When defined using a
Function
, the value will be automatically refreshed every time the window or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
null
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
});
createDraggable
(
'.circle'
, {
container
: [-
16
,
80
,
16
,
0
],
});
<
div
class
=
"large centered grid square-grid array-container"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
trigger
containerPadding

=== DOC: 065_installation.txt ===
URL: https://animejs.com/documentation/getting-started/installation
Getting started
Installation
Anime.js can be installed in multiple ways depending of your environment or workflow.
This section covers differents methods of installation.
Installation via NPM and a bundler
If you're using a bundler like
Vite
or
esbuild
, simply install the package via
NPM
.
npm install animejs
Then import
Anime.js
methods as
ES6 Modules
like this:
import
{ animate }
from
'animejs'
;
Linking from a CDN
CDN Name
URL
JsDelivr
jsdelivr.com
ES6 Modules
<
script
type
=
"module"
>
import
{ animate }
from
'https://cdn.jsdelivr.net/npm/animejs/+esm'
;
</
script
>
Global object
<
script
src
=
"https://cdn.jsdelivr.net/npm/animejs/lib/anime.iife.min.js"
>
</
script
>
<
script
>
const
{ animate } = anime;
</
script
>
Direct download from GitHub
If you prefer to download the Anime.js library manually, you can also simply grab the code from the official
GitHub repository
.
The following versions are available in the
/lib
directory:
File name
Type
anime.
esm
.
js
ES6 Module
anime.
umd
.
js
Universal Module
anime.
iife
.
js
Global Object
Once downloaded inside your project folder, link the library in your code like this:
ES6 Modules
<
script
type
=
"module"
>
import
{ animate }
from
'./path/to/anime.esm.min.js'
;
</
script
>
Global object
<
script
src
=
"path/to/anime.iife.min.js"
>
</
script
>
<
script
>
const
{ animate } = anime;
</
script
>
Previous
Next
Getting started
Imports

=== DOC: 066_stagger-value-types.txt ===
URL: https://animejs.com/documentation/stagger/stagger-value-types
Stagger
Since 2.0.0
Stagger value types
stagger
(
┌───────────────────┐
│
'1rem'
,           ├─
Stagger
Value
└───────────────────┘
{
start
:
100
,
from
:
2
,
reversed
:
false
,
ease
:
'outQuad'
,
grid
: [
8
,
8
],
}
);
In this section
Numerical
Range
Previous
Next
Timeline positions staggering
Numerical value

=== DOC: 067_autoplay.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/autoplay
Timer

Playback settings
Since 4.0.0
autoplay
Defines the play mode of a timer.
The autoplay parameter has no effect when the timer is added to a timeline, and will be overridden to
false
.
Accepts
Boolean
|
onScroll
()
If set to
true
the timer plays automatically
If set to
false
the timer has to be manually played
If set to
onScroll
()
the timer will starts when the
scroll thresholds
conditions are met
Default
true
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
autoplay
=
false
;
const
[ $time ] = utils.$(
'.time'
);
const
[ $playButton ] = utils.$(
'.play'
);
const
timer =
createTimer
({
autoplay
:
false
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
playTimer
= (
) => timer.
play
();
$playButton.
addEventListener
(
'click'
, playTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
reversed
frameRate

=== DOC: 068_autoplay.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/autoplay
Animation

Playback settings
Since 1.0.0
autoplay
Defines the play mode of an animation.
The autoplay parameter has no effect when the animation is added to a timeline, and will be overridden to
false
.
Accepts
Boolean
|
onScroll
()
If set to
true
the animation plays automatically
If set to
false
the animation has to be manually played
If set to
onScroll
()
the animation will starts when the
scroll thresholds
conditions are met
Default
true
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
autoplay
=
false
;
animate
(
'.autoplay-true'
, {
x
:
'17rem'
,
autoplay
:
true
,
// Default
});
animate
(
'.autoplay-false'
, {
x
:
'17rem'
,
autoplay
:
false
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle autoplay-true"
>
</
div
>
<
div
class
=
"padded label"
>
autoplay: true
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle autoplay-false"
>
</
div
>
<
div
class
=
"padded label"
>
autoplay: false
</
div
>
</
div
>
Previous
Next
reversed
frameRate

=== DOC: 069_precision.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters/precision
Engine

Parameters
Since 4.0.0
precision
Defines how many decimal places to round string values to during an animation.
The more decimals you add, the more precise the animations will be. Setting
0
will essentially remove all decimals during an animation.
Only string values of CSS properties, SVG and DOM Attributes are rounded (e.g.,
'120.725px'
,
'1.523'
) and the rounding is only applied during the animation, the first and last frames of the animation use the full value.
In 99% of cases, you won't need to increase the precision beyond 4, as the visual difference won't be noticeable.
Lowering the precision can help in cases where you are animating many elements simultaneously, but can drastically reduce the visual quality and smoothness of your animations.
engine.
precision
=
1
;
// values will be rounded to 1 decimal place ('120.7px')
Accepts
A
Number
greater than or equal to
0
to define the number of decimal places
A
Number
lower than
0
to skip the rounding process
Default
4
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $container ] = utils.$(
'.container'
);
const
[ $range ] = utils.$(
'.range'
);
for
(
let
i =
0
; i <
150
; i++) {
const
$particle =
document
.
createElement
(
'div'
);
$particle.
classList
.
add
(
'particle'
);
$container.
appendChild
($particle);
animate
($particle, {
x
: utils.
random
(-
10
,
10
,
2
) +
'rem'
,
y
: utils.
random
(-
3
,
3
,
2
) +
'rem'
,
scale
: [{
from
:
0
,
to
:
1
}, {
to
:
0
}],
delay
: utils.
random
(
0
,
1000
),
loop
:
true
,
});
}
function
onInput
(
) {
engine.
precision
=
this
.
value
;
}
$range.
addEventListener
(
'input'
, onInput);
<
div
class
=
"large row container"
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
5
value
=
4
step
=
1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
fps
pauseOnDocumentHidden

=== DOC: 070_oncomplete.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/oncomplete
Animation

Callbacks
Since 4.0.0
onComplete
Executes a function when all the iterations (
loops
) of an animation have finished playing.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onComplete
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
delay
:
500
,
loop
:
2
,
alternate
:
true
,
onComplete
:
self
=>
$value.
textContent
= self.
completed
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
completed
</
span
>
<
span
class
=
"value"
>
false
</
span
>
</
pre
>
</
div
>
Previous
Next
onBegin
onBeforeUpdate

=== DOC: 071_repeat.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings/repeat
ScrollObserver

Settings
Since 4.0.0
repeat
Specifies if the scroll synchronisation should repeat after the linked object completes.
If the repeat property is set to
false
, the scrollContainer instance will be reverted.
Accepts
Boolean
Defaults
true
import
{ createTimer, onScroll, utils }
from
'animejs'
;
const
[ $repeat ] = utils.$(
'.repeat .value'
);
const
[ $noRepeat ] = utils.$(
'.no-repeat .value'
);
let
repeatUpdates =
0
;
let
noRepeatUpdates =
0
;
createTimer
({
duration
:
1000
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
target
:
'.repeat'
,
enter
:
'bottom-=40 top'
,
leave
:
'top+=60 bottom'
,
onUpdate
:
() =>
$repeat.
innerHTML
= repeatUpdates++,
repeat
:
true
,
debug
:
true
,
})
});
createTimer
({
duration
:
1000
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
target
:
'.no-repeat'
,
enter
:
'bottom-=40 top'
,
leave
:
'top+=60 bottom'
,
onUpdate
:
() =>
$noRepeat.
innerHTML
= noRepeatUpdates++,
repeat
:
false
,
debug
:
true
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
pre
class
=
"repeat large log row"
>
<
span
class
=
"label"
>
repeat upddates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
pre
class
=
"no-repeat large log row"
>
<
span
class
=
"label"
>
no repeat updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll up
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
axis
ScrollObserver thresholds

=== DOC: 072_using-with-react.txt ===
URL: https://animejs.com/documentation/getting-started/using-with-react
Getting started
Since 4.0.0
Using with React
Anime.js can be used with React by combining React's
useEffect
()
and Anime.js
createScope
()
methods.
The following example showcase how to uses Anime.js methods straight into React code.
import
{ animate, createScope, createSpring, createDraggable }
from
'animejs'
;
import
{ useEffect, useRef, useState }
from
'react'
;
import
reactLogo
from
'./assets/react.svg'
;
import
'./App.css'
;
function
App
(
) {
const
root =
useRef
(
null
);
const
scope =
useRef
(
null
);
const
[ rotations, setRotations ] =
useState
(
0
);
useEffect
(
() =>
{
scope.
current
=
createScope
({ root }).
add
(
self
=>
{
// Every anime.js instances declared here are now scopped to <div ref={root}>
// Created a bounce animation loop
animate
(
'.logo'
, {
scale
: [
{
to
:
1.25
,
ease
:
'inOut(3)'
,
duration
:
200
},
{
to
:
1
,
ease
:
createSpring
({
stiffness
:
300
}) }
],
loop
:
true
,
loopDelay
:
250
,
});
// Make the logo draggable around its center
createDraggable
(
'.logo'
, {
container
: [
0
,
0
,
0
,
0
],
releaseEase
:
createSpring
({
stiffness
:
200
})
});
// Register function methods to be used outside the useEffect
self.
add
(
'rotateLogo'
,
(
i
) =>
{
animate
(
'.logo'
, {
rotate
: i *
360
,
ease
:
'out(4)'
,
duration
:
1500
,
});
});
});
// Properly cleanup all anime.js instances declared inside the scope
return
() =>
scope.
current
.
revert
()
}, []);
const
handleClick
= (
) => {
setRotations
(
prev
=>
{
const
newRotations = prev +
1
;
// Animate logo rotation on click using the method declared inside the scope
scope.
current
.
methods
.
rotateLogo
(newRotations);
return
newRotations;
});
};
return
(
<
div
ref
=
{root}
>
<
div
className
=
"large centered row"
>
<
img
src
=
{reactLogo}
className
=
"logo react"
alt
=
"React logo"
/>
</
div
>
<
div
className
=
"medium row"
>
<
fieldset
className
=
"controls"
>
<
button
onClick
=
{handleClick}
>
rotations: {rotations}
</
button
>
</
fieldset
>
</
div
>
</
div
>
)
}
export
default
App
;
Previous
Next
Using with vanilla JS
Timer

=== DOC: 073_framerate.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/framerate
Animation

Playback settings
Since 4.0.0
frameRate
V4
JS
Determines the number of frames per second (fps) an animation is played at.
This value can be modified later with
animation.
fps
=
30
.
Accepts
A
Number
greater than
0
The frame rate is capped to the monitor refresh rate or in some cases by the browser itself.
Default
120
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
frameRate
=
30
;
import
{ animate }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $fps ] = utils.$(
'.fps'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loop
:
true
,
alternate
:
true
,
frameRate
:
60
,
});
const
updateFps
= (
) => {
const
{ value } = $range;
$fps.
innerHTML
= value;
animation.
fps
= value;
}
$range.
addEventListener
(
'input'
, updateFps);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
fps
</
span
>
<
span
class
=
"fps value"
>
60
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
120
value
=
60
step
=
1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
autoplay
playbackRate

=== DOC: 074_createdrawable.txt ===
URL: https://animejs.com/documentation/svg/createdrawable
SVG
Since 4.0.0
createDrawable()
Creates a
Proxy
of an
SVGElement
exposing an extra
draw
property that defines how much of the line is visible / drawn.
const
[ drawable ] = svg.
createDrawable
(target);
Parameters
Name
Accepts
target
CSS selector
|
SVGLineElement
|
SVGPathElement
|
SVGPolylineElement
|
SVGPolylineElement
|
SVGRectElement
Returns
An
Array
of
Proxy
SVGElement
The added
draw
property accepts a
String
containing a
start
and
end
values separated by an empty space to define how much of the line is drawn.
const
[ drawable ] = svg.
createDrawable
(target);
0
1
drawable.
draw
=
'0 1'
;      |[———————————————————]|
0
.5
drawable.
draw
=
'0 .5'
;     |[—————————]          |
.25
.75
drawable.
draw
=
'.25 .75'
;  |     [—————————]     |
.5
1
drawable.
draw
=
'.5 1'
;     |          [—————————]|
1
1
drawable.
draw
=
'1 1'
;      |                   []|
Animating an element with the
vector-effect
attribute/styles set to
non-scaling-stroke
can be slow since the scale factor value for the path must be recalculated on every tick in order to handle changes in the size of the SVG.
import
{ animate, svg, stagger }
from
'animejs'
;
animate
(svg.
createDrawable
(
'.line'
), {
draw
: [
'0 0'
,
'0 1'
,
'1 1'
],
ease
:
'inOutQuad'
,
duration
:
2000
,
delay
:
stagger
(
100
),
loop
:
true
});
<
svg
viewBox
=
"0 0 304 112"
>
<
g
stroke
=
"currentColor"
fill
=
"none"
fill-rule
=
"evenodd"
stroke-linecap
=
"round"
stroke-linejoin
=
"round"
stroke-width
=
"2"
>
<
path
class
=
"line"
d
=
"M59 90V56.136C58.66 46.48 51.225 39 42 39c-9.389 0-17 7.611-17 17s7.611 17 17 17h8.5v17H42C23.222 90 8 74.778 8 56s15.222-34 34-34c18.61 0 33.433 14.994 34 33.875V90H59z"
/>
<
polyline
class
=
"line"
points
=
"59 22.035 59 90 76 90 76 22 59 22"
/>
<
path
class
=
"line"
d
=
"M59 90V55.74C59.567 36.993 74.39 22 93 22c18.778 0 34 15.222 34 34v34h-17V56c0-9.389-7.611-17-17-17-9.225 0-16.66 7.48-17 17.136V90H59z"
/>
<
polyline
class
=
"line"
points
=
"127 22.055 127 90 144 90 144 22 127 22"
/>
<
path
class
=
"line"
d
=
"M127 90V55.74C127.567 36.993 142.39 22 161 22c18.778 0 34 15.222 34 34v34h-17V56c0-9.389-7.611-17-17-17-9.225 0-16.66 7.48-17 17.136V90h-17z"
/>
<
path
class
=
"line"
d
=
"M118.5 22a8.5 8.5 0 1 1-8.477 9.067v-1.134c.283-4.42 3.966-7.933 8.477-7.933z"
/>
<
path
class
=
"line"
d
=
"M144 73c-9.389 0-17-7.611-17-17v-8.5h-17V56c0 18.778 15.222 34 34 34V73z"
/>
<
path
class
=
"line"
d
=
"M178 90V55.74C178.567 36.993 193.39 22 212 22c18.778 0 34 15.222 34 34v34h-17V56c0-9.389-7.611-17-17-17-9.225 0-16.66 7.48-17 17.136V90h-17z"
/>
<
path
class
=
"line"
d
=
"M263 73c-9.389 0-17-7.611-17-17s7.611-17 17-17c9.18 0 16.58 7.4 17 17h-17v17h34V55.875C296.433 36.994 281.61 22 263 22c-18.778 0-34 15.222-34 34s15.222 34 34 34V73z"
/>
<
path
class
=
"line"
d
=
"M288.477 73A8.5 8.5 0 1 1 280 82.067v-1.134c.295-4.42 3.967-7.933 8.477-7.933z"
/>
</
g
>
</
svg
>
Previous
Next
morphTo()
createMotionPath()

=== DOC: 075_function-based-values.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/function-based-values
Web Animation API

Improvements to WAAPI
Since 4.0.0
Function based values
Adds
Function based value
support to WAAPI animations, allowing passing different values pert targets.
Syntax comparison
Anime.js
waapi.
animate
(
'.square'
, {
translate
:
() =>
`
${utils.random(
10
,
17
)}
rem`
,
rotate
:
() =>
utils.
random
(-
180
,
180
),
scale
:
(
_, i
) =>
.25
+ (i *
.25
),
delay
:
stagger
(
100
)
});
WAAPI equivalent
document
.
querySelectorAll
(
'.square'
).
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
`
${utils.random(
10
,
17
)}
rem`
,
rotate
: utils.
random
(-
180
,
180
),
scale
:
.25
+ (i *
.25
),
}, {
duration
:
1000
,
delay
: i *
100
,
easing
:
'ease-out'
,
}).
finished
.
then
(
() =>
{
$el.
style
.
translate
=
'100px'
;
})
});
import
{ waapi, utils, stagger }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
translate
:
() =>
`
${utils.random(
10
,
17
)}
rem`
,
rotate
:
() =>
utils.
random
(-
180
,
180
),
scale
:
(
_, i
) =>
.25
+ (i *
.25
),
duration
: $el => $el.
dataset
.
duration
,
delay
:
stagger
(
100
)
});
<
div
class
=
"small row"
>
<
div
data-duration
=
"400"
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
data-duration
=
"600"
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
data-duration
=
"800"
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
data-duration
=
"1000"
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Default units
Individual CSS transforms

=== DOC: 076_ondrag.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/ondrag
Draggable

Callbacks
Since 4.0.0
onDrag
Executes a function when the element is being dragged.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
drags =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onDrag
:
() =>
$value.
textContent
= ++drags
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
drags
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
onGrab
onUpdate

=== DOC: 077_stagger-from.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-from
Stagger

Parameters
Since 2.0.0
Stagger from
Defines the starting position of the stagger effect.
Accepts
Value
Description
Number
The starting index of the effect
'first'
Equivalent to index
0
'center'
Starts the effect from the center
'last'
Starts the effect from the last element
Default
0
import
{ createtimeline, stagger }
from
'animejs'
;
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
})
.
add
(
'.row:nth-child(1) .square'
, {
scale
:
0
,
delay
:
stagger
(
50
, {
from
:
8
}),
})
.
add
(
'.row:nth-child(2) .square'
, {
scale
:
0
,
delay
:
stagger
(
50
, {
from
:
'first'
}),
})
.
add
(
'.row:nth-child(3) .square'
, {
scale
:
0
,
delay
:
stagger
(
50
, {
from
:
'center'
}),
})
.
add
(
'.row:nth-child(4) .square'
, {
scale
:
0
,
delay
:
stagger
(
50
, {
from
:
'last'
}),
});
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Stagger start
Stagger reversed

=== DOC: 078_complete.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/complete
Animation

Methods
Since 4.0.0
complete()
V4
Completes the animation instantly.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $completeButton ] = utils.$(
'.complete'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
alternate
:
true
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
completeAnimation
= (
) => animation.
complete
();
$completeButton.
addEventListener
(
'click'
, completeAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button complete"
>
Complete
</
button
>
</
fieldset
>
</
div
>
Previous
Next
resume()
cancel()

=== DOC: 079_scope-parameters.txt ===
URL: https://animejs.com/documentation/scope/scope-parameters
Scope
Since 4.0.0
Scope parameters
import
{ createScope, animate }
from
'animejs'
;
createScope
({
┌─────────────────────────────────────────────────┐
│
root
:
'.section'
,                               │
│
defaults
: {                                     │
│
duration
:
250
,                                │
│
ease
:
'out(4)'
,                               │
│ },                                              ├─
Parameters
│
mediaQueries
: {                                 │
│
mobile
:
'(max-width: 640px)'
,                 │
│
reducedMotion
:
'(prefers-reduced-motion)'
,    │
│ }                                               │
└─────────────────────────────────────────────────┘
})
.
add
(
ctx
=>
{
const
isMobile = ctx.
matches
.
mobile
;
const
reduceMotion = ctx.
matches
.
reducedMotion
;
animate
(targets, {
x
: isMobile ?
0
:
'100vw'
,
y
: isMobile ?
'100vh'
:
0
,
duration
: reduceMotion ?
0
:
750
});
});
In this section
root
defaults
mediaQueries
Previous
Next
Register method function
root

=== DOC: 080_duration.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/duration
Animation

Playback settings
Since 1.0.0
duration
Defines the default duration in milliseconds of all animation tweens.
Setting
0
to a duration completes the animation instantly upon play.
Accepts
A
Number
equal or greater than
0
A
Function based value
that returns a
Number
equal to or greater than
0
Duration values higher than
1e12
are clamped internally to
1e12
(Or approximatively 32 years).
Default
1000
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
duration
=
500
;
import
{ animate }
from
'animejs'
;
animate
(
'.dur-0'
, {
x
:
'17rem'
,
duration
:
0
,
});
animate
(
'.dur-500'
, {
x
:
'17rem'
,
duration
:
500
,
});
animate
(
'.dur-2000'
, {
x
:
'17rem'
,
duration
:
2000
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle dur-0"
>
</
div
>
<
div
class
=
"padded label"
>
duration: 0
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle dur-500"
>
</
div
>
<
div
class
=
"padded label"
>
duration: 500
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle dur-2000"
>
</
div
>
<
div
class
=
"padded label"
>
duration: 2000
</
div
>
</
div
>
Previous
Next
delay
loop

=== DOC: 081_modifier.txt ===
URL: https://animejs.com/documentation/animatable/animatable-settings/modifier
Animatable

Settings
Since 4.0.0
modifier
Defines a
Modifier function
to modify or alter the behaviour of the animated numerical value.
Accepts
Modifier function
Default
noop
import
{ createAnimatable, utils, stagger }
from
'animejs'
;
const
PI
=
Math
.
PI
;
const
clock1 =
createAnimatable
(
'.clock-1'
, {
rotate
: {
unit
:
'rad'
},
modifier
: utils.
snap
(
PI
/
10
),
duration
:
0
,
});
const
clock2 =
createAnimatable
(
'.clock-2'
, {
rotate
: {
unit
:
'rad'
},
modifier
:
v
=>
-v,
duration
:
0
,
});
const
rotateClock
= (
animatable
) => {
return
e
=>
{
const
[ $clock ] = animatable.
targets
;
const
{ width, height, left, top } = $clock.
getBoundingClientRect
();
const
x = e.
clientX
- left - width /
2
;
const
y = e.
clientY
- top - height /
2
;
animatable.
rotate
(
Math
.
atan2
(y, x) +
PI
/
2
);
}
}
const
rotateClock1 =
rotateClock
(clock1);
const
rotateClock2 =
rotateClock
(clock2);
const
onMouseMove
= e => {
rotateClock1
(e);
rotateClock2
(e);
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock clock-1"
>
</
div
>
<
div
class
=
"label"
>
snapped
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock clock-2"
>
</
div
>
<
div
class
=
"label"
>
inverted
</
div
>
</
div
>
</
div
>
Previous
Next
ease
Animatable methods

=== DOC: 082_reverse.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/reverse
Timer

Methods
Since 4.0.0
reverse()
V4
Forces the timer to play backward.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $reverseButton ] = utils.$(
'.reverse'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
duration
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
,
});
const
reverseTimer
= (
) => timer.
reverse
();
$reverseButton.
addEventListener
(
'click'
, reverseTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button reverse"
>
Reverse
</
button
>
</
fieldset
>
</
div
>
Previous
Next
play()
pause()

=== DOC: 083_restart.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/restart
Timer

Methods
Since 4.0.0
restart()
Resets all properties and set the
currentTime
of a timer to
0
.
If the
autoplay
is set to
true
, the timer plays automatically.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $restartButton ] = utils.$(
'.restart'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
restartTimer
= (
) => timer.
restart
();
$restartButton.
addEventListener
(
'click'
, restartTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button restart"
>
Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
pause()
alternate()

=== DOC: 084_stagger-ease.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-ease
Stagger

Parameters
Since 2.0.0
Stagger ease
Defines an easing applied to the staggered values distribution.
Accept
ease
Default
'linear'
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
y
:
stagger
([
'2.75rem'
,
'-2.75rem'
], {
ease
:
'inOut(3)'
}),
delay
:
stagger
(
100
, {
ease
:
'inOut(3)'
}),
});
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Stagger reversed
Stagger grid

=== DOC: 085_onsnap.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onsnap
Draggable

Callbacks
Since 4.0.0
onSnap
Executes a function every time a snap occurs when the element is being dragged.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
snaps =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
snap
:
16
,
modifier
: utils.
snap
(
16
),
// also snap the element while draggin
onSnap
:
() =>
$value.
textContent
= ++snaps
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
snaps
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
onRelease
onSettle

=== DOC: 086_tween-value-types.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types
Animation
Since 1.0.0
Tween value types
Specify the
start
and
end
values that define the animation of animatable properties.
Animation values are assigned to
Animatable properties
and accept a wide range of syntaxes.
animate
(
'.square'
, {
x
:
'6rem'
, ─────────────────┐
y
: $el => $el.
dataset
.
y
, ───┤
scale
:
'+=.25'
, ────────────┼─
Tween
Values
opacity
: {                  │
from
:
.4
, ────────────────┘
},
});
In this section
Numerical
Unit conversion
Relative
Color
Color function
CSS variable
Function based
Previous
Next
Animatable properties
Numerical value

=== DOC: 087_delay.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/delay
Animation

Tween parameters
Since 1.0.0
delay
Defines the delay in milliseconds at the beginning of all animated properties, or locally to a specific property.
Accepts
Number
equal to or greater than
0
Function based value
that returns a
Number
equal to or greater than
0
Default
The animation delay value (default
0
).
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
delay
=
500
;
import
{ animate }
from
'animejs'
;
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
rotate
: {
to
:
360
,
delay
:
1000
,
// Local delay applied only to rotate property
},
delay
:
500
,
// Global delay applied to all properties
loop
:
true
,
alternate
:
true
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
from
duration

=== DOC: 088_alternate.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/alternate
Animation

Methods
Since 1.0.0
alternate()
V4
Toggles the playback direction while adjusting the
currentTime
position to reflect the new time progress.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $alternateButton ] = utils.$(
'.button'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
alternateAnimation
= (
) => animation.
alternate
();
$alternateButton.
addEventListener
(
'click'
, alternateAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Alternate
</
button
>
</
fieldset
>
</
div
>
Previous
Next
restart()
resume()

=== DOC: 089_css-transforms.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/css-transforms
Animation

Animatable properties
Since 1.0.0
CSS transforms
The CSS
transform
property can be animated by specifying individual properties directly in the parameter object with both
JS
and
WAAPI
animate
()
versions.
This allows a greater level of control over how to animate individual transform properties, giving you more flexibility than CSS animations or native WAAPI.
The
JS
animate
()
method doesn't parse transforms declared from a CSS style declaration and transforms properties must be set directly in the inline styles of the element. You can use the built-in
utils.
set
()
function to independently set your transform values before animating an element and define in which order they must be set.
In order to animate the
transform
property directly, it's recommended to use the
WAAPI
powered
waapi.
animate
()
method.
Individual transforms with
WAAPI
only works for browsers that support
CSS
.
registerProperty
(propertyDefinition)
, and fallback to no animations.
Valid individual CSS transforms properties
Name
Shorthand
Default Value
Default Unit
translateX
x
'0px'
'px'
translateY
y
'0px'
'px'
translateZ
z
'0px'
'px'
rotate
—
'0deg'
'deg'
rotateX
—
'0deg'
'deg'
rotateY
—
'0deg'
'deg'
rotateZ
—
'0deg'
'deg'
scale
—
'1'
—
scaleX
—
'1'
—
scaleY
—
'1'
—
scaleZ
—
'1'
—
skew
—
'0deg'
'deg'
skewX
—
'0deg'
'deg'
skewY
—
'0deg'
'deg'
perspective
—
'0px'
'px'
import
{ animate, waapi }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
// TranslateX shorthand
scale
:
1.25
,
skew
: -
45
,
rotate
:
'1turn'
,
});
// the WAAPI version is recommanded if you want to animate the transform property directly
waapi.
animate
(
'.square'
, {
transform
:
'translateX(15rem) scale(1.25) skew(-45deg) rotate(1turn)'
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
span
class
=
"padded label"
>
JS / WAAPI
</
span
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
span
class
=
"padded label"
>
WAAPI
</
span
>
</
div
>
Previous
Next
CSS Properties
CSS Variables

=== DOC: 090_resume.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/resume
Timer

Methods
Since 4.0.0
resume()
Resumes the playback of a paused timer in its current direction.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $resumeButton, $pauseButton, $alternateButton ] = utils.$(
'.button'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
duration
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
,
loop
:
true
,
});
const
resumeTimer
= (
) => timer.
resume
();
const
pauseTimer
= (
) => timer.
pause
();
const
alternateTimer
= (
) => timer.
alternate
();
$resumeButton.
addEventListener
(
'click'
, resumeTimer);
$pauseButton.
addEventListener
(
'click'
, pauseTimer);
$alternateButton.
addEventListener
(
'click'
, alternateTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Resume
</
button
>
<
button
class
=
"button"
>
Pause
</
button
>
<
button
class
=
"button"
>
Alternate
</
button
>
</
fieldset
>
</
div
>
Previous
Next
alternate()
complete()

=== DOC: 091_releasedamping.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/releasedamping
Draggable

Settings
Since 4.0.0
releaseDamping
Specifies the damping applied to the dragged element after release. Affects the speed, movement distance and bounciness of the dragged element. Lower values increases the bounciness when reaching the bounds of the container.
releaseDamping
has no effect if a spring is passed to the
releaseDamping
parameter and is overridden by the spring
damping
value.
Accepts
A
Number
between
0
and
1000
Default
10
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
releaseDamping
:
5
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
releaseStiffness
:
30
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
releaseStiffness
velocityMultiplier

=== DOC: 092_reversed.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/reversed
Animation

Playback settings
Since 4.0.0
reversed
V4
Defines the initial direction of the animation.
Accepts
Boolean
If set to
true
the animation plays backwards
If set to
false
the animation plays forwards
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
reversed
=
true
;
import
{ animate }
from
'animejs'
;
animate
(
'.dir-normal'
, {
x
:
'17rem'
,
reversed
:
false
,
// Default behaviour
loop
:
true
});
animate
(
'.dir-reverse'
, {
x
:
'17rem'
,
reversed
:
true
,
loop
:
true
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle dir-normal"
>
</
div
>
<
div
class
=
"padded label"
>
reversed: false
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle dir-reverse"
>
</
div
>
<
div
class
=
"padded label"
>
reversed: true
</
div
>
</
div
>
Previous
Next
alternate
autoplay

=== DOC: 093_draggable-settings.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings
Draggable
Since 4.0.0
Draggable settings
Draggable settings are defined directly in the
createDraggable
()
parameters
Object
.
createDraggable
(
'.square'
, {
x
: {
snap
:
100
},
y
: {
snap
:
50
},
modifier
: utils.
wrap
(-
200
,
0
),
┌───────────────────────┐
│
containerPadding
:
10
, │
│
releaseStiffness
:
40
, ├─
Settings
│
releaseEase
:
'out(3)'
,│
└───────────────────────┘
onGrab
:
() =>
{},
onDrag
:
() =>
{},
onRelease
:
() =>
{},
});
In this section
trigger
container
containerPadding
containerFriction
releaseContainerFriction
releaseMass
releaseStiffness
releaseDamping
velocityMultiplier
minVelocity
maxVelocity
releaseEase
dragSpeed
scrollThreshold
scrollSpeed
cursor
Previous
Next
Draggable axes parameters
trigger

=== DOC: 094_using-with-vanilla-js.txt ===
URL: https://animejs.com/documentation/getting-started/using-with-vanilla-js
Getting started
Since 4.0.0
Using with vanilla JS
Using Anime.js in vanilla JavaScript is pretty straightforward, simply import the modules you need and start animating.
The following example showcase how to uses Anime.js methods with a vanilla JS code base.
import
{ animate, utils, createDraggable, createSpring }
from
'animejs'
;
const
[ $logo ] = utils.$(
'.logo.js'
);
const
[ $button ] = utils.$(
'button'
);
let
rotations =
0
;
// Created a bounce animation loop
animate
(
'.logo.js'
, {
scale
: [
{
to
:
1.25
,
ease
:
'inOut(3)'
,
duration
:
200
},
{
to
:
1
,
ease
:
createSpring
({
stiffness
:
300
}) }
],
loop
:
true
,
loopDelay
:
250
,
});
// Make the logo draggable around its center
createDraggable
(
'.logo.js'
, {
container
: [
0
,
0
,
0
,
0
],
releaseEase
:
createSpring
({
stiffness
:
200
})
});
// Animate logo rotation on click
const
rotateLogo
= (
) => {
rotations++;
$button.
innerText
=
`rotations:
${rotations}
`
;
animate
($logo, {
rotate
: rotations *
360
,
ease
:
'out(4)'
,
duration
:
1500
,
});
}
$button.
addEventListener
(
'click'
, rotateLogo);
<
div
class
=
"large centered row"
>
<
svg
class
=
"logo js"
preserveAspectRatio
=
"xMidYMid meet"
viewBox
=
"0 0 630 630"
>
<
path
fill
=
"currentColor"
d
=
"M577,0 C606.271092,0 630,23.7289083 630,53 L630,577 C630,606.271092 606.271092,630 577,630 L53,630 C23.7289083,630 0,606.271092 0,577 L0,53 C0,23.7289083 23.7289083,0 53,0 L577,0 Z M479.5,285.89 C426.63,285.89 392.8,319.69 392.8,364.09 C392.8,411.808 420.615238,434.63146 462.622716,452.742599 L478.7,459.64 L483.441157,461.719734 C507.57404,472.359996 521.8,479.858 521.8,498.94 C521.8,515.88 506.13,528.14 481.6,528.14 C452.4,528.14 435.89,512.91 423.2,492.19 L375.09,520.14 C392.47,554.48 427.99,580.68 482.97,580.68 C539.2,580.68 581.07,551.48 581.07,498.18 C581.07,448.74 552.67,426.75 502.37,405.18 L487.57,398.84 L485.322788,397.859899 C461.5199,387.399087 451.17,380.1172 451.17,362.89 C451.17,348.52 462.16,337.52 479.5,337.52 C496.5,337.52 507.45,344.69 517.6,362.89 L563.7,333.29 C544.2,298.99 517.14,285.89 479.5,285.89 Z M343.09,289.27 L283.89,289.27 L283.89,490.57 C283.89,520.16 271.62,527.77 252.17,527.77 C231.83,527.77 223.37,513.82 214.07,497.32 L165.88,526.495 C179.84,556.04 207.29,580.57 254.69,580.57 C307.15,580.57 343.09,552.67 343.09,491.37 L343.09,289.27 Z"
/>
</
svg
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
>
rotations: 0
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Imports
Using with React

=== DOC: 095_alternate.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/alternate
Timer

Methods
Since 4.0.0
alternate()
Toggles the playback direction while adjusting the
currentTime
position to reflect the new time progress.
Only the
iterationTime
is actually played in reverse since the
currentTime
always starts at
0
and ends at
duration
.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $alternateButton ] = utils.$(
'.button'
);
const
[ $iterationTime ] = utils.$(
'.iteration-time'
);
const
timer =
createTimer
({
duration
:
10000
,
loop
:
true
,
onUpdate
:
self
=>
{
$iterationTime.
innerHTML
= self.
iterationCurrentTime
;
}
});
const
alternateTimer
= (
) => timer.
alternate
();
$alternateButton.
addEventListener
(
'click'
, alternateTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"iteration-time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Alternate
</
button
>
</
fieldset
>
</
div
>
Previous
Next
restart()
resume()

=== DOC: 096_x.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters/x
Draggable

Axes parameters
Since 4.0.0
x
Defines the behaviour of the x-axis by either passing an object of parameters or disabling it by setting the value to
false
.
Accepts
Boolean
Draggable axes parameters
Object
Default
true
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square.enabled'
, {
x
:
true
});
createDraggable
(
'.square.disabled'
, {
x
:
false
});
<
div
class
=
"large spaced-evenly row"
>
<
div
class
=
"square enabled draggable"
>
</
div
>
<
div
class
=
"square disabled draggable"
>
</
div
>
</
div
>
<
div
class
=
"large spaced-evenly row"
>
<
div
class
=
"label"
>
x enabled
</
div
>
<
div
class
=
"label"
>
x disabled
</
div
>
</
div
>
Previous
Next
Draggable axes parameters
y

=== DOC: 097_onenterforward.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onenterforward
ScrollObserver

Callbacks
Since 4.0.0
onEnterForward
Triggers a function every time the
enter
threshold
is met by scrolling forward.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
entered =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onEnterForward
:
() =>
$value.
textContent
= ++entered,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
entered
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onEnter
onEnterBackward

=== DOC: 098_pause.txt ===
URL: https://animejs.com/documentation/engine/engine-methods/pause
Engine

Methods
Since 4.0.0
pause()
Pauses the engine's main loop, pausing all active
Timer
,
Animation
, and
Timeline
instances. Use
engine.
resume
()
to restart the animations from where they paused.
engine.
pause
();
// Stops all animations
engine.
resume
();
// Resumes all animations
Timer
,
Animation
, or
Timeline
can still be added when the engine is paused, but won't play until the engine is started again.
Returns
Engine
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $container ] = utils.$(
'.container'
);
const
[ $add, $pause ] = utils.$(
'button'
);
function
addAnimation
(
) {
const
$particle =
document
.
createElement
(
'div'
);
$particle.
classList
.
add
(
'particle'
);
$container.
appendChild
($particle);
animate
($particle, {
x
: utils.
random
(-
10
,
10
,
2
) +
'rem'
,
y
: utils.
random
(-
3
,
3
,
2
) +
'rem'
,
scale
: [{
from
:
0
,
to
:
1
}, {
to
:
0
}],
loop
:
true
,
});
}
let
timeout =
3
;
let
interval;
function
pauseEngine
(
) {
engine.
pause
();
$pause.
setAttribute
(
'disabled'
,
'true'
);
$pause.
innerHTML
=
`Resume in
${timeout--}
seconds`
;
interval =
setInterval
(
() =>
{
if
(timeout <=
0
) {
clearInterval
(interval);
engine.
resume
();
$pause.
removeAttribute
(
'disabled'
);
$pause.
innerHTML
=
'Pause for 3 seconds'
;
timeout =
3
;
}
else
{
$pause.
innerHTML
=
`Resume in
${timeout--}
seconds`
;
}
},
1000
);
}
$add.
addEventListener
(
'click'
, addAnimation);
$pause.
addEventListener
(
'click'
, pauseEngine);
<
div
class
=
"large row container"
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
>
Add animation
</
button
>
<
button
>
Pause for 3 seconds
</
button
>
</
fieldset
>
</
div
>
Previous
Next
update()
resume()

=== DOC: 099_onpause.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onpause
Timeline

Callbacks
Since 4.0.0
onPause
V4
Executes a function when a running timeline is paused, either manually or automatically.
A timeline pauses when any of the following occurs during playback:
The
.
pause
()
method is called
The
.
cancel
()
method is called
The
.
revert
()
method is called
All child animations tweens are overlapped by another timeline or animation with
composition
:
'replace'
All child animations targets have been removed and no other timers are active
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onPause
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $animateButton, $pauseButton, $removeButton ] = utils.$(
'.button'
);
const
[ $value ] = utils.$(
'.value'
);
const
shapes = utils.$(
'.shape'
);
const
[ $triangle, $square, $circle ] = shapes;
let
paused =
0
;
let
alternate =
0
;
let
tl;
const
animateShapes
= (
) => {
alternate = !alternate;
const
x = (alternate ?
15
:
0
) +
'rem'
;
const
rotate = (alternate ?
360
: -
360
);
tl =
createTimeline
({
defaults
: {
duration
:
2000
},
onPause
:
() =>
$value.
textContent
= ++paused
})
.
add
($circle, { x },
0
)
.
add
($triangle, { x },
0
)
.
add
($square, { x },
0
)
.
add
(shapes, { rotate },
0
);
}
const
pauseTL
= (
) => {
if
(tl) tl.
pause
();
}
const
removeTargets
= (
) => {
utils.
remove
(shapes);
}
animateShapes
();
$animateButton.
addEventListener
(
'click'
, animateShapes);
$pauseButton.
addEventListener
(
'click'
, pauseTL);
$removeButton.
addEventListener
(
'click'
, removeTargets);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"shape triangle"
>
</
div
>
<
div
class
=
"shape square"
>
</
div
>
<
div
class
=
"shape circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
paused
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Create TL
</
button
>
<
button
class
=
"button"
>
Pause TL
</
button
>
<
button
class
=
"button"
>
Remove shapes
</
button
>
</
fieldset
>
</
div
>
Previous
Next
onLoop
then()

=== DOC: 100_revert.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-methods/revert
ScrollObserver

Methods
Since 4.0.0
revert()
Disables the ScrollObserver, removes all
EventListener
and removes the
debug
HTMLElement
if necessary.
Returns
The ScrollObserver itself
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
1
,
debug
:
true
,
onSyncComplete
:
self
=>
self.
revert
()
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
refresh()
scrollObserver properties

=== DOC: 101_restart.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/restart
Timeline

Methods
Since 2.0.0
restart()
Sets the
currentTime
of a timeline to
0
and reset all properties of the elements to their initial state.
If the
autoplay
parameter is set to
true
, the timeline plays automatically.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $restartButton ] = utils.$(
'.restart'
);
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
restartTimeline
= (
) => tl.
restart
();
$restartButton.
addEventListener
(
'click'
, restartTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button restart"
>
Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
pause()
alternate()

=== DOC: 102_reverse.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/reverse
Timeline

Methods
Since 4.0.0
reverse()
V4
Forces the timeline to play backward.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $reverseButton ] = utils.$(
'.reverse'
);
const
tl =
createTimeline
()
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
reverseTimeline
= (
) => tl.
reverse
();
$reverseButton.
addEventListener
(
'click'
, reverseTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button reverse"
>
Reverse
</
button
>
</
fieldset
>
</
div
>
Previous
Next
play()
pause()

=== DOC: 103_onbegin.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/onbegin
Timer

Callbacks
Since 4.0.0
onBegin
Executes a function when a timer starts.
Accepts
A
Function
whose first argument returns the timer itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onBegin
=
self
=>
console
.
log
(self.
id
);
import
{ createTimer, utils }
from
'animejs'
;
const
[ $status ] = utils.$(
'.status'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
delay
:
2000
,
duration
:
2000
,
onBegin
:
self
=>
$status.
innerHTML
=
'true'
});
const
logTimer =
createTimer
({
duration
:
4000
,
onUpdate
:
self
=>
$time.
innerHTML
= timer.
currentTime
});
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
began
</
span
>
<
span
class
=
"status value"
>
false
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
Timer callbacks
onComplete

=== DOC: 104_documentation.txt ===
URL: https://animejs.com/documentation
Documentation
This documentation is only made possible with the help of my sponsors
Anime.js is developed and maintained with the generous support of my sponsors. If you're using Anime.js, a monthly contribution would be highly valuable.
Funding goal
31%
Jordan
Sebastian
Ivan Zarea
Rhemery
satoshionoda
bparrillo
Dikshith
Richard Davey
Mase Graye
Aaron Wade
entrepeneur4lyf
Matvey Levinson
Nicolaj Andersen
lilchocobo
Artisann
Daniel Cruz
Mike
Scott Ashton
Njordr
Huly® Platform™
Mr White
Ismail Magomedov
David Lapointe Gilbert
Stefan
Carmen Ansio
jamesd256
Kaze Wong
Frank Frick
Ado Kukic
bandit.camp
Osande de Jesus
talli
EvGreen
willmcinnis
Luke Jackson
Calvin Ducharme
Donovan Dikaio
Zaid Al Kazemi
Daniela Aviles
Arjun Samir Patel
lucasskywalker
Gokul Js
Micky Cormier
Umut Ozan Yıldırım
michelducker
Joshua T.
ash-ftdx
InTheScript
Sam Denty
RickEvry
Help the project via
GitHub Sponsors
.
Platinum sponsors
Huly
Ice Open Network
Your logo here
In this section
Getting started
Timer
Animation
Timeline
Animatable
Draggable
ScrollObserver
Scope
Stagger
SVG
Utilities
WAAPI
Engine
Next
Getting started

=== DOC: 105_hardware-accelerated-animations.txt ===
URL: https://animejs.com/documentation/web-animation-api/hardware-accelerated-animations
Web Animation API
Since 4.0.0
Hardware-accelerated animations
One of the biggest advantages of WAAPI over
requestAnimationFrame
powered animations is the ability to run animations off the main thread, leading to smoother animations when the CPU is busy while consuming less power, which can improve battery life.
The catch is that not all properties can be hardware-accelerated, there are currently only a few that can create a new compositor layer and run off the main thread on every browser.
Hardware-accelerated properties in every major browsers:
opacity
transform
translate
scale
rotate
Hardware-accelerated properties in some browsers:
clip-path
filter
Safari (desktop and mobile) currently won't trigger hardware acceleration if the animation is using a custom
'linear()'
easing. This mean that custom power eases like:
'out(3)'
,
'in(3)'
,
'inOut(3)'
, and every JavaScript easing passed to
waapi.
animate
()
prevents the animation to be hardware accelerated, even if the property supports it.
import
{ animate, waapi, createTimer, utils }
from
'animejs'
;
const
[ $block ] = utils.$(
'.button'
);
const
waapiAnim = waapi.
animate
(
'.waapi.square'
, {
translate
:
270
,
rotate
:
180
,
alternate
:
true
,
loop
:
true
,
ease
:
'cubicBezier(0, 0, .58, 1)'
,
});
const
jsAnim =
animate
(
'.js.square'
, {
x
:
270
,
rotate
:
180
,
ease
:
'cubicBezier(0, 0, .58, 1)'
,
alternate
:
true
,
loop
:
true
,
});
const
blockCPUTimer =
createTimer
({
onUpdate
:
() =>
{
const
end =
Date
.
now
() +
100
;
while
(
Date
.
now
() < end) {
Math
.
random
() *
Math
.
random
();
}
},
autoplay
:
false
});
let
isBusy =
false
;
const
toggleCPU
= (
) => {
blockCPUTimer[isBusy ?
'pause'
:
'play'
]();
$block.
innerText
= (isBusy ?
'block'
:
'free'
) +
' CPU'
;
isBusy = !isBusy;
}
$block.
addEventListener
(
'click'
, toggleCPU);
<
div
class
=
"medium row"
>
<
div
class
=
"waapi square"
>
</
div
>
<
span
class
=
"padded label"
>
WAAPI
</
span
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"js square"
>
</
div
>
<
span
class
=
"padded label"
>
JS
</
span
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Block CPU
</
button
>
</
fieldset
>
</
div
>
Previous
Next
When to use WAAPI
Improvements to the Web Animation API

=== DOC: 106_onleaveforward.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onleaveforward
ScrollObserver

Callbacks
Since 4.0.0
onLeaveForward
Triggers a function every time the
leave
threshold
is met by scrolling forward.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
exits =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onLeaveForward
:
() =>
$value.
textContent
= ++exits,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
exits
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onLeave
onLeaveBackward

=== DOC: 107_remove.txt ===
URL: https://animejs.com/documentation/utilities/remove
Utilities
Since 2.0.0
remove()
Removes one or multiple targets from all active animations, a specific instance or a specific property, cancelling any
Animation
or
Timeline
referencing these targets if needed.
const
removed = utils.
remove
(targets, instance, propertyName);
Parameters
Name
Accepts
targets
Targets
instance
(opt)
Animation
|
Timeline
propertyName
(opt)
Animatable Properties
name
String
Returns
An
Array
of the removed targeted elements
import
{ animate, utils }
from
'animejs'
;
let
updates =
0
;
const
[ $removeFirstButton ] = utils.$(
'.remove-1'
);
const
[ $removeSecondButton ] = utils.$(
'.remove-2'
);
const
[ $updates ] = utils.$(
'.value'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
rotate
:
360
,
alternate
:
true
,
loop
:
true
,
onUpdate
:
() =>
{
$updates.
textContent
= updates++;
}
});
$removeFirstButton.
onclick
=
() =>
{
utils.
remove
(
'.row:nth-child(1) .square'
);
}
$removeSecondButton.
onclick
=
() =>
{
utils.
remove
(
'.row:nth-child(2) .square'
, animation,
'x'
);
}
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
--
</
span
>
</
pre
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button remove-1"
>
Remove all first
</
button
>
<
button
class
=
"button remove-2"
>
Remove x second
</
button
>
</
fieldset
>
</
div
>
Previous
Next
set()
cleanInlineStyles()

=== DOC: 108_targets.txt ===
URL: https://animejs.com/documentation/animation/targets
Animation
Since 4.0.0
Targets
Specify the elements to which property value changes are applied.
Animation targets are defined in the first argument of the
animate
()
function.
animate
(
┌────────────┐
│
'.square'
, ├─
Targets
└────────────┘
{
translateX
:
100
,
scale
:
2
,
opacity
:
.5
,
duration
:
400
,
delay
:
250
,
ease
:
'out(3)'
,
loop
:
3
,
alternate
:
true
,
autoplay
:
false
,
onBegin
:
() =>
{},
onLoop
:
() =>
{},
onUpdate
:
() =>
{},
});
In this section
CSS Selector
DOM Elements
JavaScript Objects
Array of targets
Previous
Next
Animation
CSS Selector

=== DOC: 109_delay.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/delay
Timer

Playback settings
Since 4.0.0
delay
Defines the time in milliseconds before the timer starts.
Accepts
A
Number
equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
delay
=
500
;
import
{ createTimer, utils }
from
'animejs'
;
const
[ $time ] = utils.$(
'.time'
);
createTimer
({
delay
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
Timer playback settings
duration

=== DOC: 110_sety.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/sety
Draggable

Methods
Since 4.0.0
setY()
Manually set the
y
position of the draggable target.
Is equivalent updating
draggable.
y
directly when no
muteCallback
parameter is defined.
Parameters
Name
Type
Description
y
Number
The new y value
muteCallback
(opt)
Boolean
If
true
, prevents the
onUpdate
callback to fire (default
false
)
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $setButton ] = utils.$(
'.set'
);
const
draggable =
createDraggable
(
'.square'
);
const
setRandomY
= (
) => draggable.
setY
(utils.
random
(-
40
,
40
));
$setButton.
addEventListener
(
'click'
, setRandomY);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button set"
>
Set random y
</
button
>
</
fieldset
>
</
div
>
Previous
Next
setX()
animateInView()

=== DOC: 111_unit.txt ===
URL: https://animejs.com/documentation/animatable/animatable-settings/unit
Animatable

Settings
Since 4.0.0
unit
Defines the unit for the animated value of the property.
Accepts
A
String
containing a valid CSS unit
import
{ createAnimatable, utils }
from
'animejs'
;
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
[ $clock ] = utils.$(
'.clock'
);
let
bounds = $clock.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $clock.
getBoundingClientRect
();
const
clock =
createAnimatable
($clock, {
rotate
: {
unit
:
'rad'
},
// Set the unit to 'rad'
duration
:
400
,
});
const
{
PI
} =
Math
;
let
lastAngle =
0
let
angle =
PI
/
2
;
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
x = e.
clientX
- left - width /
2
;
const
y = e.
clientY
- top - height /
2
;
const
currentAngle =
Math
.
atan2
(y, x);
const
diff = currentAngle - lastAngle;
angle += diff >
PI
? diff -
2
*
PI
: diff < -
PI
? diff +
2
*
PI
: diff;
lastAngle = currentAngle;
clock.
rotate
(angle);
// Pass the new angle value in rad
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"small centered row"
>
<
span
class
=
"label"
>
Move cursor around
</
span
>
</
div
>
Previous
Next
Animatable settings
duration

=== DOC: 112_waapi-convertease.txt ===
URL: https://animejs.com/documentation/web-animation-api/waapi-convertease
Web Animation API
Since 4.0.0
waapi.convertEase()
Converts any JavaScript easing functions into a compatible WAAPI
linear easing
.
import
{ waapi, createSpring }
from
'animejs'
;
const
spring =
createSpring
({
stiffness
:
12
});
const
linearEasing = waapi.
convertEase
(spring.
ease
);
import
{ waapi, createSpring }
from
'animejs'
;
const
springs = [
createSpring
({
stiffness
:
100
}),
createSpring
({
stiffness
:
150
}),
createSpring
({
stiffness
:
200
})
]
document
.
querySelectorAll
(
'#web-animation-api-waapi-convertease .demo .square'
).
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
'17rem'
,
rotate
:
'1turn'
,
}, {
easing
: waapi.
convertEase
(springs[i].
ease
),
delay
: i *
250
,
duration
: springs[i].
duration
,
fill
:
'forwards'
});
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
stiffness: 100
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
stiffness: 150
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
stiffness: 200
</
div
>
</
div
>
Previous
Next
API differences with native WAAPI
Engine

=== DOC: 113_draggable.txt ===
URL: https://animejs.com/documentation/draggable
Draggable
V4
Adds draggable capabilities to DOM Elements.
Draggables are created using the
createDraggable
()
function.
import
{ createDraggable }
from
'animejs'
;
const
draggable =
createDraggable
(target, parameters);
Parameters
Name
Accepts
target
CSS Selector
|
DOM Element
parameters
(opt)
An
Object
of
Draggable axes parameters
,
Draggable settings
and
Draggable callbacks
Returns
Draggable
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
);
<
div
class
=
"large row centered"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
In this section
Axes parameters
Settings
Callbacks
Methods
Properties
Previous
Next
Animatable
Draggable axes parameters

=== DOC: 114_framerate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/framerate
Timeline

Playback settings
Since 4.0.0
frameRate
V4
Determines the number of frames per second (fps) a timeline is played at.
This value can be modified later with
timeline.
fps
=
30
.
Accepts
A
Number
greater than
0
The frame rate is capped to the monitor refresh rate or in some cases by the browser itself
Default
120
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
frameRate
=
30
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $fps ] = utils.$(
'.fps'
);
const
tl =
createTimeline
({
frameRate
:
60
,
loop
:
true
,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
const
updateFps
= (
) => {
const
{ value } = $range;
$fps.
innerHTML
= value;
tl.
fps
= value;
}
$range.
addEventListener
(
'input'
, updateFps);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
fps
</
span
>
<
span
class
=
"fps value"
>
60
</
span
>
</
pre
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
120
value
=
60
step
=
1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
autoplay
playbackRate

=== DOC: 115_timer.txt ===
URL: https://animejs.com/documentation/timer
Timer
V4
Schedules and controls timed function callbacks that can be used as a replacement to
setTimeout
()
or
setInterval
()
, keeping animations and callbacks in sync.
Timers are created using the
createTimer
()
function.
import
{ createTimer }
from
'animejs'
;
const
timer =
createTimer
(parameters);
Parameters
Name
Accepts
parameters
(opt)
An
Object
of
Timer playback settings
and
Timer callbacks
Returns
Timer
import
{ animate }
from
'animejs'
;
const
[ $time, $count ] = utils.$(
'.value'
);
createTimer
({
duration
:
1000
,
loop
:
true
,
frameRate
:
30
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
,
onLoop
:
self
=>
$count.
innerHTML
= self.
_currentIteration
});
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
callback fired
</
span
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
In this section
Playback settings
Callbacks
Methods
Properties
Previous
Next
Getting started
Timer playback settings

=== DOC: 116_css-variables.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/css-variables
Animation

Animatable properties
Since 4.0.0
CSS Variables
V4
JS
CSS variables with numerical or color values can be animated by directly passing the variable name as a string to the animation parameters.
This approach also enables animation of properties defined on pseudo-elements like
::after
and
::before
, which are otherwise inaccessible via JavaScript.
In order to animate CSS variables properties with the
WAAPI
powered
waapi.
animate
()
method, you need to use
CSS
.
registerProperty
(propertyDefinition)
, otherwise it falls back to no animations.
import
{ animate, utils }
from
'animejs'
;
// Set the CSS variables as properties on the animated elements
utils.
set
(
'.square'
, {
'--radius'
:
'4px'
,
'--x'
:
'0rem'
,
'--pseudo-el-after-scale'
:
'1'
,
// applied to the pseudo element "::after"
borderRadius
:
'var(--radius)'
,
translateX
:
'var(--x)'
,
});
// Animate the values of the CSS variables
animate
(
'.square'
, {
'--radius'
:
'20px'
,
'--x'
:
'16.5rem'
,
'--pseudo-el-after-scale'
:
'1.55'
// Animates the ":after" pseudo element of the element
});
<
div
class
=
"medium row"
>
<
div
class
=
"css-variables square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"css-variables square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"css-variables square"
>
</
div
>
</
div
>
Previous
Next
CSS transforms
JavaScript Object properties

=== DOC: 117_stretch.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/stretch
Animation

Methods
Since 4.0.0
stretch()
V4
JS
Changes the total duration of an animation and its tweens duration to fit a specific time.
The total duration is equal to the duration of an iteration multiplied with the total number of iterations. So if an animation is 1000ms and loops twice (3 iterations in total), the total duration will be 3000ms (1000 * 3).
animation.
stretch
(duration);
Parameters
Name
Type
Description
duration
Number
The new total duration in ms of the animation
Stretching an animation to
0
will also set all its tweens' durations to
0
, which will make them all the same length on subsequent calls to
stretch
()
.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $totalDuration ] = utils.$(
'.value'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
delay
:
stagger
(
200
),
});
const
stretchAnimation
= (
) => {
const
newDuration = +$range.
value
;
$totalDuration.
textContent
= newDuration;
animation.
stretch
(newDuration).
restart
();
}
stretchAnimation
();
$range.
addEventListener
(
'input'
, stretchAnimation);
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
total duration
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
100
max
=
2000
value
=
1000
step
=
100
class
=
"seek range"
/>
</
fieldset
>
</
div
>
Previous
Next
seek()
refresh()

=== DOC: 118_velocitymultiplier.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/velocitymultiplier
Draggable

Settings
Since 4.0.0
velocityMultiplier
Specifies a multiplier to modify the velocity applied to the dragged element after release, where
0
means no velocity at all,
1
is normal velocity and
2
double the velocity.
Accepts
A
Number
greater than or equal to
0
A
Function
that returns a
Number
greater than or equal to
0
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
1
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
velocityMultiplier
:
0
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
velocityMultiplier
:
5
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
releaseDamping
minVelocity

=== DOC: 119_sync.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/sync
Timeline

Methods
Since 4.0.0
sync()
V4
Synchronises a JS animation, WAAPI Animation, timer, timeline or even a native
WAAPI Animation
to a timeline.
const
tlChild =
createTimeline
().
add
(target, {
x
:
100
}).
add
(target, {
y
:
100
});
createTimeline
().
sync
(tlChild);
Tween value composition is handled when the timeline is created, and won't affect the timeline's existing children when added.
Parameters
Name
Accepts
synced
JSAnimation
|
Timer
|
Timeline
|
Anime.js WAAPIAnimation
|
WAAPIAnimation
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, animate, waapi }
from
'animejs'
;
const
circleAnimation = waapi.
animate
(
'.circle'
, {
x
:
'15rem'
});
const
tlA =
createTimeline
()
.
sync
(circleAnimation)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
duration
:
2000
,
})
.
add
(
'.square'
, {
x
:
'15rem'
,
});
const
tlB =
createTimeline
({
defaults
: {
duration
:
2000
} })
.
add
([
'.triangle'
,
'.square'
], {
rotate
:
360
,
},
0
)
.
add
(
'.circle'
, {
scale
: [
1
,
1.5
,
1
],
},
0
);
const
tlMain =
createTimeline
()
.
sync
(tlA)
.
sync
(tlB,
'-=2000'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
set()
label()

=== DOC: 120_draggable-axes-parameters.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters
Draggable
Since 4.0.0
Draggable axes parameters
Axes parameters are specified globally to all axes on the parameters object, or specifically to an axis by passing it an object.
createDraggable
(
'.square'
, {
┌───────────────────────────────┐
│
x
: {
snap
:
100
},             │
│
y
: {
snap
:
50
},              ├─
Axes
Parameters
│
modifier
: utils.
wrap
(-
200
,
0
),│
└───────────────────────────────┘
containerPadding
:
10
,
releaseStiffness
:
40
,
releaseEase
:
'out(3)'
,
onGrab
:
() =>
{},
onDrag
:
() =>
{},
onRelease
:
() =>
{},
});
In this section
x
y
snap
modifier
mapTo
Previous
Next
Draggable
x

=== DOC: 121_sync-waapi-animations.txt ===
URL: https://animejs.com/documentation/timeline/sync-waapi-animations
Timeline
Since 4.0.0
Sync WAAPI animations
V4
WAAPI animations can be synchronised to a timeline using the
sync
()
method.
timeline.
sync
(animation, position);
Parameters
Name
Accepts
synced
Animation
|
Timer
|
Timeline
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, waapi }
from
'animejs'
;
const
circle = waapi.
animate
(
'.circle'
, {
x
:
'15rem'
,
});
const
triangle = waapi.
animate
(
'.triangle'
, {
x
:
'15rem'
,
y
: [
0
,
'-1.5rem'
,
0
],
ease
:
'out(4)'
,
duration
:
750
,
});
const
square = waapi.
animate
(
'.square'
, {
x
:
'15rem'
,
rotateZ
:
360
,
});
const
tl =
createTimeline
()
.
sync
(circle,
0
)
.
sync
(triangle,
350
)
.
sync
(square,
250
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Add animations
Sync timelines

=== DOC: 122_pause.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/pause
Timer

Methods
Since 4.0.0
pause()
Pauses a running timer.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $pauseButton ] = utils.$(
'.pause'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
pauseTimer
= (
) => timer.
pause
();
$pauseButton.
addEventListener
(
'click'
, pauseTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button pause"
>
Pause
</
button
>
</
fieldset
>
</
div
>
Previous
Next
reverse()
restart()

=== DOC: 123_releasestiffness.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/releasestiffness
Draggable

Settings
Since 4.0.0
releaseStiffness
Specifies the stiffness applied to the dragged element after release. Affects the speed, movement distance and bounciness of the dragged element. Lower values result in slower movement.
releaseStiffness
has no effect if a spring is passed to the
releaseEase
parameter and is overridden by the spring
stiffness
value.
Accepts
A
Number
between
0
and
1000
Default
80
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
releaseStiffness
:
20
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
releaseStiffness
:
300
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
releaseMass
releaseDamping

=== DOC: 124_then.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/then
Timeline

Callbacks
Since 4.0.0
then()
V4
Returns a
Promise
that resolves and execute a callback when the timeline completes.
The
then
()
method can be directly inlined like this:
createTimeline
(parameters).
add
(targets, parameters).
then
(callback);
Or used in an
async
/
await
context:
async
function
waitForTimelineToComplete
(
) {
return
createTimeline
()
.
add
(
'.square'
, {
x
:
100
})
.
add
(
'.square'
, {
y
:
100
});
}
const
asyncTimeline =
await
waitForTimelineToComplete
();
Parameters
Name
Type
callback
A
Function
whose first argument returns the timeline itself
Returns
Promise
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loop
:
1
,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
})
.
add
(
'.square'
, {
x
:
'15rem'
});
tl.
then
(
() =>
$value.
textContent
=
'fulfilled'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
promise status
</
span
>
<
span
class
=
"value"
>
pending
</
span
>
</
pre
>
</
div
>
Previous
Next
onPause
Timeline methods

=== DOC: 125_stop.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/stop
Draggable

Methods
Since 4.0.0
stop()
Stop all currently running animations targeting the draggable, the container scroll animation and the draggable release animation.
Returns
The draggable itself
import
{ createDraggable, animate, utils }
from
'animejs'
;
const
[ $stopButton ] = utils.$(
'.stop'
);
const
draggable =
createDraggable
(
'.square'
);
animate
(draggable, {
x
: [-
100
,
100
],
alternate
:
true
,
loop
:
true
});
const
stopDraggable
= (
) => draggable.
stop
();
$stopButton.
addEventListener
(
'click'
, stopDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button stop"
>
Stop
</
button
>
</
fieldset
>
</
div
>
Previous
Next
scrollInView()
reset()

=== DOC: 126_animatable-properties.txt ===
URL: https://animejs.com/documentation/animatable/animatable-properties
Animatable
Since 4.0.0
Animatable properties
const
animatable =
createAnimatable
(targets, parameters);
┌───────────┐
animatable.│targets    ├─
Properties
animatable.│animations │
└───────────┘
Name
Description
targets
Gets the animatable
Targets
(
Array
)
animations
Gets all animatable
Animations
(
Object
)
Previous
Next
Animatable methods
Draggable

=== DOC: 127_onenterbackward.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onenterbackward
ScrollObserver

Callbacks
Since 4.0.0
onEnterBackward
Triggers a function every time the
enter
threshold
is met by scrolling backward.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
entered =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onEnterBackward
:
() =>
$value.
textContent
= ++entered,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
entered
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onEnterForward
onLeave

=== DOC: 128_pause.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/pause
Animation

Methods
Since 1.0.0
pause()
Pauses a running animation.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $pauseButton ] = utils.$(
'.pause'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
alternate
:
true
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
pauseAnimation
= (
) => animation.
pause
();
$pauseButton.
addEventListener
(
'click'
, pauseAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button pause"
>
Pause
</
button
>
</
fieldset
>
</
div
>
Previous
Next
reverse()
restart()

=== DOC: 129_label.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/label
Timeline

Methods
Since 4.0.0
label()
V4
Associate specific time positions with label names for easy reference within the timeline.
Once added to a timeline, a label can be used as a
Time position
.
timeline.
label
(labelName, position);
Parameters
Name
Accepts
labelName
String
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
()
.
label
(
'circle'
,
0
)
.
label
(
'square'
,
500
)
.
label
(
'triangle'
,
1000
)
.
add
(
'.square'
, {
x
:
'17rem'
,
duration
:
500
,
},
'square'
)
.
add
(
'.circle'
, {
x
:
'13rem'
,
duration
:
1000
,
},
'circle'
)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
500
,
},
'triangle'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
sync()
remove()

=== DOC: 130_root.txt ===
URL: https://animejs.com/documentation/scope/scope-parameters/root
Scope

Parameters
Since 4.0.0
root
Defines a root element limiting all DOM queries within that Scope to descendants of the specified
HTMLElement
. This is particularly useful for creating self-contained animation environments in component-based architectures like React applications.
Accepts
CSS Selector
DOM Element
import
{ createScope, animate }
from
'animejs'
;
createScope
({
root
:
'.row:nth-child(2)'
})
.
add
(
() =>
{
animate
(
'.square'
, {
x
:
'17rem'
,
loop
:
true
,
alternate
:
true
});
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
outside scope
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
inside scope
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
outside scope
</
div
>
</
div
>
Previous
Next
Scope parameters
defaults

=== DOC: 131_maxvelocity.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/maxvelocity
Draggable

Settings
Since 4.0.0
maxVelocity
Specifies the maximum velocity to apply to the dragged element after release.
Accepts
A
Number
greater than or equal to
0
A
Function
that returns a
Number
greater than or equal to
0
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
50
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
maxVelocity
:
0
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
maxVelocity
:
100
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
minVelocity
releaseEase

=== DOC: 132_relative-position-values.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-thresholds/relative-position-values
ScrollObserver

Thresholds
Since 4.0.0
Relative position values
Defines position values relative to the target and container top coordinate using a a
Relative value
syntax.
Accepts
Prefix
Effect
Example
'+='
Add
'+=45'
'-='
Subtracts
'-=50%'
'*='
Multiply
'*=.5'
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'center+=1em top-=100%'
,
leave
:
'center-=1em bottom+=100%'
,
debug
:
true
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Positions shorthands
Min max

=== DOC: 133_playback-progress.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes/playback-progress
ScrollObserver

Synchronisation modes
Since 4.0.0
Playback progress
Perfectly synchronises the playback progress of the linked object to the scroll position by passing a value of either
true
or
1
.
Accepts
1
true
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Method names
Smooth scroll

=== DOC: 134_animatable.txt ===
URL: https://animejs.com/documentation/animatable
Animatable
V4
Efficiently animates target properties, making it an ideal replacement for
animate
()
and
utils.
set
()
in situations where values change frequently, such as cursor events or animation loops.
Animatables are created using the
createAnimatable
()
function.
import
{ createAnimatable }
from
'animejs'
;
const
animatable =
createAnimatable
(targets, parameters);
Parameters
Name
Accepts
targets
Targets
parameters
An
Object
of
Animatable settings
Returns
An Animatable instance with animatable property functions used to
get
and
set
values:
animatable.
propertyName
(value, duration, ease);
// Triggers an animation
animatable.
propertyName
();
// Returns the current value
For performance reasons, only
Number
or
Array
<
Number
>
can be passed to an animatable property function.
import
{ createAnimatable, utils }
from
'animejs'
;
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
$demo = $demos.
querySelector
(
'.docs-demo.is-active'
);
let
bounds = $demo.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $demo.
getBoundingClientRect
();
const
animatableSquare =
createAnimatable
(
'.square'
, {
x
:
500
,
// Define the x duration to be 500ms
y
:
500
,
// Define the y duration to be 500ms
ease
:
'out(3)'
,
});
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
hw = width /
2
;
const
hh = height /
2
;
const
x = utils.
clamp
(e.
clientX
- left - hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- top - hh, -hh, hh);
animatableSquare.
x
(x);
// Animate the x value in 500ms
animatableSquare.
y
(y);
// Animate the y value in 500ms
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"small centered row"
>
<
span
class
=
"label"
>
Move cursor around
</
span
>
</
div
>
In this section
Settings
Methods
Properties
Previous
Next
Timeline
Animatable settings

=== DOC: 135_onloop.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onloop
Timeline

Callbacks
Since 4.0.0
onLoop
V4
Executes a function every time a timeline iteration completes.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onLoop
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
loops =
0
;
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loopDelay
:
500
,
loop
:
true
,
onLoop
:
self
=>
$value.
textContent
= ++loops
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
})
.
add
(
'.square'
, {
x
:
'15rem'
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onRender
onPause

=== DOC: 136_onleave.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onleave
ScrollObserver

Callbacks
Since 4.0.0
onLeave
Triggers a function every time the
leave
threshold
is met.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
exits =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
true
,
debug
:
true
,
onLeave
:
() =>
$value.
textContent
= ++exits,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
exits
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onEnterBackward
onLeaveForward

=== DOC: 137_seek.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/seek
Animation

Methods
Since 1.0.0
seek()
Updates the
currentTime
of the animation and advances it to a specific time.
animation.
seek
(time, muteCallbacks);
Parameters
Name
Type
Description
time
Number
The new
currentTime
in ms of the animation
muteCallbacks=false
(opt)
Boolean
If
true
, prevent the callbacks from being fired
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $playPauseButton ] = utils.$(
'.play-pause'
);
const
updateButtonLabel
= animation => {
$playPauseButton.
textContent
= animation.
paused
?
'Play'
:
'Pause'
;
}
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
duration
:
1750
,
delay
:
stagger
(
250
),
autoplay
:
false
,
onUpdate
:
self
=>
{
$range.
value
= self.
currentTime
;
updateButtonLabel
(self);
},
onComplete
: updateButtonLabel,
});
const
seekAnimation
= (
) => animation.
seek
(+$range.
value
);
const
playPauseAnimation
= (
) => {
if
(animation.
paused
) {
animation.
play
();
}
else
{
animation.
pause
();
updateButtonLabel
(animation);
}
}
$range.
addEventListener
(
'input'
, seekAnimation);
$playPauseButton.
addEventListener
(
'click'
, playPauseAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
2000
value
=
0
class
=
"range"
/>
<
button
style
=
"flex: 0.25;"
class
=
"button play-pause"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
revert()
stretch()

=== DOC: 138_min-max.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-thresholds/min-max
ScrollObserver

Thresholds
Since 4.0.0
Min max
Defines a threshold in the minimum or maximum scrollable space available. This is particularly useful in cases where some of the targeted elements initial position are either too small or too big to triggers
enter
and
leave
conditions.
Accepts
Value
Description
'min'
The minimum value possible to meet the enter or leave condition
'max'
The maximum value possible to meet the enter or leave condition
import
{ animate, onScroll, utils }
from
'animejs'
;
utils.$(
'.square'
).
forEach
($square => {
animate
($square, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
sync
:
1
,
enter
:
'max bottom'
,
leave
:
'min top'
,
debug
:
true
})
});
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
Relative position values
ScrollObserver synchronisation modes

=== DOC: 139_resume.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/resume
Animation

Methods
Since 1.0.0
resume()
V4
Resumes the playback of a paused animation in its current direction.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $pauseButton, $alternateButton, $resumeButton ] = utils.$(
'.button'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
pauseAnimation
= (
) => animation.
pause
();
const
alternateAnimation
= (
) => animation.
alternate
();
const
resumeAnimation
= (
) => animation.
resume
();
$pauseButton.
addEventListener
(
'click'
, pauseAnimation);
$alternateButton.
addEventListener
(
'click'
, alternateAnimation);
$resumeButton.
addEventListener
(
'click'
, resumeAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Pause
</
button
>
<
button
class
=
"button"
>
Alternate
</
button
>
<
button
class
=
"button"
>
Resume
</
button
>
</
fieldset
>
</
div
>
Previous
Next
alternate()
complete()

=== DOC: 140_getters.txt ===
URL: https://animejs.com/documentation/animatable/animatable-methods/getters
Animatable

Methods
Since 4.0.0
Getters
Every animatable properties defined in the animatable parameters are transformed into methods and accessible on the animatable object.
When calling a method without any argument, the method acts as a getter, and returns the current value of the animatable property.
Returns
A
Number
if the current animatable property has a single value
An
Array
of
Number
if the current animatable property has multiple values (like an RGB color value)
import
{ createAnimatable, utils }
from
'animejs'
;
const
$demos =
document
.
querySelector
(
'#docs-demos'
);
const
$demo = $demos.
querySelector
(
'.docs-demo.is-active'
);
const
[ $x, $y ] = utils.$(
'.coords'
);
let
bounds = $demo.
getBoundingClientRect
();
const
refreshBounds
= (
) => bounds = $demo.
getBoundingClientRect
();
const
circle =
createAnimatable
(
'.circle'
, {
x
:
500
,
y
:
500
,
ease
:
'out(2)'
,
});
// Gets and log the current x and y values
circle.
animations
.
x
.
onRender
=
() =>
{
$x.
innerHTML
= utils.
roundPad
(circle.
x
(),
2
);
$y.
innerHTML
= utils.
roundPad
(circle.
y
(),
2
);
}
const
onMouseMove
= e => {
const
{ width, height, left, top } = bounds;
const
hw = width /
2
;
const
hh = height /
2
;
const
x = utils.
clamp
(e.
clientX
- left - hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- top - hh, -hh, hh);
// Sets x and y values
circle.
x
(x);
circle.
y
(y);
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
$demos.
addEventListener
(
'scroll'
, refreshBounds);
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
x
</
span
>
<
span
class
=
"coords x value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"col"
style
=
"flex: .25; z-index: 3;"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
y
</
span
>
<
span
class
=
"coords y value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
span
class
=
"label"
>
Move cursor around
</
span
>
</
div
>
Previous
Next
Animatable methods
Setters

=== DOC: 141_animation-callbacks.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks
Animation
Since 1.0.0
Animation callbacks
Execute functions at specific points during an animation playback.
Callbacks
Function
are specified directly in the
animate
()
parameters
Object
.
animate
(
'.square'
, {
translateX
:
100
,
scale
:
2
,
opacity
:
.5
,
duration
:
400
,
delay
:
250
,
ease
:
'out(3)'
,
loop
:
3
,
alternate
:
true
,
autoplay
:
false
,
┌─────────────────────┐
│
onBegin
:
() =>
{},  │
│
onLoop
:
() =>
{},   ├─
Callbacks
│
onUpdate
:
() =>
{}, │
└─────────────────────┘
});
In this section
onBegin
onComplete
onBeforeUpdate
onUpdate
onRender
onLoop
onPause
then()
Previous
Next
Animation playback settings
onBegin

=== DOC: 142_dollar-sign.txt ===
URL: https://animejs.com/documentation/utilities/dollar-sign
Utilities
Since 4.0.0
$()
V4
Converts the provided targets parameter into an
Array
of elements, serving as an alternative to
document
.
querySelectorAll
()
.
When used within a
Scope
, it uses the Scope's
root
element instead of
document
, effectively calling
root.
querySelectorAll
()
.
const
targetsArray = utils.$(targets);
Parameters
Name
Accepts
targets
CSS selector
|
DOM Elements
Returns
An
Array
of
HTMLElement
or
SVGElement
or
SVGGeometryElement
import
{ utils, createScope }
from
'animejs'
;
// Targets all the '.square' elements
utils.$(
'.square'
).
forEach
($square => {
utils.
set
($square, {
scale
:
.5
});
});
createScope
({
root
:
'.row:nth-child(2)'
}).
add
(
() =>
{
// Limits the selection to '.row:nth-child(2) .square'
utils.$(
'.square'
).
forEach
($square => {
utils.
set
($square, {
rotate
:
45
});
});
});
<
div
class
=
"medium justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Utilities
get()

=== DOC: 143_interpolate.txt ===
URL: https://animejs.com/documentation/utilities/interpolate
Utilities
Since 4.0.0
interpolate()
V4
Interpolates a value between two numbers based on a given
progress
or creates an interpolation
Function
with pre-defined
start
and
end
parameters.
const
interpolatedValue = utils.
interpolate
(start, end, progress);
const
interpolatorFunction = utils.
interpolate
(start, end);
Parameters
Name
Accepts
start
Number
end
Number
progress
(opt)
Number
(
[
0
-
1
]
)
Returns
A
Number
if a progress value is provided, otherwise a
chain-able utility
Function
to interpolate between the specified
start
and
end
values:
const
interpolateBetween0and100 = utils.
interpolate
(
0
,
100
);
interpolateBetween0and100
(
0.5
);
// 50
interpolateBetween0and100
(
0.75
);
// 75
interpolateBetween0and100
(
0.25
);
// 25
const
interpolateAndRound = utils.
interpolate
(
0
,
100
).
round
(
2
);
// Interpolate then round to 2 decimal places
interpolateAndRound
(
0.677523
);
// 67.75
interpolateAndRound
(
1.202514
);
// 100
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'1turn'
,
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
animate
(
'.interpolated'
, {
rotate
:
'1turn'
,
modifier
: utils.
interpolate
(
0
,
12
),
// Interpolates 0 to 12 by passing the rotate progress value 0 to 1
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock interpolated"
>
</
div
>
<
div
class
=
"label"
>
interpolated [0,12]
</
div
>
</
div
>
</
div
>
Previous
Next
mapRange()
roundPad()

=== DOC: 144_utilities.txt ===
URL: https://animejs.com/documentation/utilities
Utilities
A collection of utility functions for common animation tasks and for use as
Animation modifier functions
.
All SVG utility functions are available on the
utils
object.
import
{ utils }
from
'animejs'
;
In this section
$()
get()
set()
remove()
cleanInlineStyles()
random()
randomPick()
shuffle()
sync()
lerp()
round()
clamp()
snap()
wrap()
mapRange()
interpolate()
roundPad()
padStart()
padEnd()
degToRad()
radToDeg()
Chain-able utilities
Previous
Next
SVG
$()

=== DOC: 145_playback-loopdelay.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/playback-loopdelay
Animation

Playback settings
Since 4.0.0
loopDelay
V4
JS
Defines the delay in milliseconds between loops.
Accepts
A
Number
that is equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loopDelay
=
500
;
import
{ animate }
from
'animejs'
;
const
loopDelayAnimation =
animate
(
'.circle'
, {
x
:
'16rem'
,
scale
: {
to
:
1.8
,
delay
:
500
,
duration
:
500
,
},
loopDelay
:
1000
,
loop
:
true
,
alternate
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
Previous
Next
loop
alternate

=== DOC: 146_when-to-use-waapi.txt ===
URL: https://animejs.com/documentation/web-animation-api/when-to-use-waapi
Web Animation API
Since 4.0.0
When to use WAAPI
The Web Animations API (WAAPI) offers a lot of advantages over JavaScript
requestAnimationFrame
(RAF) powered animations, but both have their strengths and downsides, and depending on the type of animation or the context in which an animation is created, it's not always possible or even recommended to use WAAPI over RAF.
Prioritize
waapi.
animate
()
when:
Animating during CPU/network load (see the
hardware-accelerated animations
section)
Initial page load time is critical and every KB counts (3KB gzip vs 10KB for the JavaScript version)
Animating complex CSS values not correctly handled by the JavaScript version, like CSS transform matrixes or CSS color functions.
Use
animate
()
when:
Animating a large amount of targets (> 500)
Animating JS/canvas/WebGL/WebGPU
Animating SVG, DOM attributes or CSS properties not handled by the Web Animation API
Animating complex timelines and keyframes
You need more
control methods
You need more advanced
callback functions
import
{ animate, waapi, utils }
from
'animejs'
;
// WAAPI Animation
waapi.
animate
(
'.waapi.square'
, {
x
:
'17rem'
,
rotate
:
180
,
loop
:
3
,
alternate
:
true
,
});
// JS Animation
const
data = {
x
:
'0rem'
,
rotate
:
'0deg'
}
const
[ $log ] = utils.$(
'code'
);
animate
(data, {
x
:
17
,
rotate
:
180
,
modifier
: utils.
round
(
0
),
loop
:
3
,
alternate
:
true
,
onRender
:
() =>
$log.
innerHTML
=
JSON
.
stringify
(data)
});
<
div
class
=
"medium row"
>
<
div
class
=
"square waapi"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
</
div
>
<
pre
class
=
"medium centered row"
>
<
code
>
{"x": '0rem',"rotate":"0deg"}
</
code
>
</
pre
>
Previous
Next
Web Animation API
Hardware-accelerated animations

=== DOC: 147_add.txt ===
URL: https://animejs.com/documentation/scope/scope-methods/add
Scope

Methods
Since 4.0.0
add()
Adds
constructor
or registers
method
functions to a Scope.
Parameters for adding a constructor
scope.
add
(callback);
Name
Accepts
callback
A
constructor
Function
Parameters for registering a method
scope.
add
(name, callback);
Name
Accepts
name
A
String
used to store and access the method
callback
A
method
Function
Returns
The Scope itself
import
{ createScope, createAnimatable, createDraggable }
from
'animejs'
;
const
scope =
createScope
({
mediaQueries
: {
isSmall
:
'(max-width: 200px)'
,
}
})
.
add
(
self
=>
{
const
[ $circle ] = utils.$(
'.circle'
);
if
(self.
matches
.
isSmall
) {
$circle.
classList
.
add
(
'draggable'
);
self.
circle
=
createDraggable
($circle, {
container
:
document
.
body
,
});
}
else
{
$circle.
classList
.
remove
(
'draggable'
);
self.
circle
=
createAnimatable
($circle, {
x
:
500
,
y
:
500
,
ease
:
'out(3)'
});
}
let
win = {
w
:
window
.
innerWidth
,
h
:
window
.
innerHeight
};
self.
add
(
'refreshBounds'
,
() =>
{
win.
w
=
window
.
innerWidth
;
win.
h
=
window
.
innerHeight
;
});
self.
add
(
'onMouseMove'
,
e
=>
{
if
(self.
matches
.
isSmall
)
return
;
const
{ w, h } = win;
const
hw = w /
2
;
const
hh = h /
2
;
const
x = utils.
clamp
(e.
clientX
- hw, -hw, hw);
const
y = utils.
clamp
(e.
clientY
- hh, -hh, hh);
if
(self.
circle
.
x
) {
self.
circle
.
x
(x);
self.
circle
.
y
(y);
}
});
self.
add
(
'onPointerDown'
,
e
=>
{
const
{ isSmall } = self.
matches
;
animate
($circle, {
scale
: [
{
to
: isSmall ?
1.25
:
.25
,
duration
: isSmall ?
50
:
150
},
{
to
:
1
,
duration
: isSmall ?
250
:
500
},
]
});
});
});
window
.
addEventListener
(
'resize'
, scope.
methods
.
refreshBounds
);
window
.
addEventListener
(
'mousemove'
, scope.
methods
.
onMouseMove
);
document
.
addEventListener
(
'pointerdown'
, scope.
methods
.
onPointerDown
);
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
Scope methods
revert()

=== DOC: 148_playbackrate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/playbackrate
Timeline

Playback settings
Since 4.0.0
playbackRate
V4
Defines a speed multiplier to speed up or slow down a timeline.
This value can be modified later with
timeline.
speed
=
.5
.
Accepts
A
Number
greater than or equal to
0
If set to
0
the timeline won't play.
Default
1
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
playbackRate
=
.75
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $speed ] = utils.$(
'.speed'
);
const
tl =
createTimeline
({
playbackRate
:
2
,
loop
:
true
,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
const
updateSpeed
= (
) => {
const
speed = utils.
roundPad
(+$range.
value
,
1
);
$speed.
innerHTML
= speed;
utils.
sync
(
() =>
tl.
speed
= speed);
}
$range.
addEventListener
(
'input'
, updateSpeed);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
speed
</
span
>
<
span
class
=
"speed value"
>
2.0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
10
value
=
2
step
=
.1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
frameRate
playbackEase

=== DOC: 149_range-value.txt ===
URL: https://animejs.com/documentation/stagger/stagger-value-types/range-value
Stagger

Value types
Since 2.0.0
Range value
Distributes values evenly between two numerical values.
Accepts
[
Number
|
String
,
Number
|
String
]
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
y
:
stagger
([
'2.75rem'
,
'-2.75rem'
]),
delay
:
stagger
([
0
,
500
]),
});
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Numerical value
Stagger parameters

=== DOC: 150_then.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/then
Timer

Callbacks
Since 4.0.0
then()
Returns a
Promise
that resolves and execute a callback when the timer completes.
The
then
()
method can be directly inlined like this:
createTimer
({
duration
:
500
}).
then
(callback);
Or used in an
async
/
await
context:
async
function
waitForTimerToComplete
(
) {
return
createTimer
({
duration
:
250
})
}
const
asyncTimer =
await
waitForTimerToComplete
();
Parameters
Name
Type
callback
A
Function
whose first argument returns the timer itself
Returns
Promise
import
{ createTimer, utils }
from
'animejs'
;
const
[ $status ] = utils.$(
'.status'
);
const
[ $time ] = utils.$(
'.time'
);
createTimer
({
duration
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
,
})
.
then
(
() =>
$status.
innerHTML
=
'fulfilled'
);
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
promise status
</
span
>
<
span
class
=
"status value"
>
pending
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
onPause
Timer methods

=== DOC: 151_ease.txt ===
URL: https://animejs.com/documentation/animatable/animatable-settings/ease
Animatable

Settings
Since 4.0.0
ease
Determines the easing function for the transition to the animated value of the property.
Accepts
ease
Default
'outQuad'
It is recommended to use an
out
type easing function to achieve interesting results.
in
type easing functions start with changes that are too subtle to be noticeable.
import
{ createAnimatable, utils, stagger }
from
'animejs'
;
const
clock1 =
createAnimatable
(
'.clock-1'
, {
rotate
: {
unit
:
'rad'
},
ease
:
'linear'
,
});
const
clock2 =
createAnimatable
(
'.clock-2'
, {
rotate
: {
unit
:
'rad'
},
ease
:
'outElastic'
,
});
const
rotateClock
= (
animatable
) => {
const
PI
=
Math
.
PI
;
let
angle =
PI
/
2
;
let
lastAngle =
0
;
return
e
=>
{
const
[ $clock ] = animatable.
targets
;
const
{ width, height, left, top } = $clock.
getBoundingClientRect
();
const
x = e.
clientX
- left - width /
2
;
const
y = e.
clientY
- top - height /
2
;
const
currentAngle =
Math
.
atan2
(y, x);
const
diff = currentAngle - lastAngle;
angle += diff >
PI
? diff -
2
*
PI
: diff < -
PI
? diff +
2
*
PI
: diff;
lastAngle = currentAngle;
animatable.
rotate
(angle);
}
}
const
rotateClock1 =
rotateClock
(clock1);
const
rotateClock2 =
rotateClock
(clock2);
const
onMouseMove
= e => {
rotateClock1
(e);
rotateClock2
(e);
}
window
.
addEventListener
(
'mousemove'
, onMouseMove);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock clock-1"
>
</
div
>
<
div
class
=
"label"
>
linear
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock clock-2"
>
</
div
>
<
div
class
=
"label"
>
outElastic
</
div
>
</
div
>
</
div
>
Previous
Next
duration
modifier

=== DOC: 152_onresize.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onresize
Draggable

Callbacks
Since 4.0.0
onResize
Executes a function when either the container or the dragged target sizes change.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
resizes =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onResize
:
self
=>
{
$value.
textContent
= ++resizes;
}
});
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
resizes
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onSettle
onAfterResize

=== DOC: 153_minvelocity.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/minvelocity
Draggable

Settings
Since 4.0.0
minVelocity
Specifies the minimum velocity to apply to the dragged element after release.
Accepts
A
Number
greater than or equal to
0
A
Function
that returns a
Number
greater than or equal to
0
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
0
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
minVelocity
:
0
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
minVelocity
:
10
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
velocityMultiplier
maxVelocity

=== DOC: 154_play.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/play
Timeline

Methods
Since 2.0.0
play()
Forces the timeline to play forward.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $playButton ] = utils.$(
'.play'
);
const
tl =
createTimeline
({
autoplay
:
false
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
playTimeline
= (
) => tl.
play
();
$playButton.
addEventListener
(
'click'
, playTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
init()
reverse()

=== DOC: 155_releasecontainerfriction.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/releasecontainerfriction
Draggable

Settings
Since 4.0.0
releaseContainerFriction
Overrides the
containerFriction
applied to the dragged element when threw out of bounds on release, where
0
means no friction at all and
1
prevents the element from going past the container bounds.
Accepts
A
Number
greater than or equal to
0
and lower than or equal to
1
A
Function
that returns a
Number
greater than or equal to
0
and lower than or equal to
1
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
The
containerFriction
value
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
releaseContainerFriction
:
0
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
releaseContainerFriction
:
1
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
containerFriction
releaseMass

=== DOC: 156_shuffle.txt ===
URL: https://animejs.com/documentation/utilities/shuffle
Utilities
Since 4.0.0
shuffle()
V4
Mutates an array by randomizing the order of its elements.
const
shuffledArray = utils.
shuffle
(array);
Parameters
Name
Accepts
array
Array
Returns
The mutated
Array
import
{ utils }
from
'animejs'
;
const
[ $shuffle ] = utils.$(
'button'
);
const
squares = utils.$(
'.square'
);
const
x =
stagger
(
'3.2rem'
);
// Initial squares x position
utils.
set
(squares, { x });
const
shuffle
= (
) =>
animate
(utils.
shuffle
(squares), { x });
$shuffle.
addEventListener
(
'click'
, shuffle);
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
A
</
div
>
<
div
class
=
"square"
>
B
</
div
>
<
div
class
=
"square"
>
C
</
div
>
<
div
class
=
"square"
>
D
</
div
>
<
div
class
=
"square"
>
E
</
div
>
<
div
class
=
"square"
>
F
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
>
Shuffle
</
button
>
</
fieldset
>
</
div
>
Previous
Next
randomPick()
sync()

=== DOC: 157_reversed.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/reversed
Timeline

Playback settings
Since 4.0.0
reversed
Defines the initial direction of the timeline.
Accepts
Boolean
If set to
true
the animation plays backwards
If set to
false
the animation plays forwards
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
reversed
=
true
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $time ] = utils.$(
'.time'
);
const
tl =
createTimeline
({
reversed
:
true
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
alternate
autoplay

=== DOC: 158_framerate.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/framerate
Timer

Playback settings
Since 4.0.0
frameRate
Determines the frames per second (fps) at which a timer runs.
This value can be modified later with
timer.
fps
=
30
.
Accepts
A
Number
greater than
0
The frame rate is capped to the monitor refresh rate or in some cases by the browser itself.
Default
120
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
frameRate
=
30
;
import
{ createTimer, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $fps ] = utils.$(
'.fps'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
frameRate
:
60
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
,
});
const
updateFps
= (
) => {
const
{ value } = $range;
$fps.
innerHTML
= value;
timer.
fps
= value;
}
$range.
addEventListener
(
'input'
, updateFps);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
fps
</
span
>
<
span
class
=
"fps value"
>
60
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
120
value
=
60
step
=
1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
autoplay
playbackRate

=== DOC: 159_chain-able-utility-functions.txt ===
URL: https://animejs.com/documentation/utilities/chain-able-utility-functions
Utilities
Since 4.0.0
Chain-able utility functions
V4
Chain-able utility functions allow for the creation of complex operations by combining multiple functions in a single expression.
const
clampRoundPad = utils.
clamp
(
0
,
100
).
round
(
2
).
padStart
(
6
,
'0'
);
clampRoundPad
(
125
)
// '000100'
clampRoundPad
(
75.25
)
// '075.25'
The following utility functions support chaining:
round
()
clamp
()
snap
()
wrap
()
mapRange
()
interpolate
()
roundPad
()
padStart
()
padEnd
()
degToRad
()
radToDeg
()
Chain-able functions works great in combinaison with the
modifier
tween parameter.
Usage
Chain-able functions are created when calling a utility function without its optional value parameter:
const
chainableClamp = utils.
clamp
(
0
,
100
);
// Returns a chain-able function
const
result =
chainableClamp
(
150
);
// 100
Chaining
Chain-able functions are combined like this:
const
normalizeAndRound = utils.
mapRange
(
0
,
255
,
0
,
1
).
round
(
1
);
normalizeAndRound
(
128
);
// '0.5'
normalizeAndRound
(
64
);
// '0.3'
import
{ animate, utils }
from
'animejs'
;
animate
(
'.value'
, {
innerHTML
:
1000
,
modifier
: utils.
wrap
(
0
,
10
).
roundPad
(
3
).
padStart
(
6
,
'0'
),
duration
:
100000
,
alternate
:
true
,
loop
:
true
,
ease
:
'linear'
,
});
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
radToDeg()
Web Animation API

=== DOC: 160_defaults.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/defaults
Timeline

Playback settings
Since 2.0.0
defaults
V4
Defines defaults parameters for the timeline children.
Accepts
An
Object
of
Tween parameters
(except
from
and
to
),
Playback settings
and
Callbacks
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
({
defaults
: {
ease
:
'inOutExpo'
,
duration
:
500
,
loop
:
2
,
reversed
:
true
,
alternate
:
true
,
}
})
.
add
(
'.square'
, {
x
:
'15rem'
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Timeline playback settings
delay

=== DOC: 161_clamp.txt ===
URL: https://animejs.com/documentation/utilities/clamp
Utilities
Since 4.0.0
clamp()
V4
Restricts a
Number
between the specified
min
and
max
values or creates a clamping
Function
with pre-defined
min
and
max
parameters.
const
clampedValue = utils.
clamp
(value, min, max);
const
clamperFunction = utils.
clamp
(min, max);
Parameters
Name
Accepts
value
(opt)
Number
min
Number
max
Number
Returns
A
Number
if a value is provided, otherwise a
chain-able utility
Function
to clamp numbers between the specified
min
and
max
values:
const
clampBetween0and100 = utils.
clamp
(
0
,
100
);
clampBetween0and100
(
90
);
// 90
clampBetween0and100
(
120
);
// 100
clampBetween0and100
(-
15
);
// 0
const
clampAndRound = utils.
clamp
(
0
,
100
).
round
(
2
);
// Clamp then round to 2 decimal places
clampAndRound
(
72.7523
);
// 72.75
clampAndRound
(
120.2514
);
// 100
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'1turn'
,
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
animate
(
'.clamped'
, {
rotate
:
'1turn'
,
modifier
: utils.
clamp
(
.25
,
.75
),
// Used as a function
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock clamped"
>
</
div
>
<
div
class
=
"label"
>
clamped [.25,.75]
</
div
>
</
div
>
</
div
>
Previous
Next
round()
snap()

=== DOC: 162_imports.txt ===
URL: https://animejs.com/documentation/getting-started/imports
Getting started
Imports
V4
Anime.js v4 API exposes the following modules:
Import methods
ES Modules
To import
Anime.js
using the ES Modules syntax, you can use the
import
statement as shown below:
import
{
animate,
createTimeline,
createTimer,
// ...other methods
}
from
'animejs'
;
Global object
You can define
Anime.js
globally using a script tag like this:
<
script
src
=
"path/to/anime.iife.min.js"
>
</
script
>
Then access all the modules directly from
anime
object:
anime.
animate
();
anime.
createTimeline
();
anime.
createTimer
();
// ...other methods
Or you can mimic the ESM import syntax by using the
object destructuring
syntax like this:
const
{
animate,
createTimeline,
createTimer,
// ...other methods
} = anime;
Previous
Next
Installation
Using with vanilla JS

=== DOC: 163_animation.txt ===
URL: https://animejs.com/documentation/animation
Animation
Animates the properties values of targeted elements, with a wide range of parameters, callbacks and methods.
Animations are created using the
animate
()
method.
import
{ animate }
from
'animejs'
;
const
animation =
animate
(targets, parameters);
Parameters
Name
Accepts
targets
Targets
parameters
An
Object
of
Animatable properties
,
Tween parameters
,
Playback settings
and
Animation callbacks
Returns
JSAnimation
WAAPI powered animations
Anime.js provides a more lightweight (3KB) version of the
animate
()
method (10KB) powered by the
Web Animation API
.
import
{ waapi }
from
'animejs'
;
const
animation = waapi.
animate
(targets, parameters);
The WAAPI version has less features overall, but covers most of the basic API.
Features only available in the JavaScript version are indicated with a (
JS
) badge and WAAPI specific features are indicated with a (
WAAPI
) badge
To know more about when to use the WAAPI version and its potential pitfalls, please refer to the
Web Animations API Guide
.
import
{ animate }
from
'animejs'
;
animate
(
'span'
, {
// Property keyframes
y
: [
{
to
:
'-2.75rem'
,
ease
:
'outExpo'
,
duration
:
600
},
{
to
:
0
,
ease
:
'outBounce'
,
duration
:
800
,
delay
:
100
}
],
// Property specific parameters
rotate
: {
from
:
'-1turn'
,
delay
:
0
},
delay
:
(
_, i
) =>
i *
50
,
// Function based value
ease
:
'inOutCirc'
,
loopDelay
:
1000
,
loop
:
true
});
<
h2
class
=
"large grid centered square-grid text-xl"
>
<
span
>
H
</
span
>
<
span
>
E
</
span
>
<
span
>
L
</
span
>
<
span
>
L
</
span
>
<
span
>
O
</
span
>
<
span
>
&nbsp;
</
span
>
<
span
>
W
</
span
>
<
span
>
O
</
span
>
<
span
>
R
</
span
>
<
span
>
L
</
span
>
<
span
>
D
</
span
>
</
h2
>
In this section
Targets
Animatable properties
Tween value types
Tween parameters
Keyframes
Playback settings
Callbacks
Methods
Properties
Previous
Next
Timer
Targets

=== DOC: 164_onupdate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onupdate
Timeline

Callbacks
Since 4.0.0
onUpdate
Executes a function on every frames of a running timeline at the specified
frameRate
.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onUpdate
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
updates =
0
;
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loopDelay
:
250
,
loop
:
true
,
onUpdate
:
self
=>
$value.
textContent
= ++updates
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'+=250'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'+=250'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onBeforeUpdate
onRender

=== DOC: 165_containerfriction.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/containerfriction
Draggable

Settings
Since 4.0.0
containerFriction
Specifies the friction applied to the dragged element when going out of bounds, where
0
means no friction at all and
1
prevents the element from going past the container bounds.
Accepts
A
Number
greater than or equal to
0
and lower than or equal to
1
A
Function
that returns a
Number
greater than or equal to
0
and lower than or equal to
1
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
0.8
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
containerFriction
:
0
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
containerFriction
:
1
,
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
containerPadding
releaseContainerFriction

=== DOC: 166_engine-methods.txt ===
URL: https://animejs.com/documentation/engine/engine-methods
Engine
Since 4.0.0
Engine methods
import
{ engine }
from
'animejs'
;
┌──────────┐
engine.│
update
()  │
engine.│
pause
()   ├─
Methods
engine.│
resume
()  │
└──────────┘
In this section
update()
pause()
resume()
Previous
Next
Engine parameters
update()

=== DOC: 167_stretch.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/stretch
Timeline

Methods
Since 4.0.0
stretch()
V4
Changes the total duration of a timeline and its children to fit a specific time.
The total duration is equal to the duration of an iteration multiplied with the total number of iterations. So if the timeline is 1000ms and loops twice (3 iterations in total), the total duration will be 3000ms (1000 * 3).
timeline.
stretch
(duration);
Parameters
Name
Type
Description
duration
Number
The new total duration in ms of the timeline
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $totalDuration ] = utils.$(
'.value'
);
const
tl =
createTimeline
({
loop
:
1
,
alternate
:
true
,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
stretchTimeline
= (
) => {
const
newDuration = +$range.
value
;
$totalDuration.
textContent
= newDuration;
tl.
stretch
(newDuration).
restart
();
}
stretchTimeline
();
$range.
addEventListener
(
'input'
, stretchTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
total duration
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium centered row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
100
max
=
2000
value
=
1000
step
=
100
class
=
"seek range"
/>
</
fieldset
>
</
div
>
Previous
Next
seek()
refresh()

=== DOC: 168_clean-inline-styles.txt ===
URL: https://animejs.com/documentation/utilities/clean-inline-styles
Utilities
Since 4.0.0
cleanInlineStyles()
V4
Removes all CSS inline styles added by the specified instance.
Can be used as a Animation or Timeline
onComplete
()
callback.
const
cleanedInstance = utils.
cleanInlineStyles
(instance);
Parameters
Name
Accepts
instance
Animation
|
Timeline
Returns
The passed
Animation
or
Timeline
instance.
import
{ animate, utils }
from
'animejs'
;
utils.
set
(
'.square'
, {
scale
:
.75
});
animate
(
'.keep-styles'
, {
x
:
'23rem'
,
borderRadius
:
'50%'
,
});
animate
(
'.clean-styles'
, {
x
:
'23rem'
,
borderRadius
:
'50%'
,
// This removes the translateX and borderRadius inline styles
// But keeps the scale previously added outside of this animation
onComplete
: utils.
cleanInlineStyles
});
<
div
class
=
"medium row"
>
<
div
class
=
"square keep-styles"
>
</
div
>
<
div
class
=
"padded label"
>
Keep styles (default)
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square clean-styles"
>
</
div
>
<
div
class
=
"padded label"
>
Clean translateX and borderRadius
</
div
>
</
div
>
Previous
Next
remove()
random()

=== DOC: 169_modifier.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/modifier
Animation

Tween parameters
Since 4.0.0
modifier
V4
JS
A
Function
that modifies or alters the behavior of the animated numerical value. Modifiers can be set globally for all animation properties or locally for a specific property. If the final animated value contains strings, like units (
'100px'
), the string part is automatically added to the final value before being applied to the element.
Most
Utilities
functions can be used as modifiers.
Accepts
A
Function
with the following parameters:
Parameters
Name
Description
value
The current animated numerical value
Must returns
Number
Default
null
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
modifier
=
v
=>
-v;
// Don't do this :D
import
{ animate, utils }
from
'animejs'
;
animate
(
'.row:nth-child(1) .square'
, {
x
:
'17rem'
,
modifier
: utils.
round
(
0
),
// Round to 0 decimals
duration
:
4000
,
});
animate
(
'.row:nth-child(2) .square'
, {
x
:
'85rem'
,
modifier
:
v
=>
v %
17
,
duration
:
4000
,
});
animate
(
'.row:nth-child(3) .square'
, {
x
:
'17rem'
,
y
: {
to
:
'70rem'
,
modifier
:
v
=>
Math
.
cos
(v) /
2
,
// Specific modifier to y property
},
duration
:
4000
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
utils.round(0)
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
v => v % 17
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
v => Math.cos(v) / 2
</
div
>
</
div
>
Previous
Next
composition
Keyframes

=== DOC: 170_containerpadding.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/containerpadding
Draggable

Settings
Since 4.0.0
containerPadding
Specifies the container's padding in pixels.
Accepts
Number
Array
<
Number
>
(
[top, right, bottom, left]
)
A
Function
that returns
Array
<
Number
>
(
[top, right, bottom, left]
)
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
0
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
containerPadding
: [
16
,
32
, -
16
,
64
],
// top, right, bottom, left
scrollThreshold
:
0
,
});
<
div
class
=
"large centered padded show-bounds grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
container
containerFriction

=== DOC: 171_onrender.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onrender
Animation

Callbacks
Since 4.0.0
onRender
V4
JS
Executes a function every time an animation renders something on the screen, this means that no rendering is happening when the
currentTime
is inside the
delay
or
loopDelay
time frames.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onRender
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $rendersLog ] = utils.$(
'.value'
);
let
renders =
0
;
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loopDelay
:
1500
,
loop
:
true
,
alternate
:
true
,
onRender
:
self
=>
$rendersLog.
textContent
= ++renders
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
renders
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onUpdate
onLoop

=== DOC: 172_seek.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/seek
Timer

Methods
Since 4.0.0
seek()
Updates the
currentTime
of the timer and advances it to a specific time.
timer.
seek
(time, muteCallbacks);
Parameters
Name
Type
Description
time
Number
The new
currentTime
in ms of the timer
muteCallbacks=false
(opt)
Boolean
If
true
, prevent the callbacks from being fired
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $playPauseButton ] = utils.$(
'.play-pause'
);
const
[ $time ] = utils.$(
'.time'
);
const
updateButtonLabel
= timer => {
$playPauseButton.
textContent
= timer.
paused
?
'Play'
:
'Pause'
;
}
const
timer =
createTimer
({
duration
:
2000
,
autoplay
:
false
,
onUpdate
:
self
=>
{
$range.
value
= self.
currentTime
;
$time.
innerHTML
= self.
currentTime
;
updateButtonLabel
(self);
},
onComplete
: updateButtonLabel,
});
const
seekTimer
= (
) => timer.
seek
(+$range.
value
);
const
playPauseTimer
= (
) => {
if
(timer.
paused
) {
timer.
play
();
}
else
{
timer.
pause
();
updateButtonLabel
(timer);
}
}
$range.
addEventListener
(
'input'
, seekTimer);
$playPauseButton.
addEventListener
(
'click'
, playPauseTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
2000
value
=
0
class
=
"range"
/>
<
button
style
=
"flex: 0.25;"
class
=
"button play-pause"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
revert()
stretch()

=== DOC: 173_oncomplete.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/oncomplete
Timer

Callbacks
Since 4.0.0
onComplete
Executes a function when all the iterations (
loop
) of a timer have finished playing.
Accepts
A
Function
whose first argument returns the timer itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onComplete
=
self
=>
console
.
log
(self.
id
);
import
{ createTimer, utils }
from
'animejs'
;
const
[ $status ] = utils.$(
'.status'
);
const
[ $time ] = utils.$(
'.time'
);
createTimer
({
duration
:
2000
,
onComplete
:
self
=>
$status.
innerHTML
=
'true'
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
completed
</
span
>
<
span
class
=
"status value"
>
false
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
onBegin
onUpdate

=== DOC: 174_keyframes.txt ===
URL: https://animejs.com/documentation/animation/keyframes
Animation
Since 2.0.0
Keyframes
Create a sequence of animations on the same animatable property.
Property value keyframes
Specific to an animated property, these keyframes are passed to the property value directly:
animate
(
'.square'
, {
┌───────────────────┐
│
x
: [
0
,
100
,
200
], ├─
Tween
Values
Array
│
y
: [
0
,
100
,
200
], │
└───────────────────┘
duration
:
3000
,
}
animate
(
'.square'
, {
┌────────────────────────────┐
│
x
: [{
to
:
100
}, {
to
:
200
}], ├─
Tween
Parameters
Array
│
y
: [{
to
:
100
}, {
to
:
200
}], │
└────────────────────────────┘
duration
:
3000
,
}
Animation keyframes
Defined at the animation level, these keyframes can animate multiple properties per keyframe:
animate
(
'.square'
, {
┌───────────────────────┐
│
keyframes
: [          │
│   {
x
:
100
,
y
:
100
}, ├─
Duration
Based
│   {
x
:
200
,
y
:
200
}, │
│ ],                    │
└───────────────────────┘
duration
:
3000
,
}
animate
(
'.square'
, {
┌───────────────────────────────┐
│
keyframes
: {                  │
│
'0%'
: {
x
:
0
,
y
:
0
}, │
│
'50%'
: {
x
:
100
,
y
:
100
}, ├─
Percentage
Based
│
'100%'
: {
x
:
200
,
y
:
200
}, │
│ },                            │
└───────────────────────────────┘
duration
:
3000
,
}
In this section
Tween values
Tween parameters
Duration based
Percentage based
Previous
Next
Tween parameters
Tween values keyframes

=== DOC: 175_mediaqueries.txt ===
URL: https://animejs.com/documentation/scope/scope-parameters/mediaqueries
Scope

Parameters
Since 4.0.0
mediaQueries
Defines the media queries to match for conditionally refreshing the
Scope
when one of their matches state changes.
Media queries matching states are accessible via the scope
matches
property.
Accepts
An
Object
where
key
is an arbitrary name
String
for the media query.
Value
is the media query definition
String
.
import
{ createScope, animate }
from
'animejs'
;
createScope
({
mediaQueries
: {
isSmall
:
'(max-width: 100px)'
,
isMedium
:
'(min-width: 101px) and (max-width: 200px)'
,
isLarge
:
'(min-width: 201px)'
,
reduceMotion
:
'(prefers-reduced-motion)'
,
}
})
.
add
(
self
=>
{
const
{ isSmall, isMedium, isLarge, reduceMotion } = self.
matches
;
utils.
set
(
'.square'
, {
scale
: isMedium ?
.75
: isLarge ?
1
:
.5
});
animate
(
'.square'
, {
x
: isSmall ?
0
: [
'-35vw'
,
'35vw'
],
y
: isSmall ? [
'-40vh'
,
'40vh'
] :
0
,
rotate
:
360
,
loop
:
true
,
alternate
:
true
,
duration
: reduceMotion ?
0
: isSmall ?
750
:
1250
});
});
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
defaults
Scope methods

=== DOC: 176_scrollobserver-properties.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-properties
ScrollObserver
Since 4.0.0
scrollObserver properties
const
scrollObserver =
onScroll
(parameters);
┌───────┐
scrollObserver.│target │
scrollObserver.│linked ├─
Properties
scrollObserver.│repeat │
└───────┘
Name
Description
id
Gets the unique identifier for the ScrollObserver instance (
Number
)
container
Gets the scroll container associated with this observer (
ScrollContainer
)
target
Gets the target element being observed (
HTMLElement
)
linked
Gets the linked object (
Animation
|
Timer
|
Timeline
)
repeat
Gets whether the observer should repeat (
Boolean
)
horizontal
Gets whether the scroll direction is horizontal (
Boolean
)
enter
Gets the enter threshold (
String
|
Number
)
leave
Gets and sets the leave threshold (
String
|
Number
)
sync
Gets whether synchronisation is enabled (
Boolean
)
velocity
Gets the current scroll velocity (
Number
)
backward
Gets whether the scroll direction is backward (
Boolean
)
scroll
Gets the current scroll position (
Number
)
progress
Gets the current progress of the observed element (0 to 1) (
Number
)
completed
Gets whether the observation has completed (
Boolean
)
began
Gets whether the observation has begun (
Boolean
)
isInView
Gets whether the observed element is currently in view (
Boolean
)
offset
Gets the offset of the observed element (
Number
)
offsetStart
Gets the start offset of the observed element (
Number
)
offsetEnd
Gets the end offset of the observed element (
Number
)
distance
Gets the scroll distance for the observed element (
Number
)
Previous
Next
ScrollObserver methods
Scope

=== DOC: 177_round.txt ===
URL: https://animejs.com/documentation/utilities/round
Utilities
Since 4.0.0
round()
Rounds a
Number
to a specified number of decimal places or creates a rounding
Function
with a pre-defined
decimalLength
parameter.
const
roundedValue = utils.
round
(value, decimalLength);
const
roundingFunction = utils.
round
(decimalLength);
Parameters
Name
Accepts
value
(opt)
Number
decimalLength
Number
Returns
A
Number
if a value is provided, otherwise a
chain-able utility
Function
to round numbers with the specified decimal length:
const
clampAndRound = utils.
clamp
(
0
,
100
).
round
(
2
);
// Clamp then round to 2 decimal places
clampAndRound
(
72.7523
);
// 72.75
clampAndRound
(
120.2514
);
// 100
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'1turn'
,
duration
:
3000
,
loop
:
true
,
});
animate
(
'.rounded'
, {
rotate
:
'1turn'
,
modifier
: utils.
round
(
1
),
// Used as a function
duration
:
3000
,
loop
:
true
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock rounded"
>
</
div
>
<
div
class
=
"label"
>
rounded (.1)
</
div
>
</
div
>
</
div
>
Previous
Next
lerp()
clamp()

=== DOC: 178_timer-playback-settings.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings
Timer
Since 4.0.0
Timer playback settings
Specify the timings and behaviours of a timer.
Playback settings properties are defined directly in the
createTimer
()
parameters
Object
.
createTimer
({
┌───────────────────┐
│
duration
:
1000
,   │
│
frameRate
:
true
,  ├─
Playback
Settings
│
loop
:
true
,       │
└───────────────────┘
onBegin
:
() =>
{},
onLoop
:
() =>
{},
onUpdate
:
() =>
{},
});
In this section
delay
duration
loop
loopDelay
alternate
reversed
autoplay
frameRate
playbackRate
Previous
Next
Timer
delay

=== DOC: 179_stagger.txt ===
URL: https://animejs.com/documentation/stagger
Stagger
Creates sequential effects by distributing values progressively across multiple targets.
Stagger
Function based values
are created using
stagger
()
function.
import
{ stagger }
from
'animejs'
;
const
functionValue =
stagger
(value, parameters);
Parameters
Name
Accepts
value
Stagger value
parameters
(opt)
Stagger parameters
Returns
Function based value
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'17rem'
,
scale
:
stagger
([
1
,
.1
]),
delay
:
stagger
(
100
),
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
In this section
Time staggering
Values staggering
Timeline staggering
Value types
Parameters
Previous
Next
Scope
Time staggering

=== DOC: 180_multi-targets-animation.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/multi-targets-animation
Web Animation API

Improvements to WAAPI
Since 4.0.0
Multi-targets animation
Targets one or multiple DOM Elements using a CSS selector, allowing animating multiple targets in one single
animate
()
call and support of the
stagger
()
method.
Syntax comparison
Anime.js
waapi.
animate
(
'.circle'
, {
translate
:
'100px'
,
delay
:
stagger
(
100
),
});
WAAPI equivalent
document
.
querySelectorAll
(
'.circle'
).
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
'100px'
,
}, {
duration
:
1000
,
delay
: i *
100
,
easing
:
'ease-out'
,
}).
finished
.
then
(
() =>
{
$el.
style
.
translate
=
'100px'
;
})
});
Accepts
Any
String
accepted by
document
.
querySelectorAll
()
import
{ waapi, stagger }
from
'animejs'
;
waapi.
animate
(
'.circle'
, {
translate
:
'17rem'
,
delay
:
stagger
(
100
),
loop
:
true
,
alternate
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
Previous
Next
Sensible defaults
Default units

=== DOC: 181_timeline.txt ===
URL: https://animejs.com/documentation/timeline
Timeline
Synchronises animations, timers, and functions together.
Timelines are created using the
createTimeline
()
function.
import
{ createTimeline }
from
'animejs'
;
const
timeline =
createTimeline
(parameters);
Parameters
Name
Accepts
parameters
(opt)
An
Object
of
Timeline playback settings
and
Timeline callbacks
Returns
A Timeline instance with various
methods
used to add animations, timers, callback functions and labels to it:
timeline.
add
(target, animationParameters, position);
timeline.
add
(timerParameters, position);
timeline.
sync
(timelineB, position);
timeline.
call
(callbackFunction, position);
timeline.
label
(labelName, position);
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
({
defaults
: {
duration
:
750
} });
tl.
label
(
'start'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
500
)
.
add
(
'.circle'
, {
x
:
'15rem'
},
'start'
)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
rotate
:
'1turn'
},
'<-=500'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
In this section
Add timers
Add animations
Sync WAAPI animations
Sync timelines
Call functions
Time position
Playback settings
Callbacks
Methods
Properties
Previous
Next
Animation
Add timers

=== DOC: 182_setx.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/setx
Draggable

Methods
Since 4.0.0
setX()
Manually set the
x
position of the draggable target.
Is equivalent updating
draggable.
x
directly when no
muteCallback
parameter is defined.
Parameters
Name
Type
Description
x
Number
The new x value
muteCallback
(opt)
Boolean
If
true
, prevents the
onUpdate
callback to fire (default
false
)
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $setButton ] = utils.$(
'.set'
);
const
draggable =
createDraggable
(
'.square'
);
const
setRandomX
= (
) => draggable.
setX
(utils.
random
(-
100
,
100
));
$setButton.
addEventListener
(
'click'
, setRandomX);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button set"
>
Set random x
</
button
>
</
fieldset
>
</
div
>
Previous
Next
enable()
setY()

=== DOC: 183_refresh.txt ===
URL: https://animejs.com/documentation/scope/scope-methods/refresh
Scope

Methods
Since 4.0.0
refresh()
Reverts
the Scope and rebuild it by calling every
constructor functions
.
Internally,
refresh
()
is called every time a media query state changes.
Returns
The Scope itself
import
{ utils, stagger, createScope, createTimeline }
from
'animejs'
;
const
[ $button1, $button2 ] = utils.$(
'.refresh'
);
const
scopeConstructor
= scope => {
const
circles = utils.$(
'.circle'
);
if
(scope.
i
===
undefined
|| scope.
i
> circles.
length
-
1
) scope.
i
=
0
;
const
i = scope.
i
++;
utils.
set
(circles, {
opacity
:
stagger
([
1
,
.25
], {
from
: i,
ease
:
'out(3)'
}),
});
createTimeline
()
.
add
(circles, {
scale
: [{
to
: [
.5
,
1
],
duration
:
250
}, {
to
:
.5
,
duration
:
750
}],
duration
:
750
,
loop
:
true
,
},
stagger
(
50
, {
from
: i }))
.
seek
(
750
)
}
const
scope1 =
createScope
({
root
:
'.row-1'
}).
add
(scopeConstructor);
const
scope2 =
createScope
({
root
:
'.row-2'
}).
add
(scopeConstructor);
const
refreshScope1
= (
) => scope1.
refresh
();
const
refreshScope2
= (
) => scope2.
refresh
();
$button1.
addEventListener
(
'click'
, refreshScope1);
$button2.
addEventListener
(
'click'
, refreshScope2);
<
div
class
=
"medium justified row row-1"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium justified row row-2"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button refresh"
>
Refresh row 1
</
button
>
<
button
class
=
"button refresh"
>
Refresh row 2
</
button
>
</
fieldset
>
</
div
>
Previous
Next
revert()
Scope properties

=== DOC: 184_cancel.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/cancel
Timer

Methods
Since 4.0.0
cancel()
Pauses the timer, removes it from the engine's main loop, and frees up memory.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $playButton ] = utils.$(
'.play'
);
const
[ $cancelButton ] = utils.$(
'.cancel'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
playTimer
= (
) => timer.
play
();
const
cancelTimer
= (
) => timer.
cancel
();
$playButton.
addEventListener
(
'click'
, playTimer);
$cancelButton.
addEventListener
(
'click'
, cancelTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button play"
>
Play
</
button
>
<
button
class
=
"button cancel"
>
Cancel
</
button
>
</
fieldset
>
</
div
>
Previous
Next
complete()
revert()

=== DOC: 185_autoplay.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/autoplay
Timeline

Playback settings
Since 2.0.0
autoplay
Defines the play mode of a timeline.
Accepts
Boolean
|
onScroll
()
If set to
true
the timeline plays automatically
If set to
false
the timeline has to be manually played
If set to
onScroll
()
the timeline will starts when the
scroll thresholds
conditions are met
Default
true
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
autoplay
=
false
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $paused ] = utils.$(
'.paused'
);
const
[ $play ] = utils.$(
'.play'
);
const
tl =
createTimeline
({
autoplay
:
false
,
onUpdate
:
self
=>
$paused.
innerHTML
= !!self.
paused
,
onComplete
:
self
=>
$paused.
innerHTML
= !!self.
paused
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
const
playTl
= (
) => tl.
paused
? tl.
restart
() : tl.
play
();
$play.
addEventListener
(
'click'
, playTl);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
paused
</
span
>
<
span
class
=
"paused value"
>
true
</
span
>
</
pre
>
</
div
>
<
div
class
=
"large row controls"
>
<
button
class
=
"play"
>
Play
</
button
>
</
div
>
Previous
Next
reversed
frameRate

=== DOC: 186_onrelease.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onrelease
Draggable

Callbacks
Since 4.0.0
onRelease
Executes a function when the element is released after a grab.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
releases =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onRelease
:
() =>
$value.
textContent
= ++releases
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
releases
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
onUpdate
onSnap

=== DOC: 187_dom-elements.txt ===
URL: https://animejs.com/documentation/animation/targets/dom-elements
Animation

Targets
Since 1.0.0
DOM Elements
Targets one or multiple DOM Elements.
Accepts
HTMLElement
SVGElement
SVGGeometryElement
NodeList
import
{ animate }
from
'animejs'
;
const
$demo =
document
.
querySelector
(
'#selector-demo'
);
const
$squares = $demo.
querySelectorAll
(
'.square'
);
animate
($demo, {
scale
:
.75
});
animate
($squares, {
x
:
'23rem'
});
<
div
id
=
"selector-demo"
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
Previous
Next
CSS Selector
JavaScript Objects

=== DOC: 188_onupdate.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onupdate
Draggable

Callbacks
Since 4.0.0
onUpdate
Executes a function every time the position of the dragged element changes.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
updates =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onUpdate
:
() =>
$value.
textContent
= ++updates
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
onDrag
onRelease

=== DOC: 189_percentage-based-keyframes.txt ===
URL: https://animejs.com/documentation/animation/keyframes/percentage-based-keyframes
Animation

Keyframes
Since 4.0.0
Percentage based keyframes
V4
JS
Sequences multiple
Animatable properties
with positions defined from a percentage of the animation total duration.
This syntax is very similar to the CSS
@keyframes
syntax and only exposes control over the
ease
parameter for each individual keyframes.
The first keyframe defines the
from value
of the tween.
keyframes
: {
'25%'
: {
x
:
100
,
y
:
50
,
ease
:
'out'
},
'50%'
: {
x
:
200
,
y
:
75
, },
}
Accepts
An
Object
where
keys
are
String
representing the percentages
values
are an
Object
containing at least one
Animatable properties
and an optional
ease
parameter.
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
keyframes
: {
'0%'
: {
x
:
'0rem'
,
y
:
'0rem'
,
ease
:
'out'
},
'13%'
: {
x
:
'0rem'
,
y
:
'-2.5rem'
, },
'37%'
: {
x
:
'17rem'
,
y
:
'-2.5rem'
,
scale
:
.5
},
'63%'
: {
x
:
'17rem'
,
y
:
'2.5rem'
,
scale
:
.5
},
'87%'
: {
x
:
'0rem'
,
y
:
'2.5rem'
,
scale
:
1
},
'100%'
: {
y
:
'0rem'
,
ease
:
'in'
}
},
rotate
: {
to
:
360
,
ease
:
'linear'
},
duration
:
3000
,
ease
:
'inOut'
,
// ease applied between each keyframes if no ease defined
playbackEase
:
'ouIn(5)'
,
// ease applied accross all keyframes
loop
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Duration based keyframes
Animation playback settings

=== DOC: 190_refresh.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/refresh
Timeline

Methods
Since 4.0.0
refresh()
V4
Re-computes the timeline children animated values defined with a
Function based value
by updating their
from
values to their current target values, and their
to
values to their newly computed values.
Only the animatable properties values are re-calculated,
duration
and
delay
cannot be refreshed.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $refreshButton ] = utils.$(
'.refresh'
);
const
tl =
createTimeline
({
loop
:
true
,
onLoop
:
self
=>
self.
refresh
()
})
.
add
(
'.circle'
,   {
x
:
() =>
utils.
random
(
0
,
15
) +
'rem'
},
0
)
.
add
(
'.triangle'
, {
x
:
() =>
utils.
random
(
0
,
15
) +
'rem'
},
0
)
.
add
(
'.square'
,   {
x
:
() =>
utils.
random
(
0
,
15
) +
'rem'
},
0
);
const
refreshTimeline
= (
) => tl.
refresh
().
restart
();
$refreshButton.
addEventListener
(
'click'
, refreshTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button refresh"
>
Refresh & Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
stretch()
Timeline properties

=== DOC: 191_pause.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/pause
Timeline

Methods
Since 2.0.0
pause()
Pauses a running timeline.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $pauseButton ] = utils.$(
'.pause'
);
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
pauseTimeline
= (
) => tl.
pause
();
$pauseButton.
addEventListener
(
'click'
, pauseTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button pause"
>
Pause
</
button
>
</
fieldset
>
</
div
>
Previous
Next
reverse()
restart()

=== DOC: 192_web-animation-api.txt ===
URL: https://animejs.com/documentation/web-animation-api
Web Animation API
V4
Create WAAPI powered animations with the simplicity of Anime.js
Anime.js offers a even more lightweight alternative (3KB versus 10KB) to the
animate
()
method that uses the Web Animation
Element
.
animate
()
API under the hood.
WAAPI powered animations are created using the
waapi.
animate
()
method.
import
{ waapi }
from
'animejs'
;
const
animation = waapi.
animate
(targets, parameters);
Parameters
Name
Accepts
targets
Targets
parameters
An
Object
of
Animatable properties
,
Tween parameters
,
Playback settings
and
Animation callbacks
Returns
WAAPIAnimation
import
{ waapi, stagger }
from
'animejs'
;
waapi.
animate
(
'span'
, {
translate
:
`0 -2rem`
,
delay
:
stagger
(
100
),
duration
:
600
,
loop
:
true
,
alternate
:
true
,
ease
:
'inOut(2)'
,
});
<
h2
class
=
"large grid centered square-grid text-xl"
>
<
span
>
H
</
span
>
<
span
>
E
</
span
>
<
span
>
L
</
span
>
<
span
>
L
</
span
>
<
span
>
O
</
span
>
<
span
>
&nbsp;
</
span
>
<
span
>
W
</
span
>
<
span
>
A
</
span
>
<
span
>
A
</
span
>
<
span
>
P
</
span
>
<
span
>
I
</
span
>
</
h2
>
In this section
When to use
Hardware-acceleration
Improvements to WAAPI
API differences
convertEase()
Previous
Next
Utilities
When to use WAAPI

=== DOC: 193_reset.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/reset
Draggable

Methods
Since 4.0.0
reset()
Restores the draggable element to its initial position.
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $resetButton ] = utils.$(
'.reset'
);
const
draggable =
createDraggable
(
'.square'
);
const
resetDraggable
= (
) => draggable.
reset
();
$resetButton.
addEventListener
(
'click'
, resetDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button reset"
>
Reset
</
button
>
</
fieldset
>
</
div
>
Previous
Next
stop()
revert()

=== DOC: 194_timeline-properties.txt ===
URL: https://animejs.com/documentation/timeline/timeline-properties
Timeline
Timeline properties
const
timeline =
createTimeline
(parameters);
┌────────────┐
timeline.│labels      │
timeline.│currentTime ├─
Properties
timeline.│duration    │
└────────────┘
Name
Description
id
Gets and sets the ID of the timeline (
String
|
Number
)
labels
Gets and sets the map of time position labels of the timeline (
Object
)
currentTime
Gets and sets the global current time in ms of the timeline (
Number
)
iterationCurrentTime
Gets and sets the current iteration time in ms (
Number
)
deltaTime
Gets the time in ms elapsed between the current and previous frame (
Number
)
progress
Gets and sets the overall progress of the timeline from
0
to
1
(
Number
)
iterationProgress
Gets and sets the progress of the current iteration from
0
to
1
(
Number
)
currentIteration
Gets and sets the current iteration count (
Number
)
duration
Gets the total duration in ms of the timeline (
Number
)
speed
Gets and sets the speed multiplier of the timeline (
Number
)
fps
Gets and sets the fps of the timeline (
Number
)
paused
Gets and sets whether the timeline is paused (
Boolean
)
began
Gets and sets whether the timeline has started (
Boolean
)
completed
Gets and sets whether the timeline has completed (
Boolean
)
reversed
Gets and sets whether the timeline is reversed (
Boolean
)
Previous
Next
Timeline methods
Animatable

=== DOC: 195_individual-css-transforms.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/individual-css-transforms
Web Animation API

Improvements to WAAPI
Since 4.0.0
Individual CSS transforms
Unlike CSS animations or native WAAPI, the CSS
transform
property can be animated by specifying individual properties.
This allows a greater level of control over how to animate individual transform properties.
Individual transforms with
WAAPI
only works for browsers that support
CSS
.
registerProperty
(propertyDefinition)
, and fallback to no animations.
Individual transforms cannot be
hardware-accelerated
.
Valid individual CSS transforms properties
Name
Shorthand
Default Value
Default Unit
translateX
x
'0px'
'px'
translateY
y
'0px'
'px'
translateZ
z
'0px'
'px'
rotate
—
'0deg'
'deg'
rotateX
—
'0deg'
'deg'
rotateY
—
'0deg'
'deg'
rotateZ
—
'0deg'
'deg'
scale
—
'1'
—
scaleX
—
'1'
—
scaleY
—
'1'
—
scaleZ
—
'1'
—
skew
—
'0deg'
'deg'
skewX
—
'0deg'
'deg'
skewY
—
'0deg'
'deg'
import
{ waapi, utils }
from
'animejs'
;
const
$squares = utils.$(
'.square'
);
const
animateSquares
= (
) => {
waapi.
animate
($squares, {
x
:
() =>
utils.
random
(
0
,
17
) +
'rem'
,
y
:
() =>
utils.
random
(-
1
,
1
) +
'rem'
,
rotateX
:
() =>
utils.
random
(-
90
,
90
),
rotateY
:
() =>
utils.
random
(-
90
,
90
),
onComplete
:
() =>
animateSquares
()
});
}
animateSquares
();
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Function based values
Individual property parameters

=== DOC: 196_scrollspeed.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/scrollspeed
Draggable

Settings
Since 4.0.0
scrollSpeed
Specifies a value that affects the automatic scrolling speed of the container. The higher the value, the faster the scroll goes and
0
prevents the container from scrolling.
Accepts
A
Number
A
Function
that returns a
Number
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
1.5
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.scroll-container'
,
scrollSpeed
:
2
,
});
<
div
class
=
"scroll-container scroll-x scroll-y"
>
<
div
class
=
"scroll-content"
>
<
div
class
=
"large padded grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
scrollThreshold
cursor

=== DOC: 197_numerical-value.txt ===
URL: https://animejs.com/documentation/stagger/stagger-value-types/numerical-value
Stagger

Value types
Since 2.0.0
Numerical value
Represents by how much each staggered value is incremented by.
Accepts
Number
String
containing at least one
Number
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
// Increase translateX by 5.75rem for each elements
x
:
stagger
(
'5.75rem'
),
// Increase delay by 100ms for each elements
delay
:
stagger
(
100
)
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 0rem      delay: 0ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 5.75rem   delay: 100ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 11.5rem   delay: 200ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 17.25rem  delay: 300ms
</
div
>
</
div
>
Previous
Next
Stagger value types
Range value

=== DOC: 198_iterations.txt ===
URL: https://animejs.com/documentation/web-animation-api/api-differences-with-native-waapi/iterations
Web Animation API

API differences
Since 4.0.0
iterations
The
iterations
parameter is replaced by the
loop
parameter and determines how many times the animation will repeat instead of the total number of iterations.
iterations
loop
Effect
1
0
No repeat
3
2
Repeat twice
Infinity
Infinity
|
true
| -1
Repeat indefinitely
Syntax comparison
Anime.js
waapi.
animate
(
'.square'
, {
x
:
100
,
loop
:
3
});
WAAPI equivalent
const
targets =
document
.
querySelectorAll
(
'.square'
);
targets.
forEach
(
(
$el, i
) =>
{
$el.
animate
({
translate
:
'100px'
,
}, {
fill
:
'forwards'
,
duration
:
1000
,
iterations
:
4
})
});
Accepts
A
Number
[
0
,
Infinity
]
A
Boolean
where
true
is equivalent to
Infinity
and
false
doesn't loop
import
{ waapi, stagger }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
translate
:
'17rem'
,
loop
:
3
,
alternate
:
true
,
delay
:
stagger
(
100
)
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
API differences with native WAAPI
direction

=== DOC: 199_snap.txt ===
URL: https://animejs.com/documentation/utilities/snap
Utilities
Since 4.0.0
snap()
V4
Rounds a
Number
to the nearest specified
increment
or creates a snapping
Function
with a pre-defined
increment
parameter.
If an
Array
is provided as the increment, it selects the closest value from the array.
const
snappedValue = utils.
snap
(value, increment);
const
snapperFunction = utils.
snap
(increment);
Parameters
Name
Accepts
value
(opt)
Number
increment
Number
|
Array
<
Number
>
Returns
A
Number
if a value is provided, otherwise a
chain-able utility
Function
to snap numbers to the nearest
increment
or array value:
const
snapTo10 = utils.
snap
(
10
);
snapTo10
(
94
);
// 90
snapTo10
(-
17
);
// -20
const
snapToArray = utils.
snap
([
0
,
50
,
100
]);
snapToArray
(
30
);
// 50
snapToArray
(
75
);
// 100
snapToArray
(-
10
);
// 0
const
clampAndSnap = utils.
clamp
(
0
,
100
).
snap
(
30
);
clampAndSnap
(
72.7523
);
// 60
clampAndSnap
(
120.2514
);
// 90
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'1turn'
,
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
animate
(
'.snapped'
, {
rotate
:
'1turn'
,
modifier
: utils.
snap
(
.25
),
// Used as a modifier
duration
:
3000
,
loop
:
true
,
ease
:
'inOut'
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock snapped"
>
</
div
>
<
div
class
=
"label"
>
snapped (.25)
</
div
>
</
div
>
</
div
>
Previous
Next
clamp()
wrap()

=== DOC: 200_scrollthreshold.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/scrollthreshold
Draggable

Settings
Since 4.0.0
scrollThreshold
Specifies the number of pixels the draggable element must cross beyond the area bounds before the container starts scrolling automatically.
Accepts
A
Number
A
Function
that returns a
Number
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
20
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.scroll-container'
,
scrollThreshold
:
12
,
});
<
div
class
=
"scroll-container scroll-x scroll-y"
>
<
div
class
=
"scroll-content"
>
<
div
class
=
"large padded grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
dragSpeed
scrollSpeed

=== DOC: 201_delay.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/delay
Animation

Playback settings
Since 1.0.0
delay
Defines the default delay in milliseconds of the animation tweens.
Accepts
A
Number
equal or greater than
0
A
Function based value
that returns a
Number
equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
delay
=
500
;
import
{ animate }
from
'animejs'
;
const
playbackDelay =
animate
(
'.delay'
, {
x
:
'16rem'
,
scale
:
1.8
,
delay
:
500
,
// Global delay applied to all properties
loop
:
true
,
alternate
:
true
});
<
div
class
=
"medium row"
>
<
div
class
=
"circle delay"
>
</
div
>
</
div
>
Previous
Next
Animation playback settings
duration

=== DOC: 202_revert.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/revert
Animation

Methods
Since 4.0.0
revert()
V4
Cancels the animation, reverts all its animated values to their original state, cleanup the CSS inline styles, and reverts the linked
onScroll
()
instance if necessary.
Use
revert
()
when you want to completely stop and destroy an animation.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $revertButton ] = utils.$(
'.revert'
);
const
[ $restartButton ] = utils.$(
'.restart'
);
// Set an initial translateX value
utils.
set
(
'.square'
, {
x
:
'17rem'
});
const
animation =
animate
(
'.square'
, {
x
:
0
,
alternate
:
true
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
revertAnimation
= (
) => animation.
revert
();
const
restartAnimation
= (
) => animation.
restart
();
$revertButton.
addEventListener
(
'click'
, revertAnimation);
$restartButton.
addEventListener
(
'click'
, restartAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button revert"
>
Revert
</
button
>
<
button
class
=
"button restart"
>
Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
cancel()
seek()

=== DOC: 203_loop.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/loop
Animation

Playback settings
Since 1.0.0
loop
V4
Defines how many times an animation repeats.
Accepts
Value
Effect
Number
The number of loops in the range
[
0
,
Infinity
]
Infinity
Loop indefinitely
true
Equivalent to
Infinity
-
1
Equivalent to
Infinity
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loop
=
true
;
import
{ animate }
from
'animejs'
;
animate
(
'.loop'
, {
x
:
'17.5rem'
,
loop
:
3
,
});
animate
(
'.loop-alternate'
, {
x
:
'17.5rem'
,
loop
:
3
,
alternate
:
true
,
});
animate
(
'.loop-reverse'
, {
x
:
'17.5rem'
,
loop
:
3
,
reversed
:
true
,
});
animate
(
'.loop-infinity'
, {
x
:
'17.5rem'
,
loop
:
true
,
// Or Infinity
});
<
div
class
=
"small row"
>
<
div
class
=
"circle loop"
>
</
div
>
<
div
class
=
"padded label"
>
loop: 3
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"circle loop-alternate"
>
</
div
>
<
div
class
=
"padded label"
>
loop: 3, alternate: true
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"circle loop-reverse"
>
</
div
>
<
div
class
=
"padded label"
>
loop: 3, reversed: true
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"circle loop-infinity"
>
</
div
>
<
div
class
=
"padded label"
>
loop: true
</
div
>
</
div
>
Previous
Next
duration
loopDelay

=== DOC: 204_onloop.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onloop
Animation

Callbacks
Since 4.0.0
onLoop
V4
JS
Executes a function every time an animation iteration (
loop
) completes.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onLoop
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
loops =
0
;
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loopDelay
:
1500
,
loop
:
true
,
alternate
:
true
,
onLoop
:
self
=>
$value.
textContent
= ++loops
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onRender
onPause

=== DOC: 205_play.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/play
Timer

Methods
Since 4.0.0
play()
Forces the timer to play forward.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $playButton ] = utils.$(
'.play'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
duration
:
2000
,
autoplay
:
false
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
,
});
const
playTimer
= (
) => timer.
play
();
$playButton.
addEventListener
(
'click'
, playTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Timer methods
reverse()

=== DOC: 206_getting-started.txt ===
URL: https://animejs.com/documentation/getting-started
Getting started
This section covers how to download, install and import Anime.js in your project.
If you're migrating from v3, please check out the
migration guide
on GitHub.
In this section
Installation
Imports
Using with vanilla JS
Using with React
Previous
Next
Documentation
Installation

=== DOC: 207_scrollobserver-settings.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings
ScrollObserver
Since 4.0.0
ScrollObserver settings
ScrollObserver settings properties are defined directly in the
onScroll
()
parameters
Object
.
animate
(
'.square'
, {
x
:
100
,
autoplay
:
onScroll
({
┌──────────────────────────┐
│
container
:
'.container'
, │
│
target
:
'.section'
,      ├─
Settings
│
axis
:
'y'
,               │
└──────────────────────────┘
enter
:
'bottom top'
,
leave
:
'top bottom'
,
sync
:
true
,
onEnter
:
() =>
{},
onLeave
:
() =>
{},
onUpdate
:
() =>
{},
})
});
In this section
container
target
debug
axis
repeat
Previous
Next
ScrollObserver
container

=== DOC: 208_restart.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/restart
Animation

Methods
Since 1.0.0
restart()
Resets all properties and set the
currentTime
of an animation to
0
.
If the
autoplay
is set to
true
, the animation plays automatically.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $restartButton ] = utils.$(
'.restart'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
direction
:
'alternate'
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
)
});
const
restartAnimation
= (
) => animation.
restart
();
$restartButton.
addEventListener
(
'click'
, restartAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button restart"
>
Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
pause()
alternate()

=== DOC: 209_cancel.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/cancel
Animation

Methods
Since 4.0.0
cancel()
V4
Pauses the animation, removes it from the engine's main loop, and frees up memory.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $cancelButton ] = utils.$(
'.cancel'
);
const
[ $playButton ] = utils.$(
'.play'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
alternate
:
true
,
ease
:
'inOutSine'
,
loop
:
true
,
delay
:
stagger
(
100
),
});
const
cancelAnimation
= (
) => animation.
cancel
();
const
playAnimation
= (
) => animation.
play
();
$cancelButton.
addEventListener
(
'click'
, cancelAnimation);
$playButton.
addEventListener
(
'click'
, playAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button cancel"
>
Cancel
</
button
>
<
button
class
=
"button play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
complete()
revert()

=== DOC: 210_onbeforeupdate.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onbeforeupdate
Animation

Callbacks
Since 4.0.0
onBeforeUpdate
V4
JS
Executes a function before updating the tween values, on every frames of a running animation at the specified
frameRate
.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onBeforeUpdate
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
mult =
1
;
let
updates =
0
;
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loopDelay
:
1500
,
modifier
:
v
=>
mult * v,
loop
:
true
,
alternate
:
true
,
onBeforeUpdate
:
self
=>
{
$value.
textContent
= ++updates;
// Update the mult value just before updating the tweens
mult =
1
- self.
iterationProgress
;
}
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onComplete
onUpdate

=== DOC: 211_html-attributes.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/html-attributes
Animation

Animatable properties
Since 1.0.0
HTML Attributes
JS
Numerical and color HTML attributes can be passed directly to the animation parameters.
import
{ animate, utils }
from
'animejs'
;
animate
(
'input'
, {
value
:
1000
,
// animate the input "value" attribute
alternate
:
true
,
loop
:
true
,
modifier
: utils.
round
(
0
),
});
<
pre
class
=
"row large centered"
>
<
input
type
=
"range"
value
=
"0"
min
=
"0"
max
=
"1000"
/>
<
input
type
=
"text"
value
=
"0"
size
=
"5"
/>
</
pre
>
Previous
Next
JavaScript Object properties
SVG Attributes

=== DOC: 212_stagger-parameters.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters
Stagger
Since 2.0.0
Stagger parameters
stagger
(
'1rem'
,
{
┌───────────────────┐
│
start
:
100
,       │
│
from
:
2
,          │
│
reversed
:
false
,  ├─
Stagger
Parameters
│
ease
:
'outQuad'
,  │
│
grid
: [
8
,
8
],     │
└───────────────────┘
}
);
In this section
start value
from
reversed
ease
grid
axis
modifier
Previous
Next
Stagger value types
Stagger start

=== DOC: 213_css-selector.txt ===
URL: https://animejs.com/documentation/animation/targets/css-selector
Animation

Targets
Since 1.0.0
CSS Selector
Targets one or multiple DOM Elements using a CSS selector.
Accepts
Any
String
accepted by
document
.
querySelectorAll
()
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'17rem'
});
animate
(
'#css-selector-id'
, {
rotate
:
'1turn'
});
animate
(
'.row:nth-child(3) .square'
, {
scale
: [
1
,
.5
,
1
] });
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
id
=
"css-selector-id"
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Targets
DOM Elements

=== DOC: 214_play.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/play
Animation

Methods
Since 1.0.0
play()
Forces the animation to play forward.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $playButton ] = utils.$(
'.play'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
delay
:
stagger
(
100
),
autoplay
:
false
,
// The animation is paused by default
});
const
playAnimation
= (
) => animation.
play
();
$playButton.
addEventListener
(
'click'
, playAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Animation methods
reverse()

=== DOC: 215_reversed.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/reversed
Timer

Playback settings
Since 4.0.0
reversed
Sets the initial direction of the timer.
The timer
currentTime
always progresses from
0
to
duration
.
Only the
iterationTime
property is actually reversed.
Accepts
Boolean
If set to
true
the timer's first iteration runs in reverse
If set to
false
the timer's first iteration runs normally
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
reversed
=
true
;
import
{ animate }
from
'animejs'
;
const
[ $iterationTime ] = utils.$(
'.iteration-time'
);
const
[ $currentTime ] = utils.$(
'.current-time'
);
createTimer
({
duration
:
10000
,
reversed
:
true
,
onUpdate
:
self
=>
{
$iterationTime.
innerHTML
= self.
iterationCurrentTime
;
$currentTime.
innerHTML
= self.
currentTime
;
}
});
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"iteration-time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"current-time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
alternate
autoplay

=== DOC: 216_refresh.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-methods/refresh
ScrollObserver

Methods
Since 4.0.0
refresh()
Updates the bounding values, and re-compute the
Function based value
of a ScrollObserver instance.
The following parameters can be refreshed when set with a
Function based value
:
repeat
axis
enter
leave
No need to call
.
refresh
()
when the container size changes, this is already handled internally.
Returns
The ScrollObserver itself
import
{ animate, onScroll }
from
'animejs'
;
const
scrollSettings = {
enter
:
20
,
leave
:
60
,
}
const
animation =
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
() =>
`bottom-=
${scrollSettings.enter}
top`
,
leave
:
() =>
`top+=
${scrollSettings.leave}
bottom`
,
sync
:
.5
,
debug
:
true
,
})
});
animate
(scrollSettings, {
enter
:
90
,
leave
:
100
,
loop
:
true
,
alternate
:
true
,
modifier
: utils.
round
(
0
),
onUpdate
:
() =>
animation.
_autoplay
.
refresh
()
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
link()
revert()

=== DOC: 217_draggable-properties.txt ===
URL: https://animejs.com/documentation/draggable/draggable-properties
Draggable
Since 4.0.0
Draggable properties
const
draggable =
createDraggable
(target, parameters);
┌──────────┐
draggable.│progressX │
draggable.│progressY ├─
Properties
draggable.│velocity  │
└──────────┘
Name
Description
snapX
Gets and sets the snap value of the x axis (
Number
|
Array
<
Number
>
)
snapY
Gets and sets the snap value of the y axis (
Number
|
Array
<
Number
>
)
scrollSpeed
Gets and sets the speed value at which the draggable container auto scrolls (
Number
)
scrollThreshold
Gets and sets the threshold distance from container edges before auto-scrolling begins (
Number
)
dragSpeed
Gets and sets the speed value at which the draggable element gets dragged (
Number
)
maxVelocity
Gets and sets the maximum velocity limit for the draggable element (
Number
)
minVelocity
Gets and sets the minimum velocity limit for the draggable element (
Number
)
velocityMultiplier
Gets and sets the multiplier applied to velocity calculations (
Number
)
releaseEase
Gets and sets the easing function applied to the draggable element animations (
Function
)
releaseSpring
Gets the internal spring used to move the draggable element after release (
Spring
)
containerPadding
Gets and sets padding values for the container [top, right, bottom, left] (
Array
<
Number
>
)
containerFriction
Gets and sets the friction value applied within the container (
Number
)
containerBounds
Gets the bounds of the container [top, right, bottom, left] (
Array
<
Number
>
)
containerArray
Gets array of container elements if multiple containers were provided (
Array
<
HTMLElement
>|
null
)
$container
Gets and sets the container element (
HTMLElement
)
$target
Gets and sets the target element (
HTMLElement
)
$trigger
Gets the trigger element (
HTMLElement
)
$scrollContainer
Gets the scroll container (window or container element) (
Window
|
HTMLElement
)
x
Gets and sets the x position (
Number
)
y
Gets and sets the y position of the dragged element (
Number
)
progressX
Gets and sets the progress (0-1) of the x position relative to the container (
Number
)
progressY
Gets and sets the progress (0-1) of the y position relative to the container (
Number
)
velocity
Gets the current velocity of the draggable element (
Number
)
angle
Gets the current angle in radians of the draggable element (
Number
)
xProp
Gets the mapped x property name (
String
)
yProp
Gets the mapped y property name (
String
)
destX
Gets the currently defined destination of the x axis (
Number
)
destY
Gets the currently defined destination of the y axis (
Number
)
deltaX
Gets the current delta of the x axis (
Number
)
deltaY
Gets the current delta of the y axis (
Number
)
enabled
Returns
true
if the draggable is enabled (
Boolean
)
grabbed
Returns
true
if the element is currently being grabbed (
Boolean
)
dragged
Returns
true
if the element is currently being dragged (
Boolean
)
cursor
Gets and sets cursor behavior (
Boolean
|
DraggableCursorParams
)
disabled
Gets the disabled state for [x, y] axes (
Array
<
Number
>
)
fixed
Returns
true
if the target element has position:fixed (
Boolean
)
useWin
Returns
true
if using window as container (
Boolean
)
isFinePointer
Gets and sets whether fine pointer (e.g. mouse) is being used (
Boolean
)
initialized
Returns
true
if the draggable has been initialized (
Boolean
)
canScroll
Returns
true
if auto-scrolling is possible (
Boolean
)
contained
Returns
true
if draggable is contained within bounds (
Boolean
)
manual
Returns
true
if in manual control mode (
Boolean
)
released
Returns
true
if element was just released (
Boolean
)
updated
Returns
true
if position was just updated (
Boolean
)
scroll
Gets the current scroll position {x, y} (
Object
)
coords
Gets the current and previous coordinates [x, y, prevX, prevY] (
Array
<
Number
>
)
snapped
Gets the snap state for [x, y] axes (
Array
<
Number
>
)
pointer
Gets current and previous pointer positions [x, y, prevX, prevY] (
Array
<
Number
>
)
scrollView
Gets the scroll view dimensions [width, height] (
Array
<
Number
>
)
dragArea
Gets the drag area bounds [x, y, width, height] (
Array
<
Number
>
)
scrollBounds
Gets the scroll container bounds [top, right, bottom, left] (
Array
<
Number
>
)
targetBounds
Gets the target element bounds [top, right, bottom, left] (
Array
<
Number
>
)
window
Gets the window dimensions [width, height] (
Array
<
Number
>
)
pointerVelocity
Gets the current pointer velocity (
Number
)
pointerAngle
Gets the current pointer angle in radians (
Number
)
activeProp
Gets the active property being animated (
String
)
onGrab
Gets and sets the callback fired when element is grabbed (
Function
)
onDrag
Gets and sets the callback fired while dragging (
Function
)
onRelease
Gets and sets the callback fired on release (
Function
)
onUpdate
Gets and sets the callback fired on any position update (
Function
)
onSettle
Gets and sets the callback fired when movement settles (
Function
)
onSnap
Gets and sets the callback fired when element snaps (
Function
)
onResize
Gets and sets the callback fired when container/element resizes (
Function
)
onAfterResize
Gets and sets the callback fired after resize handling completes (
Function
)
Previous
Next
Draggable methods
ScrollObserver

=== DOC: 218_cancel.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/cancel
Timeline

Methods
Since 4.0.0
cancel()
V4
Pauses the timeline, removes it from the engine's main loop, and frees up memory.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $cancelButton ] = utils.$(
'.cancel'
);
const
[ $playButton ] = utils.$(
'.play'
);
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
cancelTimeline
= (
) => tl.
cancel
();
const
playTimeline
= (
) => tl.
play
();
$cancelButton.
addEventListener
(
'click'
, cancelTimeline);
$playButton.
addEventListener
(
'click'
, playTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button cancel"
>
Cancel
</
button
>
<
button
class
=
"button play"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
complete()
revert()

=== DOC: 219_call-functions.txt ===
URL: https://animejs.com/documentation/timeline/call-functions
Timeline
Since 4.0.0
Call functions
V4
Functions are added to a timeline with the
call
()
method.
timeline.
call
(callback, position);
Parameters
Name
Accepts
callback
Function
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $functionA ] = utils.$(
'.function-A'
);
const
[ $functionB ] = utils.$(
'.function-B'
);
const
[ $functionC ] = utils.$(
'.function-C'
);
const
tl =
createTimeline
()
.
call
(
() =>
$functionA.
innerHTML
=
'A'
,
0
)
.
call
(
() =>
$functionB.
innerHTML
=
'B'
,
800
)
.
call
(
() =>
$functionC.
innerHTML
=
'C'
,
1200
);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function A
</
span
>
<
span
class
=
"function-A value lcd"
>
--
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function B
</
span
>
<
span
class
=
"function-B value lcd"
>
--
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function C
</
span
>
<
span
class
=
"function-C value lcd"
>
--
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
Sync timelines
Time position

=== DOC: 220_oncomplete.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/oncomplete
Timeline

Callbacks
Since 4.0.0
onComplete
Executes a function when all the iterations (loops) of a timeline have finished playing.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onComplete
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loop
:
1
,
onComplete
:
self
=>
$value.
textContent
= self.
completed
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
})
.
add
(
'.square'
, {
x
:
'15rem'
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
completed
</
span
>
<
span
class
=
"value"
>
false
</
span
>
</
pre
>
</
div
>
Previous
Next
onBegin
onBeforeUpdate

=== DOC: 221_tween-parameters-keyframes.txt ===
URL: https://animejs.com/documentation/animation/keyframes/tween-parameters-keyframes
Animation

Keyframes
Since 2.0.0
Tween parameters keyframes
JS
Sequences multiple
Tween parameters
specific to an
Animatable property
.
This syntax allows very fine control over an animation by giving access to
ease
,
delay
,
duration
and
modifier
parameters for each individual keyframes.
The default
duration
of a keyframe equals the total animation duration divided by the total number of keyframes.
Accepts
An
Array
of
Tween parameters
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
x
: [
{
to
:
'17rem'
,
duration
:
700
,
delay
:
400
},
{
to
:
0
,
duration
:
700
,
delay
:
800
},
],
y
: [
{
to
:
'-2.5rem'
,
ease
:
'out'
,
duration
:
400
},
{
to
:
'2.5rem'
,
duration
:
800
,
delay
:
700
},
{
to
:
0
,
ease
:
'in'
,
duration
:
400
,
delay
:
700
},
],
scale
: [
{
to
:
.5
,
duration
:
700
,
delay
:
400
},
{
to
:
1
,
duration
:
700
,
delay
:
800
},
],
rotate
: {
to
:
360
,
ease
:
'linear'
},
duration
:
3000
,
ease
:
'inOut'
,
// ease applied between each keyframes if no ease defined
playbackEase
:
'ouIn(5)'
,
// ease applied accross all keyframes
loop
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Tween values keyframes
Duration based keyframes

=== DOC: 222_map-range.txt ===
URL: https://animejs.com/documentation/utilities/map-range
Utilities
Since 4.0.0
mapRange()
V4
Maps a
Number
from one range to another or creates a mapping
Function
with pre-defined ranges parameters.
const
mappedValue = utils.
mapRange
(value, fromLow, fromHigh, toLow, toHigh);
const
mapperFunction = utils.
mapRange
(fromLow, fromHigh, toLow, toHigh);
Parameters
Name
Accepts
value
(opt)
Number
fromLow
Number
fromHigh
Number
toLow
Number
toHigh
Number
Returns
A
Number
if a value is provided, otherwise a
chain-able utility
Function
to map numbers from one range to another:
const
mapFrom0and100to0and200 = utils.
mapRange
(
0
,
100
,
0
,
200
);
mapFrom0and100to0and200
(
45
);
// 90
mapFrom0and100to0and200
(
120
);
// 240
mapFrom0and100to0and200
(-
15
);
// -30
const
normalizeAndClamp = utils.
mapRange
(-
100
,
100
,
0
,
1
).
clamp
(
0
,
1
);
// Normalize then clamp between 0 and 1
normalizeAndClamp
(
50
);
// 0.75
normalizeAndClamp
(
120
);
// 1
import
{ animate, utils }
from
'animejs'
;
animate
(
'.normal'
, {
rotate
:
'12turn'
,
duration
:
12000
,
loop
:
true
,
ease
:
'inOut'
,
});
animate
(
'.mapped'
, {
rotate
:
'12turn'
,
modifier
: utils.
mapRange
(
0
,
12
,
0
,
1
),
// Used as a modifier
duration
:
12000
,
loop
:
true
,
ease
:
'inOut'
,
});
<
div
class
=
"x-large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"clock normal"
>
</
div
>
<
div
class
=
"label"
>
normal
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"clock mapped"
>
</
div
>
<
div
class
=
"label"
>
mapped [0,12] [0,1]
</
div
>
</
div
>
</
div
>
Previous
Next
wrap()
interpolate()

=== DOC: 223_playbackrate.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/playbackrate
Animation

Playback settings
Since 4.0.0
playbackRate
V4
Defines a speed multiplier to speed up or slow down an animation.
This value can be modified later with
animation.
speed
=
.5
.
Accepts
A
Number
greater than or equal to
0
If set to
0
the animation won't play.
Default
1
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
playbackRate
=
.75
;
import
{ animate, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $speed ] = utils.$(
'.speed'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loop
:
true
,
alternate
:
true
,
playbackRate
:
1
,
});
const
updateSpeed
= (
) => {
const
{ value } = $range;
$speed.
innerHTML
= utils.
roundPad
(+value,
2
);
utils.
sync
(
() =>
animation.
speed
= value);
}
$range.
addEventListener
(
'input'
, updateSpeed);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
speed
</
span
>
<
span
class
=
"speed value"
>
1.00
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
5
value
=
1
step
=
.01
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
frameRate
playbackEase

=== DOC: 224_releaseease.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/releaseease
Draggable

Settings
Since 4.0.0
releaseEase
Specifies a custom easing applied to the dragged element after release, a snap event, or repositioning when dragged out of bounds.
Accepts
ease
Passing
createSpring
()
overrides the draggable
releaseMass
,
releaseStiffness
and
releaseDamping
parameters. The
velocity
parameter of
createSpring
()
has no effect and is replaced with the actual velocity of the dragged element.
Default
eases.
outQuint
import
{ createDraggable, createSpring }
from
'animejs'
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
releaseEase
:
'outElastic'
,
});
createDraggable
(
'.circle'
, {
container
:
'.grid'
,
releaseEase
:
createSpring
({
stiffness
:
150
,
damping
:
15
,
})
});
<
div
class
=
"large centered grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
maxVelocity
dragSpeed

=== DOC: 225_onbeforeupdate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onbeforeupdate
Timeline

Callbacks
Since 4.0.0
onBeforeUpdate
Executes a function before updating the child animations values, on every frames of a running timeline at the specified
frameRate
.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onUpdate
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
updates =
0
;
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loopDelay
:
250
,
loop
:
true
,
onBeforeUpdate
:
self
=>
$value.
textContent
= ++updates
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'+=250'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'+=250'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onComplete
onUpdate

=== DOC: 226_revert.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/revert
Draggable

Methods
Since 4.0.0
revert()
Restores the draggable element to its initial state and deactivates it.
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $revertButton ] = utils.$(
'.revert'
);
const
draggable =
createDraggable
(
'.square'
);
function
revertDraggable
(
) {
draggable.
revert
();
$revertButton.
disabled
=
true
;
}
$revertButton.
addEventListener
(
'click'
, revertDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button revert"
>
Revert
</
button
>
</
fieldset
>
</
div
>
Previous
Next
reset()
refresh()

=== DOC: 227_scrollobserver-synchronisation-modes.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes
ScrollObserver
Since 4.0.0
ScrollObserver synchronisation modes
Determines the behaviour of the animation and how it is synchronised relative to the scroll progress or by meeting certain thresholds.
The different synchronisation modes are defined on the
sync
property of the
onScroll
()
parameters
Object
.
animate
(
'.square'
, {
x
:
100
,
autoplay
:
onScroll
({
container
:
'.container'
,
target
:
'.section'
,
axis
:
'y'
,
enter
:
'bottom top'
,
leave
:
'top bottom'
,
┌──────────────────────────┐
│
sync
:
true
,            ├─
Synchronisation
Mode
└──────────────────────────┘
onEnter
:
() =>
{},
onLeave
:
() =>
{},
onUpdate
:
() =>
{},
})
});
In this section
Method names
Playback progress
Smooth scroll
Eased scroll
Previous
Next
ScrollObserver thresholds
Method names

=== DOC: 228_playbackrate.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/playbackrate
Timer

Playback settings
Since 4.0.0
playbackRate
Defines a speed multiplier to speed up or slow down a timer playback (
1.0
is normal speed).
This value can be modified later with
timer.
speed
=
.5
.
Accepts
A
Number
greater than or equal to
0
If set to
0
the timer won't play.
Default
1
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
playbackRate
=
.75
;
import
{ createTimer, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $speed ] = utils.$(
'.speed'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
playbackRate
:
2
,
onUpdate
:
self
=>
$time.
innerHTML
= utils.
round
(self.
currentTime
,
0
),
});
const
updateSpeed
= (
) => {
const
speed = utils.
roundPad
(+$range.
value
,
1
);
$speed.
innerHTML
= speed;
utils.
sync
(
() =>
timer.
speed
= speed);
}
$range.
addEventListener
(
'input'
, updateSpeed);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
speed
</
span
>
<
span
class
=
"speed value"
>
2.0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
10
value
=
2
step
=
.1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
frameRate
Timer callbacks

=== DOC: 229_animation-properties.txt ===
URL: https://animejs.com/documentation/animation/animation-properties
Animation
Animation properties
const
animation =
animate
(targets, parameters);
┌────────────┐
animation.│targets     │
animation.│currentTime ├─
Properties
animation.│duration    │
└────────────┘
Name
Description
id
JS
Gets and sets the ID of the animation (
String
|
Number
)
targets
Gets the current animation targets (
Array
)
currentTime
Gets and sets the global current time in ms of the animation (
Number
)
iterationCurrentTime
JS
Gets and sets the current iteration time in ms (
Number
)
deltaTime
JS
Gets the time in ms elapsed between the current and previous frame (
Number
)
progress
Gets and sets the overall progress of the animation from
0
to
1
(
Number
)
iterationProgress
JS
Gets and sets the progress of the current iteration from
0
to
1
(
Number
)
currentIteration
JS
Gets and sets the current iteration count (
Number
)
duration
Gets the total duration in ms of the animation (
Number
)
speed
Gets and sets the speed multiplier of the animation (
Number
)
fps
JS
Gets and sets the fps of the animation (
Number
)
paused
Gets and sets whether the animation is paused (
Boolean
)
began
JS
Gets and sets whether the animation has started (
Boolean
)
completed
Gets and sets whether the animation has completed (
Boolean
)
reversed
JS
Gets and sets whether the animation is reversed (
Boolean
)
Previous
Next
Animation methods
Timeline

=== DOC: 230_onrender.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onrender
Timeline

Callbacks
Since 4.0.0
onRender
V4
Executes a function every time a timeline renders something on the screen, this means that no rendering is happening when the
currentTime
is inside the
delay
or
loopDelay
time frames, or if neither of its children are rendering.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onRender
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
renders =
0
;
const
tl =
createTimeline
({
defaults
: {
duration
:
500
},
loopDelay
:
250
,
loop
:
true
,
onRender
:
self
=>
$value.
textContent
= ++renders
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'+=250'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'+=250'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
renders
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onUpdate
onLoop

=== DOC: 231_onsettle.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks/onsettle
Draggable

Callbacks
Since 4.0.0
onSettle
Executes a function when the dragged target has completely stopped moving when released after a grab.
Accepts
A
Function
whose first argument returns the draggable itself
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
stops =
0
;
createDraggable
(
'.square'
, {
container
:
'.grid'
,
onSettle
:
() =>
$value.
textContent
= ++stops
});
<
div
class
=
"large padded grid square-grid"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
stops
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
onSnap
onResize

=== DOC: 232_loop.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/loop
Timeline

Playback settings
Since 2.0.0
loop
Defines how many times a timeline repeats.
Accepts
Value
Effect
Number
The number of loops in the range
[
0
,
Infinity
]
Infinity
Loop indefinitely
true
Equivalent to
Infinity
-
1
Equivalent to
Infinity
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loop
=
true
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
let
loops =
0
;
const
tl =
createTimeline
({
loop
:
true
,
onLoop
:
self
=>
$loops.
innerHTML
= ++loops,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
delay
loopDelay

=== DOC: 233_onpause.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/onpause
Timer

Callbacks
Since 4.0.0
onPause
Executes a function when a running timer is paused.
Accepts
A
Function
whose first argument returns the timer itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onPause
=
self
=>
console
.
log
(self.
id
);
import
{ createTimer, utils }
from
'animejs'
;
const
[ $resumeButton, $pauseButton ] = utils.$(
'.button'
);
const
[ $paused ] = utils.$(
'.paused'
);
const
[ $time ] = utils.$(
'.time'
);
let
paused =
0
;
const
timer =
createTimer
({
onPause
:
() =>
$paused.
innerHTML
= ++paused,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
pauseTimer
= (
) => timer.
pause
();
const
resumeTimer
= (
) => timer.
resume
();
$resumeButton.
addEventListener
(
'click'
, resumeTimer);
$pauseButton.
addEventListener
(
'click'
, pauseTimer);
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
paused
</
span
>
<
span
class
=
"value paused"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
elapsed time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Resume
</
button
>
<
button
class
=
"button"
>
Pause
</
button
>
</
fieldset
>
</
div
>
Previous
Next
onLoop
then()

=== DOC: 234_improvements-to-the-web-animation-api.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api
Web Animation API
Since 4.0.0
Improvements to the Web Animation API
The
waapi.
animate
()
method adds lots of quality of life improvements and greatly improves the overall experience of using WAAPI.
On top of all the improvements to the API listed in this chapter, it is also possible to link WAAPI animations to Anime.js built-in
ScrollObserver
waapi.
animate
(
'.square'
, {
translate
:
'100px'
,
autoplay
:
onScroll
()
});
And use a
Scope
for easy media queries handling and component cleanup:
createScope
({
mediaQueries
: {
reduceMotion
:
'(prefers-reduced-motion)'
}
})
.
add
(
(
{ matches }
) =>
{
const
{ reduceMotion } = matches;
waapi.
animate
(
'.square'
, {
transform
: reduceMotion ? [
'100px'
,
'100px'
] :
'100px'
,
opacity
: [
0
,
1
],
});
});
In this section
Sensible defaults
Multi-targets animation
Default units
Function based values
Individual transforms
Individual property params
Spring and custom easings
Previous
Next
Hardware-accelerated animations
Sensible defaults

=== DOC: 235_onpause.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onpause
Animation

Callbacks
Since 4.0.0
onPause
V4
JS
Executes a function when a running animation is paused, either manually or automatically.
An animation pauses when any of the following occurs during playback:
The
.
pause
()
method is called
The
.
cancel
()
method is called
The
.
revert
()
method is called
All animation tweens are overlapped by another animation with
composition
:
'replace'
All animation targets have been removed
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onPause
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $animateButton, $pauseButton, $removeButton ] = utils.$(
'.button'
);
const
[ $value ] = utils.$(
'.value'
);
const
[ $circle ] = utils.$(
'.circle'
);
let
paused =
0
;
let
alternate =
0
;
let
animation;
const
animateX
= (
) => {
alternate = !alternate;
animation =
animate
($circle, {
x
:
() =>
(alternate ?
16
:
0
) +
'rem'
,
duration
:
2000
,
onPause
:
() =>
$value.
innerHTML
= ++paused,
});
}
const
pauseAnimation
= (
) => {
if
(animation) animation.
pause
();
}
const
removeTarget
= (
) => {
utils.
remove
($circle);
}
animateX
();
$animateButton.
addEventListener
(
'click'
, animateX);
$pauseButton.
addEventListener
(
'click'
, pauseAnimation);
$removeButton.
addEventListener
(
'click'
, removeTarget);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
paused
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Animate x
</
button
>
<
button
class
=
"button"
>
Pause anim
</
button
>
<
button
class
=
"button"
>
Remove target
</
button
>
</
fieldset
>
</
div
>
Previous
Next
onLoop
then()

=== DOC: 236_onbegin.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onbegin
Animation

Callbacks
Since 4.0.0
onBegin
JS
Executes a function when an animation begins to play.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onBegin
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
delay
:
1000
,
// Delays the onBegin() callback by 1000ms
onBegin
:
self
=>
$value.
textContent
= self.
began
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
began
</
span
>
<
span
class
=
"value"
>
false
</
span
>
</
pre
>
</
div
>
Previous
Next
Animation callbacks
onComplete

=== DOC: 237_duration.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/duration
Animation

Tween parameters
Since 1.0.0
duration
Defines the duration in milliseconds of all animated properties, or of a specific property.
Accepts
Number
equal to or greater than
0
Function based value
that returns a
Number
equal to or greater than
0
Duration values higher than
1e12
or equal to
Infinity
are clamped internally to
1e12
(approximately 32 years).
Default
The animation duration value (default
1000
).
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
duration
=
500
;
import
{ animate }
from
'animejs'
;
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
rotate
: {
to
:
360
,
duration
:
1500
,
// Local duration only applied to rotate property
},
duration
:
3000
,
// Global duration applied to all properties
loop
:
true
,
alternate
:
true
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
delay
ease

=== DOC: 238_pauseondocumenthidden.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters/pauseondocumenthidden
Engine

Parameters
Since 4.0.0
pauseOnDocumentHidden
Controls whether the engine pauses animations when the browser tab is hidden.
When
true
, animations pause automatically when the tab loses focus. When
false
, animations will adjust their
currentTime
to catch up how long they have been idle in the background, making it looks like they never paused.
engine.
pauseOnDocumentHidden
=
true
;
Accepts
Boolean
Default
true
import
{ engine, utils, createTimer }
from
'animejs'
;
const
[ $globalTime ] = utils.$(
'.global-time'
);
const
[ $engineTime ] = utils.$(
'.engine-time'
);
const
[ $toggle ] = utils.$(
'.toggle'
);
const
startTime =
Date
.
now
();
const
globalTimer =
setInterval
(
() =>
{
$globalTime.
innerHTML
=
Date
.
now
() - startTime;
},
16
);
const
engineTimer =
createTimer
({
onUpdate
:
self
=>
$engineTime.
innerHTML
= self.
currentTime
});
const
toggleSetting
= (
) => {
const
isPauseWhenHidden = engine.
pauseOnDocumentHidden
;
if
(isPauseWhenHidden) {
engine.
pauseOnDocumentHidden
=
false
;
$toggle.
innerHTML
=
'○ Disabled (Switch tab to see the effect)'
;
}
else
{
engine.
pauseOnDocumentHidden
=
true
;
$toggle.
innerHTML
=
'● Enabled (Switch tab to see the effect)'
;
}
}
// Switch tab to see the effect
$toggle.
addEventListener
(
'click'
, toggleSetting);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
global time
</
span
>
<
span
class
=
"global-time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
engine time
</
span
>
<
span
class
=
"engine-time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button toggle"
>
● Enabled (Switch tab to see the effect)
</
button
>
</
fieldset
>
</
div
>
Previous
Next
precision
Engine methods

=== DOC: 239_target.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings/target
ScrollObserver

Settings
Since 4.0.0
target
Specifies which
HTMLElement
triggers the scroll event.
Accepts
CSS Selector
DOM Element
Defaults
If defined on an animation, the first targeted
HTMLElement
of the animation.
null
if defined outside of an animation
import
{ createTimer, utils, onScroll }
from
'animejs'
;
const
[ $timer ] = utils.$(
'.timer'
);
createTimer
({
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
onUpdate
:
self
=>
{
$timer.
innerHTML
= self.
iterationCurrentTime
},
autoplay
:
onScroll
({
target
: $timer,
container
:
'.scroll-container'
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
timer
</
span
>
<
span
class
=
"timer value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
container
debug

=== DOC: 240_engine-parameters.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters
Engine
Since 4.0.0
Engine parameters
import
{ engine }
from
'animejs'
;
┌────────────┐
engine.│speed       │
engine.│fps         ├─
Parameters
engine.│precision   │
└────────────┘
In this section
timeUnit
speed
fps
precision
pauseOnDocumentHidden
Previous
Next
Engine
timeUnit (seconds / milliseconds)

=== DOC: 241_method-names.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes/method-names
ScrollObserver

Synchronisation modes
Since 4.0.0
Method names
Defines a list of method names of the linked
Object
to be called when specific
callbacks
are triggered.
Accepts
A
String
containing a list of
Animation methods
,
Timer methods
or
Timeline methods
names separated by an empty space
Callbacks definition order
'enter'
Defines a method to be triggered when the enter threshold is crossed or when the element re-enters the viewport.
{
sync
:
'play'
,
}
'enter leave'
Defines methods to be triggered when the enter and leave thresholds are crossed.
{
sync
:
'play pause'
,
}
'enterForward leaveForward enterBackward leaveBackward'
Defines methods to be triggered when the enter and leave thresholds are crossed when scrolling forward and when the enter and leave thresholds are crossed when scrolling backward.
{
sync
:
'play pause reverse reset'
,
}
Default
'play pause'
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
'resume pause reverse reset'
,
debug
:
true
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
ScrollObserver synchronisation modes
Playback progress

=== DOC: 242_unit-conversion-value.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/unit-conversion-value
Animation

Tween value types
Since 2.0.0
Unit conversion value
Converts and animates to a value with a different unit than the default or currently used one.
When using the
JS
animate
()
method, unit conversions may sometimes produce unexpected results depending on the unit type and animated properties used.
For more predictable results, it's recommended to define the unit outside of the animation using
utils.
set
()
, and then animate to the current unit.
Or simply use the
WAAPI
animate
()
method.
Accepts
String
import
{ animate, utils }
from
'animejs'
;
animate
(
'.square'
, {
width
:
'25%'
,
// from '48px' to '25%',
x
:
'15rem'
,
// from '0px' to '15rem',
rotate
:
'.75turn'
,
// from `0deg` to '.75turn',
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Numerical value
Relative value

=== DOC: 243_reverse.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/reverse
Animation

Methods
Since 1.0.0
reverse()
V4
Forces the animation to play backward.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate, utils, stagger }
from
'animejs'
;
const
[ $reverseButton ] = utils.$(
'.reverse'
);
const
animation =
animate
(
'.square'
, {
x
:
'17rem'
,
ease
:
'inOutSine'
,
delay
:
stagger
(
100
),
});
const
reverseAnimation
= (
) => animation.
reverse
();
$reverseButton.
addEventListener
(
'click'
, reverseAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button reverse"
>
Reverse
</
button
>
</
fieldset
>
</
div
>
Previous
Next
play()
pause()

=== DOC: 244_timeline-methods.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods
Timeline
Since 2.0.0
Timeline methods
Provide control over the timing, behaviour and progression of a timeline.
Timeline methods are available on a Timeline instance
Object
.
const
timeline =
createTimeline
(parameters);
┌──────────┐
timeline.│
pause
()   │
timeline.│
play
()    ├─
Methods
timeline.│
restart
() │
└──────────┘
In this section
add()
set()
sync()
label()
remove()
call()
init()
play()
reverse()
pause()
restart()
alternate()
resume()
complete()
cancel()
revert()
seek()
stretch()
refresh()
Previous
Next
Timeline callbacks
add()

=== DOC: 245_call.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/call
Timeline

Methods
Since 4.0.0
call()
V4
Calls the passed function callback at the specified time position.
timeline.
call
(callback, position);
Parameters
Name
Accepts
callback
Function
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $functionA ] = utils.$(
'.function-A'
);
const
[ $functionB ] = utils.$(
'.function-B'
);
const
[ $functionC ] = utils.$(
'.function-C'
);
const
tl =
createTimeline
()
.
call
(
() =>
$functionA.
innerHTML
=
'A'
,
0
)
.
call
(
() =>
$functionB.
innerHTML
=
'B'
,
800
)
.
call
(
() =>
$functionC.
innerHTML
=
'C'
,
1200
);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function A
</
span
>
<
span
class
=
"function-A value lcd"
>
--
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function B
</
span
>
<
span
class
=
"function-B value lcd"
>
--
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
function C
</
span
>
<
span
class
=
"function-C value lcd"
>
--
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
remove()
init()

=== DOC: 246_scrollobserver-methods.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-methods
ScrollObserver
Since 4.0.0
ScrollObserver methods
Controls the state and behaviour of a
ScrollObserver
.
ScrollObserver methods are available on the
ScrollObserver
instance returned by a
onScroll
()
function.
const
scrollObserver =
onScroll
(parameters);
┌──────────┐
scrollObserver.│
link
()    │
scrollObserver.│
refresh
() ├─
Methods
scrollObserver.│
revert
()  │
└──────────┘
In this section
link()
refresh()
revert()
Previous
Next
ScrollObserver callbacks
link()

=== DOC: 247_sensible-defaults.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/sensible-defaults
Web Animation API

Improvements to WAAPI
Since 4.0.0
Sensible defaults
By default, a native WAAPI animation requires a duration to be set, won't have any easing applied, and more annoyingly, won't persist its final value, letting the user to take care of setting the final styles manually after the animation completes.
Anime.js simplifies all that by making sure the animation state is preserved after the animation completes, and uses the same default duration and delay as the JS
animate
()
method.
Syntax comparison
Anime.js
waapi.
animate
(
'.circle'
, {
translate
:
'100px'
});
WAAPI equivalent
const
$el =
document
.
querySelector
(
'.circle'
);
$el.
animate
({
translate
:
'100px'
}, {
duration
:
1000
,
easing
:
'ease-out'
,
}).
finished
.
then
(
() =>
{
$el.
style
.
translate
=
'100px'
;
});
import
{ waapi }
from
'animejs'
;
waapi.
animate
(
'.circle'
, {
translate
:
'16rem'
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
Previous
Next
Improvements to the Web Animation API
Multi-targets animation

=== DOC: 248_pad-end.txt ===
URL: https://animejs.com/documentation/utilities/pad-end
Utilities
Since 4.0.0
padEnd()
V4
Pads a
Number
from the end with a string until the result reaches a given length or creates a padding
Function
with pre-defined
totalLength
and
padString
parameters.
const
paddedValue = utils.
padEnd
(value, totalLength, padString);
const
padderFunction = utils.
padEnd
(totalLength, padString);
Parameters
Name
Accepts
value
(opt)
String
/
Number
totalLength
Number
padString
String
Returns
A
String
if a value is provided, otherwise a
chain-able utility
Function
to pad numbers from the end:
const
padTo5WithZeros = utils.
padEnd
(
5
,
'0'
);
padTo5WithZeros
(
'123'
);
// '12300'
padTo5WithZeros
(
78
);
// '78000'
padTo5WithZeros
(
'1234'
);
// '12340'
const
roundAndPadEnd = utils.
round
(
0
).
padEnd
(
5
,
'0'
);
// Round to nearest integer then pad to 5 characters
roundAndPadEnd
(
123.456
);
// '12300'
roundAndPadEnd
(
7.8
);
// '80000'
import
{ animate, utils }
from
'animejs'
;
animate
(
'.value'
, {
innerHTML
:
1
,
modifier
: utils.
round
(
3
).
padEnd
(
6
,
'-'
),
duration
:
100000
,
ease
:
'linear'
,
});
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
padStart()
degToRad()

=== DOC: 249_onloop.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks/onloop
Timer

Callbacks
Since 4.0.0
onLoop
Executes a function every time a timer iteration completes.
Accepts
A
Function
whose first argument returns the timer itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onLoop
=
self
=>
console
.
log
(self.
id
);
import
{ createTimer, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
const
[ $time ] = utils.$(
'.time'
);
let
loops =
0
;
createTimer
({
loop
:
true
,
duration
:
1000
,
onLoop
:
self
=>
$loops.
innerHTML
= ++loops,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
,
});
<
div
class
=
"large row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
onUpdate
onPause

=== DOC: 250_set.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/set
Timeline

Methods
Since 4.0.0
set()
V4
Instantly sets targets property values at a specific time of the timeline.
timeline.
set
(targets, parameters, position);
Parameters
Name
Accepts
targets
Targets
parameters
Animatable properties
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
()
.
set
(
'.circle'
, {
x
:
'15rem'
})
.
set
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
set
(
'.square'
, {
x
:
'15rem'
},
1000
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
add()
sync()

=== DOC: 251_svg-attributes.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/svg-attributes
Animation

Animatable properties
Since 1.0.0
SVG Attributes
JS
Numerical and color SVG attributes can be animated by passing them directly to the animation parameters.
For more convenient SVG animations, check out the built-in
SVG utility methods
.
import
{ animate }
from
'animejs'
;
animate
([
'feTurbulence'
,
'feDisplacementMap'
], {
baseFrequency
:
.05
,
scale
:
15
,
alternate
:
true
,
loop
:
true
});
animate
(
'polygon'
, {
points
:
'64 68.64 8.574 100 63.446 67.68 64 4 64.554 67.68 119.426 100'
,
alternate
:
true
,
loop
:
true
});
<
div
class
=
"large centered row"
>
<
svg
width
=
"128"
height
=
"128"
viewBox
=
"0 0 128 128"
>
<
filter
id
=
"displacementFilter"
>
<
feTurbulence
type
=
"turbulence"
numOctaves
=
"2"
baseFrequency
=
"0"
result
=
"turbulence"
/>
<
feDisplacementMap
in2
=
"turbulence"
in
=
"SourceGraphic"
scale
=
"1"
xChannelSelector
=
"R"
yChannelSelector
=
"G"
/>
</
filter
>
<
polygon
points
=
"64 128 8.574 96 8.574 32 64 0 119.426 32 119.426 96"
fill
=
"currentColor"
/>
</
svg
>
</
div
>
Previous
Next
HTML Attributes
Tween value types

=== DOC: 252_resume.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/resume
Timeline

Methods
Since 2.0.0
resume()
V4
Resumes the playback of a paused timeline in its current direction.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ creatTimeline, utils }
from
'animejs'
;
const
[ $pauseButton, $alternateButton, $resumeButton ] = utils.$(
'.button'
);
const
tl =
createTimeline
({
loop
:
true
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
pauseTimeline
= (
) => tl.
pause
();
const
alternateTimeline
= (
) => tl.
alternate
();
const
resumeTimeline
= (
) => tl.
resume
();
$pauseButton.
addEventListener
(
'click'
, pauseTimeline);
$alternateButton.
addEventListener
(
'click'
, alternateTimeline);
$resumeButton.
addEventListener
(
'click'
, resumeTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Pause
</
button
>
<
button
class
=
"button"
>
Alternate
</
button
>
<
button
class
=
"button"
>
Resume
</
button
>
</
fieldset
>
</
div
>
Previous
Next
alternate()
complete()

=== DOC: 253_playback-loopdelay.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/playback-loopdelay
Timeline

Playback settings
Since 4.0.0
loopDelay
V4
Defines the delay in milliseconds between each loops.
Accepts
A
Number
equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loopDelay
=
500
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
const
tl =
createTimeline
({
loopDelay
:
500
,
loop
:
true
,
onLoop
:
self
=>
$loops.
innerHTML
= self.
_currentIteration
,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
loop
alternate

=== DOC: 254_to.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/to
Animation

Tween parameters
Since 4.0.0
to
Animates
to
a specified value from the current target value.
Must be defined inside a local tween parameter
Object
.
Required
Only if no
from
property is defined
Accepts
Any valid
Tween value types
An
Array
of two
Tween value keyframes
(
[fromValue, toValue]
)
Default
The current target value is used if only a
from
property is defined
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
x
: {
to
:
'16rem'
,
// From 0px to 16rem
ease
:
'outCubic'
,
},
rotate
: {
to
:
'.75turn'
,
// From 0turn to .75turn
ease
:
'inOutQuad'
},
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Tween parameters
from

=== DOC: 255_animation-methods.txt ===
URL: https://animejs.com/documentation/animation/animation-methods
Animation
Since 1.0.0
Animation methods
Provide control over the timing, behaviour and progression of an animation.
Animation methods are available on an Animation instance
Object
.
const
animation =
animate
(target, parameters);
┌──────────┐
animation.│
pause
()   │
animation.│
play
()    ├─
Methods
animation.│
restart
() │
└──────────┘
In this section
play()
reverse()
pause()
restart()
alternate()
resume()
complete()
cancel()
revert()
seek()
stretch()
refresh()
Previous
Next
Animation callbacks
play()

=== DOC: 256_speed.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters/speed
Engine

Parameters
Since 4.0.0
speed
Controls the global playback rate of all animations managed by the engine.
Values greater than
1
speed up animations, while values between
0
and
1
slow them down.
Adjusting the global playback rate is useful for creating slow-motion or fast-forward effects across all animations simultaneously.
engine.
speed
=
0.5
;
// Run all animations at half speed
Accepts
A
Number
greater than or equal to
0
Default
1
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $container ] = utils.$(
'.container'
);
const
[ $range ] = utils.$(
'.range'
);
for
(
let
i =
0
; i <
150
; i++) {
const
$particle =
document
.
createElement
(
'div'
);
$particle.
classList
.
add
(
'particle'
);
$container.
appendChild
($particle);
animate
($particle, {
x
: utils.
random
(-
10
,
10
,
2
) +
'rem'
,
y
: utils.
random
(-
3
,
3
,
2
) +
'rem'
,
scale
: [{
from
:
0
,
to
:
1
}, {
to
:
0
}],
delay
: utils.
random
(
0
,
1000
),
loop
:
true
,
});
}
function
onInput
(
) {
utils.
sync
(
() =>
engine.
speed
=
this
.
value
);
}
$range.
addEventListener
(
'input'
, onInput);
<
div
class
=
"large row container"
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0.1
max
=
2
value
=
1
step
=
.01
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
timeUnit (seconds / milliseconds)
fps

=== DOC: 257_spring-and-custom-easings.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/spring-and-custom-easings
Web Animation API

Improvements to WAAPI
Since 4.0.0
Spring and custom easings
Uses any spring and custom JavaScript easing function.
All Anime.js built-in easing functions can be used by passing the function accessible on the
eases
object.
import
{ eases }
from
'animejs'
;
const
{ linear, outExpo, cubicBezier } = eases;
The
createSpring
()
easing function must be imported separately.
import
{ createSpring }
from
'animejs'
;
Built-in eases
Built-in string
Function
Parameters
'linear'
'linear(0, .5 75%, 1)'
linear
()
coords (
0
,
'.5 75%'
,
1
)
'steps'
'steps(10)'
steps
()
steps =
10
'cubicBezier'
'cubicBezier(.5,0,.5,1)'
cubicBezier
()
x1 =
.5
, y1 =
0
, x2 =
.5
, y2 =
1
'in'
'in(1.675)'
in
()
power =
1.675
'out'
'out(1.675)'
out
()
power =
1.675
'inOut'
'inOut(1.675)'
inOut
()
power =
1.675
Default
'out(2)'
import
{ waapi, utils, stagger, createSpring, eases }
from
'animejs'
;
waapi.
animate
(
'.circle'
, {
y
: [
0
, -
30
,
0
],
ease
:
createSpring
({
stiffness
:
150
,
damping
:
5
}),
delay
:
stagger
(
75
),
loop
:
true
,
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
Previous
Next
Individual property parameters
API differences with native WAAPI

=== DOC: 258_container.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings/container
ScrollObserver

Settings
Since 4.0.0
container
Specifies the container
HTMLElement
to which the scroll event is applied.
Accepts
CSS Selector
DOM Element
Default
null
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
ScrollObserver settings
target

=== DOC: 259_round-pad.txt ===
URL: https://animejs.com/documentation/utilities/round-pad
Utilities
Since 4.0.0
roundPad()
V4
Rounds a value to a specified decimal length, pads with zeros if needed, and returns the result as a string, or creates a rounding and padding
Function
with a pre-defined
decimalLength
parameter.
const
roundedPaddedValue = utils.
roundPad
(value, decimalLength);
const
roundPadderFunction = utils.
roundPad
(decimalLength);
Parameters
Name
Accepts
value
(opt)
Number
/
String
decimalLength
Number
Returns
A
String
if a value is provided, otherwise a
chain-able utility
Function
to round and pad numbers to the specified decimal length:
const
roundPadTo2Decimals = utils.
roundPad
(
2
);
roundPadTo2Decimals
(
90.12345
);
// '90.12'
roundPadTo2Decimals
(
120
);
// '120.00'
roundPadTo2Decimals
(
15.9
);
// '15.90'
const
snapAndRoundPad = utils.
snap
(
50
).
roundPad
(
2
);
// Snap to nearest 50 then roundPad to 2 decimal places
snapAndRoundPad
(
123.456
);
// '100.00'
snapAndRoundPad
(
175.789
);
// '200.00'
import
{ animate, utils }
from
'animejs'
;
animate
(
'.value'
, {
innerHTML
:
'8.1'
,
modifier
: utils.
roundPad
(
3
),
duration
:
10000
,
ease
:
'linear'
,
});
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"value lcd"
>
0.000
</
span
>
</
pre
>
</
div
>
Previous
Next
interpolate()
padStart()

=== DOC: 260_css-properties.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/css-properties
Animation

Animatable properties
Since 1.0.0
CSS Properties
Any CSS numerical and color properties can be animated.
Properties containing a dash in their name, like
background-color
, must be converted to camel case (
backgroundColor
), or written as a
String
(
'background-color'
).
Most CSS properties can cause layout changes or repaint leading to choppy animations. To achieve smoother animations, always prioritise opacity and
CSS transforms
as much as possible.
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
left
:
'calc(7.75rem * 2)'
,
borderRadius
:
64
,
'background-color'
:
'#F9F640'
,
filter
:
'blur(5px)'
,
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Animatable properties
CSS transforms

=== DOC: 261_scope-methods.txt ===
URL: https://animejs.com/documentation/scope/scope-methods
Scope
Since 4.0.0
Scope methods
const
scope =
createScope
(parameters);
┌──────────┐
scope.│
add
()     │
scope.│
refresh
() ├─
Methods
scope.│
revert
()  │
└──────────┘
In this section
add()
revert()
refresh()
Previous
Next
Scope parameters
add()

=== DOC: 262_trigger.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/trigger
Draggable

Settings
Since 4.0.0
trigger
Specifies a different element than the defined target to trigger the drag animation.
Accepts
CSS Selector
DOM Element
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.row'
, {
trigger
:
'.circle'
,
});
<
div
class
=
"large centered row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Draggable settings
container

=== DOC: 263_stagger-start.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-start
Stagger

Parameters
Since 2.0.0
Stagger start
Defines the starting value of the stagger.
Accepts
Number
|
Timeline time position
(Only when used as a timeline position argument)
Default
0
import
{ animate, stagger }
from
'animejs'
;
animate
(
'.square'
, {
x
:
stagger
(
'1rem'
, {
start
:
14
}),
// adds 14 to the staggered value
delay
:
stagger
(
100
, {
start
:
500
}),
// adds 500 to the staggered value
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 14rem, delay: 500ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 15rem, delay: 600ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 16rem, delay: 700ms
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: 17rem, delay: 700ms
</
div
>
</
div
>
Previous
Next
Stagger parameters
Stagger from

=== DOC: 264_set.txt ===
URL: https://animejs.com/documentation/utilities/set
Utilities
Since 2.0.0
set()
Immediately sets one or multiple properties values to one or multiple targets.
const
setter = utils.
set
(targets, properties);
Parameters
Name
Accepts
Description
targets
Targets
The targeted element(s)
properties
Object
An object of valid properties and values of the target
Returns
Animation
utils.
set
()
is useful for setting complex values, but for repeatedly updating the same properties on the same targets, using an
Animatable
is recommended for better performances.
utils.
set
()
won't work if you try to set an attribute on a DOM or SVG element not already defined on the element.
import
{ utils, stagger }
from
'animejs'
;
const
[ $set, $revert ] = utils.$(
'button'
);
const
squares = utils.$(
'.square'
);
const
colors = [
'red'
,
'orange'
,
'yellow'
];
let
setter;
const
setStyles
= (
) => {
setter = utils.
set
(squares, {
borderRadius
:
'50%'
,
y
:
() =>
utils.
random
(-
1
,
1
) +
'rem'
,
scale
:
stagger
(
.1
, {
start
:
.25
,
ease
:
'out'
}),
color
:
() =>
`var(--hex-
${utils.randomPick(colors)}
)`
});
$set.
setAttribute
(
'disabled'
,
'true'
);
$revert.
removeAttribute
(
'disabled'
);
}
const
revertStyles
= (
) => {
setter.
revert
();
$set.
removeAttribute
(
'disabled'
);
$revert.
setAttribute
(
'disabled'
,
'true'
);
}
$set.
addEventListener
(
'click'
, setStyles);
$revert.
addEventListener
(
'click'
, revertStyles);
<
div
class
=
"large justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
>
Set styles
</
button
>
<
button
disabled
>
Revert styles
</
button
>
</
fieldset
>
</
div
>
Previous
Next
get()
remove()

=== DOC: 265_alternate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/alternate
Timeline

Methods
Since 2.0.0
alternate()
V4
Toggles the playback direction while adjusting the
currentTime
position to reflect the new time progress.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ creatTimeline, utils }
from
'animejs'
;
const
[ $alternateButton ] = utils.$(
'.button'
);
const
tl =
createTimeline
({
loop
:
true
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
pauseTimeline
= (
) => tl.
pause
();
const
playTimeline
= (
) => tl.
play
();
const
alternateTimeline
= (
) => tl.
alternate
();
$alternateButton.
addEventListener
(
'click'
, alternateTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button"
>
Alternate
</
button
>
</
fieldset
>
</
div
>
Previous
Next
restart()
resume()

=== DOC: 266_enable.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/enable
Draggable

Methods
Since 4.0.0
enable()
Reactivates a previously disabled draggable, making it interactive again.
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $enableButton ] = utils.$(
'.enable'
);
const
draggable =
createDraggable
(
'.square'
);
draggable.
disable
();
const
enableDraggable
= (
) => draggable.
enable
();
$enableButton.
addEventListener
(
'click'
, enableDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button enable"
>
Enable
</
button
>
</
fieldset
>
</
div
>
Previous
Next
disable()
setX()

=== DOC: 267_random-pick.txt ===
URL: https://animejs.com/documentation/utilities/random-pick
Utilities
Since 4.0.0
randomPick()
V4
Returns a random element from a collection.
const
ramdomElement = utils.
randomPick
(collection);
Parameters
Name
Accepts
collection
Array
|
NodeList
|
String
Returns
An random element from the collection
import
{ utils }
from
'animejs'
;
utils.
set
(
'.letter'
, {
x
:
() =>
utils.
randomPick
([
5
,
9
,
13
,
17
]) +
'rem'
,
scale
:
() =>
utils.
randomPick
([
1
,
1.25
,
1.5
,
1.75
]),
color
:
() =>
`var(--hex-
${utils.randomPick([
'red'
,
'orange'
,
'yellow'
])}
)`
,
innerHTML
:
() =>
utils.
randomPick
(
'ABCD'
),
});
<
div
class
=
"small row"
>
<
div
class
=
"letter"
>
A
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"letter"
>
B
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"letter"
>
C
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"letter"
>
D
</
div
>
</
div
>
Previous
Next
random()
shuffle()

=== DOC: 268_individual-property-parameters.txt ===
URL: https://animejs.com/documentation/web-animation-api/improvements-to-the-web-animation-api/individual-property-parameters
Web Animation API

Improvements to WAAPI
Since 4.0.0
Individual property parameters
Each property can have specific
delay
,
duration
and
ease
parameters by passing an
Object
with at least one
to
or
from
properties as value.
import
{ waapi, utils, stagger }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
y
: {
to
: [
0
, -
30
,
0
],
ease
:
'out(4)'
,
duration
:
1000
,
},
rotate
: {
from
: -
180
,
to
:
0
,
ease
:
'out(3)'
},
scale
: {
to
: [
.65
,
1
,
.65
],
ease
:
'inOut(3)'
},
duration
:
500
,
delay
:
stagger
(
75
),
loop
:
true
,
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Individual CSS transforms
Spring and custom easings

=== DOC: 269_seek.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/seek
Timeline

Methods
Since 2.0.0
seek()
Updates the
currentTime
of the timeline to a specific time.
timeline.
seek
(time, muteCallbacks);
Parameters
Name
Type
Description
time
Number
The new
currentTime
in ms of the timeline
muteCallbacks=false
(opt)
Boolean
If
true
, prevent the callbacks from being fired
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $playPauseButton ] = utils.$(
'.play-pause'
);
const
updateButtonLabel
= tl => {
$playPauseButton.
textContent
= tl.
paused
?
'Play'
:
'Pause'
;
}
const
tl =
createTimeline
({
autoplay
:
false
,
onUpdate
:
self
=>
{
$range.
value
= self.
currentTime
;
updateButtonLabel
(self);
},
onComplete
: updateButtonLabel,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
seekTimeline
= (
) => tl.
seek
(+$range.
value
);
const
playPauseTimeline
= (
) => {
if
(tl.
paused
) {
tl.
play
();
}
else
{
tl.
pause
();
updateButtonLabel
(tl);
}
}
$range.
addEventListener
(
'input'
, seekTimeline);
$playPauseButton.
addEventListener
(
'click'
, playPauseTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium centered row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
2000
value
=
0
class
=
"range"
/>
<
button
style
=
"flex: 0.25;"
class
=
"button play-pause"
>
Play
</
button
>
</
fieldset
>
</
div
>
Previous
Next
revert()
stretch()

=== DOC: 270_loop.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/loop
Timer

Playback settings
Since 4.0.0
loop
Defines how many times a timer repeats.
Accepts
Value
Effect
Number
The number of loops in the range
[
0
,
Infinity
]
Infinity
Loop indefinitely
true
Equivalent to
Infinity
-
1
Equivalent to
Infinity
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
loop
=
true
;
import
{ createTimer, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
const
[ $time ] = utils.$(
'.time'
);
let
loops =
0
;
createTimer
({
loop
:
true
,
duration
:
1000
,
onLoop
:
() =>
$loops.
innerHTML
= ++loops,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
});
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops count
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
duration
loopDelay

=== DOC: 271_composition.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/composition
Animation

Tween parameters
Since 4.0.0
composition
V4
JS
Defines how animations behave when another animation on the same target with the same property is playing simultaneously. The composition mode can be defined globally for all animation properties or locally for a specific property.
Accepts
Mode
Description
'replace'
Replace and cancel the running animation.
'none'
JS
Do not replace the running animation. This means the previous animation will continue running if its duration is longer than the new animation. This mode can also offer better performance.
'blend'
JS
Creates an additive animation and blends its values with the running animation.
0
JS
Shorthand for
'replace'
.
1
JS
Shorthand for
'none'
.
2
JS
Shorthand for
'blend'
.
Default
'replace'
if the animation targets count is below
1000
; otherwise, the default composition is set to
'none'
on the
JS
version if no composition mode is defined.
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
composition
=
'blend'
;
Additive animations
The
'blend'
mode lets you create
additive animations
. This type of animation allows you to smoothly blend two animations of the same property on the same target together. This mode works best on properties that visually
move
on the screen, like
'translate'
,
'scale'
, and
'rotation'
.
It is not currently possible to use the additive mode when using keyframes or with color values.
import
{ animate, utils }
from
'animejs'
;
const
squares = utils.$(
'.square'
);
const
[ $none, $replace, $blend ] = squares;
// Animate each square with a different composition mode
squares.
forEach
($square => {
// 'none', 'replace', 'blend'
const
mode = $square.
classList
[
1
];
animate
($square, {
scale
: [
.5
,
1
],
alternate
:
true
,
loop
:
true
,
duration
:
750
,
composition
: mode,
});
});
// Common animation parameters
const
enter = {
scale
:
1.5
,
duration
:
350
};
const
leave = {
scale
:
1.0
,
duration
:
250
};
// Composition none animations
const
enterNone
= (
) =>
animate
($none, {
composition
:
'none'
, ...enter
});
const
leaveNone
= (
) =>
animate
($none, {
composition
:
'none'
, ...leave
});
$none.
addEventListener
(
'mouseenter'
, enterNone);
$none.
addEventListener
(
'mouseleave'
, leaveNone);
// Composition replace animations
const
enterReplace
= (
) =>
animate
($replace, {
composition
:
'replace'
, ...enter
});
const
leaveReplace
= (
) =>
animate
($replace, {
composition
:
'replace'
, ...leave
});
$replace.
addEventListener
(
'mouseenter'
, enterReplace);
$replace.
addEventListener
(
'mouseleave'
, leaveReplace);
// Composition blend animations
const
enterBlend
= (
) =>
animate
($blend, {
composition
:
'blend'
, ...enter
});
const
leaveBlend
= (
) =>
animate
($blend, {
composition
:
'blend'
, ...leave
});
$blend.
addEventListener
(
'mouseenter'
, enterBlend);
$blend.
addEventListener
(
'mouseleave'
, leaveBlend);
<
div
class
=
"large spaced-evenly row"
>
<
div
class
=
"col"
>
<
div
class
=
"centered row"
>
<
span
class
=
"label centered"
>
none
<
br
>
<
br
>
</
span
>
<
div
class
=
"square none"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"centered row"
>
<
span
class
=
"label centered"
>
replace
<
br
>
<
br
>
</
span
>
<
div
class
=
"square replace"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"col"
>
<
div
class
=
"centered row"
>
<
span
class
=
"label centered"
>
blend
<
br
>
<
br
>
</
span
>
<
div
class
=
"square blend"
>
</
div
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium spaced-evenly centered row"
>
<
div
class
=
"label"
>
<
br
>
<
br
>
(Hover the squares)
</
div
>
</
div
>
Previous
Next
ease
modifier

=== DOC: 272_numerical-value.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/numerical-value
Animation

Tween value types
Since 1.0.0
Numerical value
Specifies the numerical value of the animated property by passing either a
Number
or a
String
containing at least one
Number
.
If no unit is specified for properties that expect a unit, like
width
for example, the resulting animation will use the default browser unit.
animate
(target, {
width
:
100
});
// Defaults to px
Accepts
Number
String
If a specific unit is already specified, the
JS
animate
()
method can inherits previously defined units and the next value set without a unit on the same target property inherits the previously defined unit.
animate
(target, {
width
:
'50%'
});
// Uses '%'
animate
(target, {
width
:
75
});
// Inherits '%' -> '75%'
The
WAAPI
animate
()
method only falls back automatically to
'px'
with the following properties:
- x / translateX
- y / translateY
- z / translateZ
- perspective
- top
- right
- bottom
- left
- width
- height
- margin
- padding
- borderWidth
- borderRadius
- fontSize
import
{ waapi }
from
'animejs'
;
waapi.
animate
(
'.square'
, {
x
:
240
,
//  -> 240px
width
:
75
,
// -> 75px
rotate
:
'.75turn'
,
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Tween value types
Unit conversion value

=== DOC: 273_stretch.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/stretch
Timer

Methods
Since 4.0.0
stretch()
Changes the total duration of a timer to fit a specific time.
The total duration is equal to the duration of an iteration multiplied with the total number of iterations. So if a timer has a duration of 1000ms and loops twice (3 iterations in total), the total duration is 3000ms (1000 * 3).
timer.
stretch
(duration);
Parameters
Name
Type
Description
duration
Number
The new total duration in ms of the timer
Returns
The timer itself
Can be chained with other timer methods.
import
{ animate, utils }
from
'animejs'
;
const
[ $range ] = utils.$(
'.range'
);
const
[ $duration ] = utils.$(
'.duration'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
duration
:
2000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
stretchTimer
= (
) => {
timer.
stretch
(+$range.
value
);
$duration.
innerHTML
= timer.
duration
;
timer.
restart
();
}
$range.
addEventListener
(
'input'
, stretchTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
duration
</
span
>
<
span
class
=
"duration value"
>
2000
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
4000
value
=
2000
step
=
100
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
seek()
Timer properties

=== DOC: 274_fps.txt ===
URL: https://animejs.com/documentation/engine/engine-parameters/fps
Engine

Parameters
Since 4.0.0
fps
Controls the global frame rate at which animations are updated and rendered.
Adjusting the frame rate can help optimize performance on lower-end devices or when running many complex animations simultaneously. However, it may affect the perceived smoothness of animations.
engine.
fps
=
30
;
// Set all animations to update at 30 fps
Accepts
A
Number
greater than
0
Default
120
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $container ] = utils.$(
'.container'
);
const
[ $range ] = utils.$(
'.range'
);
for
(
let
i =
0
; i <
150
; i++) {
const
$particle =
document
.
createElement
(
'div'
);
$particle.
classList
.
add
(
'particle'
);
$container.
appendChild
($particle);
animate
($particle, {
x
: utils.
random
(-
10
,
10
,
2
) +
'rem'
,
y
: utils.
random
(-
3
,
3
,
2
) +
'rem'
,
scale
: [{
from
:
0
,
to
:
1
}, {
to
:
0
}],
delay
: utils.
random
(
0
,
1000
),
loop
:
true
,
});
}
function
onInput
(
) {
engine.
fps
=
this
.
value
;
}
$range.
addEventListener
(
'input'
, onInput);
<
div
class
=
"large row container"
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
input
type
=
"range"
min
=
0
max
=
240
value
=
60
step
=
1
class
=
"range"
/>
</
fieldset
>
</
div
>
Previous
Next
speed
precision

=== DOC: 275_stagger-grid-axis.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-grid-axis
Stagger

Parameters
Since 2.0.0
Stagger grid axis
Defines the direction of a staggered grid effect by restricting which axis of the grid can update.
Accepts
Value
Effect
'x'
Restrict the direction to the x axis
'y'
Restrict the direction to the y axis
import
{ animate, stagger }
from
'animejs'
;
const
grid = [
11
,
4
];
const
$squares = utils.$(
'.square'
);
function
animateGrid
(
) {
const
from
= utils.
random
(
0
,
11
*
4
);
animate
($squares, {
translateX
: [
{
to
:
stagger
(
'-.75rem'
, { grid,
from
,
axis
:
'x'
}) },
{
to
:
0
,
ease
:
'inOutQuad'
, },
],
translateY
: [
{
to
:
stagger
(
'-.75rem'
, { grid,
from
,
axis
:
'y'
}) },
{
to
:
0
,
ease
:
'inOutQuad'
},
],
opacity
: [
{
to
:
.5
},
{
to
:
1
}
],
delay
:
stagger
(
85
, { grid,
from
}),
onComplete
: animateGrid
});
}
animateGrid
();
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Stagger grid
Stagger modifier

=== DOC: 276_init.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/init
Timeline

Methods
Since 4.0.0
init()
V4
Initialises the initial values of all the elements of a timeline.
Animations with specific initial values added to a timeline are not automatically set to their
from
state like a normal call to
animate
()
would, instead, they are initialised when the timeline playhead reaches the element in the timeline.
This is where
.
init
()
comes in handy, it forces a render of all the children initial state and updates their values.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline }
from
'animejs'
;
const
tl =
createTimeline
()
.
add
(
'.square'
,   {
x
: {
from
:
'15rem'
} })
.
add
(
'.triangle'
, {
x
: {
from
:
'15rem'
} },
500
)
.
add
(
'.circle'
,   {
x
: {
from
:
'15rem'
} },
1000
)
.
init
();
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
call()
play()

=== DOC: 277_revert.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/revert
Timeline

Methods
Since 4.0.0
revert()
V4
Cancels the timeline, reverts all its children's animated values to their original state, cleans up the CSS inline styles, and reverts the linked
onScroll
()
instance if necessary.
Use
.
revert
()
when you want to completely stop and destroy a timeline.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $revertButton ] = utils.$(
'.revert'
);
const
[ $restartButton ] = utils.$(
'.restart'
);
// Set an initial x value
utils.
set
([
'.circle'
,
'.triangle'
,
'.square'
], {
x
:
'15rem'
});
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
})
.
add
(
'.circle'
,   {
x
:
0
})
.
add
(
'.triangle'
, {
x
:
0
},
500
)
.
add
(
'.square'
,   {
x
:
0
},
1000
);
const
revertTimeline
= (
) => tl.
revert
();
const
restartTimeline
= (
) => tl.
restart
();
$revertButton.
addEventListener
(
'click'
, revertTimeline);
$restartButton.
addEventListener
(
'click'
, restartTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button revert"
>
Revert
</
button
>
<
button
class
=
"button restart"
>
Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
cancel()
seek()

=== DOC: 278_from.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/from
Animation

Tween parameters
Since 4.0.0
from
V4
Animates
from
a specified value to the current target value.
Must be defined inside a local tween parameter
Object
.
Required
Only if no
to
property is defined
Accepts
Any valid
Tween value types
Default
The current target value is used if only a
to
property is defined
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
opacity
: {
from
:
.5
},
// Animate from .5 opacity to 1 opacity
translateX
: {
from
:
'16rem'
},
// From 16rem to 0rem
rotate
: {
from
:
'-.75turn'
,
// From -.75turn to 0turn
ease
:
'inOutQuad'
,
},
});
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
to
delay

=== DOC: 279_alternate.txt ===
URL: https://animejs.com/documentation/timer/timer-playback-settings/alternate
Timer

Playback settings
Since 4.0.0
alternate
Defines if the direction of the timer alternates on each iteration when the
loop
is set to
true
or superior to
1
.
Accepts
Boolean
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
alternate
=
true
;
import
{ animate }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
const
[ $time ] = utils.$(
'.time'
);
let
loops =
0
;
createTimer
({
loop
:
true
,
duration
:
1000
,
alternate
:
true
,
onLoop
:
() =>
$loops.
innerHTML
= ++loops,
onUpdate
:
self
=>
$time.
innerHTML
= self.
iterationCurrentTime
});
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops count
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
<
div
class
=
"col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
iteration time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
Previous
Next
loopDelay
reversed

=== DOC: 280_scroll.txt ===
URL: https://animejs.com/documentation/scroll
ScrollObserver
V4
Triggers and synchronises Timer, Animation and Timeline instances on scroll
ScrollObservers are created with the
onScroll
()
function and can be directly declared in the
autoplay parameter
.
import
{ onScroll, animate }
from
'animejs'
;
animate
(targets, {
x
:
100
,
autoplay
:
onScroll
(parameters) });
Parameters
Name
Accepts
parameters
An
Object
of
ScrollObserver settings
,
ScrollObserver thresholds
,
ScrollObserver sync modes
and
ScrollObserver callbacks
Returns
ScrollObserver
import
{ animate, utils, onScroll }
from
'animejs'
;
const
[ container ] = utils.$(
'.scroll-container'
);
const
debug =
true
;
// Animation
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
autoplay
:
onScroll
({ container, debug })
});
// Timer
const
[ $timer ] = utils.$(
'.timer'
);
createTimer
({
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
onUpdate
:
self
=>
{
$timer.
innerHTML
= self.
iterationCurrentTime
},
autoplay
:
onScroll
({
target
: $timer.
parentNode
,
container,
debug
})
});
// Timeline
const
circles = utils.$(
'.circle'
);
createTimeline
({
alternate
:
true
,
loop
:
true
,
autoplay
:
onScroll
({
target
: circles[
0
],
container,
debug
})
})
.
add
(circles[
2
], {
x
:
'9rem'
})
.
add
(circles[
1
], {
x
:
'9rem'
})
.
add
(circles[
0
], {
x
:
'9rem'
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
timer
</
span
>
<
span
class
=
"timer value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
In this section
Settings
Thresholds
Synchronisation modes
Callbacks
Methods
Properties
Previous
Next
Draggable
ScrollObserver settings

=== DOC: 281_timeline-callbacks.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks
Timeline
Since 2.0.0
Timeline callbacks
Execute functions at specific points during a timeline playback.
Timeline callbacks functions are defined directly in the
createTimeline
()
parameters
Object
.
createTimeline
({
defaults
: {
ease
:
'out(3)'
,
duration
:
500
,
},
loop
:
3
,
alternate
:
true
,
autoplay
:
false
,
┌─────────────────────┐
│
onBegin
:
() =>
{},  │
│
onLoop
:
() =>
{},   ├─
Callbacks
│
onUpdate
:
() =>
{}, │
└─────────────────────┘
});
In this section
onBegin
onComplete
onBeforeUpdate
onUpdate
onRender
onLoop
onPause
then()
Previous
Next
Timeline playback settings
onBegin

=== DOC: 282_function-based.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/function-based
Animation

Tween value types
Since 1.0.0
Function based value
Sets different values for each target of a multi-target animation by using a
Function
as the value.
Function-based values can be re-calculated without creating a new animation using the
animation.
refresh
()
method.
Accepts
A
Function
with the following parameters:
animate
(targets, {
x
:
(
target, index, length
) =>
target.
dataset
.
value
* (length - index),
});
Parameters
Name
Description
target
The current animated target element
index
The index of current targeted element
length
The total number of animated targets of the animation
Must return
Tween value
Tween parameters
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
x
: $el =>
/**
@type
{
HTMLElement
} */
($el).
getAttribute
(
'data-x'
),
y
:
(
_, i
) =>
50
+ (-
50
* i),
scale
:
(
_, i, l
) =>
(l - i) *
.75
,
rotate
:
() =>
utils.
random
(-
360
,
360
),
borderRadius
:
() =>
`+=
${utils.random(
0
,
8
)}
`
,
duration
:
() =>
utils.
random
(
1200
,
1800
),
delay
:
() =>
utils.
random
(
0
,
400
),
ease
:
'outElastic(1, .5)'
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
data-x
=
"170"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
data-x
=
"80"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
data-x
=
"270"
>
</
div
>
</
div
>
Previous
Next
CSS variable
Tween parameters

=== DOC: 283_scrollobserver-callbacks.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks
ScrollObserver
Since 4.0.0
ScrollObserver callbacks
Triggers functions at specific points during scroll.
ScrollObservers callbacks functions are defined directly in the
onScroll
()
parameters
Object
.
animate
(
'.square'
, {
x
:
100
,
autoplay
:
onScroll
({
container
:
'.container'
,
target
:
'.section'
,
axis
:
'y'
,
enter
:
'bottom top'
,
leave
:
'top bottom'
,
sync
:
true
,
┌──────────────────────────┐
│
onEnter
:
() =>
{},     │
│
onLeave
:
() =>
{},     ├─
Callbacks
│
onUpdate
:
() =>
{},    │
└──────────────────────────┘
})
});
In this section
onEnter
onEnterForward
onEnterBackward
onLeave
onLeaveForward
onLeaveBackward
onUpdate
onSyncComplete
Previous
Next
ScrollObserver synchronisation modes
onEnter

=== DOC: 284_debug.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings/debug
ScrollObserver

Settings
Since 4.0.0
debug
Displays markers to better visualise the
enter
and
leave
thresholds
values.
Each ScrollObserver instances has a dedicated color.
The left side of the ruler represents the container
threshold
, and the right side the target
threshold
values.
Accepts
Boolean
Default
false
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
debug
:
true
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll up
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
target
axis

=== DOC: 285_timer-properties.txt ===
URL: https://animejs.com/documentation/timer/timer-properties
Timer
Timer properties
const
timer =
createTimer
(parameters);
┌────────────┐
timer.│progress    │
timer.│currentTime ├─
Properties
timer.│duration    │
└────────────┘
Name
Description
id
Gets and sets the ID of the timer (
String
|
Number
)
deltaTime
Gets the time in ms elapsed between the current and previous frame (
Number
)
currentTime
Gets and sets the global current time in ms of the timer (
Number
)
iterationCurrentTime
Gets and sets the current iteration time in ms (
Number
)
progress
Gets and sets the overall progress of the timer from
0
to
1
(
Number
)
iterationProgress
Gets and sets the progress of the current iteration from
0
to
1
(
Number
)
currentIteration
Gets and sets the current iteration count (
Number
).
speed
Gets and sets the playbackRate multiplier of the timer (
Number
)
fps
Gets and sets the frameRate of the timer (
Number
)
paused
Gets and sets whether the timer is paused (
Boolean
)
began
Gets and sets whether the timer has started (
Boolean
)
completed
Gets and sets whether the timer has completed (
Boolean
)
reversed
Gets and sets whether the timer is reversed (
Boolean
)
Previous
Next
Timer methods
Animation

=== DOC: 286_tween-values-keyframes.txt ===
URL: https://animejs.com/documentation/animation/keyframes/tween-values-keyframes
Animation

Keyframes
Since 4.0.0
Tween values keyframes
V4
Sequences multiple
Tween value
specific to an
Animatable property
using an
Array
.
The duration between each keyframe equals the total animation duration divided by the number of transitions between each keyframes.
The first keyframe defines the
from value
of the tween.
You can use this syntax to quickly set the initial
from value
value of an animation:
animate
(
target
: {
x
: [-
100
,
100
] });
// Animate x from -100 to 100
Accepts
An
Array
of valid
Tween values
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
translateX
: [
'0rem'
,
0
,
17
,
17
,
0
,
0
],
translateY
: [
'0rem'
, -
2.5
, -
2.5
,
2.5
,
2.5
,
0
],
scale
: [
1
,
1
,
.5
,
.5
,
1
,
1
],
rotate
: {
to
:
360
,
ease
:
'linear'
},
duration
:
3000
,
ease
:
'inOut'
,
// ease applied between each keyframes if no ease defined
playbackEase
:
'ouIn(5)'
,
// ease applied accross all keyframes
loop
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Keyframes
Tween parameters keyframes

=== DOC: 287_onsynccomplete.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-callbacks/onsynccomplete
ScrollObserver

Callbacks
Since 4.0.0
onSyncComplete
Triggers a function when the linked object synchronisation completes.
Accepts
A
Function
whose first argument returns the ScrollObserver instance
Default
noop
import
{ animate, onScroll, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
completions =
0
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom top'
,
leave
:
'center bottom'
,
sync
:
.5
,
debug
:
true
,
onSyncComplete
:
() =>
$value.
textContent
= ++completions,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded sticky"
>
<
div
class
=
"large row"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
completions
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
onUpdate
ScrollObserver methods

=== DOC: 288_javascript-object-properties.txt ===
URL: https://animejs.com/documentation/animation/animatable-properties/javascript-object-properties
Animation

Animatable properties
Since 1.0.0
JavaScript Object properties
JS
Numerical and color JavaScript
Object
properties can be passed directly to the animation parameters.
import
{ animate, utils }
from
'animejs'
;
const
myObject = {
number
:
1337
,
unit
:
'42%'
,
}
const
[ $log ] = utils.$(
'code'
);
animate
(myObject, {
number
:
50
,
unit
:
'100%'
,
modifier
: utils.
round
(
0
),
onRender
:
function
(
) {
$log.
innerHTML
=
JSON
.
stringify
(myObject);
}
});
<
pre
class
=
"row large centered"
>
<
code
>
{"number":1337,"unit":"42%"}
</
code
>
</
pre
>
Previous
Next
CSS Variables
HTML Attributes

=== DOC: 289_sync-timelines.txt ===
URL: https://animejs.com/documentation/timeline/sync-timelines
Timeline
Since 4.0.0
Sync timelines
V4
Timelines can be synchronised to an other timeline using the
sync
()
method.
timelineA.
sync
(timelineB, position);
Parameters
Name
Accepts
synced
Animation
|
Timer
|
Timeline
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, animate }
from
'animejs'
;
const
circleAnimation =
animate
(
'.circle'
, {
x
:
'15rem'
});
const
tlA =
createTimeline
()
.
sync
(circleAnimation)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
duration
:
2000
,
})
.
add
(
'.square'
, {
x
:
'15rem'
,
});
const
tlB =
createTimeline
({
defaults
: {
duration
:
2000
} })
.
add
([
'.triangle'
,
'.square'
], {
rotate
:
360
,
},
0
)
.
add
(
'.circle'
, {
scale
: [
1
,
1.5
,
1
],
},
0
);
const
tlMain =
createTimeline
()
.
sync
(tlA)
.
sync
(tlB,
'-=2000'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Sync WAAPI animations
Call functions

=== DOC: 290_refresh.txt ===
URL: https://animejs.com/documentation/animation/animation-methods/refresh
Animation

Methods
Since 4.0.0
refresh()
V4
JS
Re-computes animated properties values defined with a
Function based value
by updating the
from
values to the current target values, and the
to
values to the newly computed values.
Only the animatable properties values are re-calculated,
duration
and
delay
cannot be refreshed.
Returns
The animation itself
Can be chained with other animation methods.
import
{ animate }
from
'animejs'
;
const
[ $refreshButton ] = utils.$(
'.refresh'
);
const
animation =
animate
(
'.square'
, {
x
:
() =>
utils.
random
(
0
,
17
) +
'rem'
,
y
:
() =>
utils.
random
(-
1
,
1
) +
'rem'
,
rotate
:
() =>
utils.
random
(-
360
,
360
,
1
),
scale
:
() =>
utils.
random
(
.1
,
1.5
,
2
),
duration
:
750
,
loop
:
true
,
onLoop
:
self
=>
self.
refresh
()
});
const
refreshAnimation
= (
) => animation.
refresh
().
restart
();
$refreshButton.
addEventListener
(
'click'
, refreshAnimation);
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button refresh"
>
Refresh & Restart
</
button
>
</
fieldset
>
</
div
>
Previous
Next
stretch()
Animation properties

=== DOC: 291_modifier.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters/modifier
Draggable

Axes parameters
Since 4.0.0
modifier
Defines a
Modifier function
that alter of modify the value of either both axes or one specific axis.
Accepts
Modifier function
Default
noop
import
{ createDraggable, utils }
from
'animejs'
;
createDraggable
(
'.square'
, {
modifier
: utils.
wrap
(-
32
,
32
),
// Global to both x and y
x
: {
modifier
: utils.
wrap
(-
128
,
128
) },
// Specific to x
});
<
div
class
=
"large grid centered square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
Previous
Next
snap
mapTo

=== DOC: 292_stagger-grid.txt ===
URL: https://animejs.com/documentation/stagger/stagger-parameters/stagger-grid
Stagger

Parameters
Since 2.0.0
Stagger grid
Distributes values on a 2d
Array
.
Accepts
[<
Number
>, <
Number
>]
Default
null
import
{ animate, stagger }
from
'animejs'
;
const
$squares = utils.$(
'.square'
);
function
animateGrid
(
) {
animate
($squares, {
scale
: [
{
to
: [
0
,
1.25
] },
{
to
:
0
}
],
boxShadow
: [
{
to
:
'0 0 1rem 0 currentColor'
},
{
to
:
'0 0 0rem 0 currentColor'
}
],
delay
:
stagger
(
100
, {
grid
: [
11
,
4
],
from
: utils.
random
(
0
,
11
*
4
)
}),
onComplete
: animateGrid
});
}
animateGrid
();
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Stagger ease
Stagger grid axis

=== DOC: 293_cursor.txt ===
URL: https://animejs.com/documentation/draggable/draggable-settings/cursor
Draggable

Settings
Since 4.0.0
cursor
Specifies custom CSS cursor style properties for the hovered and grabbed states on devices that match the media query
'(pointer:fine)'
.
Accepts
Boolean
(
false
disable custom styling)
{
onHover
:
'grab'
,
onGrab
:
'grabbing'
}
A
Function
that returns an of the above
When defined using a
Function
, the value will be automatically refreshed every time the container or target element is resized.
It can also be refreshed manually using the
refresh
()
method.
Default
{
onHover
:
'grab'
,
onGrab
:
'grabbing'
}
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square'
, {
cursor
:
false
});
createDraggable
(
'.circle'
, {
cursor
: {
onHover
:
'move'
,
onGrab
:
'wait'
}
});
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
<
div
class
=
"circle draggable"
>
</
div
>
</
div
>
Previous
Next
scrollSpeed
Draggable callbacks

=== DOC: 294_disable.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/disable
Draggable

Methods
Since 4.0.0
disable()
Deactivates the draggable, rendering it inert.
Returns
The draggable itself
import
{ createDraggable, utils }
from
'animejs'
;
const
[ $disableButton ] = utils.$(
'.disable'
);
const
draggable =
createDraggable
(
'.square'
);
const
disableDraggable
= (
) => draggable.
disable
();
$disableButton.
addEventListener
(
'click'
, disableDraggable);
<
div
class
=
"large centered row"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
<
div
class
=
"large row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button disable"
>
Disable
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Draggable methods
enable()

=== DOC: 295_add.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/add
Timeline

Methods
Since 2.0.0
add()
V4
Creates and adds animations and timers to a timeline.
The type of element added to the timeline depends of the parameters passed to
add
()
.
Add animation
timeline.
add
(targets, parameters, position);
Parameter
Accepts
targets
Targets
parameters
Animatable properties
&
Tween parameters
&
Animation playback settings
&
Animation callbacks
position
(opt)
Time position
Add timer
timeline.
add
(timerParameters, position);
Parameter
Type
timerParameters
Timer playback settings
&
Timer callbacks
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
tl =
createTimeline
()
// Add labels
.
label
(
'start timer 1'
,
0
)
.
label
(
'animate circle'
,
1000
)
.
label
(
'start timer 2'
,
2000
)
// Add Timer
.
add
({
duration
:
1000
,
onUpdate
:
self
=>
$value.
innerHTML
= self.
currentTime
,
},
'start timer 1'
)
// Add Animation
.
add
(
'.circle'
, {
duration
:
2000
,
x
:
'16rem'
,
},
'animate circle'
)
// Add Timer
.
add
({
duration
:
1000
,
onUpdate
:
self
=>
$value.
innerHTML
= self.
currentTime
,
},
'start timer 2'
);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
value
</
span
>
<
span
class
=
"value lcd"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
Timeline methods
set()

=== DOC: 296_positions-shorthands.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-thresholds/positions-shorthands
ScrollObserver

Thresholds
Since 4.0.0
Positions shorthands
Defines the position of the target and container by passing the position name.
Accepts
Value
Returns
'top'
The top y value
'bottom'
The bottom y value
'left'
The left x value
'right'
The right x value
'center'
The center x or y value
'start'
Equivalent to
'top'
and
'left'
depending of the axis
'end'
Equivalent to
'bottom'
and
'right'
depending of the axis
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'center top'
,
leave
:
'center bottom'
,
debug
:
true
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Numeric values
Relative position values

=== DOC: 297_y.txt ===
URL: https://animejs.com/documentation/draggable/draggable-axes-parameters/y
Draggable

Axes parameters
Since 4.0.0
y
Defines the behaviour of the y-axis by either passing an object of parameters or disabling it by setting the value to
false
.
Accepts
Boolean
Draggable axes parameters
Object
Default
true
import
{ createDraggable }
from
'animejs'
;
createDraggable
(
'.square.enabled'
, {
y
:
true
});
createDraggable
(
'.square.disabled'
, {
y
:
false
});
<
div
class
=
"large spaced-evenly row"
>
<
div
class
=
"square enabled draggable"
>
</
div
>
<
div
class
=
"square disabled draggable"
>
</
div
>
</
div
>
<
div
class
=
"large spaced-evenly row"
>
<
div
class
=
"label"
>
y enabled
</
div
>
<
div
class
=
"label"
>
y disabled
</
div
>
</
div
>
Previous
Next
x
snap

=== DOC: 298_draggable-callbacks.txt ===
URL: https://animejs.com/documentation/draggable/draggable-callbacks
Draggable
Since 4.0.0
Draggable callbacks
Execute functions at specific points while dragging an element.
Draggable callback functions are specified directly in the
createDraggable
()
parameters
Object
.
createDraggable
(
'.square'
, {
x
: {
snap
:
100
},
y
: {
snap
:
50
},
modifier
: utils.
wrap
(-
200
,
0
),
containerPadding
:
10
,
containerStiffness
:
40
,
containerEase
:
'out(3)'
,
┌────────────────────────┐
│
onGrab
:
() =>
{},      │
│
onDrag
:
() =>
{},      ├─
Callbaks
│
onRelease
:
() =>
{},   │
└────────────────────────┘
});
In this section
onGrab
onDrag
onUpdate
onRelease
onSnap
onSettle
onResize
onAfterResize
Previous
Next
Draggable settings
onGrab

=== DOC: 299_delay.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/delay
Timeline

Playback settings
Since 2.0.0
delay
Defines the delay, in milliseconds, before the timeline starts.
Accepts
A
Number
equal to or greater than
0
Default
0
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
delay
=
500
;
import
{ createTimeline, createTimer, utils }
from
'animejs'
;
const
tl =
createTimeline
({
delay
:
2000
,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
// For logging delayed time only
const
[ $time ] = utils.$(
'.time'
);
createTimer
({
duration
:
2000
+ tl.
duration
,
onUpdate
:
self
=>
$time.
innerHTML
= (
2000
- self.
currentTime
) * -
1
,
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
defaults
loop

=== DOC: 300_register-method-function.txt ===
URL: https://animejs.com/documentation/scope/register-method-function
Scope
Since 4.0.0
Register method function
A method can be registered within a Scope by passing a
String
name and a
Function
to the Scope's
add
()
method. Once registered, the method becomes available on the Scope instance's
methods
object. This allows the method to be called from outside the Scope while maintaining its execution context within the Scope.
scope.
add
(
'methodName'
, methodFunction);
// Register the method
scope.
methods
.
methodName
();
// Execute the method
Method arguments
Name
Type
...args
Any
import
{ utils, animate, createScope }
from
'animejs'
;
const
scope =
createScope
({
mediaQueries
: {
isSmall
:
'(max-width: 200px)'
},
})
.
add
(
self
=>
{
/* Registering the method inside the scope allows access to the scope itself */
self.
add
(
'onClick'
,
(
e
) =>
{
const
{ clientX, clientY } = e;
const
{ isSmall } = self.
matches
;
animate
(
'.square'
, {
rotate
: isSmall ?
'+=360'
:
0
,
x
: isSmall ?
0
: clientX - (
window
.
innerWidth
/
2
),
y
: isSmall ?
0
: clientY - (
window
.
innerHeight
/
2
),
duration
: isSmall ?
750
:
400
,
});
});
utils.
set
(
document
.
body
, {
cursor
: self.
matches
.
isSmall
?
'alias'
:
'crosshair'
});
});
/* Methods can be called outside the scope */
document
.
addEventListener
(
'click'
, scope.
methods
.
onClick
);
<
div
class
=
"iframe-content resizable"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"col"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
Add constructor function
Scope parameters

=== DOC: 301_playbackease.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings/playbackease
Animation

Playback settings
Since 4.0.0
playbackEase
V4
JS
Applies and easing function to the entire playback of the animation.
Unlike the tween
ease
parameter that is applied in between every property keyframes like this:
0
────────────────────────────────›
1
A ──ease──› B ──ease──› C ──ease──› D
The
playbackEase
parameter is applied globally like this:
0
──────────────ease──────────────›
1
A ────────› B ────────› C ────────› D
Accepts
ease
Default
null
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
playbackEase
=
'inOut'
;
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
keyframes
: [
{
y
:
'-2.5rem'
,
duration
:
400
},
{
x
:
'17rem'
,
rotate
:
180
,
scale
:
.5
},
{
y
:
'2.5rem'
},
{
x
:
0
,
rotate
:
360
,
scale
:
1
},
{
y
:
0
,
duration
:
400
}
],
duration
:
4000
,
playbackEase
:
'inOut(3)'
,
// this ease is applied accross all keyframes
loop
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
playbackRate
Animation callbacks

=== DOC: 302_css-variable.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/css-variable
Animation

Tween value types
Since 4.0.0
CSS variable
WAAPI
The
WAAPI
animate
()
method can natively animate any css variable by simply passing the variable value using the
'var(--my-value)'
syntax.
Accepts
CSS variable
CSS Variables can be used with the
JS
animate
()
method by combining a
Function based value
and
utils.
get
()
.
color
: $target => utils.
get
($target,
'--variable-name'
)
import
{ waapi, animate }
from
'animejs'
;
waapi.
animate
(
'.square'
,  {
rotate
:
'var(--rotation)'
,
borderColor
: [
'var(--hex-orange)'
,
'var(--hex-red)'
],
});
// Helper for the JS animate() method
const
cssVar
= name => $el => utils.
get
($el, name);
animate
(
'.square'
,  {
scale
:
cssVar
(
'--scale'
),
background
: [
cssVar
(
'--hex-red'
),
cssVar
(
'--hex-orange'
)],
});
<
div
class
=
"medium justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Color function value
Function based value

=== DOC: 303_onupdate.txt ===
URL: https://animejs.com/documentation/animation/animation-callbacks/onupdate
Animation

Callbacks
Since 4.0.0
onUpdate
JS
Executes a function on every frames of a running animation at the specified
frameRate
.
Accepts
A
Function
whose first argument returns the animation itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onUpdate
=
self
=>
console
.
log
(self.
id
);
import
{ animate, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
let
updates =
0
;
const
animation =
animate
(
'.circle'
, {
x
:
'16rem'
,
loopDelay
:
1500
,
loop
:
true
,
alternate
:
true
,
onUpdate
:
self
=>
$value.
textContent
= ++updates
});
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
updates
</
span
>
<
span
class
=
"value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
onBeforeUpdate
onRender

=== DOC: 304_complete.txt ===
URL: https://animejs.com/documentation/timer/timer-methods/complete
Timer

Methods
Since 4.0.0
complete()
Completes a timer instantly.
Returns
The timer itself
Can be chained with other timer methods.
import
{ createTimer, utils }
from
'animejs'
;
const
[ $completeButton ] = utils.$(
'.complete'
);
const
[ $time ] = utils.$(
'.time'
);
const
timer =
createTimer
({
duration
:
100000
,
onUpdate
:
self
=>
$time.
innerHTML
= self.
currentTime
});
const
completeTimer
= (
) => timer.
complete
();
$completeButton.
addEventListener
(
'click'
, completeTimer);
<
div
class
=
"large centered row"
>
<
div
class
=
"half col"
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
current time
</
span
>
<
span
class
=
"time value lcd"
>
0
</
span
>
</
pre
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button complete"
>
Complete
</
button
>
</
fieldset
>
</
div
>
Previous
Next
resume()
cancel()

=== DOC: 305_duration-based-keyframes.txt ===
URL: https://animejs.com/documentation/animation/keyframes/duration-based-keyframes
Animation

Keyframes
Since 2.0.0
Duration based keyframes
JS
Sequences multiple
Animatable property
one after another.
This syntax allows very fine control over an animation by giving access to
ease
,
delay
,
duration
and
modifier
parameters for each individual keyframes.
The default duration of a keyframe equals the total animation duration divided by the total number of keyframes.
keyframes
: [
{
y
:
50
,
ease
:
'out'
,
duration
:
400
},
{
x
:
75
,
scale
:
.5
,
duration
:
800
},
]
Accepts
An
Array
of
Object
containing one
Animatable property
and
Tween parameters
import
{ animate }
from
'animejs'
;
animate
(
'.square'
, {
keyframes
: [
{
y
:
'-2.5rem'
,
ease
:
'out'
,
duration
:
400
},
{
x
:
'17rem'
,
scale
:
.5
,
duration
:
800
},
{
y
:
'2.5rem'
},
// The duration here is 3000 / 5 = 600ms
{
x
:
0
,
scale
:
1
,
duration
:
800
},
{
y
:
0
,
ease
:
'in'
,
duration
:
400
}
],
rotate
: {
to
:
360
,
ease
:
'linear'
},
duration
:
3000
,
ease
:
'inOut'
,
// ease applied between each keyframes if no ease defined
playbackEase
:
'ouIn(5)'
,
// ease applied accross all keyframes
loop
:
true
,
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Tween parameters keyframes
Percentage based keyframes

=== DOC: 306_draggable-methods.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods
Draggable
Since 4.0.0
Draggable methods
Controls the state and behaviour of a draggable.
Draggable methods are accessible through a Draggable instance
Object
.
const
draggable =
createDraggable
(target, parameters);
┌──────────┐
draggable.│
disable
() │
draggable.│
enable
()  ├─
Methods
draggable.│
revert
()  │
└──────────┘
In this section
disable()
enable()
setX()
setY()
animateInView()
scrollInView()
stop()
reset()
revert()
refresh()
Previous
Next
Draggable callbacks
disable()

=== DOC: 307_numeric-values.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-thresholds/numeric-values
ScrollObserver

Thresholds
Since 4.0.0
Numeric values
Defines an offset from the top of the target and container by passing a numeric values.
If no unit is defined, the values is interpreted as pixels.
Accepts
Type
Example
Description
Number
100
100px from the top of the target or container
Unit
'1rem'
1rem from the top of the target or container
Percentage
'10%'
10% of the target or container height, from the top of the target or container
Default unit
px
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
// -48px from the top of the target, 80px from the top of the container
enter
:
'80 -48'
,
// 250% from the top of the target, 67.5% from the top of the container
leave
:
'67.5% 250%'
,
debug
:
true
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
ScrollObserver thresholds
Positions shorthands

=== DOC: 308_values-staggering.txt ===
URL: https://animejs.com/documentation/stagger/values-staggering
Stagger
Since 2.0.0
Values staggering
All tweens animatable properties accept function-based values, enabling the use of the stagger function returned by the
stagger
()
method in multi-target animations.
This results in each target having a staggered value, increasing by a set number for each subsequent target.
import
{ animate, stagger }
from
'animejs'
;
const
animation =
animate
(
'.square'
, {
y
:
stagger
([
'-2.75rem'
,
'2.75rem'
]),
rotate
: {
from
:
stagger
(
'-.125turn'
) },
loop
:
true
,
alternate
:
true
});
<
div
class
=
"small justified row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
Time staggering
Timeline positions staggering

=== DOC: 309_alternate.txt ===
URL: https://animejs.com/documentation/timeline/timeline-playback-settings/alternate
Timeline

Playback settings
Since 4.0.0
alternate
Defines if the direction of the timeline alternates on each iteration when the loop parameter is set to
true
or superior to
1
.
Accepts
Boolean
Default
false
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
alternate
=
true
;
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $loops ] = utils.$(
'.loops'
);
let
loops =
0
;
const
tl =
createTimeline
({
loop
:
true
,
alternate
:
true
,
onLoop
:
self
=>
$loops.
innerHTML
= ++loops,
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
'-=500'
)
.
add
(
'.square'
, {
x
:
'15rem'
},
'-=500'
);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
loops
</
span
>
<
span
class
=
"loops value"
>
0
</
span
>
</
pre
>
</
div
>
Previous
Next
loopDelay
reversed

=== DOC: 310_complete.txt ===
URL: https://animejs.com/documentation/timeline/timeline-methods/complete
Timeline

Methods
Since 4.0.0
complete()
V4
Completes the timeline instantly.
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $completeButton ] = utils.$(
'.complete'
);
const
tl =
createTimeline
({
loop
:
true
,
})
.
add
(
'.circle'
,   {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
},
500
)
.
add
(
'.square'
,   {
x
:
'15rem'
},
1000
);
const
completeTimeline
= (
) => tl.
complete
();
$completeButton.
addEventListener
(
'click'
, completeTimeline);
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button complete"
>
Complete
</
button
>
</
fieldset
>
</
div
>
Previous
Next
resume()
cancel()

=== DOC: 311_relative-value.txt ===
URL: https://animejs.com/documentation/animation/tween-value-types/relative-value
Animation

Tween value types
Since 2.0.0
Relative value
JS
Adds, subtracts or multiplies the current target value by a specified amount.
Accepts
Prefix
Effect
Examples
'+='
Add
'+=45'
|
'+=45px'
'-='
Subtracts
'-=45'
|
'-=45deg'
'*='
Multiply
'*=.5'
import
{ animate, utils }
from
'animejs'
;
const
[ $clock ] = utils.$(
'.clock'
);
const
[ $add ] = utils.$(
'.add'
);
const
[ $sub ] = utils.$(
'.sub'
);
const
[ $mul ] = utils.$(
'.mul'
);
const
add
= (
) =>
animate
($clock, {
rotate
:
'+=90'
});
const
sub
= (
) =>
animate
($clock, {
rotate
:
'-=90'
});
const
mul
= (
) =>
animate
($clock, {
rotate
:
'*=.5'
});
$add.
addEventListener
(
'click'
, add);
$sub.
addEventListener
(
'click'
, sub);
$mul.
addEventListener
(
'click'
, mul);
<
div
class
=
"large centered row"
>
<
div
class
=
"clock"
>
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
class
=
"button add"
>
+ 90°
</
button
>
<
button
class
=
"button sub"
>
- 90°
</
button
>
<
button
class
=
"button mul"
>
× .5
</
button
>
</
fieldset
>
</
div
>
Previous
Next
Unit conversion value
Color value

=== DOC: 312_onbegin.txt ===
URL: https://animejs.com/documentation/timeline/timeline-callbacks/onbegin
Timeline

Callbacks
Since 4.0.0
onBegin
Executes a function when an timeline begins to play.
Accepts
A
Function
whose first argument returns the timeline itself
Default
noop
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
onBegin
=
self
=>
console
.
log
(self.
id
);
import
{ createTimeline, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
tl =
createTimeline
({
delay
:
1000
,
// Delays the onBegin() callback by 1000ms
onBegin
:
self
=>
$value.
textContent
= self.
began
})
.
add
(
'.circle'
, {
x
:
'15rem'
})
.
add
(
'.triangle'
, {
x
:
'15rem'
})
.
add
(
'.square'
, {
x
:
'15rem'
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
began
</
span
>
<
span
class
=
"value"
>
false
</
span
>
</
pre
>
</
div
>
Previous
Next
Timeline callbacks
onComplete

=== DOC: 313_smooth-scroll.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes/smooth-scroll
ScrollObserver

Synchronisation modes
Since 4.0.0
Smooth scroll
Smoothly animate the playback progress of the linked object to the scroll position by passing a value between
0
and
1
. The closer the value gets to
0
, the longer the animation takes to catch up with the current scroll position.
Accepts
A
Number
greater than or equal to
0
and lower to or equal
1
import
{ animate, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
ease
:
'linear'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
enter
:
'bottom-=50 top'
,
leave
:
'top+=60 bottom'
,
sync
:
.25
,
debug
:
true
,
})
});
<
div
class
=
"scroll-container scroll-y"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"label"
>
scroll down
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Playback progress
Eased scroll

=== DOC: 314_random.txt ===
URL: https://animejs.com/documentation/utilities/random
Utilities
Since 2.0.0
random()
Returns a random
Number
within a specified range, with an optional third parameter determining the number of decimal places.
const
randomValue = utils.
random
(min, max, decimalLength);
Parameters
Name
Accepts
min
Number
max
Number
decimalLength=0
(opt)
Number
Returns
Number
import
{ utils }
from
'animejs'
;
utils.
set
(
'.square'
, {
x
:
() =>
utils.
random
(
2
,
18
,
2
) +
'rem'
,
rotate
:
() =>
utils.
random
(
0
,
180
),
scale
:
() =>
utils.
random
(
.25
,
1.5
,
3
),
});
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
<
div
class
=
"small row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
Previous
Next
cleanInlineStyles()
randomPick()

=== DOC: 315_ease.txt ===
URL: https://animejs.com/documentation/animation/tween-parameters/ease
Animation

Tween parameters
Since 4.0.0
ease
Defines the easing function for all animated properties or a specific property.
Easing functions control the rate of change of a property value over time, determining the animation's speed at different points during playback.
All Anime.js built-in easing functions can either be used by passing the easing name
String
or the function accessible on the
eases
object.
import
{ eases }
from
'animejs'
;
const
{ linear, outExpo, cubicBezier } = eases;
The
createSpring
()
easing function must be imported separately.
import
{ createSpring }
from
'animejs'
;
Accepts
Built-in string
Function
Parameters
'linear'
'linear(0, .5 75%, 1)'
linear
()
coords (
0
,
'.5 75%'
,
1
)
'irregular'
JS
'irregular(10, 1)'
JS
irregular
()
length =
10
, randomness =
1
'steps'
'steps(10)'
steps
()
steps =
10
'cubicBezier'
'cubicBezier(.5,0,.5,1)'
cubicBezier
()
x1 =
.5
, y1 =
0
, x2 =
.5
, y2 =
1
'in'
'in(1.675)'
in
()
power =
1.675
'out'
'out(1.675)'
out
()
power =
1.675
'inOut'
'inOut(1.675)'
inOut
()
power =
1.675
'inQuad'
JS
inQuad
-
'outQuad'
JS
outQuad
-
'inOutQuad'
JS
inOutQuad
-
'inCubic'
JS
inCubic
-
'outCubic'
JS
outCubic
-
'inOutCubic'
JS
inOutCubic
-
'inQuart'
JS
inQuart
-
'outQuart'
JS
outQuart
-
'inOutQuart'
JS
inOutQuart
-
'inQuint'
JS
inQuint
-
'outQuint'
JS
outQuint
-
'inOutQuint'
JS
inOutQuint
-
'inSine'
JS
inSine
-
'outSine'
JS
outSine
-
'inOutSine'
JS
inOutSine
-
'inCirc'
JS
inCirc
-
'outCirc'
JS
outCirc
-
'inOutCirc'
JS
inOutCirc
-
'inExpo'
JS
inExpo
-
'outExpo'
JS
outExpo
-
'inOutExpo'
JS
inOutExpo
-
'inBounce'
JS
inBounce
-
'outBounce'
JS
outBounce
-
'inOutBounce'
JS
inOutBounce
-
'inBack'
JS
'inBack(1.70158) '
JS
inBack
()
overshoot =
1.70158
'outBack'
JS
'outBack(1.70158) '
JS
outBack
()
overshoot =
1.70158
'inOutBack'
JS
'inOutBack(1.70158) '
JS
inOutBack
()
overshoot =
1.70158
'inElastic'
JS
'inElastic(1, .3) '
JS
inElastic
()
amplitude =
1
, period =
.3
'outElastic'
JS
'outElastic(1, .3) '
JS
outElastic
()
amplitude =
1
, period =
.3
'inOutElastic'
JS
'inOutElastic(1, .3) '
JS
inOutElastic
()
amplitude =
1
, period =
.3
-
createSpring
()
{
mass
:
1
,
stiffness
:
100
,
damping
:
10
,
velocity
:
0
}
Default
'out(2)'
To change the default value globally, update the
engine.
defaults
object.
import
{ engine }
from
'animejs'
;
engine.
defaults
.
ease
=
'outElastic(1, .5)'
;
// // v3 throwback :)
import
{ animate, waapi, eases, createSpring }
from
'animejs'
;
animate
(
'.row:nth-child(1) .square'
, {
x
:
'17rem'
,
rotate
:
360
,
ease
:
'inQuad'
,
});
animate
(
'.row:nth-child(2) .square'
, {
x
:
'17rem'
,
rotate
:
360
,
ease
: eases.
outQuad
,
});
waapi.
animate
(
'.row:nth-child(3) .square'
, {
x
:
'17rem'
,
rotate
: {
to
:
360
,
ease
:
'out(6)'
,
},
ease
:
createSpring
({
stiffness
:
70
}),
});
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
all: 'inQuad'
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
all: eases.outQuad
</
div
>
</
div
>
<
div
class
=
"medium row"
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"padded label"
>
x: createSpring()
<
br
>
rotate: 'inQuad'
</
div
>
</
div
>
Previous
Next
duration
composition

=== DOC: 316_svg.txt ===
URL: https://animejs.com/documentation/svg
SVG
A collection of utility functions to help with SVG morphing, line drawing and motion path animations.
All SVG utilities functions are available on the
svg
object.
import
{ svg }
from
'animejs'
;
In this section
morphTo()
createDrawable()
createMotionPath()
Previous
Next
Stagger
morphTo()

=== DOC: 317_axis.txt ===
URL: https://animejs.com/documentation/scroll/scrollobserver-settings/axis
ScrollObserver

Settings
Since 4.0.0
axis
Specifies the scroll direction of the ScrollObserver container
HTMLElement
.
Accepts
'x'
'y'
Defaults
'y'
import
{ createTimer, utils, onScroll }
from
'animejs'
;
animate
(
'.square'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
2000
,
alternate
:
true
,
loop
:
true
,
ease
:
'inOutQuad'
,
autoplay
:
onScroll
({
container
:
'.scroll-container'
,
axis
:
'x'
,
})
});
<
div
class
=
"scroll-container scroll-x"
>
<
div
class
=
"scroll-content grid square-grid"
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large centered row"
>
<
div
class
=
"label"
>
scroll right →
</
div
>
</
div
>
</
div
>
<
div
class
=
"scroll-section padded"
>
<
div
class
=
"large row"
>
<
div
class
=
"square"
>
</
div
>
</
div
>
</
div
>
</
div
>
</
div
>
Previous
Next
debug
repeat

=== DOC: 318_finished.txt ===
URL: https://animejs.com/documentation/web-animation-api/api-differences-with-native-waapi/finished
Web Animation API

API differences
Since 4.0.0
finished
animation.
finished
is replaced by the
animation.
then
()
method. It returns a
Promise
that resolves and execute a callback when the animation completes.
Syntax comparison
Anime.js
The
then
()
method can be directly inlined like this:
waapi.
animate
(target, {
translate
:
'100px'
,
duration
:
500
,
}).
then
(callback);
Or used in an
async
/
await
context:
async
function
waitForAnimationToComplete
(
) {
return
animate
(target, {
translate
:
'100px'
,
duration
:
500
,
});
}
const
asyncAnimation =
await
waitForAnimationToComplete
();
WAAPI equivalent
const
targets =
document
.
querySelectorAll
(
'.square'
);
const
animations = [];
targets.
forEach
(
(
$el, i
) =>
{
animations[i] = $el.
animate
({
translate
:
'100px'
,
}, {
fill
:
'forwards'
,
duration
:
500
,
});
});
Promise
.
all
(
animations
.
map
(
(
animation
) =>
animation.
finished
)
.
then
(
() =>
console
.
log
(
'completed'
))
);
Parameters
Name
Type
callback
A
Function
whose first argument returns the animation itself
Returns
Promise
import
{ waapi, utils }
from
'animejs'
;
const
[ $value ] = utils.$(
'.value'
);
const
animation = waapi.
animate
(
'.circle'
, {
translate
:
'16rem'
,
loop
:
2
,
alternate
:
true
,
});
animation.
then
(
() =>
$value.
textContent
=
'fulfilled'
);
<
div
class
=
"large row"
>
<
div
class
=
"circle"
>
</
div
>
<
pre
class
=
"large log row"
>
<
span
class
=
"label"
>
promise status
</
span
>
<
span
class
=
"value"
>
pending
</
span
>
</
pre
>
</
div
>
Previous
Next
easing
waapi.convertEase()

=== DOC: 319_scrollinview.txt ===
URL: https://animejs.com/documentation/draggable/draggable-methods/scrollinview
Draggable

Methods
Since 4.0.0
scrollInView()
Animate the scroll position of the container if the draggable  position is outside of the
scroll threshold
.
Parameters
Name
Type
Description
duration
(opt)
Number
The duration of the animation (default
350
)
gap
(opt)
Boolean
How much extra distance from the edges of the container the draggable should be animated to
ease
(opt)
ease
The easing function applied to the animation (default
InOutQuad
Returns
The draggable itself
import
{ createDraggable }
from
'animejs'
;
const
[ $scrollInView ] = utils.$(
'.scroll-button'
);
const
draggable =
createDraggable
(
'.square'
, {
container
:
'.scroll-container'
,
});
const
scrollInView
= (
) => {
draggable.
scrollInView
(
400
,
100
);
}
// Set the draggable position outside the scroll viewport
draggable.
x
=
120
;
draggable.
y
=
200
;
$scrollInView.
addEventListener
(
'click'
, scrollInView);
<
div
class
=
"scroll-container scroll-x scroll-y"
>
<
div
class
=
"scroll-content"
>
<
div
class
=
"large padded grid square-grid"
>
<
div
class
=
"square draggable"
>
</
div
>
</
div
>
</
div
>
</
div
>
<
fieldset
class
=
"absolute controls"
>
<
button
class
=
"button scroll-button"
>
Scroll in view
</
button
>
</
fieldset
>
Previous
Next
animateInView()
stop()

=== DOC: 320_animation-playback-settings.txt ===
URL: https://animejs.com/documentation/animation/animation-playback-settings
Animation
Since 1.0.0
Animation playback settings
Specify the timings and behaviours of an animation.
Playback settings properties are defined directly in the
animate
()
parameters
Object
.
animate
(
'.square'
, {
translateX
:
100
,
scale
:
2
,
opacity
:
.5
,
duration
:
400
,
delay
:
250
,
ease
:
'out(3)'
,
┌───────────────────┐
│
loop
:
3
,          │
│
alternate
:
true
,  ├─
Playback
Settings
│
autoplay
:
false
,  │
└───────────────────┘
onBegin
:
() =>
{},
onLoop
:
() =>
{},
onUpdate
:
() =>
{},
});
In this section
delay
duration
loop
loopDelay
alternate
reversed
autoplay
frameRate
playbackRate
playbackEase
Previous
Next
Keyframes
delay

=== DOC: 321_createmotionpath.txt ===
URL: https://animejs.com/documentation/svg/createmotionpath
SVG
createMotionPath()
Creates pre-defined
Tween parameter
objects that animate along an SVGPathElement's coordinates and inclination.
const
{ translateX, translateY, rotate } = svg.
createMotionPath
(path);
Parameters
Name
Type
path
CSS selector
|
SVGPathElement
Returns
An
Object
with the following properties:
Name
Type
Description
translateX
Tween parameter
Map to the x coordinate of the path element
translateY
Tween parameter
Map to the y coordinate of the path element
rotate
Tween parameter
Map to the angle of the path element
import
{ animate, svg }
from
'animejs'
;
// Animate the transforms properties of .car the motion path values
const
carAnimation =
animate
(
'.car'
, {
ease
:
'linear'
,
duration
:
5000
,
loop
:
true
,
...svg.
createMotionPath
(
'path'
)
});
// Line drawing animation following the motion path values
// For demo aesthetic only
animate
(svg.
createDrawable
(
'path'
), {
draw
:
'0 1'
,
ease
:
'linear'
,
duration
:
5000
,
loop
:
true
});
<
svg
viewBox
=
"0 0 304 112"
>
<
title
>
Suzuka
</
title
>
<
g
stroke
=
"none"
fill
=
"none"
fill-rule
=
"evenodd"
>
<
path
d
=
"M189.142857,4 C227.456875,4 248.420457,4.00974888 256.864191,4.00974888 C263.817211,4.00974888 271.61219,3.69583517 274.986231,6.63061513 C276.382736,7.84531176 279.193529,11.3814152 280.479499,13.4815847 C281.719344,15.5064248 284.841964,20.3571626 275.608629,20.3571626 C265.817756,20.3571626 247.262478,19.9013915 243.955117,19.9013915 C239.27946,19.9013915 235.350655,24.7304885 228.6344,24.7304885 C224.377263,24.7304885 219.472178,21.0304113 214.535324,21.0304113 C207.18393,21.0304113 200.882842,30.4798911 194.124187,30.4798911 C186.992968,30.4798911 182.652552,23.6245972 173.457298,23.6245972 C164.83277,23.6245972 157.191045,31.5424105 157.191045,39.1815359 C157.191045,48.466779 167.088672,63.6623005 166.666679,66.9065088 C166.378668,69.1206889 155.842137,79.2568633 151.508744,77.8570506 C145.044576,75.7689355 109.126667,61.6405346 98.7556561,52.9785141 C96.4766876,51.0750861 89.3680347,39.5769094 83.4195005,38.5221785 C80.6048001,38.0231057 73.0179337,38.7426555 74.4158694,42.6956376 C76.7088819,49.1796531 86.3280337,64.1214904 87.1781062,66.9065088 C88.191957,70.2280995 86.4690152,77.0567847 82.2060607,79.2503488 C79.2489435,80.7719756 73.1324132,82.8858479 64.7015706,83.0708761 C55.1604808,83.2802705 44.4254811,80.401884 39.1722168,80.401884 C25.7762119,80.401884 24.3280517,89.1260466 22.476679,94.4501705 C21.637667,96.8629767 20.4337535,108 33.2301959,108 C37.8976087,108 45.0757044,107.252595 53.4789069,103.876424 C61.8821095,100.500252 122.090049,78.119656 128.36127,75.3523302 C141.413669,69.5926477 151.190142,68.4987755 147.018529,52.0784879 C143.007818,36.291544 143.396957,23.4057975 145.221196,19.6589263 C146.450194,17.1346449 148.420955,14.8552817 153.206723,15.7880203 C155.175319,16.1716965 155.097637,15.0525421 156.757598,11.3860986 C158.417558,7.71965506 161.842736,4.00974888 167.736963,4.00974888 C177.205308,4.00974888 184.938832,4 189.142857,4 Z"
id
=
"suzuka"
stroke
=
"currentColor"
stroke-width
=
"2"
>
</
path
>
</
g
>
</
svg
>
<
div
class
=
"square car motion-path-car"
style
=
"transform: translateX(189px) translateY(4px);"
>
</
div
>
Previous
Next
createDrawable()
Utilities

=== DOC: 322_resume.txt ===
URL: https://animejs.com/documentation/engine/engine-methods/resume
Engine

Methods
Since 4.0.0
resume()
Resumes the engine after being either paused with a call to
engine.
pause
()
.
engine.
pause
();
// Pauses the engine and all animations
engine.
resume
();
// Resumes the engine and all animations
Returns
Engine
import
{ engine, animate, utils }
from
'animejs'
;
const
[ $container ] = utils.$(
'.container'
);
const
[ $pause, $resume ] = utils.$(
'button'
);
function
addAnimation
(
) {
const
$particle =
document
.
createElement
(
'div'
);
$particle.
classList
.
add
(
'particle'
);
$container.
appendChild
($particle);
animate
($particle, {
x
: utils.
random
(-
10
,
10
,
2
) +
'rem'
,
y
: utils.
random
(-
3
,
3
,
2
) +
'rem'
,
scale
: [{
from
:
0
,
to
:
1
}, {
to
:
0
}],
loop
:
true
,
delay
: utils.
random
(
0
,
1000
)
});
}
for
(
let
i =
0
; i <
150
; i++)
addAnimation
();
const
resumeEngine
= (
) => engine.
resume
();
const
pauseEngine
= (
) => engine.
pause
();
$pause.
addEventListener
(
'click'
, pauseEngine);
$resume.
addEventListener
(
'click'
, resumeEngine);
<
div
class
=
"large row container"
>
</
div
>
<
div
class
=
"medium row"
>
<
fieldset
class
=
"controls"
>
<
button
>
Pause
</
button
>
<
button
>
Resume
</
button
>
</
fieldset
>
</
div
>
Previous
Next
pause()
Engine properties

=== DOC: 323_timer-callbacks.txt ===
URL: https://animejs.com/documentation/timer/timer-callbacks
Timer
Since 4.0.0
Timer callbacks
Execute functions at specific points during a timer playback.
Callbacks
Function
are specified directly in the
createTimer
()
parameters
Object
.
createTimer
({
duration
:
1000
,
frameRate
:
true
,
loop
:
true
,
┌─────────────────────┐
│
onBegin
:
() =>
{},  │
│
onLoop
:
() =>
{},   ├─
Callbacks
│
onUpdate
:
() =>
{}, │
└─────────────────────┘
});
In this section
onBegin
onComplete
onUpdate
onLoop
onPause
then()
Previous
Next
Timer playback settings
onBegin

=== DOC: 324_add-animations.txt ===
URL: https://animejs.com/documentation/timeline/add-animations
Timeline
Since 2.0.0
Add animations
Animations can be added to a timeline using the
add
()
method or the
sync
()
method.
Animation creation
Creates and adds an animation directly to the timeline with the
add
()
method.
This allows tween value composition with the timeline's existing children.
timeline.
add
(targets, parameters, position);
Parameters
Name
Accepts
targets
Targets
parameters
An
Object
of
Animatable properties
,
Tween parameters
,
Playback settings
and
Animation callbacks
position
(opt)
Time position
Animation synchronisation
Synchronises an existing animation with the
sync
()
method.
Tween value composition is handled when the animation is created, and won't affect the timeline's existing children when added.
const
animation =
animate
(target, {
x
:
100
});
timeline.
sync
(animation, position);
Parameters
Name
Accepts
animation
Animation
position
(opt)
Time position
Returns
The timeline itself
Can be chained with other timeline methods.
import
{ createTimeline, animate }
from
'animejs'
;
const
circleAnimation =
animate
(
'.circle'
, {
x
:
'15rem'
});
const
tl =
createTimeline
()
.
sync
(circleAnimation)
.
add
(
'.triangle'
, {
x
:
'15rem'
,
rotate
:
'1turn'
,
duration
:
500
,
alternate
:
true
,
loop
:
2
,
})
.
add
(
'.square'
, {
x
:
'15rem'
,
});
<
div
class
=
"large row"
>
<
div
class
=
"medium pyramid"
>
<
div
class
=
"triangle"
>
</
div
>
<
div
class
=
"square"
>
</
div
>
<
div
class
=
"circle"
>
</
div
>
</
div
>
</
div
>
Previous
Next
Add timers
Sync WAAPI animations


====================================================================================================
DOCUMENTATION SITE: MODAL
Size: 1.4 MB
====================================================================================================

=== MODAL DOCUMENTATION COLLECTION ===
Generated: /Users/pandujakkampudi/Desktop/Project1/doc-collector-ai-insights
Source: Documentation scraper
============================================================

=== DOC: 001_index.txt ===
URL: https://modal.com/docs
Modal Documentation
Modal provides a serverless cloud for engineers and researchers who want
to build compute-intensive applications without thinking about
infrastructure.
Run generative AI models, large-scale batch workflows, job queues, and more,
all faster than ever before.
Try the playground
Guide
Everything you need to know to run code on Modal. Dive deep into all of our features and best practices.
Examples
Powerful applications built with Modal. Explore guided starting points for your use case.
Reference
Technical information about the Modal API. Quickly refer to basic descriptions of various programming functionalities.
Playground
Interactive tutorials to learn how to start using Modal. Run serverless cloud functions from your browser.
Guide
Everything you need to know to run code on Modal. Dive deep into all of our features and best practices.
Examples
Powerful applications built with Modal. Explore guided starting points for your use case.
Reference
Technical information about the Modal API. Quickly refer to basic descriptions of various programming functionalities.
Playground
Interactive tutorials to learn how to start using Modal. Run serverless cloud functions from your browser.
Featured Examples
View all
Deploy an OpenAI-compatible LLM service
Run large language models with a drop-in replacement for the OpenAI API.
Custom pet art from Flux with Hugging Face and Gradio
Fine-tune an image generation model on pictures of your pet.
Run llama.cpp
Run DeepSeek-R1 and Phi-4 on llama.cpp
Voice chat with LLMs
Build an interactive voice chat app.
Serve diffusion models
Serve Flux on Modal with a number of optimizations for blazingly fast inference.
Fold proteins with Chai-1
Predict molecular structures from sequences with SotA open source models.
Serverless TensorRT-LLM (LLaMA 3 8B)
Run interactive language model applications.
Star in custom music videos
Fine-tune a Wan2.1 video model on your face and run it in parallel
Create music
Turn prompts into music with MusicGen
Sandbox a LangGraph agent's code
Run an LLM coding agent that runs its own language models.
RAG Chat with PDFs
Use ColBERT-style, multimodal embeddings with a Vision-Language Model to answer questions about documents.
Bring images to life
Prompt a generative video model to animate an image.
Fast podcast transcriptions
Build an end-to-end podcast transcription app that leverages dozens of containers for super-fast processing.
Build a protein folding dashboard
Serve a web UI for a protein model with ESM3, Molstar, and Gradio
Deploy a Hacker News Slackbot
Periodically post new Hacker News posts to Slack.
Retrieval-Augmented Generation (RAG) for Q&A
Build a question-answering web endpoint that can cite its sources.
Document OCR job queue
Use Modal as an infinitely scalable job queue that can service async tasks from a web app.
Parallel processing of Parquet files on S3
Analyze data from the Taxi and Limousine Commission of NYC in parallel.

=== DOC: 002_examples_flux.txt ===
URL: https://modal.com/docs/examples/flux
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Run Flux fast on H100s with
torch.compile
Update: To speed up inference by another >2x, check out the additional optimization
techniques we tried in
this blog post
In this guide, we’ll run Flux as fast as possible on Modal using open source tools.
We’ll use
torch.compile
and NVIDIA H100 GPUs.
Setting up the image and dependencies
import
time
from
import
BytesIO
from
pathlib
import
Path
import
modal
Copy
We’ll make use of the full
CUDA toolkit
in this example, so we’ll build our container image off of the
nvidia/cuda
base.
cuda_version =
"12.4.0"
# should be no greater than host CUDA version
flavor =
"devel"
# includes full CUDA toolkit
operating_sys =
"ubuntu22.04"
tag =
cuda_version
flavor
operating_sys
cuda_dev_image = modal.Image.from_registry(
"nvidia/cuda:
add_python
"3.11"
).entrypoint([])
Copy
Now we install most of our dependencies with
For Hugging Face’s
Diffusers
library
we install from GitHub source and so pin to a specific commit.
PyTorch added [faster attention kernels for Hopper GPUs in version 2.5
diffusers_commit_sha =
"81cf3b2f155f1de322079af28f625349ee21ec6b"
flux_image = (
cuda_dev_image.apt_install(
"git"
"libglib2.0-0"
"libsm6"
"libxrender1"
"libxext6"
"ffmpeg"
"libgl1"
.pip_install(
"invisible_watermark==0.2.0"
"transformers==4.44.0"
"huggingface_hub[hf_transfer]==0.26.2"
"accelerate==0.33.0"
"safetensors==0.4.4"
"sentencepiece==0.2.0"
"torch==2.5.0"
"git+https://github.com/huggingface/diffusers.git@
diffusers_commit_sha
"numpy<2"
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
"HF_HUB_CACHE"
"/cache"
Copy
Later, we’ll also use
torch.compile
to increase the speed further.
Torch compilation needs to be re-executed when each new container starts,
So we turn on some extra caching to reduce compile times for later containers.
flux_image = flux_image.env(
"TORCHINDUCTOR_CACHE_DIR"
"/root/.inductor-cache"
"TORCHINDUCTOR_FX_GRAPH_CACHE"
Copy
Finally, we construct our Modal
set its default image to the one we just constructed,
and import
FluxPipeline
for downloading and running Flux.1.
app = modal.App(
"example-flux"
image
=flux_image)
with
flux_image.imports():
import
torch
from
diffusers
import
FluxPipeline
Copy
Defining a parameterized
Model
inference class
Next, we map the model’s setup and inference code onto Modal.
We the model setun in the method decorated with
@modal.enter()
. This includes  loading the
weights and moving them to the GPU, along with an optional
torch.compile
step (see details below).
@modal.enter()
decorator ensures that this method runs only once, when a new container starts,
instead of in the path of every call.
We run the actual inference in methods decorated with
@modal.method()
MINUTES =
# seconds
VARIANT =
"schnell"
# or "dev", but note [dev] requires you to accept terms and conditions on HF
NUM_INFERENCE_STEPS =
# use ~50 for [dev], smaller for [schnell]
@app.cls
"H100"
# fastest GPU on Modal
scaledown_window
* MINUTES,
timeout
* MINUTES,
# leave plenty of time for compilation
volumes
# add Volumes to store serializable compilation artifacts, see section on torch.compile below
"/cache"
: modal.Volume.from_name(
"hf-hub-cache"
create_if_missing
True
"/root/.nv"
: modal.Volume.from_name(
"nv-cache"
create_if_missing
True
"/root/.triton"
: modal.Volume.from_name(
"triton-cache"
create_if_missing
True
"/root/.inductor-cache"
: modal.Volume.from_name(
"inductor-cache"
create_if_missing
True
class
Model
compile
bool
# see section on torch.compile below for details
modal.parameter(
default
False
@modal.enter
enter
self
pipe = FluxPipeline.from_pretrained(
"black-forest-labs/FLUX.1-
VARIANT
torch_dtype
=torch.bfloat16
).to(
"cuda"
# move model to GPU
self
.pipe = optimize(pipe,
compile
self
.compile)
@modal.method
inference
self
prompt
) ->
bytes
print
"🎨 generating image..."
out =
self
.pipe(
prompt,
output_type
"pil"
num_inference_steps
=NUM_INFERENCE_STEPS,
).images[
byte_stream = BytesIO()
out.save(byte_stream,
format
"JPEG"
return
byte_stream.getvalue()
Copy
Calling our inference function
To generate an image we just need to call the
Model
generate
method
with
.remote
appended to it.
You can call
.generate.remote
from any Python environment that has access to your Modal credentials.
The local environment will get back the image as bytes.
Here, we wrap the call in a Modal
local_entrypoint
so that it can be run with
modal run
modal
flux.py
Copy
By default, we call
generate
twice to demonstrate how much faster
the inference is after cold start. In our tests, clients received images in about 1.2 seconds.
We save the output bytes to a temporary file.
@app.local_entrypoint
main
prompt
"a computer screen showing ASCII terminal art of the"
" word 'Modal' in neon green. two programmers are pointing excitedly"
" at the screen."
twice
bool
True
compile
bool
False
t0 = time.time()
image_bytes = Model(
compile
compile
).inference.remote(prompt)
print
"🎨 first inference latency:
time.time() - t0
:.2f}
seconds"
twice:
t0 = time.time()
image_bytes = Model(
compile
compile
).inference.remote(prompt)
print
"🎨 second inference latency:
time.time() - t0
:.2f}
seconds"
output_path = Path(
"/tmp"
"flux"
"output.jpg"
output_path.parent.mkdir(
exist_ok
True
parents
True
print
"🎨 saving output to
output_path
output_path.write_bytes(image_bytes)
Copy
Speeding up Flux with
torch.compile
By default, we do some basic optimizations, like adjusting memory layout
and re-expressing the attention head projections as a single matrix multiplication.
But there are additional speedups to be had!
PyTorch 2 added a compiler that optimizes the
compute graphs created dynamically during PyTorch execution.
This feature helps close the gap with the performance of static graph frameworks
like TensorRT and TensorFlow.
Here, we follow the suggestions from Hugging Face’s
guide to fast diffusion inference
which we verified with our own internal benchmarks.
Review that guide for detailed explanations of the choices made below.
The resulting compiled Flux
schnell
deployment returns images to the client in under a second (~700 ms), according to our testing.
Super schnell
Compilation takes up to twenty minutes on first iteration.
As of time of writing in late 2024,
the compilation artifacts cannot be fully serialized,
so some compilation work must be re-executed every time a new container is started.
That includes when scaling up an existing deployment or the first time a Function is invoked with
modal run
We cache compilation outputs from
nvcc
triton
, and
inductor
which can reduce compilation time by up to an order of magnitude.
For details see
this tutorial
You can turn on compilation with the
--compile
flag.
Try it out with:
modal
flux.py
--compile
Copy
compile
option is passed by a
modal.parameter
on our class.
Each different choice for a
parameter
creates a
separate auto-scaling deployment
That means your client can use arbitrary logic to decide whether to hit a compiled or eager endpoint.
optimize
pipe
compile
True
# fuse QKV projections in Transformer and VAE
pipe.transformer.fuse_qkv_projections()
pipe.vae.fuse_qkv_projections()
# switch memory layout to Torch's preferred, channels_last
pipe.transformer.to(
memory_format
=torch.channels_last)
pipe.vae.to(
memory_format
=torch.channels_last)
compile
return
pipe
# set torch compile flags
config = torch._inductor.config
config.disable_progress =
False
# show progress bar
config.conv_1x1_as_mm =
True
# treat 1x1 convolutions as matrix muls
# adjust autotuning algorithm
config.coordinate_descent_tuning =
True
config.coordinate_descent_check_all_directions =
True
config.epilogue_fusion =
False
# do not fuse pointwise ops into matmuls
# tag the compute-intensive modules, the Transformer and VAE decoder, for compilation
pipe.transformer = torch.compile(
pipe.transformer,
mode
"max-autotune"
fullgraph
True
pipe.vae.decode = torch.compile(
pipe.vae.decode,
mode
"max-autotune"
fullgraph
True
# trigger torch compilation
print
"🔦 running torch compilation (may take up to 20 minutes)..."
pipe(
"dummy prompt to trigger torch compilation"
output_type
"pil"
num_inference_steps
=NUM_INFERENCE_STEPS,
# use ~50 for [dev], smaller for [schnell]
).images[
print
"🔦 finished torch compilation"
return
pipe
Copy
Run Flux fast on H100s with torch.compile
Setting up the image and dependencies
Defining a parameterized Model inference class
Calling our inference function
Speeding up Flux with torch.compile
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/stable_diffusion/flux.py
--no-compile
Copy

=== DOC: 003_examples_hackernews_alerts.txt ===
URL: https://modal.com/docs/examples/hackernews_alerts
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Run cron jobs in the cloud to search Hacker News
In this example, we use Modal to deploy a cron job that periodically queries Hacker News for
new posts matching a given search term, and posts the results to Slack.
Import and define the app
Let’s start off with imports, and defining a Modal app.
import
from
datetime
import
datetime, timedelta
import
modal
app = modal.App(
"example-hn-bot"
Copy
Now, let’s define an image that has the
slack-sdk
package installed, in which we can run a function
that posts a slack message.
slack_sdk_image = modal.Image.debian_slim().pip_install(
"slack-sdk"
Copy
Defining the function and importing the secret
Our Slack bot will need access to a bot token.
We can use Modal’s
Secrets
interface to accomplish this.
To quickly create a Slack bot secret, click the “Create new secret” button.
Then, select the Slack secret template from the list options,
and follow the instructions in the “Where to find the credentials?” panel.
Name your secret
hn-bot-slack.
Now, we define the function
post_to_slack
, which simply instantiates the Slack client using our token,
and then uses it to post a message to a given channel name.
@app.function
image
=slack_sdk_image,
secrets
=[modal.Secret.from_name(
"hn-bot-slack"
required_keys
"SLACK_BOT_TOKEN"
])],
async
post_to_slack
message
import
slack_sdk
client = slack_sdk.WebClient(
token
=os.environ[
"SLACK_BOT_TOKEN"
client.chat_postMessage(
channel
"hn-alerts"
text
=message)
Copy
Searching Hacker News
We are going to use Algolia’s
Hacker News Search API
to query for posts
matching a given search term in the past X days. Let’s define our search term and query period.
QUERY =
"serverless"
WINDOW_SIZE_DAYS =
Copy
Let’s also define an image that has the
requests
package installed, so we can query the API.
requests_image = modal.Image.debian_slim().pip_install(
"requests"
Copy
We can now define our main entrypoint, that queries Algolia for the term, and calls
post_to_slack
on all the results. We specify a
schedule
in the function decorator, which means that our function will run automatically at the given interval.
@app.function
image
=requests_image)
search_hackernews
import
requests
url =
"http://hn.algolia.com/api/v1/search"
threshold = datetime.utcnow() - timedelta(
days
=WINDOW_SIZE_DAYS)
params = {
"query"
: QUERY,
"numericFilters"
"created_at_i>
threshold.timestamp()
response = requests.get(url, params,
timeout
).json()
urls = [item[
"url"
item
response[
"hits"
item.get(
"url"
print
"Query returned
(urls)
items."
post_to_slack.for_each(urls)
Copy
Test running
We can now test run our scheduled function as follows:
modal run hackernews_alerts.py::app.search_hackernews
Defining the schedule and deploying
Let’s define a function that will be called by Modal every day
@app.function
schedule
=modal.Period(
days
run_daily
search_hackernews.remote()
Copy
In order to deploy this as a persistent cron job, you can run
modal deploy hackernews_alerts.py
Once the job is deployed, visit the
apps page
page to see
its execution history, logs and other stats.
Run cron jobs in the cloud to search Hacker News
Import and define the app
Defining the function and importing the secret
Searching Hacker News
Test running
Defining the schedule and deploying
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
05_scheduling/hackernews_alerts.py
Copy

=== DOC: 004_examples_music-video-gen.txt ===
URL: https://modal.com/docs/examples/music-video-gen
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
Deploy a personalized music video generation service on Modal
Music videos are
cool
but unless you are famous or
pay a lot of money
you don’t get to star in them.
Until now!
The repo
includes all the code you need to deploy a custom
music video generator on
Modal
a serverless infrastructure platform for data, ML, and AI applications.
Below is a sample video, generated by Modal Developer Advocate
@charles_irl
And because Modal is
generic serverless infrastructure
you can customize this custom music video generator however you wish —
it’s just code and containers!
Setup
In the Python environment of your choosing,
pip install modal
If you run into trouble with Python environments,
we suggest using
this Google Colab notebook
where we’ve set the environment up for you.
It’s a bit of work to get used to running terminal commands in a notebook
if you haven’t done that before, but the Python setup works and running the notebook in Colab is free!
All you need is a Google account.
Then, if you’ve never used Modal on the computer you’re using,
modal setup
to create an account on Modal (if you don’t have one)
and set up authentication.
Data Prep
Create a folder inside
data/
, parallel to the sample data,
data/sample
You can name it whatever you want.
Place at least four images of yourself in that folder —
ideally eight or more.
Images should be in
.png
.jpg
format
and around 400 to 800 pixels on each side.
For best results, we recommend putting a variety of images,
in particular where you are wearing different clothes and making different faces,
and including some images that have other people in them.
But you can also just take a few photos of yourself right now!
Optionally, add captions in
.txt
files in that same folder.
They should look something like
"[trigger] smiling at the camera, outdoor scene, close-up, selfie"
See the sample data for more example image-caption pairs.
Training
Start up a JupyterLab server on Modal with
modal
train_from_notebook.py
Copy
Click the
modal.host
URL that appears in the output
to open Jupyter in the browser.
Open the training notebook,
training.ipynb
Read the notebook and run it, following the instructions to edit cells as needed.
In particular, change the dataset path to the folder you created —
it has been mounted on the remote cloud machine where the notebook is running.
You can also directly upload data to the
/root/data
folder on the remote machine.
You can even edit caption files inside of JupyterLab!
This data will stick around between runs, and you can find it with
modal
volume
finetune-video-data
Copy
See the help for
modal volume
and its subcommands for details.
The notebook will kick off training, which takes a few minutes.
Take note of the name given to your training run.
By default, it’s a hash like
38c67a92f6ce87882044ab53bf94cce0
but you can customize it in the notebook.
This is your
finetune-id
If you forget it, you can show all of your
finetune-id
by running
modal
volume
finetune-video-models
Copy
Inference
Test out your new fine-tuned model by running:
modal
inference.py
--finetune-id
{your-finetune-id}
--num-frames
Copy
You can also provide a
--prompt
to customize the generation.
You can deploy the video generator onto Modal with
modal
deploy
inference.py
Copy
Modal is serverless, so this won’t cost you any money when it isn’t serving any traffic.
Music video generation
Once you’ve deployed an inference endpoint,
you can generate a music video starring yourself by running
modal
music_video_generator.py
--finetune-id
{your-finetune-id}
Copy
With the default settings, this will create a thirty second video in about five minutes
by running generation in parallel on seven H100s.
The music can be changed by passing in a different song via the
--mp3-file
argument.
The default is a Modal-themed song in
data/coding-up-a-storm.mp3
This song was created with
Suno
a music generation service — that runs on Modal!
If you want to DIY music generation as well,
this example
in the Modal docs.
The generated clips can be changed by passing a different list of prompts via the
--prompt-file
argument.
The default is a set of prompts created with OpenAI’s GPT-4.5 system.
You can write your own or generate them with a language model.
If you want to serve your own language model,
this example
in the Modal docs.
Deploy a personalized music video generation service on Modal
Setup
Data Prep
Training
Inference
Music video generation

=== DOC: 005_reference_modal_Image.txt ===
URL: https://modal.com/docs/reference/modal.Image
Changelog
API Reference
modal.App
modal.Client
modal.CloudBucketMount
modal.Cls
modal.Cron
modal.Dict
modal.Error
modal.FilePatternMatcher
modal.Function
modal.FunctionCall
modal.Image
modal.NetworkFileSystem
modal.Period
modal.Proxy
modal.Queue
modal.Retries
modal.Sandbox
modal.SandboxSnapshot
modal.Secret
modal.Tunnel
modal.Volume
modal.asgi_app
modal.batched
modal.call_graph
modal.concurrent
modal.container_process
modal.current_function_call_id
modal.current_input_id
modal.enable_output
modal.enter
modal.exit
modal.fastapi_endpoint
modal.file_io
modal.forward
modal.gpu
modal.interact
modal.io_streams
modal.is_local
modal.method
modal.parameter
modal.web_endpoint
modal.web_server
modal.wsgi_app
modal.exception
modal.config
CLI Reference
modal app
modal config
modal container
modal deploy
modal dict
modal environment
modal launch
modal nfs
modal profile
modal queue
modal run
modal secret
modal serve
modal setup
modal shell
modal token
modal volume
modal.Image
class
Image
modal
object
Object
Copy
Base class for container images to run functions in.
Do not construct this class directly; instead use one of its static factory methods,
such as
modal.Image.debian_slim
modal.Image.from_registry
, or
modal.Image.micromamba
hydrate
hydrate
self
client
: Optional[_Client] =
None
) -> Self:
Copy
Synchronize the local object with its identity on the Modal server.
It is rarely necessary to call this method explicitly, as most operations
will lazily hydrate when needed. The main use case is when you need to
access object metadata, such as its ID.
Added in v0.72.39
: This method replaces the deprecated
.resolve()
method.
add_local_file
add_local_file
self
local_path
: Union[
, Path],
remote_path
, *,
copy
bool
False
) ->
"_Image"
Copy
Adds a local file to the image at
remote_path
within the container
By default (
copy=False
), the files are added to containers on startup and are not built into the actual Image,
which speeds up deployment.
copy=True
to copy the files into an Image layer at build time instead, similar to how
COPY
works in a
Dockerfile
copy=True can slow down iteration since it requires a rebuild of the Image and any subsequent
build steps whenever the included files change, but it is required if you want to run additional
build steps after this one.
Added in v0.66.40
: This method replaces the deprecated
modal.Image.copy_local_file
method.
add_local_dir
add_local_dir
self
local_path
: Union[
, Path],
remote_path
copy
bool
False
# Predicate filter function for file exclusion, which should accept a filepath and return `True` for exclusion.
# Defaults to excluding no files. If a Sequence is provided, it will be converted to a FilePatternMatcher.
# Which follows dockerignore syntax.
ignore
: Union[Sequence[
], Callable[[Path],
bool
]] = [],
) ->
"_Image"
Copy
Adds a local directory’s content to the image at
remote_path
within the container
By default (
copy=False
), the files are added to containers on startup and are not built into the actual Image,
which speeds up deployment.
copy=True
to copy the files into an Image layer at build time instead, similar to how
COPY
works in a
Dockerfile
copy=True can slow down iteration since it requires a rebuild of the Image and any subsequent
build steps whenever the included files change, but it is required if you want to run additional
build steps after this one.
Usage:
from
modal
import
FilePatternMatcher
image = modal.Image.debian_slim().add_local_dir(
"~/assets"
remote_path
"/assets"
ignore
"*.venv"
image = modal.Image.debian_slim().add_local_dir(
"~/assets"
remote_path
"/assets"
ignore
lambda
: p.is_relative_to(
".venv"
image = modal.Image.debian_slim().add_local_dir(
"~/assets"
remote_path
"/assets"
ignore
=FilePatternMatcher(
"**/*.txt"
# When including files is simpler than excluding them, you can use the `~` operator to invert the matcher.
image = modal.Image.debian_slim().add_local_dir(
"~/assets"
remote_path
"/assets"
ignore
=~FilePatternMatcher(
"**/*.py"
# You can also read ignore patterns from a file.
image = modal.Image.debian_slim().add_local_dir(
"~/assets"
remote_path
"/assets"
ignore
=FilePatternMatcher.from_file(
"/path/to/ignorefile"
Copy
Added in v0.66.40
: This method replaces the deprecated
modal.Image.copy_local_dir
method.
add_local_python_source
add_local_python_source
self
modules
copy
bool
False
ignore
: Union[Sequence[
], Callable[[Path],
bool
]] = NON_PYTHON_FILES
) ->
"_Image"
Copy
Adds locally available Python packages/modules to containers
Adds all files from the specified Python package or module to containers running the Image.
Packages are added to the
/root
directory of containers, which is on the
PYTHONPATH
of any executed Modal Functions, enabling import of the module by that name.
By default (
copy=False
), the files are added to containers on startup and are not built into the actual Image,
which speeds up deployment.
copy=True
to copy the files into an Image layer at build time instead. This can slow down iteration since
it requires a rebuild of the Image and any subsequent build steps whenever the included files change, but it is
required if you want to run additional build steps after this one.
Note:
This excludes all dot-prefixed subdirectories or files and all
.pyc
__pycache__
files.
To add full directories with finer control, use
.add_local_dir()
instead and specify
/root
the destination directory.
By default only includes
-files in the source modules. Set the
ignore
argument to a list of patterns
or a callable to override this behavior, e.g.:
# includes everything except data.json
modal.Image.debian_slim().add_local_python_source(
"mymodule"
ignore
"data.json"
# exclude large files
modal.Image.debian_slim().add_local_python_source(
"mymodule"
ignore
lambda
: p.stat().st_size >
Copy
Added in v0.67.28
: This method replaces the deprecated
modal.Mount.from_local_python_packages
pattern.
from_id
staticmethod
from_id
image_id
client
: Optional[_Client] =
None
) ->
"_Image"
Copy
Construct an Image from an id and look up the Image result.
The ID of an Image object can be accessed using
.object_id
pip_install
pip_install
self
packages
: Union[
, list[
# A list of Python packages, eg. ["numpy", "matplotlib>=3.5.0"]
find_links
: Optional[
None
# Passes -f (--find-links) pip install
index_url
: Optional[
None
# Passes -i (--index-url) to pip install
extra_index_url
: Optional[
None
# Passes --extra-index-url to pip install
bool
False
# Passes --pre (allow pre-releases) to pip install
extra_options
# Additional options to pass to pip install, e.g. "--no-build-isolation --no-clean"
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install a list of Python packages using pip.
Examples
Simple installation:
image = modal.Image.debian_slim().pip_install(
"click"
"httpx~=0.23.3"
Copy
More complex installation:
image = (
modal.Image.from_registry(
"nvidia/cuda:12.2.0-devel-ubuntu22.04"
add_python
"3.11"
.pip_install(
"ninja"
"packaging"
"wheel"
"transformers==4.40.2"
.pip_install(
"flash-attn==2.5.8"
extra_options
"--no-build-isolation"
Copy
pip_install_private_repos
pip_install_private_repos
self
repositories
git_user
find_links
: Optional[
None
# Passes -f (--find-links) pip install
index_url
: Optional[
None
# Passes -i (--index-url) to pip install
extra_index_url
: Optional[
None
# Passes --extra-index-url to pip install
bool
False
# Passes --pre (allow pre-releases) to pip install
extra_options
# Additional options to pass to pip install, e.g. "--no-build-isolation --no-clean"
: GPU_T =
None
secrets
: Sequence[_Secret] = [],
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
) ->
"_Image"
Copy
Install a list of Python packages from private git repositories using pip.
This method currently supports Github and Gitlab only.
Github:
Provide a
modal.Secret
that contains a
GITHUB_TOKEN
key-value pair
Gitlab:
Provide a
modal.Secret
that contains a
GITLAB_TOKEN
key-value pair
These API tokens should have permissions to read the list of private repositories provided as arguments.
We recommend using Github’s
‘fine-grained’ access tokens
These tokens are repo-scoped, and avoid granting read permission across all of a user’s private repos.
Example
image = (
modal.Image
.debian_slim()
.pip_install_private_repos(
"github.com/ecorp/private-one@1.0.0"
"github.com/ecorp/private-two@main"
"github.com/ecorp/private-three@d4776502"
# install from 'inner' directory on default branch.
"github.com/ecorp/private-four#subdirectory=inner"
git_user
"erikbern"
secrets
=[modal.Secret.from_name(
"github-read-private"
Copy
pip_install_from_requirements
pip_install_from_requirements
self
requirements_txt
# Path to a requirements.txt file.
find_links
: Optional[
None
# Passes -f (--find-links) pip install
index_url
: Optional[
None
# Passes -i (--index-url) to pip install
extra_index_url
: Optional[
None
# Passes --extra-index-url to pip install
bool
False
# Passes --pre (allow pre-releases) to pip install
extra_options
# Additional options to pass to pip install, e.g. "--no-build-isolation --no-clean"
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install a list of Python packages from a local
requirements.txt
file.
pip_install_from_pyproject
pip_install_from_pyproject
self
pyproject_toml
optional_dependencies
: list[
] = [],
find_links
: Optional[
None
# Passes -f (--find-links) pip install
index_url
: Optional[
None
# Passes -i (--index-url) to pip install
extra_index_url
: Optional[
None
# Passes --extra-index-url to pip install
bool
False
# Passes --pre (allow pre-releases) to pip install
extra_options
# Additional options to pass to pip install, e.g. "--no-build-isolation --no-clean"
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install dependencies specified by a local
pyproject.toml
file.
optional_dependencies
is a list of the keys of the
optional-dependencies section(s) of the
pyproject.toml
file
(e.g. test, doc, experiment, etc). When provided,
all of the packages in each listed section are installed as well.
poetry_install_from_file
poetry_install_from_file
self
poetry_pyproject_toml
poetry_lockfile
: Optional[
None
# Path to lockfile. If not provided, uses poetry.lock in same directory.
ignore_lockfile
bool
False
# If set to True, do not use poetry.lock, even when present
# If set to True, use old installer. See https://github.com/python-poetry/poetry/issues/3336
old_installer
bool
False
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
# Selected optional dependency groups to install (See https://python-poetry.org/docs/cli/#install)
with_
: list[
] = [],
# Selected optional dependency groups to exclude (See https://python-poetry.org/docs/cli/#install)
without
: list[
] = [],
only
: list[
] = [],
# Only install dependency groups specifed in this list.
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install poetry
dependencies
specified by a local
pyproject.toml
file.
If not provided as argument the path to the lockfile is inferred. However, the
file has to exist, unless
ignore_lockfile
is set to
True
Note that the root project of the poetry project is not installed, only the dependencies.
For including local python source files see
add_local_python_source
dockerfile_commands
dockerfile_commands
self
dockerfile_commands
: Union[
, list[
context_files
: dict[
] = {},
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
context_mount
: Optional[_Mount] =
None
# Deprecated: the context is now inferred
context_dir
: Optional[Union[Path,
]] =
None
# Context for relative COPY commands
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
ignore
: Union[Sequence[
], Callable[[Path],
bool
]] = AUTO_DOCKERIGNORE,
) ->
"_Image"
Copy
Extend an image with arbitrary Dockerfile-like commands.
Usage:
from
modal
import
FilePatternMatcher
# By default a .dockerignore file is used if present in the current working directory
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
ignore
"*.venv"
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
ignore
lambda
: p.is_relative_to(
".venv"
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
ignore
=FilePatternMatcher(
"**/*.txt"
# When including files is simpler than excluding them, you can use the `~` operator to invert the matcher.
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
ignore
=~FilePatternMatcher(
"**/*.py"
# You can also read ignore patterns from a file.
image = modal.Image.debian_slim().dockerfile_commands(
"COPY data /data"
ignore
=FilePatternMatcher.from_file(
"/path/to/dockerignore"
Copy
entrypoint
entrypoint
self
entrypoint_commands
: list[
) ->
"_Image"
Copy
Set the entrypoint for the image.
shell
shell
self
shell_commands
: list[
) ->
"_Image"
Copy
Overwrite default shell for the image.
run_commands
run_commands
self
commands
: Union[
, list[
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
) ->
"_Image"
Copy
Extend an image with a list of shell commands to run.
micromamba
staticmethod
micromamba
python_version
: Optional[
None
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
) ->
"_Image"
Copy
A Micromamba base image. Micromamba allows for fast building of small Conda-based containers.
micromamba_install
micromamba_install
self
# A list of Python packages, eg. ["numpy", "matplotlib>=3.5.0"]
packages
: Union[
, list[
# A local path to a file containing package specifications
spec_file
: Optional[
None
# A list of Conda channels, eg. ["conda-forge", "nvidia"].
channels
: list[
] = [],
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install a list of additional packages using micromamba.
from_registry
staticmethod
from_registry
secret
: Optional[_Secret] =
None
setup_dockerfile_commands
: list[
] = [],
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
add_python
: Optional[
None
kwargs
) ->
"_Image"
Copy
Build a Modal Image from a public or private image registry, such as Docker Hub.
The image must be built for the
linux/amd64
platform.
If your image does not come with Python installed, you can use the
add_python
parameter
to specify a version of Python to add to the image. Otherwise, the image is expected to
have Python on PATH as
python
, along with
You may also use
setup_dockerfile_commands
to run Dockerfile commands before the
remaining commands run. This might be useful if you want a custom Python installation or to
set a
SHELL
. Prefer
run_commands()
when possible though.
To authenticate against a private registry with static credentials, you must set the
secret
parameter to
modal.Secret
containing a username (
REGISTRY_USERNAME
) and
an access token or password (
REGISTRY_PASSWORD
To authenticate against private registries with credentials from a cloud provider,
Image.from_gcp_artifact_registry()
Image.from_aws_ecr()
Examples
modal.Image.from_registry(
"python:3.11-slim-bookworm"
modal.Image.from_registry(
"ubuntu:22.04"
add_python
"3.11"
modal.Image.from_registry(
"nvcr.io/nvidia/pytorch:22.12-py3"
Copy
from_gcp_artifact_registry
staticmethod
from_gcp_artifact_registry
secret
: Optional[_Secret] =
None
setup_dockerfile_commands
: list[
] = [],
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
add_python
: Optional[
None
kwargs
) ->
"_Image"
Copy
Build a Modal image from a private image in Google Cloud Platform (GCP) Artifact Registry.
You will need to pass a
modal.Secret
containing
your GCP service account key data
SERVICE_ACCOUNT_JSON
. This can be done from the
Secrets
page.
Your service account should be granted a specific role depending on the GCP registry used:
For Artifact Registry images (
pkg.dev
domains) use
“Artifact Registry Reader”
role
For Container Registry images (
gcr.io
domains) use
“Storage Object Viewer”
role
Note:
This method does not use
GOOGLE_APPLICATION_CREDENTIALS
as that
variable accepts a path to a JSON file, not the actual JSON string.
Image.from_registry()
for information about the other parameters.
Example
modal.Image.from_gcp_artifact_registry(
"us-east1-docker.pkg.dev/my-project-1234/my-repo/my-image:my-version"
secret
=modal.Secret.from_name(
"my-gcp-secret"
required_keys
"SERVICE_ACCOUNT_JSON"
add_python
"3.11"
Copy
from_aws_ecr
staticmethod
from_aws_ecr
secret
: Optional[_Secret] =
None
setup_dockerfile_commands
: list[
] = [],
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
add_python
: Optional[
None
kwargs
) ->
"_Image"
Copy
Build a Modal image from a private image in AWS Elastic Container Registry (ECR).
You will need to pass a
modal.Secret
containing
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
, and
AWS_REGION
to access the target ECR registry.
IAM configuration details can be found in the AWS documentation for
“Private repository policies”
Image.from_registry()
for information about the other parameters.
Example
modal.Image.from_aws_ecr(
"000000000000.dkr.ecr.us-east-1.amazonaws.com/my-private-registry:my-version"
secret
=modal.Secret.from_name(
"aws"
required_keys
"AWS_ACCESS_KEY_ID"
"AWS_SECRET_ACCESS_KEY"
"AWS_REGION"
add_python
"3.11"
Copy
from_dockerfile
staticmethod
from_dockerfile
path
: Union[
, Path],
# Filepath to Dockerfile.
context_mount
: Optional[_Mount] =
None
# Deprecated: the context is now inferred
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
context_dir
: Optional[Union[Path,
]] =
None
# Context for relative COPY commands
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
add_python
: Optional[
None
ignore
: Union[Sequence[
], Callable[[Path],
bool
]] = AUTO_DOCKERIGNORE,
) ->
"_Image"
Copy
Build a Modal image from a local Dockerfile.
If your Dockerfile does not have Python installed, you can use the
add_python
parameter
to specify a version of Python to add to the image.
Usage:
from
modal
import
FilePatternMatcher
# By default a .dockerignore file is used if present in the current working directory
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
ignore
"*.venv"
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
ignore
lambda
: p.is_relative_to(
".venv"
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
ignore
=FilePatternMatcher(
"**/*.txt"
# When including files is simpler than excluding them, you can use the `~` operator to invert the matcher.
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
ignore
=~FilePatternMatcher(
"**/*.py"
# You can also read ignore patterns from a file.
image = modal.Image.from_dockerfile(
"./Dockerfile"
add_python
"3.12"
ignore
=FilePatternMatcher.from_file(
"/path/to/dockerignore"
Copy
debian_slim
staticmethod
debian_slim
python_version
: Optional[
None
force_build
bool
False
) ->
"_Image"
Copy
Default image, based on the official
python
Docker images.
apt_install
apt_install
self
packages
: Union[
, list[
# A list of packages, e.g. ["ssh", "libpq-dev"]
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
secrets
: Sequence[_Secret] = [],
: GPU_T =
None
) ->
"_Image"
Copy
Install a list of Debian packages using
Example
image = modal.Image.debian_slim().apt_install(
"git"
Copy
run_function
run_function
self
raw_f
: Callable[..., Any],
secrets
: Sequence[_Secret] = (),
# Optional Modal Secret objects with environment variables for the container
: Union[GPU_T, list[GPU_T]] =
None
# Requested GPU or or list of acceptable GPUs( e.g. ["A10", "A100"])
volumes
: dict[Union[
, PurePosixPath], Union[_Volume, _CloudBucketMount]] = {},
# Volume mount paths
network_file_systems
: dict[Union[
, PurePosixPath], _NetworkFileSystem] = {},
# NFS mount paths
: Optional[
float
None
# How many CPU cores to request. This is a soft limit.
memory
: Optional[
None
# How much memory to request, in MiB. This is a soft limit.
timeout
: Optional[
# Maximum execution time of the function in seconds.
force_build
bool
False
# Ignore cached builds, similar to 'docker build --no-cache'
cloud
: Optional[
None
# Cloud provider to run the function on. Possible values are aws, gcp, oci, auto.
region
: Optional[Union[
, Sequence[
]]] =
None
# Region or regions to run the function on.
args
: Sequence[Any] = (),
# Positional arguments to the function.
kwargs
: dict[
, Any] = {},
# Keyword arguments to the function.
include_source
: Optional[
bool
None
) ->
"_Image"
Copy
Run user-defined function
raw_f
as an image build step. The function runs just like an ordinary Modal
function, and any kwargs accepted by
@app.function
(such as
Mount
NetworkFileSystem
and resource requests) can be supplied to it.
After it finishes execution, a snapshot of the resulting container file system is saved as an image.
Note
Only the source code of
raw_f
, the contents of
**kwargs
, and any referenced
global
variables
are used to determine whether the image has changed and needs to be rebuilt.
If this function references other functions or variables, the image will not be rebuilt if you
make changes to them. You can force a rebuild by changing the function’s source code itself.
Example
my_build_function
open
"model.pt"
).write(
"parameters!"
image = (
modal.Image
.debian_slim()
.pip_install(
"torch"
.run_function(my_build_function,
secrets
=[...],
mounts
=[...])
Copy
self
vars
: dict[
]) ->
"_Image"
Copy
Sets the environment variables in an Image.
Example
image = (
modal.Image.debian_slim()
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
Copy
workdir
workdir
self
path
: Union[
, PurePosixPath]) ->
"_Image"
Copy
Set the working directory for subsequent image build steps and function execution.
Example
image = (
modal.Image.debian_slim()
.run_commands(
"git clone https://xyz app"
.workdir(
"/app"
.run_commands(
"yarn install"
Copy
self
: list[
]) ->
"_Image"
Copy
Set the default entrypoint argument (
) for the image.
Example
image = (
modal.Image.debian_slim().cmd([
"python"
"app.py"
Copy
imports
@contextlib.contextmanager
imports
self
Copy
Used to import packages in global scope that are only available when running remotely.
By using this context manager you can avoid an
ImportError
due to not having certain
packages installed locally.
Usage:
with
image.imports():
import
torch
Copy
modal.Image
hydrate
add_local_file
add_local_dir
add_local_python_source
from_id
pip_install
pip_install_private_repos
pip_install_from_requirements
pip_install_from_pyproject
poetry_install_from_file
dockerfile_commands
entrypoint
shell
run_commands
micromamba
micromamba_install
from_registry
from_gcp_artifact_registry
from_aws_ecr
from_dockerfile
debian_slim
apt_install
run_function
workdir
imports

=== DOC: 006_examples.txt ===
URL: https://modal.com/docs/examples
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
Featured Examples
Featured
Images, video & 3D
Fine-tuning
Language modeling
Batch processing
Audio
Sandboxed code execution
Computational biology
Deploy an OpenAI-compatible LLM service
Run large language models with a drop-in replacement for the OpenAI API.
Custom pet art from Flux with Hugging Face and Gradio
Fine-tune an image generation model on pictures of your pet.
Run llama.cpp
Run DeepSeek-R1 and Phi-4 on llama.cpp
Voice chat with LLMs
Build an interactive voice chat app.
Serve diffusion models
Serve Flux on Modal with a number of optimizations for blazingly fast inference.
Fold proteins with Chai-1
Predict molecular structures from sequences with SotA open source models.
Serverless TensorRT-LLM (LLaMA 3 8B)
Run interactive language model applications.
Star in custom music videos
Fine-tune a Wan2.1 video model on your face and run it in parallel
Create music
Turn prompts into music with MusicGen
Sandbox a LangGraph agent's code
Run an LLM coding agent that runs its own language models.
RAG Chat with PDFs
Use ColBERT-style, multimodal embeddings with a Vision-Language Model to answer questions about documents.
Bring images to life
Prompt a generative video model to animate an image.
Fast podcast transcriptions
Build an end-to-end podcast transcription app that leverages dozens of containers for super-fast processing.
Build a protein folding dashboard
Serve a web UI for a protein model with ESM3, Molstar, and Gradio
Deploy a Hacker News Slackbot
Periodically post new Hacker News posts to Slack.
Retrieval-Augmented Generation (RAG) for Q&A
Build a question-answering web endpoint that can cite its sources.
Document OCR job queue
Use Modal as an infinitely scalable job queue that can service async tasks from a web app.
Parallel processing of Parquet files on S3
Analyze data from the Taxi and Limousine Commission of NYC in parallel.

=== DOC: 007_reference.txt ===
URL: https://modal.com/docs/reference
Changelog
API Reference
modal.App
modal.Client
modal.CloudBucketMount
modal.Cls
modal.Cron
modal.Dict
modal.Error
modal.FilePatternMatcher
modal.Function
modal.FunctionCall
modal.Image
modal.NetworkFileSystem
modal.Period
modal.Proxy
modal.Queue
modal.Retries
modal.Sandbox
modal.SandboxSnapshot
modal.Secret
modal.Tunnel
modal.Volume
modal.asgi_app
modal.batched
modal.call_graph
modal.concurrent
modal.container_process
modal.current_function_call_id
modal.current_input_id
modal.enable_output
modal.enter
modal.exit
modal.fastapi_endpoint
modal.file_io
modal.forward
modal.gpu
modal.interact
modal.io_streams
modal.is_local
modal.method
modal.parameter
modal.web_endpoint
modal.web_server
modal.wsgi_app
modal.exception
modal.config
CLI Reference
modal app
modal config
modal container
modal deploy
modal dict
modal environment
modal launch
modal nfs
modal profile
modal queue
modal run
modal secret
modal serve
modal setup
modal shell
modal token
modal volume
API Reference
This is the API reference for the
modal
Python package, which allows you to run distributed applications on Modal.
The reference is intended to be limited to low-level descriptions of various
programmatic functionality. If you’re just getting started with Modal, we would
instead recommend looking at the
guide
first
or to get started quickly with an
example
Application construction
The main unit of deployment for code on Modal
App.function
Decorator for registering a function with an App
App.cls
Decorator for registering a class with an App
Serverless execution
Function
A serverless function backed by an autoscaling container pool
A serverless class supporting parametrization and lifecycle hooks
Extended Function configuration
Class parametrization
parameter
Used to define class parameters, akin to a Dataclass field
Lifecycle hooks
enter
Decorator for a method that will be executed during container startup
exit
Decorator for a method that will be executed during container shutdown
method
Decorator for exposing a method as an invokable function
Web integrations
fastapi_endpoint
Decorator for exposing a simple FastAPI-based endpoint
asgi_app
Decorator for functions that construct an ASGI web application
wsgi_app
Decorator for functions that construct a WSGI web application
web_server
Decorator for functions that construct an HTTP web server
Function semantics
batched
Decorator that enables
dynamic input batching
concurrent
Decorator that enables
input concurrency
Scheduling
Cron
A schedule that runs based on cron syntax
Period
A schedule that runs at a fixed interval
Exception handling
Retries
Function retry policy for input failures
Sandboxed execution
Sandbox
An interface for restricted code execution
ContainerProcess
An object representing a sandboxed process
FileIO
A handle for a file in the Sandbox filesystem
Container configuration
Image
An API for specifying container images
Secret
A pointer to secrets that will be exposed as environment variables
Data primitives
Persistent storage
Volume
Distributed storage supporting highly performant parallel reads
CloudBucketMount
Storage backed by a third-party cloud bucket (S3, etc.)
NetworkFileSystem
Shared, writeable cloud storage (superseded by
modal.Volume
In-memory storage
Dict
A distributed key-value store
Queue
A distributed FIFO queue
Networking
Proxy
An object that provides a static outbound IP address for containers
forward
A context manager for publicly exposing a port from a container
API Reference
Application construction
Serverless execution
Extended Function configuration
Class parametrization
Lifecycle hooks
Web integrations
Function semantics
Scheduling
Exception handling
Sandboxed execution
Container configuration
Data primitives
Persistent storage
In-memory storage
Networking

=== DOC: 008_examples_doc_ocr_jobs.txt ===
URL: https://modal.com/docs/examples/doc_ocr_jobs
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Run a job queue for GOT-OCR
This tutorial shows you how to use Modal as an infinitely scalable job queue
that can service async tasks from a web app. For the purpose of this tutorial,
we’ve also built a
React + FastAPI web app on Modal
that works together with it, but note that you don’t need a web app running on Modal
to use this pattern. You can submit async tasks to Modal from any Python
application (for example, a regular Django app running on Kubernetes).
Our job queue will handle a single task: running OCR transcription for images of receipts.
We’ll make use of a pre-trained model:
General OCR Theory (GOT) 2.0 model
Try it out for yourself
here
Define an App
Let’s first import
modal
and define an
Later, we’ll use the name provided for our
to find it from our web app and submit tasks to it.
from
typing
import
Optional
import
modal
app = modal.App(
"example-doc-ocr-jobs"
Copy
We also define the dependencies for our Function by specifying an
Image
inference_image = modal.Image.debian_slim(
python_version
"3.12"
).pip_install(
"accelerate==0.28.0"
"huggingface_hub[hf_transfer]==0.27.1"
"numpy<2"
"tiktoken==0.6.0"
"torch==2.5.1"
"torchvision==0.20.1"
"transformers==4.48.0"
"verovio==4.3.1"
Copy
Cache the pre-trained model on a Modal Volume
We can obtain the pre-trained model we want to run from Hugging Face
using its name and a revision identifier.
MODEL_NAME =
"ucaslcl/GOT-OCR2_0"
MODEL_REVISION =
"cf6b7386bc89a54f09785612ba74cb12de6fa17c"
Copy
The logic for loading the model based on this information
is encapsulated in the
setup
function below.
setup
import
warnings
from
transformers
import
AutoModel, AutoTokenizer
with
warnings.catch_warnings():
# filter noisy warnings from GOT modeling code
warnings.simplefilter(
"ignore"
tokenizer = AutoTokenizer.from_pretrained(
MODEL_NAME,
revision
=MODEL_REVISION,
trust_remote_code
True
model = AutoModel.from_pretrained(
MODEL_NAME,
revision
=MODEL_REVISION,
trust_remote_code
True
device_map
"cuda"
use_safetensors
True
pad_token_id
=tokenizer.eos_token_id,
return
tokenizer, model
Copy
.from_pretrained
methods from Hugging Face are smart enough
to only download models if they haven’t been downloaded before.
But in Modal’s serverless environment, filesystems are ephemeral,
and so using this code alone would mean that models need to get downloaded
on every request.
So instead, we create a Modal
Volume
to store the model — a durable filesystem that any Modal Function can access.
model_cache = modal.Volume.from_name(
"hf-hub-cache"
create_if_missing
True
Copy
We also update the environment variables for our Function
to include this new path for the model cache —
and to enable fast downloads with the
hf_transfer
library.
MODEL_CACHE_PATH =
"/root/models"
inference_image = inference_image.env(
"HF_HUB_CACHE"
: MODEL_CACHE_PATH,
"HF_HUB_ENABLE_HF_TRANSFER"
Copy
Run OCR inference on Modal by wrapping with
app.function
Now let’s set up the actual OCR inference.
Using the
@app.function
decorator, we set up a Modal
Function
We provide arguments to that decorator to customize the hardware, scaling, and other features
of the Function.
Here, we say that this Function should use NVIDIA L40S
GPUs
automatically
retry
failures up to 3 times,
and have access to our
shared model cache
@app.function
"l40s"
retries
volumes
={MODEL_CACHE_PATH: model_cache},
image
=inference_image,
parse_receipt
image
bytes
) ->
from
tempfile
import
NamedTemporaryFile
tokenizer, model = setup()
with
NamedTemporaryFile(
delete
False
mode
"wb+"
temp_img_file:
temp_img_file.write(image)
output = model.chat(tokenizer, temp_img_file.name,
ocr_type
"format"
print
"Result: "
, output)
return
output
Copy
Deploy
Now that we have a function, we can publish it by deploying the app:
modal
deploy
doc_ocr_jobs.py
Copy
Once it’s published, we can
look up
this Function
from another Python process and submit tasks to it:
fn = modal.Function.from_name(
"example-doc-ocr-jobs"
"parse_receipt"
fn.spawn(my_image)
Copy
Modal will auto-scale to handle all the tasks queued, and
then scale back down to 0 when there’s no work left. To see how you could use this from a Python web
app, take a look at the
receipt parser frontend
tutorial.
Run manually
We can also trigger
parse_receipt
manually for easier debugging:
modal
doc_ocr_jobs
Copy
To try it out, you can find some
example receipts
here
@app.local_entrypoint
main
receipt_filename
: Optional[
None
import
urllib.request
from
pathlib
import
Path
receipt_filename
None
receipt_filename = Path(
__file__
).parent /
"receipt.png"
else
receipt_filename = Path(receipt_filename)
receipt_filename.exists():
image = receipt_filename.read_bytes()
print
"running OCR on
receipt_filename
else
receipt_url =
"https://modal-cdn.com/cdnbot/Brandys-walmart-receipt-8g68_a_hk_f9c25fce.webp"
request = urllib.request.Request(receipt_url)
with
urllib.request.urlopen(request)
response:
image = response.read()
print
"running OCR on sample from URL
receipt_url
print
(parse_receipt.remote(image))
Copy
Run a job queue for GOT-OCR
Define an App
Cache the pre-trained model on a Modal Volume
Run OCR inference on Modal by wrapping with app.function
Deploy
Run manually
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
09_job_queues/doc_ocr_jobs.py
Copy

=== DOC: 009_examples_dreambooth_app.txt ===
URL: https://modal.com/docs/examples/dreambooth_app
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Fine-tune Flux on your pet using LoRA
This example finetunes the
Flux.1-dev model
on images of a pet (by default, a puppy named Qwerty)
using a technique called textual inversion from
the “Dreambooth” paper
Effectively, it teaches a general image generation model a new “proper noun”,
allowing for the personalized generation of art and photos.
We supplement textual inversion with low-rank adaptation (LoRA)
for increased efficiency during training.
It then makes the model shareable with others — without costing $25/day for a GPU server—
by hosting a
Gradio app
on Modal.
It demonstrates a simple, productive, and cost-effective pathway
to building on large pretrained models using Modal’s building blocks, like
GPU-accelerated
Modal Functions and Clses for compute-intensive work,
Volumes
for storage,
web endpoints
for serving.
And with some light customization, you can use it to generate images of your pet!
You can find a video walkthrough of this example on the Modal YouTube channel
here
Imports and setup
We start by importing the necessary libraries and setting up the environment.
from
dataclasses
import
dataclass
from
pathlib
import
Path
import
modal
Copy
Building up the environment
Machine learning environments are complex, and the dependencies can be hard to manage.
Modal makes creating and working with environments easy via
containers and container images
We start from a base image and specify all of our dependencies.
We’ll call out the interesting ones as they come up below.
Note that these dependencies are not installed locally
— they are only installed in the remote environment where our Modal App runs.
app = modal.App(
name
"example-lora-flux"
image = modal.Image.debian_slim(
python_version
"3.10"
).pip_install(
"accelerate==0.31.0"
"datasets~=2.13.0"
"fastapi[standard]==0.115.4"
"ftfy~=6.1.0"
"gradio~=5.5.0"
"huggingface-hub==0.26.2"
"hf_transfer==0.1.8"
"numpy<2"
"peft==0.11.1"
"pydantic==2.9.2"
"sentencepiece>=0.1.91,!=0.1.92"
"smart_open~=6.4.0"
"starlette==0.41.2"
"transformers~=4.41.2"
"torch~=2.2.0"
"torchvision~=0.16"
"triton~=2.2.0"
"wandb==0.17.6"
Copy
Downloading scripts and installing a git repo with
run_commands
We’ll use an example script from the
diffusers
library to train the model.
We acquire it from GitHub and install it in our environment with a series of commands.
The container environments Modal Functions run in are highly flexible —
the docs
for more details.
GIT_SHA =
"e649678bf55aeaa4b60bd1f68b1ee726278c0304"
# specify the commit to fetch
image = (
image.apt_install(
"git"
# Perform a shallow fetch of just the target `diffusers` commit, checking out
# the commit in the container's home directory, /root. Then install `diffusers`
.run_commands(
"cd /root && git init ."
"cd /root && git remote add origin https://github.com/huggingface/diffusers"
"cd /root && git fetch --depth=1 origin
GIT_SHA
&& git checkout
GIT_SHA
"cd /root && pip install -e ."
Copy
Configuration with
dataclass
Machine learning apps often have a lot of configuration information.
We collect up all of our configuration into dataclasses to avoid scattering special/magic values throughout code.
@dataclass
class
SharedConfig
"""Configuration information shared across project components."""
# The instance name is the "proper noun" we're teaching the model
instance_name:
"Qwerty"
# That proper noun is usually a member of some class (person, bird),
# and sharing that information with the model helps it generalize better.
class_name:
"Golden Retriever"
# identifier for pretrained models on Hugging Face
model_name:
"black-forest-labs/FLUX.1-dev"
Copy
Storing data created by our app with
modal.Volume
The tools we’ve used so far work well for fetching external information,
which defines the environment our app runs in,
but what about data that we create or modify during the app’s execution?
A persisted
modal.Volume
can store and share data across Modal Apps and Functions.
We’ll use one to store both the original and fine-tuned weights we create during training
and then load them back in for inference.
volume = modal.Volume.from_name(
"dreambooth-finetuning-volume-flux"
create_if_missing
True
MODEL_DIR =
"/model"
Copy
Note that access to the Flux.1-dev model on Hugging Face is
gated by a license agreement
which
you must agree to
here
After you have accepted the license,
create a Modal Secret
with the name
huggingface-secret
following the instructions in the template.
huggingface_secret = modal.Secret.from_name(
"huggingface-secret"
required_keys
"HF_TOKEN"
image = image.env(
"HF_HUB_ENABLE_HF_TRANSFER"
# turn on faster downloads from HF
@app.function
volumes
={MODEL_DIR: volume},
image
=image,
secrets
=[huggingface_secret],
timeout
# 10 minutes
download_models
config
import
torch
from
diffusers
import
DiffusionPipeline
from
huggingface_hub
import
snapshot_download
snapshot_download(
config.model_name,
local_dir
=MODEL_DIR,
ignore_patterns
"*.pt"
"*.bin"
# using safetensors
DiffusionPipeline.from_pretrained(MODEL_DIR,
torch_dtype
=torch.bfloat16)
Copy
Load fine-tuning dataset
Part of the magic of the low-rank fine-tuning is that we only need 3-10 images for fine-tuning.
So we can fetch just a few images, stored on consumer platforms like Imgur or Google Drive,
whenever we need them — no need for expensive, hard-to-maintain data pipelines.
load_images
image_urls
: list[
]) -> Path:
import
PIL.Image
from
smart_open
import
open
img_path = Path(
"/img"
img_path.mkdir(
parents
True
exist_ok
True
ii, url
enumerate
(image_urls):
with
open
(url,
"rb"
image = PIL.Image.open(f)
image.save(img_path /
.png"
print
ii +
images loaded"
return
img_path
Copy
Low-Rank Adapation (LoRA) fine-tuning for a text-to-image model
The base model we start from is trained to do a sort of “reverse
ekphrasis
it attempts to recreate a visual work of art or image from only its description.
We can use the model to synthesize wholly new images
by combining the concepts it has learned from the training data.
We use a pretrained model, the Flux model from Black Forest Labs.
In this example, we “finetune” Flux, making only small adjustments to the weights.
Furthermore, we don’t change all the weights in the model.
Instead, using a technique called
low-rank adaptation
we change a much smaller matrix that works “alongside” the existing weights, nudging the model in the direction we want.
We can get away with such a small and simple training process because we’re just teach the model the meaning of a single new word: the name of our pet.
The result is a model that can generate novel images of our pet:
as an astronaut in space, as painted by Van Gogh or Bastiat, etc.
Finetuning with Hugging Face 🧨 Diffusers and Accelerate
The model weights, training libraries, and training script are all provided by
🤗 Hugging Face
You can kick off a training job with the command
modal run dreambooth_app.py::app.train
It should take about ten minutes.
Training machine learning models takes time and produces a lot of metadata —
metrics for performance and resource utilization,
metrics for model quality and training stability,
and model inputs and outputs like images and text.
This is especially important if you’re fiddling around with the configuration parameters.
This example can optionally use
Weights & Biases
to track all of this training information.
Just sign up for an account, switch the flag below, and add your API key as a
Modal Secret
USE_WANDB =
False
Copy
You can see an example W&B dashboard
here
Check out
this run
which
despite having high GPU utilization
suffered from numerical instability during training and produced only black images — hard to debug without experiment management logs!
You can read more about how the values in
TrainConfig
are chosen and adjusted
in this blog post on Hugging Face
To run training on images of your own pet, upload the images to separate URLs and edit the contents of the file at
TrainConfig.instance_example_urls_file
to point to them.
Tip: if the results you’re seeing don’t match the prompt too well, and instead produce an image
of your subject without taking the prompt into account, the model has likely overfit. In this case, repeat training with a lower
value of
max_train_steps
. If you used W&B, look back at results earlier in training to determine where to stop.
On the other hand, if the results don’t look like your subject, you might need to increase
max_train_steps
@dataclass
class
TrainConfig
SharedConfig
"""Configuration for the finetuning step."""
# training prompt looks like `{PREFIX} {INSTANCE_NAME} the {CLASS_NAME} {POSTFIX}`
prefix:
"a photo of"
postfix:
# locator for plaintext file with urls for images of target instance
instance_example_urls_file:
Path(
__file__
).parent /
"instance_example_urls.txt"
# Hyperparameters/constants from the huggingface training example
resolution:
train_batch_size:
rank:
# lora rank
gradient_accumulation_steps:
learning_rate:
float
4e-4
lr_scheduler:
"constant"
lr_warmup_steps:
max_train_steps:
checkpointing_steps:
1000
seed:
@app.function
image
=image,
"A100-80GB"
# fine-tuning is VRAM-heavy and requires a high-VRAM GPU
volumes
={MODEL_DIR: volume},
# stores fine-tuned model
timeout
1800
# 30 minutes
secrets
=[huggingface_secret]
[modal.Secret.from_name(
"wandb-secret"
required_keys
"WANDB_API_KEY"
USE_WANDB
else
train
instance_example_urls
config
import
subprocess
from
accelerate.utils
import
write_basic_config
# load data locally
img_path = load_images(instance_example_urls)
# set up hugging face accelerate library for fast training
write_basic_config(
mixed_precision
"bf16"
# define the training prompt
instance_phrase =
config.instance_name
config.class_name
prompt =
config.prefix
instance_phrase
config.postfix
.strip()
# the model training is packaged as a script, so we have to execute it as a subprocess, which adds some boilerplate
_exec_subprocess
: list[
"""Executes subprocess and prints log to terminal while subprocess is running."""
process = subprocess.Popen(
cmd,
stdout
=subprocess.PIPE,
stderr
=subprocess.STDOUT,
with
process.stdout
pipe:
line
iter
(pipe.readline,
line_str = line.decode()
print
line_str
exitcode := process.wait() !=
raise
subprocess.CalledProcessError(exitcode,
.join(cmd))
# run training -- see huggingface accelerate docs for details
print
"launching dreambooth training script"
_exec_subprocess(
"accelerate"
"launch"
"examples/dreambooth/train_dreambooth_lora_flux.py"
"--mixed_precision=bf16"
# half-precision floats most of the time for faster training
"--pretrained_model_name_or_path=
MODEL_DIR
"--instance_data_dir=
img_path
"--output_dir=
MODEL_DIR
"--instance_prompt=
prompt
"--resolution=
config.resolution
"--train_batch_size=
config.train_batch_size
"--gradient_accumulation_steps=
config.gradient_accumulation_steps
"--learning_rate=
config.learning_rate
"--lr_scheduler=
config.lr_scheduler
"--lr_warmup_steps=
config.lr_warmup_steps
"--max_train_steps=
config.max_train_steps
"--checkpointing_steps=
config.checkpointing_steps
"--seed=
config.seed
# increased reproducibility by seeding the RNG
"--report_to=wandb"
# validation output tracking is useful, but currently broken for Flux LoRA training
# f"--validation_prompt={prompt} in space",  # simple test prompt
# f"--validation_epochs={config.max_train_steps // 5}",
USE_WANDB
else
# The trained model information has been output to the volume mounted at `MODEL_DIR`.
# To persist this data for use in our web app, we 'commit' the changes
# to the volume.
volume.commit()
Copy
Running our model
To generate images from prompts using our fine-tuned model, we define a Modal Function called
inference
Naively, this would seem to be a bad fit for the flexible, serverless infrastructure of Modal:
wouldn’t you need to include the steps to load the model and spin it up in every function call?
In order to initialize the model just once on container startup,
we use Modal’s
container lifecycle
features, which require the function to be part
of a class. Note that the
modal.Volume
we saved the model to is mounted here as well,
so that the fine-tuned model created  by
train
is available to us.
@app.cls
image
=image,
"A100"
volumes
={MODEL_DIR: volume})
class
Model
@modal.enter
load_model
self
import
torch
from
diffusers
import
DiffusionPipeline
# Reload the modal.Volume to ensure the latest state is accessible.
volume.reload()
# set up a hugging face inference pipeline using our model
pipe = DiffusionPipeline.from_pretrained(
MODEL_DIR,
torch_dtype
=torch.bfloat16,
).to(
"cuda"
pipe.load_lora_weights(MODEL_DIR)
self
.pipe = pipe
@modal.method
inference
self
text
config
image =
self
.pipe(
text,
num_inference_steps
=config.num_inference_steps,
guidance_scale
=config.guidance_scale,
).images[
return
image
Copy
Wrap the trained model in a Gradio web UI
Gradio
makes it super easy to expose a model’s functionality
in an easy-to-use, responsive web interface.
This model is a text-to-image generator,
so we set up an interface that includes a user-entry text box
and a frame for displaying images.
We also provide some example text inputs to help
guide users and to kick-start their creative juices.
And we couldn’t resist adding some Modal style to it as well!
You can deploy the app on Modal with the command
modal deploy dreambooth_app.py
You’ll be able to come back days, weeks, or months later and find it still ready to go,
even though you don’t have to pay for a server to run while you’re not using it.
@dataclass
class
AppConfig
SharedConfig
"""Configuration information for inference."""
num_inference_steps:
guidance_scale:
float
web_image = image.add_local_dir(
# Add local web assets to the image
Path(
__file__
).parent /
"assets"
remote_path
"/assets"
@app.function
image
=web_image,
max_containers
@modal.concurrent
max_inputs
1000
@modal.asgi_app
fastapi_app
import
gradio
from
fastapi
import
FastAPI
from
fastapi.responses
import
FileResponse
from
gradio.routes
import
mount_gradio_app
web_app = FastAPI()
# Call out to the inference in a separate Modal environment with a GPU
text
text:
text = example_prompts[
return
Model().inference.remote(text, config)
# set up AppConfig
config = AppConfig()
instance_phrase =
config.instance_name
config.class_name
example_prompts = [
instance_phrase
"a painting of
instance_phrase.title()
With A Pearl Earring, by Vermeer"
"oil painting of
instance_phrase
flying through space as an astronaut"
"a painting of
instance_phrase
in cyberpunk city. character design by cory loftis. volumetric light, detailed, rendered in octane"
"drawing of
instance_phrase
high quality, cartoon, path traced, by studio ghibli and don bluth"
modal_docs_url =
"https://modal.com/docs"
modal_example_url =
modal_docs_url
/examples/dreambooth_app"
description =
"""Describe what they are doing or how a particular artist or style would depict them. Be fantastical! Try the examples below for inspiration.
### Learn how to make a "Dreambooth" for your own pet [here](
modal_example_url
# custom styles: an icon, a background, and a theme
@web_app.get
"/favicon.ico"
include_in_schema
False
async
favicon
return
FileResponse(
"/assets/favicon.svg"
@web_app.get
"/assets/background.svg"
include_in_schema
False
async
background
return
FileResponse(
"/assets/background.svg"
with
open
"/assets/index.css"
css = f.read()
theme = gr.themes.Default(
primary_hue
"green"
secondary_hue
"emerald"
neutral_hue
"neutral"
# add a gradio UI around inference
with
gr.Blocks(
theme
=theme,
=css,
title
"Generate images of
config.instance_name
on Modal"
interface:
gr.Markdown(
"# Generate images of
instance_phrase
\n\n
description
with
gr.Row():
inp = gr.Textbox(
# input text component
label
placeholder
"Describe the version of
instance_phrase
you'd like to see"
lines
out = gr.Image(
# output image component
height
width
label
min_width
elem_id
"output"
with
gr.Row():
btn = gr.Button(
"Dream"
variant
"primary"
scale
btn.click(
=go,
inputs
=inp,
outputs
=out
# connect inputs and outputs with inference function
gr.Button(
# shameless plug
"⚡️ Powered by Modal"
variant
"secondary"
link
"https://modal.com"
with
gr.Column(
variant
"compact"
# add in a few examples to inspire users
ii, prompt
enumerate
(example_prompts):
btn = gr.Button(prompt,
variant
"secondary"
btn.click(
lambda
=ii: example_prompts[idx],
outputs
=inp)
# mount for execution on Modal
return
mount_gradio_app(
=web_app,
blocks
=interface,
path
Copy
Running your fine-tuned model from the command line
You can use the
modal
command-line interface to set up, customize, and deploy this app:
modal run diffusers_lora_finetune.py
will train the model. Change the
instance_example_urls_file
to point to your own pet’s images.
modal serve diffusers_lora_finetune.py
will
serve
the Gradio interface at a temporary location. Great for iterating on code!
modal shell diffusers_lora_finetune.py
is a convenient helper to open a bash
shell
in our image. Great for debugging environment issues.
Remember, once you’ve trained your own fine-tuned model, you can deploy it permanently — for no cost when it is not being used! —
using
modal deploy diffusers_lora_finetune.py
If you just want to try the app out, you can find our deployment
here
@app.local_entrypoint
# add more config params here to make training configurable
max_train_steps
print
"🎨 loading model"
download_models.remote(SharedConfig())
print
"🎨 setting up training"
config = TrainConfig(
max_train_steps
=max_train_steps)
instance_example_urls = (
Path(TrainConfig.instance_example_urls_file).read_text().splitlines()
train.remote(instance_example_urls, config)
print
"🎨 training finished"
Copy
Fine-tune Flux on your pet using LoRA
Imports and setup
Building up the environment
Downloading scripts and installing a git repo with run_commands
Configuration with dataclasses
Storing data created by our app with modal.Volume
Load fine-tuning dataset
Low-Rank Adapation (LoRA) fine-tuning for a text-to-image model
Finetuning with Hugging Face 🧨 Diffusers and Accelerate
Running our model
Wrap the trained model in a Gradio web UI
Running your fine-tuned model from the command line
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/dreambooth/diffusers_lora_finetune.py
Copy

=== DOC: 010_examples_llm-voice-chat.txt ===
URL: https://modal.com/docs/examples/llm-voice-chat
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
QuiLLMan: Voice Chat with Moshi
QuiLLMan
is a complete voice chat application built on Modal: you speak and the chatbot speaks back!
At the core is Kyutai Lab’s
Moshi
model, a speech-to-speech language model that will continuously listen, plan, and respond to the user.
Thanks to bidirectional websocket streaming and
Opus audio compression
, response times on good internet can be nearly instantaneous, closely matching the cadence of human speech.
You can find the demo live
here
Everything — from the React frontend to the model backend — is deployed serverlessly on Modal, allowing it to automatically scale and ensuring you only pay for the compute you use.
This page provides a high-level walkthrough of the
GitHub repo
Code overview
Traditionally, building a bidirectional streaming web application as compute-heavy as QuiLLMan would take a lot of work, and it’s especially difficult to make it robust and scale to handle many concurrent users.
But with Modal, it’s as simple as writing two different classes and running a CLI command.
Our project structure looks like this:
Moshi Websocket Server
: loads an instance of the Moshi model and maintains a bidirectional websocket connection with the client.
React Frontend
: runs client-side interaction logic.
Let’s go through each of these components in more detail.
FastAPI Server
Both frontend and backend are served via a
FastAPI Server
, which is a popular Python web framework for building REST APIs.
On Modal, a function or class method can be exposed as a web endpoint by decorating it with
@app.asgi_app()
and returning a FastAPI app. You’re then free to configure the FastAPI server however you like, including adding middleware, serving static files, and running websockets.
Moshi Websocket Server
Traditionally, a speech-to-speech chat app requires three distinct modules: speech-to-text, text-to-text, and text-to-speech. Passing data between these modules introduces bottlenecks, and can limit the speed of the app and forces a turn-by-turn conversation which can feel unnatural.
Kyutai Lab’s
Moshi
bundles all modalities into one model, which decreases latency and makes for a much simpler app.
Under the hood, Moshi uses the
Mimi
streaming encoder/decoder model to maintain an unbroken stream of audio in and out. The encoded audio is processed by a
speech-text foundation model
, which uses an internal monologue to determine when and how to respond.
Using a streaming model introduces a few challenges not normally seen in inference backends:
The model is
stateful
, meaning it maintains context of the conversation so far. This means a model instance cannot be shared between user conversations, so we must run a unique GPU per user session, which is normally not an easy feat!
The model is
streaming
, so the interface around it is not as simple as a POST request. We must find a way to stream audio data in and out, and do it fast enough for seamless playback.
We solve both of these in
src/moshi.py
, using a few Modal features.
To solve statefulness, we just spin up a new GPU per concurrent user.
That’s easy with Modal!
@app.cls
image
=image,
"A10G"
scaledown_window
class
Moshi
# ...
Copy
With this setting, if a new user connects, a new GPU instance is created! When any user disconnects, the state of their model is reset and that GPU instance is returned to the warm pool for re-use (for up to 300 seconds). Be aware that a GPU per user is not going to be cheap, but it’s the simplest way to ensure user sessions are isolated.
For streaming, we use FastAPI’s support for bidirectional websockets. This allows clients to establish a single connection at the start of their session, and stream audio data both ways.
Just as a FastAPI server can run from a Modal function, it can also be attached to a Modal class method, allowing us to couple a prewarmed Moshi model to a websocket session.
@modal.asgi_app
self
from
fastapi
import
FastAPI, Response, WebSocket, WebSocketDisconnect
web_app = FastAPI()
@web_app.websocket
"/ws"
async
websocket
: WebSocket):
with
torch.no_grad():
await
ws.accept()
# handle user session
# spawn loops for async IO
async
recv_loop
while
True
data =
await
ws.receive_bytes()
# send data into inference stream...
async
send_loop
while
True
await
asyncio.sleep(
0.001
msg =
self
.opus_stream_outbound.read_bytes()
# send inference output to user ...
Copy
To run a
development server
for the Moshi module, run this command from the root of the repo.
modal
serve
src.moshi
Copy
In the terminal output, you’ll find a URL for creating a websocket connection.
React Frontend
The frontend is a static React app, found in the
src/frontend
directory and served by
src/app.py
We use the
Web Audio API
to record audio from the user’s microphone and playback audio responses from the model.
For efficient audio transmission, we use the
Opus codec
to compress audio across the network. Opus recording and playback are supported by the
opus-recorder
ogg-opus-decoder
libraries.
To serve the frontend assets, run this command from the root of the repo.
modal
serve
src.app
Copy
Since
src/app.py
imports the
src/moshi.py
module, this
serve
command also serves the Moshi websocket server as its own endpoint.
Deploy
When you’re ready to go live, use the
deploy
command to deploy the app to Modal.
modal
deploy
src.app
Copy
Steal this example
The code for this entire example is
available on GitHub
, so feel free to fork it and make it your own!
QuiLLMan: Voice Chat with Moshi
Code overview
FastAPI Server
Moshi Websocket Server
React Frontend
Deploy
Steal this example

=== DOC: 011_examples_musicgen.txt ===
URL: https://modal.com/docs/examples/musicgen
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Create your own music samples with MusicGen
MusicGen is a popular open-source music-generation model family from Meta.
In this example, we show you how you can run MusicGen models on Modal GPUs,
along with a Gradio UI for playing around with the model.
We use
Audiocraft
the inference library released by Meta
for MusicGen and its kin, like AudioGen.
Setting up dependencies
from
pathlib
import
Path
from
typing
import
Optional
from
uuid
import
uuid4
import
modal
Copy
We start by defining the environment our generation runs in.
This takes some explaining since, like most cutting-edge ML environments, it is a bit fiddly.
This environment is captured by a
container image
which we build step-by-step by calling methods to add dependencies,
like
apt_install
to add system packages and
pip_install
to add
Python packages.
Note that we don’t have to install anything with “CUDA”
in the name — the drivers come for free with the Modal environment
and the rest gets installed
. That makes our life a lot easier!
If you want to see the details, check out
this guide
in our docs.
image = (
modal.Image.debian_slim(
python_version
"3.11"
.apt_install(
"git"
"ffmpeg"
.pip_install(
"huggingface_hub[hf_transfer]==0.27.1"
# speed up model downloads
"torch==2.1.0"
# version pinned by audiocraft
"numpy<2"
# defensively cap the numpy version
"git+https://github.com/facebookresearch/audiocraft.git@v1.3.0"
# we can install directly from GitHub!
Copy
In addition to source code, we’ll also need the model weights.
Audiocraft integrates with the Hugging Face ecosystem, so setting up the models
is straightforward — the same
get_pretrained
method we use to load the weights for execution
will also download them if they aren’t present.
load_model
and_return
False
from
audiocraft.models
import
MusicGen
model_large = MusicGen.get_pretrained(
"facebook/musicgen-large"
and_return:
return
model_large
Copy
But Modal Functions are serverless: instances spin down when they aren’t being used.
If we want to avoid downloading the weights every time we start a new instance,
we need to store the weights somewhere besides our local filesystem.
So we add a Modal
Volume
to store the weights in the cloud.
cache_dir =
"/cache"
model_cache = modal.Volume.from_name(
"audiocraft-model-cache"
create_if_missing
True
Copy
We don’t need to change any of the model loading code —
we just need to make sure the model gets stored in the right directory.
To do that, we set an environment variable that Hugging Face expects
(and another one that speeds up downloads, for good measure)
and then run the
load_model
Python function.
image = image.env(
"HF_HUB_CACHE"
: cache_dir,
"HF_HUB_ENABLE_HF_TRANSER"
).run_function(load_model,
volumes
={cache_dir: model_cache})
Copy
While we’re at it, let’s also define the environment for our UI.
We’ll stick with Python and so use FastAPI and Gradio.
web_image = modal.Image.debian_slim(
python_version
"3.11"
).pip_install(
"fastapi[standard]==0.115.4"
"gradio==4.44.1"
Copy
This is a totally different environment from the one we run our model in.
Say goodbye to Python dependency conflict hell!
Running music generation on Modal
Now, we write our music generation logic.
This is bit complicated because we want to support generating long samples,
but the model has a maximum context length of thirty seconds.
We can get longer clips by feeding the model’s output back as input,
auto-regressively, but we have to write that ourselves.
There are also a few bits to make this work well with Modal:
We make an
to organize our deployment.
We load the model at start, instead of during inference, with
modal.enter
which requires that we use a Modal
In the
app.cls
decorator, we specify the Image we built and attach the Volume.
We also pick a GPU to run on — here, an NVIDIA L40S.
app = modal.App(
"example-musicgen"
MAX_SEGMENT_DURATION =
# maximum context window size
@app.cls
"l40s"
image
=image,
volumes
={cache_dir: model_cache})
class
MusicGen
@modal.enter
init
self
self
.model = load_model(
and_return
True
@modal.method
generate
self
prompt
duration
overlap
format
"wav"
# or mp3
) ->
bytes
"""Generate a music clip based on the prompt.
Clips longer than the MAX_SEGMENT_DURATION of
MAX_SEGMENT_DURATION
are generated by clipping all but `overlap` seconds and running inference again."""
context =
None
overlap =
(overlap, MAX_SEGMENT_DURATION -
remaining_duration = duration
remaining_duration <
return
bytes
while
remaining_duration >
# calculate duration of the next segment
segment_duration = remaining_duration
context
None
segment_duration += overlap
segment_duration =
(segment_duration, MAX_SEGMENT_DURATION)
# generate next segment
generated_duration = (
segment_duration
context
None
else
(segment_duration - overlap)
print
"🎼 generating
generated_duration
seconds of music"
self
.model.set_generation_params(
duration
=segment_duration)
next_segment =
self
._generate_next_segment(prompt, context, overlap)
# update remaining duration
remaining_duration -= generated_duration
# combine with previous segments
context =
self
._combine_segments(context, next_segment, overlap)
output = context.detach().cpu().float()[
return
to_audio_bytes(
output,
self
.model.sample_rate,
format
format
# for more on audio encoding parameters, see the docs for audiocraft
strategy
"loudness"
loudness_compressor
True
_generate_next_segment
self
prompt
context
overlap
"""Generate the next audio segment, either fresh or as continuation of a context."""
context
None
return
self
.model.generate(
descriptions
=[prompt])
else
overlap_samples = overlap *
self
.model.sample_rate
last_chunk = context[:, :, -overlap_samples:]
# B, C, T
return
self
.model.generate_continuation(
last_chunk,
self
.model.sample_rate,
descriptions
=[prompt]
_combine_segments
self
context
next_segment
overlap
"""Combine context with next segment, handling overlap."""
import
torch
context
None
return
next_segment
# Calculate where to trim the context (removing overlap)
overlap_samples = overlap *
self
.model.sample_rate
context_trimmed = context[:, :, :-overlap_samples]
# B, C, T
return
torch.cat([context_trimmed, next_segment],
Copy
We can then generate music from anywhere by running code like what we have in the
local_entrypoint
below.
@app.local_entrypoint
main
prompt
: Optional[
None
duration
overlap
format
"wav"
# or mp3
prompt
None
prompt =
"Amapiano polka, klezmers, log drum bassline, 112 BPM"
print
"🎼 generating
duration
seconds of music from prompt '
prompt[:
] + (
'...'
(prompt) >
else
audiocraft = MusicGen()
clip = audiocraft.generate.remote(prompt,
duration
=duration,
format
format
= Path(
"/tmp/audiocraft"
.mkdir(
exist_ok
True
parents
True
output_path =
slugify(prompt)[:
format
print
"🎼 Saving to
output_path
output_path.write_bytes(clip)
Copy
You can execute it with a command like:
modal
musicgen.py
--prompt=
"Baroque boy band, Bachstreet Boys, basso continuo, Top 40 pop music"
--duration=60
Copy
Hosting a web UI for the music generator
With the Gradio library, we can create a simple web UI in Python
that calls out to our music generator,
then host it on Modal for anyone to try out.
To deploy both the music generator and the UI, run
modal
deploy
musicgen.py
Copy
Share the URL with your friends and they can generate their own songs!
@app.function
image
=web_image,
# Gradio requires sticky sessions
# so we limit the number of concurrent containers to 1
# and allow it to scale to 1000 concurrent inputs
max_containers
@modal.concurrent
max_inputs
1000
@modal.asgi_app
import
gradio
from
fastapi
import
FastAPI
from
gradio.routes
import
mount_gradio_app
api = FastAPI()
# Since this Gradio app is running from its own container,
# we make a `.remote` call to the music generator
model = MusicGen()
generate = model.generate.remote
temp_dir = Path(
"/dev/shm"
async
generate_music
prompt
duration
format
"wav"
audio_bytes =
await
generate.aio(prompt,
duration
=duration,
format
format
audio_path = temp_dir /
uuid4()
format
audio_path.write_bytes(audio_bytes)
return
audio_path
with
gr.Blocks(
theme
"soft"
demo:
gr.Markdown(
"# MusicGen"
with
gr.Row():
with
gr.Column():
prompt = gr.Textbox(
label
"Prompt"
duration = gr.Number(
label
"Duration (seconds)"
value
minimum
maximum
format
= gr.Radio([
"wav"
"mp3"
label
"Format"
value
"wav"
btn = gr.Button(
"Generate"
with
gr.Column():
clip_output = gr.Audio(
label
"Generated Music"
autoplay
True
btn.click(
generate_music,
inputs
=[prompt, duration,
format
outputs
=[clip_output],
return
mount_gradio_app(
=api,
blocks
=demo,
path
Copy
Addenda
The remainder of the code here is not directly related to Modal
or to music generation, but is used in the example above.
to_audio_bytes
sample_rate
, **
kwargs
) ->
bytes
from
audiocraft.data.audio
import
audio_write
# audiocraft provides a nice utility for converting waveform tensors to audio,
# but it saves to a file path. here, we create a file path that is actually
# just backed by memory, instead of disk, to save on some latency
shm = Path(
"/dev/shm"
# /dev/shm is a memory-backed filesystem
stem_name = shm /
(uuid4())
output_path = audio_write(stem_name, wav, sample_rate, **kwargs)
return
output_path.read_bytes()
slugify
string
return
string.lower()
.replace(
.replace(
.replace(
.replace(
Copy
Create your own music samples with MusicGen
Setting up dependencies
Running music generation on Modal
Hosting a web UI for the music generator
Addenda
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/text-to-audio/musicgen.py
Copy

=== DOC: 012_guide_getting-started.txt ===
URL: https://modal.com/docs/guide/getting-started
Not Found
Sorry, this page doesn't exist! We weren't able to find the documentation
that you were looking for. Did you type the correct URL?
You can find the rest of the Modal documentation
here

=== DOC: 013_examples_chai1.txt ===
URL: https://modal.com/docs/examples/chai1
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Fold proteins with Chai-1
In biology, function follows form quite literally:
the physical shapes of proteins dictate their behavior.
Measuring those shapes directly is difficult
and first-principles physical simulation prohibitively expensive.
And so predicting protein shape from content —
determining how the one-dimensional chain of amino acids encoded by DNA
folds
into a 3D object —
has emerged as a key application for machine learning and neural networks in biology.
In this example, we demonstrate how to run the open source
Chai-1
protein structure prediction model on Modal’s flexible serverless infrastructure.
For details on how the Chai-1 model works and what it can be used for,
see the authors’
technical report on bioRxiv
This simple script is meant as a starting point showing how to handle fiddly bits
like installing dependencies, loading weights, and formatting outputs so that you can get on with the fun stuff.
To experience the full power of Modal, try scaling inference up and running on hundreds or thousands of structures!
Setup
import
hashlib
import
json
from
pathlib
import
Path
from
typing
import
Optional
from
uuid
import
uuid4
import
modal
here = Path(
__file__
).parent
# the directory of this file
MINUTES =
# seconds
app = modal.App(
name
"example-chai1-inference"
Copy
Fold a protein from the command line
The logic for running Chai-1 is encapsulated in the function below,
which you can trigger from the command line by running
modal
chai1
Copy
This will set up the environment for running Chai-1 inference in Modal’s cloud,
run it, and then save the results remotely and locally. The results are returned in the
Crystallographic Information File
format,
which you can render with the online
Molstar Viewer
To see more options, run the command with the
--help
flag.
To learn how it works, read on!
@app.local_entrypoint
main
force_redownload
bool
False
fasta_file
: Optional[
None
inference_config_file
: Optional[
None
output_dir
: Optional[
None
run_id
: Optional[
None
print
"🧬 checking inference dependencies"
download_inference_dependencies.remote(
force
=force_redownload)
fasta_file
None
fasta_file = here /
"data"
"chai1_default_input.fasta"
print
"🧬 running Chai inference on
fasta_file
fasta_content = Path(fasta_file).read_text()
inference_config_file
None
inference_config_file = here /
"data"
"chai1_default_inference.json"
print
"🧬 loading Chai inference config from
inference_config_file
inference_config = json.loads(Path(inference_config_file).read_text())
run_id
None
run_id = hashlib.sha256(uuid4().bytes).hexdigest()[:
# short id
print
"🧬 running inference with
run_id
results = chai1_inference.remote(fasta_content, inference_config, run_id)
output_dir
None
output_dir = Path(
"/tmp/chai1"
output_dir.mkdir(
parents
True
exist_ok
True
print
"🧬 saving results to disk locally in
output_dir
ii, (scores, cif)
enumerate
(results):
(Path(output_dir) /
run_id
-scores.model_idx_
.npz"
).write_bytes(scores)
(Path(output_dir) /
run_id
-preds.model_idx_
.cif"
).write_text(cif)
Copy
Installing Chai-1 Python dependencies on Modal
Code running on Modal runs inside containers built from
container images
that include that code’s dependencies.
Because Modal images include
GPU drivers
by default,
installation of higher-level packages like
chai_lab
that require GPUs is painless.
Here, we do it with one line, using the
package manager for extra speed.
image = modal.Image.debian_slim(
python_version
"3.12"
).run_commands(
"uv pip install --system --compile-bytecode chai_lab==0.5.0 hf_transfer==0.1.8"
Copy
Storing Chai-1 model weights on Modal with Volumes
Not all “dependencies” belong in a container image. Chai-1, for example, depends on
the weights of several models.
Rather than loading them dynamically at run-time (which would add several minutes of GPU time to each inference),
or installing them into the image (which would require they be re-downloaded any time the other dependencies changed),
we load them onto a
Modal Volume
A Modal Volume is a file system that all of your code running on Modal (or elsewhere!) can access.
For more on storing model weights on Modal, see
this guide
chai_model_volume = (
modal.Volume.from_name(
# create distributed filesystem for model weights
"chai1-models"
create_if_missing
True
models_dir = Path(
"/models/chai1"
Copy
The details of how we handle the download here (e.g. running concurrently for extra speed)
are in the
Addenda
image = image.env(
# update the environment variables in the image to...
"CHAI_DOWNLOADS_DIR"
(models_dir),
# point the chai code to it
"HF_HUB_ENABLE_HF_TRANSFER"
# speed up downloads
Copy
Storing Chai-1 outputs on Modal Volumes
Chai-1 produces its outputs by writing to disk —
the model’s scores for the structure and the structure itself along with rich metadata.
But Modal is a
serverless
platform, and the filesystem your Modal Functions write to
is not persistent. Any file can be converted into bytes and sent back from a Modal Function
— and we mean any! You can send files that are gigabytes in size that way.
So we do that below.
But for larger jobs, like folding every protein in the PDB, storing bytes on a local client
like a laptop won’t cut it.
So we again lean on Modal Volumes, which can store thousands of files each.
We attach a Volume to a Modal Function that runs Chai-1 and the inference code
saves the results to distributed storage, without any fuss or source code changes.
chai_preds_volume = modal.Volume.from_name(
"chai1-preds"
create_if_missing
True
preds_dir = Path(
"/preds"
Copy
Running Chai-1 on Modal
Now we’re ready to define a Modal Function that runs Chai-1.
We put our function on Modal by wrapping it in a decorator,
@app.function
We provide that decorator with some arguments that describe the infrastructure our code needs to run:
the Volumes we created, the Image we defined, and of course a fast GPU!
Note that Chai-1 takes a file path as input —
specifically, a path to a file in the
FASTA format
We pass the file contents to the function as a string and save them to disk so they can be picked up by the inference code.
Because Modal is serverless, we don’t need to worry about cleaning up these resources:
the disk is ephemeral and the GPU only costs you money when you’re using it.
@app.function
timeout
* MINUTES,
"H100"
volumes
={models_dir: chai_model_volume, preds_dir: chai_preds_volume},
image
=image,
chai1_inference
fasta_content
inference_config
dict
run_id
) -> list[(
bytes
from
pathlib
import
Path
import
torch
from
chai_lab
import
chai1
N_DIFFUSION_SAMPLES =
# hard-coded in chai-1
fasta_file = Path(
"/tmp/inputs.fasta"
fasta_file.write_text(fasta_content.strip())
output_dir = Path(
"/preds"
) / run_id
chai1.run_inference(
fasta_file
=fasta_file,
output_dir
=output_dir,
device
=torch.device(
"cuda"
**inference_config,
print
"🧬 done, results written to /
output_dir.relative_to(
'/preds'
on remote volume"
results = []
range
(N_DIFFUSION_SAMPLES):
scores = (output_dir /
"scores.model_idx_
.npz"
).read_bytes()
cif = (output_dir /
"pred.model_idx_
.cif"
).read_text()
results.append((scores, cif))
return
results
Copy
Addenda
Above, we glossed over just how we got hold of the model weights —
local_entrypoint
just called a function named
download_inference_dependencies
Here’s that function’s implementation.
A few highlights:
This Modal Function can access the model weights Volume, like the inference Function,
but it can’t access the model predictions Volume.
This Modal Function has a different Image (the default!) and doesn’t use a GPU. Modal helps you
separate the concerns, and the costs, of your infrastructure’s components.
We use the
async
keyword here so that we can run the download for each model file
as a separate task, concurrently. We don’t need to worry about this use of
async
spreading to the rest of our code — Modal launches just this Function in an async runtime.
@app.function
volumes
={models_dir: chai_model_volume})
async
download_inference_dependencies
force
False
import
asyncio
import
aiohttp
base_url =
"https://chaiassets.com/chai1-inference-depencencies/"
# sic
inference_dependencies = [
"conformers_v1.apkl"
"models_v2/trunk.pt"
"models_v2/token_embedder.pt"
"models_v2/feature_embedding.pt"
"models_v2/diffusion_module.pt"
"models_v2/confidence_head.pt"
headers = {
"User-Agent"
"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
# launch downloads concurrently
async
with
aiohttp.ClientSession(
headers
=headers)
session:
tasks = []
inference_dependencies:
local_path = models_dir / dep
force
local_path.exists():
url = base_url + dep
print
"🧬 downloading
tasks.append(download_file(session, url, local_path))
# run all of the downloads and await their completion
await
asyncio.gather(*tasks)
chai_model_volume.commit()
# ensures models are visible on remote filesystem before exiting, otherwise takes a few seconds, racing with inference
async
download_file
session
local_path
: Path):
async
with
session.get(url)
response:
response.raise_for_status()
local_path.parent.mkdir(
parents
True
exist_ok
True
with
open
(local_path,
"wb"
while
chunk :=
await
response.content.read(
8192
f.write(chunk)
Copy
Fold proteins with Chai-1
Setup
Fold a protein from the command line
Installing Chai-1 Python dependencies on Modal
Storing Chai-1 model weights on Modal with Volumes
Storing Chai-1 outputs on Modal Volumes
Running Chai-1 on Modal
Addenda
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/protein-folding/chai1.py
Copy

=== DOC: 014_examples_llama_cpp.txt ===
URL: https://modal.com/docs/examples/llama_cpp
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Run large and small language models with llama.cpp (DeepSeek-R1, Phi-4)
This example demonstrate how to run small (Phi-4) and large (DeepSeek-R1)
language models on Modal with
llama.cpp
By default, this example uses DeepSeek-R1 to produce a “Flappy Bird” game in Python —
see the video below. The code used in the video is
here
along with the model’s raw outputs.
Note that getting the game to run required a small bugfix from a human —
our jobs are still safe, for now.
from
pathlib
import
Path
from
typing
import
Optional
import
modal
Copy
What GPU can run DeepSeek-R1? What GPU can run Phi-4?
Our large model is a real whale:
DeepSeek-R1
which has 671B total parameters and so consumes over 100GB of storage,
even when
quantized down to one ternary digit (1.58 bits)
per parameter.
To make sure we have enough room for it and its activations/KV cache,
we select four L40S GPUs, which together have 192 GB of memory.
Phi-4
on the other hand, is a svelte 14B total parameters,
or roughly 5 GB when quantized down to
two bits per parameter
That’s small enough that it can be comfortably run on a CPU,
especially for a single-user setup like the one we’ll build here.
GPU_CONFIG =
"L40S:4"
# for DeepSeek-R1, literal `None` for phi-4
Copy
Calling a Modal Function from the command line
To start, we define our
main
function —
the Python function that we’ll run locally to
trigger our inference to run on Modal’s cloud infrastructure.
This function, like the others that form our inference service
running on Modal, is part of a Modal
Specifically, it is a
local_entrypoint
Any Python code can call Modal Functions remotely,
but local entrypoints get a command-line interface for free.
app = modal.App(
"example-llama-cpp"
@app.local_entrypoint
main
prompt
: Optional[
None
model
"DeepSeek-R1"
# or "phi-4"
n_predict
# max number of tokens to predict, -1 is infinite
args
: Optional[
None
# string of arguments to pass to llama.cpp's cli
"""Run llama.cpp inference on Modal for phi-4 or deepseek r1."""
import
shlex
org_name =
"unsloth"
# two sample models: the diminuitive phi-4 and the chonky deepseek r1
model.lower() ==
"phi-4"
model_name =
"phi-4-GGUF"
quant =
"Q2_K"
model_entrypoint_file =
"phi-4-
quant
.gguf"
model_pattern =
quant
revision =
None
parsed_args = DEFAULT_PHI_ARGS
args
None
else
shlex.split(args)
elif
model.lower() ==
"deepseek-r1"
model_name =
"DeepSeek-R1-GGUF"
quant =
"UD-IQ1_S"
model_entrypoint_file = (
model
quant
/DeepSeek-R1-
quant
-00001-of-00003.gguf"
model_pattern =
quant
revision =
"02656f62d2aa9da4d3f0cdb34c341d30dd87c3b6"
parsed_args = DEFAULT_DEEPSEEK_R1_ARGS
args
None
else
shlex.split(args)
else
raise
ValueError
"Unknown model
model
repo_id =
org_name
model_name
download_model.remote(repo_id, [model_pattern], revision)
# call out to a `.remote` Function on Modal for inference
result = llama_cpp_inference.remote(
model_entrypoint_file,
prompt,
n_predict,
parsed_args,
store_output
=model.lower() ==
"deepseek-r1"
output_path = Path(
"/tmp"
"llama-cpp-
model
.txt"
output_path.parent.mkdir(
parents
True
exist_ok
True
print
"🦙 writing response to
output_path
output_path.write_text(result)
Copy
You can trigger inference from the command line with
modal
llama_cpp.py
Copy
To try out Phi-4 instead, use the
--model
argument:
modal
llama_cpp.py
--model=
"phi-4"
Copy
Note that this will run for up to 30 minutes, which costs ~$5.
To allow it to proceed even if your local terminal fails,
add the
--detach
flag after
modal run
See below for details on getting the outputs.
You can pass prompts with the
--prompt
argument and set the maximum number of tokens
with the
--n-predict
argument.
Additional arguments for
llama-cli
are passed as a string like
--args="--foo 1 --bar"
For convenience, we set a number of sensible defaults for DeepSeek-R1,
following the suggestions by the team at unsloth,
quantized the model to 1.58 bit
DEFAULT_DEEPSEEK_R1_ARGS = [
# good default llama.cpp cli args for deepseek-r1
"--cache-type-k"
"q4_0"
"--threads"
"12"
"-no-cnv"
"--prio"
"--temp"
"0.6"
"--ctx-size"
"8192"
DEFAULT_PHI_ARGS = [
# good default llama.cpp cli args for phi-4
"--threads"
"16"
"-no-cnv"
"--ctx-size"
"16384"
Copy
Compiling llama.cpp with CUDA support
In order to run inference, we need the model’s weights
and we need code to run inference with those weights.
llama.cpp
is a no-frills C++ library for running large language models.
It supports highly-quantized versions of models ideal for running
single-user language modeling services on CPU or GPU.
We compile it, with CUDA support, and add it to a Modal
container image
using the code below.
For more details on using CUDA on Modal, including why
we need to use the
nvidia/cuda
registry image in this case
(hint: it’s for the
nvcc
compiler
see the
Modal guide to using CUDA
LLAMA_CPP_RELEASE =
"b4568"
MINUTES =
cuda_version =
"12.4.0"
# should be no greater than host CUDA version
flavor =
"devel"
#  includes full CUDA toolkit
operating_sys =
"ubuntu22.04"
tag =
cuda_version
flavor
operating_sys
image = (
modal.Image.from_registry(
"nvidia/cuda:
add_python
"3.12"
.apt_install(
"git"
"build-essential"
"cmake"
"curl"
"libcurl4-openssl-dev"
.run_commands(
"git clone https://github.com/ggerganov/llama.cpp"
.run_commands(
"cmake llama.cpp -B llama.cpp/build "
"-DBUILD_SHARED_LIBS=OFF -DGGML_CUDA=ON -DLLAMA_CURL=ON "
.run_commands(
# this one takes a few minutes!
"cmake --build llama.cpp/build --config Release -j --clean-first --target llama-quantize llama-cli"
.run_commands(
"cp llama.cpp/build/bin/llama-* llama.cpp"
.entrypoint([])
# remove NVIDIA base container entrypoint
Copy
Storing models on Modal
To make the model weights available on Modal,
we download them from Hugging Face.
Modal is serverless, so disks are by default ephemeral.
To make sure our weights don’t disappear between runs,
which would trigger a long download, we store them in a
Modal
Volume
For more on how to use Modal Volumes to store model weights,
this guide
model_cache = modal.Volume.from_name(
"llamacpp-cache"
create_if_missing
True
cache_dir =
"/root/.cache/llama.cpp"
download_image = (
modal.Image.debian_slim(
python_version
"3.11"
.pip_install(
"huggingface_hub[hf_transfer]==0.26.2"
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
@app.function
image
=download_image,
volumes
={cache_dir: model_cache},
timeout
* MINUTES
download_model
repo_id
allow_patterns
revision
: Optional[
None
from
huggingface_hub
import
snapshot_download
print
"🦙 downloading model from
repo_id
if not present"
snapshot_download(
repo_id
=repo_id,
revision
=revision,
local_dir
=cache_dir,
allow_patterns
=allow_patterns,
model_cache.commit()
# ensure other Modal Functions can see our writes before we quit
print
"🦙 model loaded"
Copy
Storing model outputs on Modal
Contemporary large reasoning models are slow —
for the sample “flappy bird” prompt we provide,
results are sometimes produced only after several (or even tens of) minutes.
That makes their outputs worth storing.
In addition to sending them back to clients,
like our local command line,
we’ll store the results on a Modal Volume for safe-keeping.
results = modal.Volume.from_name(
"llamacpp-results"
create_if_missing
True
results_dir =
"/root/results"
Copy
You can retrieve the results later in a number of ways.
You can use the Volume CLI:
modal
volume
llamacpp-results
Copy
You can attach the Volume to a Modal
shell
to poke around in a familiar terminal environment:
modal
shell
--volume
llamacpp-results
# then cd into /mnt
Copy
Or you can access it from any other Python environment
by using the same
modal.Volume
call as above to instantiate it:
results = modal.Volume.from_name(
"llamacpp-results"
print
(results))
# show methods
Copy
Running llama.cpp as a Modal Function
Now, let’s put it all together.
At the top of our
llama_cpp_inference
function,
we add an
app.function
decorator to attach all of our infrastructure:
image
with the dependencies
volumes
with the weights and where we can put outputs
we want, if any
We also specify a
timeout
after which to cancel the run.
Inside the function, we call the
llama.cpp
with
subprocess.Popen
. This requires a bit of extra ceremony
because we want to both show the output as we run
and store the output to save and return to the local caller.
For details, see the
Addenda section
below.
Alternatively, you might set up an OpenAI-compatible server
using base
llama.cpp
or its
Python wrapper library
along with one of
Modal’s decorators for web hosting
@app.function
image
=image,
volumes
={cache_dir: model_cache, results_dir: results},
=GPU_CONFIG,
timeout
* MINUTES,
llama_cpp_inference
model_entrypoint_file
prompt
: Optional[
None
n_predict
args
: Optional[list[
]] =
None
store_output
bool
True
import
subprocess
from
uuid
import
uuid4
prompt
None
prompt = DEFAULT_PROMPT
# see end of file
"deepseek"
model_entrypoint_file.lower():
prompt =
"<｜User｜>"
+ prompt +
"<think>"
args
None
args = []
# set layers to "off-load to", aka run on, GPU
GPU_CONFIG
None
n_gpu_layers =
9999
# all
else
n_gpu_layers =
store_output:
result_id =
(uuid4())
print
"🦙 running inference with id:
result_id
command = [
"/llama.cpp/llama-cli"
"--model"
cache_dir
model_entrypoint_file
"--n-gpu-layers"
(n_gpu_layers),
"--prompt"
prompt,
"--n-predict"
(n_predict),
] + args
print
"🦙 running commmand:"
, command,
\n\t
p = subprocess.Popen(
command,
stdout
=subprocess.PIPE,
stderr
=subprocess.PIPE,
text
False
stdout, stderr = collect_output(p)
p.returncode !=
raise
subprocess.CalledProcessError(p.returncode, command, stdout, stderr)
store_output:
# save results to a Modal Volume if requested
print
"🦙 saving results for
result_id
result_dir = Path(results_dir) / result_id
result_dir.mkdir(
parents
True
(result_dir /
"out.txt"
).write_text(stdout)
(result_dir /
"err.txt"
).write_text(stderr)
return
stdout
Copy
Addenda
The remainder of this code is less interesting from the perspective
of running LLM inference on Modal but necessary for the code to run.
For example, it includes the default “Flappy Bird in Python” prompt included in
unsloth’s announcement
of their 1.58 bit quantization of DeepSeek-R1.
DEFAULT_PROMPT =
"""Create a Flappy Bird game in Python. You must include these things:
You must use pygame.
The background color should be randomly chosen and is a light shade. Start with a light blue color.
Pressing SPACE multiple times will accelerate the bird.
The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.
Place on the bottom some land colored as dark brown or yellow chosen randomly.
Make a score shown on the top right side. Increment if you pass pipes and don't hit them.
Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.
When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.
The final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section."""
stream_output
stream
queue
write_stream
"""Reads lines from a stream and writes to a queue and a write stream."""
line
iter
(stream.readline,
line = line.decode(
"utf-8"
errors
"replace"
write_stream.write(line)
write_stream.flush()
queue.put(line)
stream.close()
collect_output
process
"""Collect up the stdout and stderr of a process while still streaming it out."""
import
from
queue
import
Queue
from
threading
import
Thread
stdout_queue = Queue()
stderr_queue = Queue()
stdout_thread = Thread(
target
=stream_output,
args
=(process.stdout, stdout_queue, sys.stdout)
stderr_thread = Thread(
target
=stream_output,
args
=(process.stderr, stderr_queue, sys.stderr)
stdout_thread.start()
stderr_thread.start()
stdout_thread.join()
stderr_thread.join()
process.wait()
stdout_collected =
.join(stdout_queue.queue)
stderr_collected =
.join(stderr_queue.queue)
return
stdout_collected, stderr_collected
Copy
Run large and small language models with llama.cpp (DeepSeek-R1, Phi-4)
What GPU can run DeepSeek-R1? What GPU can run Phi-4?
Calling a Modal Function from the command line
Compiling llama.cpp with CUDA support
Storing models on Modal
Storing model outputs on Modal
Running llama.cpp as a Modal Function
Addenda
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/llm-serving/llama_cpp.py
--n-predict
1024
Copy

=== DOC: 015_examples_esm3.txt ===
URL: https://modal.com/docs/examples/esm3
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Build a protein folding dashboard with ESM3, Molstar, and Gradio
There are perhaps a quadrillion distinct proteins on the planet Earth,
each one a marvel of nanotechnology discovered by painstaking evolution.
We know the amino acid sequence of nearly a billion but we only
know the three-dimensional structure of a few hundred thousand,
gathered by slow, difficult observational methods like X-ray crystallography.
Built upon this data are machine learning models like
EvolutionaryScale’s
ESM3
that can predict the structure of any sequence in seconds.
In this example, we’ll show how you can use Modal to not
just run the latest protein-folding model but also build tools around it for
you and your team of scientists to understand and analyze the results.
Basic Setup
import
base64
import
from
pathlib
import
Path
from
typing
import
Optional
import
modal
MINUTES =
# seconds
app = modal.App(
"example-esm3-dashboard"
Copy
Create a Volume to store ESM3 model weights and Entrez sequence data
To minimize cold start times, we’ll store the ESM3 model weights on a Modal
Volume
For patterns and best practices for storing model weights on Modal, see
this guide
We’ll use this same distributed storage primitive to store sequence data.
volume = modal.Volume.from_name(
"example-esm3-dashboard"
create_if_missing
True
VOLUME_PATH = Path(
"/vol"
MODELS_PATH = VOLUME_PATH /
"models"
DATA_PATH = VOLUME_PATH /
"data"
Copy
Define dependencies in container images
The container image for structure inference is based on Modal’s default slim Debian
Linux image with
for loading and running the model,
gemmi
managing protein structure file conversions, and
hf_transfer
for faster downloading of the model weights from Hugging Face.
esm3_image = (
modal.Image.debian_slim(
python_version
"3.11"
.pip_install(
"esm==3.1.1"
"torch==2.4.1"
"gemmi==0.7.0"
"huggingface_hub[hf_transfer]==0.26.2"
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
"HF_HOME"
(MODELS_PATH)})
Copy
We’ll also define a separate image, with different dependencies,
for the part of our app that hosts the dashboard.
This helps reduce the complexity of Python dependency management
by “walling off” the different parts, e.g. separating
functions that depend on finicky ML packages
from those that depend on pedantic web packages.
Dependencies include
gradio
for building a web UI in Python and
biotite
for extracting sequences from UniProt accession numbers.
You can read more about how to configure container images on Modal in
this guide
web_app_image = (
modal.Image.debian_slim(
python_version
"3.11"
.pip_install(
"gradio~=4.44.0"
"biotite==0.41.2"
"fastapi[standard]==0.115.4"
.add_local_dir(Path(
__file__
).parent /
"frontend"
remote_path
"/assets"
Copy
Here we “pre-import” libraries that will be used by the functions we run
on Modal in a given image using the
with image.imports
context manager.
with
esm3_image.imports():
import
tempfile
import
gemmi
import
torch
from
esm.models.esm3
import
ESM3
from
esm.sdk.api
import
ESMProtein, GenerationConfig
with
web_app_image.imports():
import
biotite.database.entrez
entrez
import
biotite.sequence.io.fasta
fasta
from
fastapi
import
FastAPI
Copy
Define a
Model
inference class for ESM3
Next, we map the model’s setup and inference code onto Modal.
For setup code that only needs to run once, we put it in a method
decorated with
@enter
, which runs on container start. For details,
this guide
The rest of the inference code goes in a method decorated with
@method
We accelerate the compute-intensive inference with a GPU, specifically an A10G.
For more on using GPUs on Modal, see
this guide
@app.cls
image
=esm3_image,
volumes
={VOLUME_PATH: volume},
secrets
=[modal.Secret.from_name(
"huggingface-secret"
"A10G"
timeout
* MINUTES,
class
Model
@modal.enter
enter
self
self
.model = ESM3.from_pretrained(
"esm3_sm_open_v1"
self
.model.to(
"cuda"
print
"using half precision and tensor cores for fast ESM3 inference"
self
.model =
self
.model.half()
torch.backends.cuda.matmul.allow_tf32 =
True
self
.max_steps =
print
"setting max ESM steps to:
{self
.max_steps
convert_protein_to_MMCIF
self
esm_protein
output_path
structure = gemmi.read_pdb_string(esm_protein.to_pdb_string())
doc = structure.make_mmcif_document()
doc.write_file(
(output_path), gemmi.cif.WriteOptions())
get_generation_config
self
num_steps
return
GenerationConfig(
track
"structure"
num_steps
=num_steps)
@modal.method
inference
self
sequence
num_steps =
(sequence),
self
.max_steps)
print
"running ESM3 inference with num_steps=
num_steps
esm_protein =
self
.model.generate(
ESMProtein(
sequence
=sequence),
self
.get_generation_config(num_steps)
print
"checking for errors in output"
hasattr
(esm_protein,
"error_msg"
raise
ValueError
(esm_protein.error_msg)
print
"converting ESMProtein into MMCIF file"
save_path = Path(tempfile.mktemp() +
".mmcif"
self
.convert_protein_to_MMCIF(esm_protein, save_path)
print
"returning MMCIF bytes"
return
io.BytesIO(save_path.read_bytes())
Copy
Serve a dashboard as an
asgi_app
In this section we’ll create a web interface around the ESM3 model
that can help scientists and stakeholders understand and interrogate the results of the model.
You can deploy this UI, along with the backing inference endpoint,
with the following command:
modal
deploy
esm3.py
Copy
Integrating Modal Functions
The integration between our dashboard and our inference backend
is made simple by the Modal SDK:
because the definition of the
Model
class is available in the same Python
context as the defintion of the web UI,
we can instantiate an instance and call its methods with
.remote
The inference runs in a GPU-accelerated container with all of ESM3’s
dependencies, while this code executes in a CPU-only container
with only our web dependencies.
run_esm
sequence
) ->
sequence = sequence.strip()
print
"running ESM"
mmcif_buffer = Model().inference.remote(sequence)
print
"converting mmCIF bytes to base64 for compatibility with HTML"
mmcif_content = mmcif_buffer.read().decode()
mmcif_base64 = base64.b64encode(mmcif_content.encode()).decode()
return
get_molstar_html(mmcif_base64)
Copy
Building a UI in Python with Gradio
We’ll visualize the results using
Mol*
Mol* (pronounced “molstar”) is an open-source toolkit for
visualizing and analyzing large-scale molecular data, including secondary structures
and residue-specific positions of proteins.
Second, we’ll create links to lookup the metadata and structure of known
proteins using the
Universal Protein Resource
database from the UniProt consortium which is supported by the European
Bioinformatics Institute, the National Human Genome Research
Institute, and the Swiss Institute of Bioinformatics. UniProt
is also a hub that links to many other databases, like the RCSB Protein
Data Bank.
To pull sequence data, we’ll use the
Biotite
library to pull
FASTA
files from
UniProt which contain labelled sequences.
You should see the URL for this UI in the output of
modal deploy
or on your
Modal app dashboard
for this app.
@app.function
image
=web_app_image,
volumes
={VOLUME_PATH: volume},
max_containers
# Gradio requires sticky sessions
@modal.concurrent
max_inputs
1000
# Gradio can handle many async inputs
@modal.asgi_app
import
gradio
from
fastapi.responses
import
FileResponse
from
gradio.routes
import
mount_gradio_app
web_app = FastAPI()
# custom styles: an icon, a background, and some CSS
@web_app.get
"/favicon.ico"
include_in_schema
False
async
favicon
return
FileResponse(
"/assets/favicon.svg"
@web_app.get
"/assets/background.svg"
include_in_schema
False
async
background
return
FileResponse(
"/assets/background.svg"
css = Path(
"/assets/index.css"
).read_text()
theme = gr.themes.Default(
primary_hue
"green"
secondary_hue
"emerald"
neutral_hue
"neutral"
title =
"Predict & Visualize Protein Structures"
with
gr.Blocks(
theme
=theme,
=css,
title
=title,
=always_dark())
interface:
gr.Markdown(
title
with
gr.Row():
with
gr.Column():
gr.Markdown(
"## Enter UniProt ID "
uniprot_num_box = gr.Textbox(
label
"Enter UniProt ID or select one on the right"
placeholder
"e.g. P02768, P69905,  etc."
get_sequence_button = gr.Button(
"Retrieve Sequence from UniProt ID"
variant
"primary"
uniprot_link_button = gr.Button(
value
"View protein on UniProt website"
uniprot_link_button.click(
None
inputs
=uniprot_num_box,
=get_js_for_uniprot_link(),
with
gr.Column():
example_uniprots = get_uniprot_examples()
extract_uniprot_num
example_idx
uniprot = example_uniprots[example_idx]
return
uniprot[uniprot.index(
: uniprot.index(
gr.Markdown(
"## Example UniProt Accession Numbers"
with
gr.Row():
half_len =
(example_uniprots) /
with
gr.Column():
i, uniprot
enumerate
(example_uniprots[:half_len]):
btn = gr.Button(uniprot,
variant
"secondary"
btn.click(
lambda
=i: extract_uniprot_num(j),
outputs
=uniprot_num_box,
with
gr.Column():
i, uniprot
enumerate
(example_uniprots[half_len:]):
btn = gr.Button(uniprot,
variant
"secondary"
btn.click(
lambda
=i + half_len: extract_uniprot_num(j),
outputs
=uniprot_num_box,
gr.Markdown(
"## Enter Sequence"
sequence_box = gr.Textbox(
label
"Enter a sequence or retrieve it from a UniProt ID"
placeholder
"e.g. MVTRLE..., PVTTIMHALL..., etc."
get_sequence_button.click(
=get_sequence,
inputs
=[uniprot_num_box],
outputs
=[sequence_box]
run_esm_button = gr.Button(
"Run ESM3 Folding"
variant
"primary"
gr.Markdown(
"## ESM3 Predicted Structure"
molstar_html = gr.HTML()
run_esm_button.click(
=run_esm,
inputs
=sequence_box,
outputs
=molstar_html)
# return a FastAPI app for Modal to serve
return
mount_gradio_app(
=web_app,
blocks
=interface,
path
Copy
Folding from the command line
If you want to quickly run the ESM3 model without the web interface, you can
run it from the command line like this:
modal
esm3
Copy
This will run the same inference code above on Modal. The results are
returned in the
Crystallographic Information File
format, which you can render with the online
Molstar Viewer
@app.local_entrypoint
main
sequence
: Optional[
None
output_dir
: Optional[
None
sequence
None
print
"using sequence for insulin [P01308]"
sequence =
"MRTPMLLALLALATLCLAGRADAKPGDAESGKGAAFVSKQEGSEVVKRLRRYLDHWLGAPAPYPDPLEPKREVCELNPDCDELADHIGFQEAYRRFYGPV"
output_dir
None
output_dir = Path(
"/tmp/esm3"
output_dir.mkdir(
parents
True
exist_ok
True
output_path = output_dir /
"output.mmcif"
print
"starting inference on Modal"
results_buffer = Model().inference.remote(sequence)
print
"writing results to
output_path
output_path.write_bytes(results_buffer.read())
Copy
Addenda
The remainder of this code is boilerplate.
Extracting Sequences from UniProt Accession Numbers
To retrieve sequence information we’ll utilize the
biotite
library which
will allow us to fetch
fasta
sequence files from the
National Center for Biotechnology Information (NCBI) Entrez database
get_sequence
uniprot_num
) ->
DATA_PATH.mkdir(
parents
True
exist_ok
True
uniprot_num = uniprot_num.strip()
fasta_path = DATA_PATH /
uniprot_num
.fasta"
print
"Fetching
fasta_path
from the entrez database"
entrez.fetch_single_file(
uniprot_num, fasta_path,
db_name
"protein"
ret_type
"fasta"
fasta_file = fasta.FastaFile.read(fasta_path)
protein_sequence = fasta.get_sequence(fasta_file)
return
(protein_sequence)
except
Exception
return
"Error:
Copy
Supporting functions for the Gradio app
The following Python code is used to enhance the Gradio app,
mostly by generating some extra HTML & JS and handling styling.
get_js_for_uniprot_link
url =
"https://www.uniprot.org/uniprotkb/"
end =
"/entry#structure"
return
"""(uni_id) =>
if (!uni_id) return; window.open("
" + uni_id + "
get_molstar_html
mmcif_base64
return
<iframe
id="molstar_frame"
style="width: 100%; height: 600px; border: none;"
srcdoc='
<!DOCTYPE html>
<html>
<head>
<script src="https://cdn.jsdelivr.net/npm/@rcsb/rcsb-molstar/build/dist/viewer/rcsb-molstar.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@rcsb/rcsb-molstar/build/dist/viewer/rcsb-molstar.css">
</head>
<body>
<div id="protein-viewer" style="width: 1200px; height: 400px; position: center"></div>
<script>
console.log("Initializing viewer...");
(async function()
// Create plugin instance
const viewer = new rcsbMolstar.Viewer("protein-viewer");
// CIF data in base64
const mmcifData = "
mmcif_base64
// Convert base64 to blob
const blob = new Blob(
[atob(mmcifData)],
type: "text/plain"
// Create object URL
const url = URL.createObjectURL(blob);
// Load structure
await viewer.loadStructureFromUrl(url, "mmcif");
catch (error)
console.error("Error loading structure:", error);
)();
</script>
</body>
</html>
</iframe>"""
get_uniprot_examples
return
"Albumin [P02768]"
"Insulin [P01308]"
"Hemoglobin [P69905]"
"Lysozyme [P61626]"
"BRCA1 [P38398]"
"Immunoglobulin [P01857]"
"Actin [P60709]"
"Ribonuclease [P07998]"
always_dark
return
function refresh() {
const url = new URL(window.location);
if (url.searchParams.get('__theme') !== 'dark') {
url.searchParams.set('__theme', 'dark');
window.location.href = url.href;
Copy
Build a protein folding dashboard with ESM3, Molstar, and Gradio
Basic Setup
Create a Volume to store ESM3 model weights and Entrez sequence data
Define dependencies in container images
Define a Model inference class for ESM3
Serve a dashboard as an asgi_app
Integrating Modal Functions
Building a UI in Python with Gradio
Folding from the command line
Addenda
Extracting Sequences from UniProt Accession Numbers
Supporting functions for the Gradio app
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/protein-folding/esm3.py
Copy

=== DOC: 016_reference_changelog.txt ===
URL: https://modal.com/docs/reference/changelog
Changelog
API Reference
modal.App
modal.Client
modal.CloudBucketMount
modal.Cls
modal.Cron
modal.Dict
modal.Error
modal.FilePatternMatcher
modal.Function
modal.FunctionCall
modal.Image
modal.NetworkFileSystem
modal.Period
modal.Proxy
modal.Queue
modal.Retries
modal.Sandbox
modal.SandboxSnapshot
modal.Secret
modal.Tunnel
modal.Volume
modal.asgi_app
modal.batched
modal.call_graph
modal.concurrent
modal.container_process
modal.current_function_call_id
modal.current_input_id
modal.enable_output
modal.enter
modal.exit
modal.fastapi_endpoint
modal.file_io
modal.forward
modal.gpu
modal.interact
modal.io_streams
modal.is_local
modal.method
modal.parameter
modal.web_endpoint
modal.web_server
modal.wsgi_app
modal.exception
modal.config
CLI Reference
modal app
modal config
modal container
modal deploy
modal dict
modal environment
modal launch
modal nfs
modal profile
modal queue
modal run
modal secret
modal serve
modal setup
modal shell
modal token
modal volume
Changelog
This changelog documents user-facing updates (features, enhancements, fixes, and deprecations) to the
modal
client library.
Latest
1.0.4 (2025-06-13)
When
modal.Cls.with_options
is called multiple times on the same instance, the overrides will now be merged. For example, the following configuration will use an H100 GPU and request 16 CPU cores:
Model.with_options(
"A100"
).with_options(
"H100"
Copy
Added a
--secret
option to
modal shell
for including environment variables defined by named Secret(s) in the shell session:
modal shell --secret huggingface --secret wandb
Copy
Added a
verbose: bool
option to
modal.Sandbox.create()
. When this is set to
True
, execs and file system operations will appear in the Sandbox logs.
Updated
modal.Sandbox.watch()
so that exceptions are now raised in (and can be caught by) the calling task.
1.0.3 (2025-06-05)
Added support for specifying a timezone on
Cron
schedules, which allows you to run a Function at a specific local time regardless of daylight savings:
import
modal
app = modal.App()
@app.function
schedule
=modal.Cron(
"* 6 * * *"
timezone
"America/New_York"
# Use tz database naming conventions
print
"This function will run every day at 6am New York time."
Copy
Added an
h2_ports
parameter to
Sandbox.create
, which exposes encrypted ports using HTTP/2. The following example will create an H2 port on 5002 and a port using HTTPS over HTTP/1.1 on 5003:
sb = modal.Sandbox.create(
=app,
h2_ports
5002
encrypted_ports
5003
Copy
Added
--from-dotenv
--from-json
options to
modal secret create
, which will read from local files to populate Secret contents.
Sandbox.terminate
no longer waits for container shutdown to complete before returning. It still ensures that a terminated container will shutdown imminently. To restore the previous behavior (i.e., to wait until the Sandbox is actually terminated), call
sb.wait(raise_on_termination=False)
after calling
sb.terminate()
Improved performance and stability for
modal volume get
Fixed a rare race condition that could sometimes make
Function.map
and similar calls deadlock.
Fixed an issue where
Function.map()
and similar methods would stall for 55 seconds when passed an empty iterator as input instead of completing immediately.
We now raise an error during App setup when using interactive mode without the
modal.enable_output
context manager. Previously, this would run the App but raise when
modal.interact()
was called.
1.0.2 (2025-05-26)
Fixed an incompatibility with breaking changes in
aiohttp
v3.12.0, which caused issues with Volume and large input uploads. The issues typically manifest as
Local data and remote data checksum mismatch
'_io.BufferedReader' object has no attribute 'getbuffer'
errors.
1.0.1 (2025-05-19)
Added a
--timestamps
flag to
modal app logs
that prepends a timestamp to each log line.
Fixed a bug where objects returned by
Sandbox.list
returncode == 0
running
Sandboxes. Now the return code for running Sandboxes will be
None
Fixed a bug affecting systems where the
sys.platform.node
name includes unicode characters.
1.0.0 (2025-05-16)
With this release, we’re beginning to enforce the deprecations discussed in the
1.0 migration guide
. Going forward, we’ll include breaking changes for outstanding deprecations in
1.Y.0
releases, so we recommend pinning Modal on a minor version (
modal~=1.0.0
) if you have not addressed the existing warnings. While we’ll continue to make improvements to the Modal API, new deprecations will be introduced at a substantially reduced rate, and support windows for older client versions will lengthen.
⚠️ In this release, we’ve made some breaking changes to Modal’s “automounting” behavior.️ If you’ve not already adapted your source code in response to warnings about automounting, Apps built with 1.0+ will have different files included and may not run as expected:
Previously, Modal containers would automatically include the source for local Python packages that were imported by your Modal App. Going forward, it will be necessary to explicitly include such packages in the Image (i.e., with
modal.Image.add_local_python_source
Support for the
automount
configuration (
MODAL_AUTOMOUNT
) has been removed; this environment variable will no longer have any effect.
Modal will continue to automatically include the Python module or package where the Function is defined. This is narrower in scope than the old automounting behavior: it’s limited to at most a single package, and it includes only
files. The limited automounting can also be disabled in cases where your Image definition already includes the package defining the App: set
include_source=False
in the
modal.App
constructor or
@app.function
decorator.
Additionally, we have enforced a number of previously-introduced deprecations:
Removed
modal.Mount
as a public object, along with various
mount=
parameters where Mounts could be passed into the Modal API. Usage can be replaced with
modal.Image
methods, e.g.:
@app.function
image
=image,
mounts
=[modal.Mount.from_local_dir(
"data"
"/root/data"
# This is now an error!
@app.function
image
=image.add_local_dir(
"data"
"/root/data"
# Correct spelling
Copy
Removed the
show_progress
parameter from
modal.App.run
. This parameter has been replaced by the
modal.enable_output
context manager:
with
modal.enable_output(), app.run():
# Will produce verbose Modal output
Copy
Passing flagged options to the
Image.pip_install
package list will now raise an error. Use the
extra_options
parameter to specify options that aren’t exposed through the
Image.pip_install
signature:
image.pip_install(
"flash-attn"
"--no-build-isolation"
# This is now an error!
image.pip_install(
"flash-attn"
extra_options
"--no-build-isolation"
# Correct spelling
Copy
Removed backwards compatibility for using
label=
tag=
keywords in object lookup methods. We standardized these methods to use
name=
as the parameter name, but we recommend using positional arguments:
f = modal.Function.from_name(
"my-app"
# No longer supported! Will raise an error!
f = modal.Function.from_name(
"my-app"
# Preferred spelling
Copy
It’s no longer possible to invoke a generator Function with
Function.spawn
; previously this warned, now it raises an
InvalidError
. Additionally, the
FunctionCall.get_gen
method has been removed, and it’s no longer possible to set
is_generator
when using
FunctionCall.from_id
Removed the
.resolve()
method on Modal objects. This method had not been publicly documented, but where used it can be replaced straightforwardly with
.hydrate()
. Note that explicit hydration should rarely be necessary: in most cases you can rely on lazy hydration semantics (i.e., objects will be hydrated when the first method that requires server metadata is called).
Functions decorated with
@modal.asgi_app
@modal.wsgi_app
are now required to be nullary. Previously, we warned in the case where a function was defined with parameters that all had default arguments.
Referencing the deprecated
modal.Stub
object will now raise an
AttributeError
, whereas previously it was an alias for
modal.App
. This is a simple name change.
0.77
0.77.0 (2025-05-13)
This is the final pre-1.0 release of the Modal client. The next release will be version 1.0. While we do not plan to enforce most major deprecations until later in the 1.0 cycle, there will be some breaking changes introduced in the next release.
0.76
0.76.3 (2025-05-12)
Fixed the behavior of
modal app history --json
when the history contains versions with and without commit information or “tag” metadata. Commit information is now always included (with a
null
placeholder when absent), while tag metadata is included only when there is at least one tagged release (other releases will have a
null
placeholder).
0.76.0 (2025-05-12)
Fixed the behavior of
ignore=
modal.Image
methods, including when
.dockerignore
files are implicitly used in docker-oriented methods. This may result in Image rebuilds with different final inventories:
When using
modal.Image.add_local_dir
, exclusion patterns are now correctly interpreted as relative to the directory being added (e.g.,
*.json
will now ignore all json files in the top-level of the directory).
When using
modal.Image.from_dockerfile
, exclusion patterns are correctly interpreted as relative to the context directory.
As in Docker, leading or trailing path delimiters are stripped from the ignore patterns before being applied.
Breaking change
: When providing a custom function to
ignore=
, file paths passed into the function will now be
relative
, rather than absolute.
0.75
0.75.8 (2025-05-12)
Introduced
modal.Cls.with_concurrency
modal.Cls.with_batching
for runtime configuration of functionality that is exposed through the
@modal.concurrent
@modal.batched
decorators.
model = Model.with_options(
"H100"
).with_concurrency(
max_inputs
Copy
Added a deprecation warning when using
allow_concurrent_inputs
modal.Cls.with_options
Added
buffer_containers
modal.Cls.with_options
Behavior change:
when
modal.Cls.with_options
is called multiple times on the same object, the configurations will be merged rather than using the most recent.
0.75.4 (2025-05-09)
Fixed issue with .spawn_map producing wrong number of arguments
0.75.3 (2025-05-08)
modal.Dict
s (forthcoming on 2025-05-20) use a new durable storage backend with more “cache-like” behavior - items expire after 7 days of inactivity (no reads or writes). Previously created
modal.Dict
s will continue to use the old backend, but support will eventually be dropped.
modal.Dict.put
now supports an
skip_if_exists
flag that can be used to avoid overwriting the value for existing keys:
item_created = my_dict.put("foo", "bar", skip_if_exists=True)
assert item_created
new_item_created = my_dict.put("foo", "baz", skip_if_exists=True)
assert not new_item_created
Copy
Note that this flag only works for
modal.Dict
objects with the new backend (forthcoming on 2025-05-20) and will raise an error otherwise.
0.75.2 (2025-05-08)
Reverts defective changes to the interpretation of
ignore=
patterns and
.dockerignore
files that were introduced in v0.75.0.
0.75.0 (2025-05-08)
Introduced some changes to the handling of
ignore=
patterns in
modal.Image
methods. Due to a defect around the handling of leading path delimiter characters, these changes reverted in 0.75.2 and later reintroduced in 0.76.0.
0.74
0.74.63 (2025-05-08)
Deprecates
Function.web_url
in favor of a new
Function.get_web_url()
method. This also allows the url of a
Function
to be retrieved in an async manner using
Function.get_web_url.aio()
(like all other io-bearing methods in the Modal API)
0.74.61 (2025-05-07)
Adds a deprecation warning when data is passed directly to
modal.Dict.from_name
modal.Dict.ephemeral
. Going forward, it will be necessary to separate
Dict
population from creation.
0.74.60 (2025-05-07)
modal.Dict.update
now also accepts a positional Mapping, like Python’s
dict
type:
d = modal.Dict.from_name(
"some-dict"
d.update({
"a_key"
"another_key"
some_kwarg
True
Copy
0.74.56 (2025-05-06)
Experimental
modal cluster
subcommand is added.
0.74.53 (2025-05-06)
Added functionality for
.spawn_map
on a function instantiated from
Function.from_name
0.74.51 (2025-05-06)
modal
client library can now be installed with Protobuf 6.
0.74.49 (2025-05-06)
Changes the log format of the modal client’s default logger. Instead of
[%(threadName)s]
, the client now logs
[modal-client]
as the log line prefix.
Adds a configuration option (MODAL_LOG_PATTERN) to the modal config for setting the log formatting pattern, in case users want to customize the format. To get the old format, use
MODAL_LOG_PATTERN='[%(threadName)s] %(asctime)s %(message)s'
(or add this to your
.modal.toml
in the
log_pattern
field).
0.74.48 (2025-05-05)
Added a new method for spawning many function calls in parallel:
Function.spawn_map
0.74.46 (2025-05-05)
Introduces a new
.update_autoscaler()
method, which will replace the existing
.keep_warm()
method with the ability to dynamically change the entire autoscaler configuration (
min_containers
max_containers
buffer_containers
, and
scaledown_window
0.74.39 (2025-04-30)
modal
client no longer includes
fastapi
as a library dependency.
0.74.36 (2025-04-29)
A new parameter,
restrict_modal_access
, can be provided on a Function to prevent it from interacting with other resources in your Modal Workspace like Queues, Volumes, or other Functions. This can be useful for running user-provided or LLM-written code in a safe way.
0.74.35 (2025-04-29)
Fixed a bug that prevented doing
modal run
against an entrypoint defined by
Cls.with_options
0.74.32 (2025-04-29)
When setting a custom
name=
@app.function()
, an error is now raised unless
serialized=True
is also set.
0.74.25 (2025-04-25)
App.include
method now returns
self
so it’s possible to build up an App through chained calls:
app = modal.App(
"main-app"
).include(sub_app_1).include(sub_app_2)
Copy
0.74.23 (2025-04-25)
Marked some parameters in a small number of Modal functions as requiring keyword arguments (namely,
modal.App.run
modal.Cls.with_options
, all
.from_name
methods, and a few others). Code that calls these functions with positional arguments will now raise an error. This is expected to be minimally disruptive as the affected parameters are mostly “extra” options or positioned after parameters that have previously been deprecated.
0.74.22 (2025-04-24)
Added a
modal secret delete
command to the CLI.
0.74.21 (2025-04-24)
allow_cross_region_volumes
parameter of the
@app.function
@app.cls
decorators now issues a deprecation warning; the parameter is always treated as
True
on the Modal backend.
0.74.18 (2025-04-23)
Adds a
.deploy()
method to the
object. This method allows you programmatically deploy Apps from Python:
app = modal.App(
"programmatic-deploy"
app.deploy()
Copy
0.74.12 (2025-04-18)
@app.function
@app.cls
decorators now support
experimental_options
, which we’ll use going forward when testing experimental functionality that depends only on server-side configuration.
0.74.7 (2025-04-17)
Modal will now raise an error if local files included in the App are modified during the build process. This behavior can be controlled with the
MODAL_BUILD_VALIDATION
configuration, which accepts
error
(default),
warning
, or
ignore
0.74.6 (2025-04-17)
Internal change that makes containers for functions/classes with
serialized=True
start up
slightly
faster than before
0.74.0 (2025-04-15)
Introduces a deprecation warning when using explicit constructors (
__init__
methods) on
@modal.cls
-decorated classes. Class parameterization should instead be done via
dataclass-style
modal.parameter()
declarations
. Initialization logic should run in
@modal.enter()
-decorated
lifecycle methods
0.73
0.73.173 (2025-04-15)
Fix bug where containers hang with batch sizes above 100 (with
@modal.batched
Fix bug where containers can fail with large outputs and batch sizes above 49 (with
@modal.batched
0.73.170 (2025-04-14)
Fixes a bug where
modal run
didn’t recognize
modal.parameter()
class parameters
0.73.165 (2025-04-11)
Allow running new ephemeral apps from
within
Modal containers using
with app.run(): ...
. Use with care, as putting such a run block in global scope of a module could easily lead to infinite app creation recursion
0.73.160 (2025-04-10)
allow_concurrent_inputs
parameter of
@app.function
@app.cls
is now deprecated in favor of the
@modal.concurrent
decorator. See the
Modal 1.0 Migration Guide
and documentation on
input concurrency
for more information.
0.73.159 (2025-04-10)
Fixes a bug where
serialized=True
classes could not
self.
reference other methods on the class, or use
modal.parameter()
synthetic constructors
0.73.158 (2025-04-10)
Adds support for
bool
type to class parameters using
name: bool = modal.parameter()
. Note that older clients can’t instantiate classes with bool parameters unless those have default values which are not modified. Bool parameters are also not supported by web endpoints at this time.
0.73.148 (2025-04-07)
Fixes a bug introduced in 0.73.147 that broke App builds when using
@modal.batched
on a class method.
0.73.147 (2025-04-07)
Improved handling of cases where
@modal.concurrent
is stacked with other decorators.
0.73.144 (2025-04-04)
Adds a
context_dir
parameter to
modal.Image.from_dockerfile
modal.Image.dockerfile_commands
. This parameter can be used to provide a local reference for relative COPY commands.
0.73.139 (2025-04-02)
Added
modal.experimental.ipython
module, which can be loaded in Jupyter notebooks with
%load_ext modal.experimental.ipython
. Currently it provides the
%modal
line magic for looking up functions:
%modal
from
main/my-app
import
my_function, MyClass
# Now you can use my_function() and Foo in your notebook.
my_function.remote()
Foo().my_method.remote()
Copy
Removed the legacy
modal.extensions.ipython
module from 2022.
0.73.135 (2025-03-29)
Fix shutdown race bug that emitted spurious error-level logs.
0.73.132 (2025-03-28)
Adds the
@modal.concurrent
decorator, which will be replacing the beta
allow_concurrent_inputs=
parameter of
@app.function
@app.cls
for enabling input concurrency. Notably,
@modal.concurrent
introduces a distinction between
max_inputs
target_inputs
, allowing containers to burst over the concurrency level targeted by the Modal autoscaler during periods of high load.
0.73.131 (2025-03-28)
Instantiation of classes using keyword arguments that are not defined as as
modal.parameter()
will now raise an error on the calling side rather than in the receiving container. Note that this only applies if there is at least one modal.parameter() defined on the class, but this will likely apply to parameter-less classes in the future as well.
0.73.121 (2025-03-24)
Adds a new “commit info” column to the
modal app history
command. It shows the short git hash at the time of deployment, with an asterisk
if the repository had uncommitted changes.
0.73.119 (2025-03-21)
Class parameters are no longer automatically cast into their declared type. If the wrong type is provided to a class parameter, method calls to that class instance will now fail with an exception.
0.73.115 (2025-03-19)
Adds support for new strict
bytes
type for
modal.parameter
Usage:
import
typing
import
modal
app = modal.App()
@app.cls
class
bytes
= modal.parameter(
default
"hello"
@modal.method
self
return
"hello
{self
@app.local_entrypoint
main
foo = Foo(
"world"
foo.bar.remote()
Copy
Note
: For parameterized web endoints you must base64 encode the bytes before passing them in as a query parameter.
0.73.107 (2025-03-14)
Include git commit info at the time of app deployment.
0.73.105 (2025-03-14)
Added
Image.cmd()
for setting image default entrypoint args (a.k.a.
0.73.95 (2025-03-12)
Fixes a bug which could cause
Function.map
and sibling methods to stall indefinitely if there was an exception in the input iterator itself (i.e. not the mapper function)
0.73.89 (2025-03-05)
@modal.web_endpoint
decorator is now deprecated. We are replacing it with
@modal.fastapi_endpoint
. This can be a simple name substitution in your code; the two decorators have identical semantics.
0.73.84 (2025-03-04)
keep_warm=
parameter has been removed from the
@modal.method
decorator. This parameter has been nonfunctional since v0.63.0; all autoscaler configuration must be done at the level of the modal Cls.
0.73.82 (2025-03-04)
Adds
modal.fastapi_endpoint
as an alias for
modal.web_endpoint
. We will be deprecating the
modal.web_endpoint
name
(but not the functionality) as part of the Modal 1.0 release.
0.73.81 (2025-03-03)
wait_for_response
parameter of Modal’s web endpoint decorators has been removed (originally deprecated in May 2024).
0.73.78 (2025-03-01)
It is now possible to call
Cls.with_options
on an unhydrated Cls, e.g.
ModelWithGPU = modal.Cls.from_name(
"my-app"
"Model"
).with_options(
"H100"
Copy
0.73.77 (2025-03-01)
Cls.with_options()
now accept unhydated volume and secrets
0.73.76 (2025-02-28)
We’re renaming several
App.function
App.cls
parameters that configure the behavior of Modal’s autoscaler:
concurrency_limit
is now
max_containers
keep_warm
is now
min_containers
container_idle_timeout
is now
scaledown_window
The old names will continue to work, but using them will issue a deprecation warning. The aim of the renaming is to reduce some persistent confusion about what these parameters mean. Code updates should require only a simple substitution of the new name.
We’re adding a new parameter,
buffer_containers
(previously available as
_experimental_buffer_containers
). When your Function is actively handling inputs, the autoscaler will spin up additional
buffer_containers
so that subsequent inputs will not be blocked on cold starts. When the Function is idle, it will still scale down to the value given by
min_containers
0.73.75 (2025-02-28)
Adds a new config field,
ignore_cache
(also accessible via environment variables as
MODAL_IGNORE_CACHE=1
), which will force Images used by the App to rebuild but not clobber any existing cached Images. This can be useful for testing an App’s robustness to Image rebuilds without affecting other Apps that depend on the same base Image layer(s).
0.73.73 (2025-02-28)
Adds a deprecation warning to the
workspace
parameter in
modal.Cls
lookup methods. This argument is unused and will be removed in the future.
0.73.69 (2025-02-25)
We’ve moved the
modal.functions.gather
function to be a staticmethod on
modal.FunctionCall.gather
. The former spelling has been deprecated and will be removed in a future version.
0.73.68 (2025-02-25)
Fixes issue where running
modal shell
with a dot-separated module reference as input would not accept the required
flag for “module mode”, but still emitted a warning telling users to use
0.73.60 (2025-02-20)
Fixes an issue where
modal.runner.deploy_app()
didn’t work when called from within a running (remote) Modal Function
0.73.58 (2025-02-20)
Introduces an
flag to
modal run
modal shell
modal serve
modal deploy
, which indicates that the modal app/function file is specified using python “module syntax” rather than a file path. In the future this will be a required flag when using module syntax.
Old syntax:
modal
my_package/modal_main.py
modal
my_package.modal_main
Copy
New syntax (note the
on the second line):
modal
my_package/modal_main.py
modal
my_package.modal_main
Copy
0.73.54 (2025-02-18)
Passing
App.lookup
an invalid name now raises an error. App names may contain only alphanumeric characters, dashes, periods, and underscores, must be shorter than 64 characters, and cannot conflict with App ID strings.
0.73.51 (2025-02-14)
Fixes a bug where sandboxes returned from
Sandbox.list()
were not snapshottable even if they were created with
_experimental_enable_snapshot
0.73.44 (2025-02-13)
modal.FunctionCall
is now available in the top-level
modal
namespace. We recommend referencing the class this way instead of using the the fully-qualified
modal.functions.FunctionCall
name.
0.73.40 (2025-02-12)
Function.web_url
will now return None (instead of raising an error) when the Function is not a web endpoint
0.73.31 (2025-02-10)
Deprecate the GPU classes (
gpu=A100(...)
etc) in favor of just using strings (
gpu="A100"
etc)
0.73.26 (2025-02-10)
Adds a pending deprecation warning when looking up class methods using
Function.from_name
, e.g.
Function.from_name("some_app", "SomeClass.some_method")
. The recommended way to reference methods of classes is to look up the class instead:
RemoteClass = Cls.from_name("some_app", "SomeClass")
0.73.25 (2025-02-09)
Fixes an issue introduced in
0.73.19
that prevented access to GPUs during image builds
0.73.18 (2025-02-06)
When using a parameterized class (with at least one
modal.parameter()
specified), class instantiation with an incorrect construction signature (wrong arguments or types) will now fail at the
.remote()
calling site instead of container startup for the called class.
0.73.14 (2025-02-04)
Fixed the status message shown in terminal logs for ephemeral Apps to accurately report the number of active containers.
0.73.11 (2025-02-04)
Warns users if the
modal.Image
of a Function/Cls doesn’t include all the globally imported “local” modules (using
.add_local_python_source()
), and the user hasn’t explicitly set an
include_source
value of True/False. This is in preparation for an upcoming deprecation of the current “auto mount” logic.
0.73.10 (2025-02-04)
Modal functions, methods and entrypoints can now accept variable-length arguments to skip Modal’s default CLI parsing. This is useful if you want to use Modal with custom argument parsing via
argparse
HfArgumentParser
. For example, the following function can be invoked with
modal run my_file.py --foo=42 --bar="baz"
import
argparse
@app.function
train
arglist
parser = argparse.ArgumentParser()
parser.add_argument(
"--foo"
type
parser.add_argument(
"--bar"
type
args = parser.parse_args(
args
= arglist)
Copy
0.73.1 (2025-01-30)
modal run
now runs a single local entrypoints/function in the selected module. If exactly one local entrypoint or function exists in the selected module, the user doesn’t have to qualify the runnable
in the modal run command, even if some of the module’s referenced apps have additional local entrypoints or functions. This partially restores “auto-inferred function” functionality that was changed in v0.72.48.
0.73.0 (2025-01-30)
Introduces an
include_source
argument in the
App.function
App.cls
decorators that let users configure which class of python packages are automatically included as source mounts in created modal functions/classes (what we used to call “automount” behavior). This will supersede the MODAL_AUTOMOUNT configuration value which will eventually be deprecated. As a convenience, the
modal.App
constructor will also accept an
include_source
argument which serves as the default for all the app’s functions and classes.
include_source
argument accepts the following values:
True
(default in a future version of Modal) Automatically includes the Python files of the source package of the function’s own home module, but not any other local packages. Roughly equivalent ot
MODAL_AUTOMOUNT=0
in previous versions of Modal.
False
- don’t include
local source. Assumes the function’s home module is importable in the container environment through some other means (typically added to the provided
modal.Image
’s Python environment).
None
(the default) - use current soon-to-be-deprecated automounting behavior, including source of all first party packages that are not installed into site-packages locally.
Minor change to
MODAL_AUTOMOUNT=0
:  When running/deploying using a module path (e.g.
modal run mypak.mymod
all non .pyc files
of the source package (
mypak
in this case) are now included in the function’s container. Previously, only the function’s home
module file + any
__init__.py
files in its package structure were included. Note that this is only for MODAL_AUTOMOUNT=0. To get full control over which source files are included with your functions, you can set
include_source=False
on your function (see above) and manually specify the files to include using the
ignore
argument to
Image.add_local_python_source
0.72
0.72.56 (2025-01-28)
Deprecated
.lookup
methods on Modal objects. Users are encouraged to use
.from_name
instead. In most cases this will be a simple name substitution. See
the 1.0 migration guide
for more information.
0.72.54 (2025-01-28)
Fixes bug introduced in v0.72.48 where
modal run
didn’t work with files having global
Function.from_name()
Function.lookup()
Cls.from_name()
Cls.lookup()
calls.
0.72.48 (2025-01-24)
Fixes a CLI bug where you couldn’t reference functions via a qualified app, e.g.
mymodule::{app_variable}.{function_name}
modal run
modal serve
modal shell
commands get more consistent error messages in cases where the passed app or function reference isn’t resolvable to something that the current command expects.
Removes the deprecated
__getattr__
__setattr__
__getitem__
__setitem__
methods from
modal.App
0.72.39 (2025-01-22)
Introduced a new public method,
.hydrate
, for on-demand hydration of Modal objects. This method replaces the existing semi-public
.resolve
method, which is now deprecated.
0.72.33 (2025-01-20)
The Image returned by
Sandbox.snapshot_filesystem
now has
object_id
and other metadata pre-assigned rather than require loading by subsequent calls to sandboxes or similar to set this data.
0.72.30 (2025-01-18)
Adds a new
oidc_auth_role_arn
field to
CloudBucketMount
for using OIDC authentication to create the mountpoint.
0.72.24 (2025-01-17)
No longer prints a warning if
app.include
re-includes an already included function (warning is still printed if
another
function with the same name is included)
0.72.22 (2025-01-17)
Internal refactor of the
modal.object
module. All entities except
Object
from that module have now been moved to the
modal._object
“private” module.
0.72.17 (2025-01-16)
@modal.build
decorator is now deprecated. For storing large assets (e.g. model weights), we now recommend using a
modal.Volume
over writing data to the
modal.Image
filesystem directly.
0.72.16 (2025-01-16)
Fixes bug introduced in v0.72.9 where
modal run SomeClass.some_method
would incorrectly print a deprecation warning.
0.72.15 (2025-01-15)
Added an
environment_name
parameter to the
App.run
context manager.
0.72.8 (2025-01-10)
Fixes a bug introduced in v0.72.2 when specifying
add_python="3.9"
Image.from_registry
0.72.0 (2025-01-09)
The default behavior
Image.from_dockerfile()
image.dockerfile_commands()
if no parameter is passed to
ignore
will be to automatically detect if there is a valid dockerignore file in the current working directory or next to the dockerfile following the same rules as
dockerignore
does using
docker
commands. Previously no patterns were ignored.
0.71
0.71.13 (2025-01-09)
FilePatternMatcher
has a new constructor
from_file
which allows you to read file matching patterns from a file instead of having to pass them in directly, this can be used for
Image
methods accepting an
ignore
parameter in order to read ignore patterns from files.
0.71.11 (2025-01-08)
Modal Volumes can now be renamed via the CLI (
modal volume rename
) or SDK (
modal.Volume.rename
0.71.7 (2025-01-08)
Adds
Image.from_id
, which returns an
Image
object from an existing image id.
0.71.1 (2025-01-06)
Sandboxes now support fsnotify-like file watching:
from
modal.file_io
import
FileWatchEventType
app = modal.App.lookup(
"file-watch"
create_if_missing
True
sb = modal.Sandbox.create(
=app)
events = sb.watch(
"/foo"
event
events:
event.type == FileWatchEventType.Modify:
print
(event.paths)
Copy
0.70
0.70.1 (2024-12-27)
The sandbox filesystem API now accepts write payloads of sizes up to 1 GiB.
0.69
0.69.0 (2024-12-21)
Image.from_dockerfile()
image.dockerfile_commands()
now auto-infer which files need to be uploaded based on COPY commands in the source if
context_mount
is omitted. The
ignore=
argument to these methods can be used to selectively omit files using a set of glob patterns.
0.68
0.68.53 (2024-12-20)
You can now point
modal launch vscode
at an arbitrary Dockerhub base image:
modal launch vscode --image=nvidia/cuda:12.4.0-devel-ubuntu22.04
0.68.44 (2024-12-19)
You can now run GPU workloads on
Nvidia L40S GPUs
@app.function
"L40S"
my_gpu_fn
Copy
0.68.43 (2024-12-19)
Fixed a bug introduced in v0.68.39 that changed the exception type raise when the target object for
.from_name
.lookup
methods was not found.
0.68.39 (2024-12-18)
Standardized terminology in
.from_name
.lookup
.delete
methods to use
name
consistently where
label
were used interchangeably before. Code that invokes these methods using
label=
as an explicit keyword argument will issue a deprecation warning and will break in a future release.
0.68.29 (2024-12-17)
The internal
deprecation_error
deprecation_warning
utilities have been moved to a private namespace
0.68.28 (2024-12-17)
Sandboxes now support additional filesystem commands
mkdir
, and
app = modal.App.lookup(
"sandbox-fs"
create_if_missing
True
sb = modal.Sandbox.create(
=app)
sb.mkdir(
"/foo"
with
sb.open(
"/foo/bar.txt"
f.write(
"baz"
print
(sb.ls(
"/foo"
Copy
0.68.27 (2024-12-17)
Two previously-introduced deprecations are now enforced and raise an error:
App.spawn_sandbox
method has been removed in favor of
Sandbox.create
Sandbox.create
now requires an
object to be passed
0.68.24 (2024-12-16)
modal run
CLI now has a
--write-result
option. When you pass a filename, Modal will write the return value of the entrypoint function to that location on your local filesystem. The return value of the function must be either
bytes
to use this option; otherwise, an error will be raised. It can be useful for exercising a remote function that returns text, image data, etc.
0.68.21 (2024-12-13)
Adds an
ignore
parameter to our
Image
add_local_dir
copy_local_dir
methods. It is similar to the
condition
method on
Mount
methods but instead operates on a
Path
object. It takes either a list of string patterns to ignore which follows the
dockerignore
syntax implemented in our
FilePatternMatcher
class, or you can pass in a callable which allows for more flexible selection of files.
Usage:
img.add_local_dir(
"./local-dir"
remote_path
"/remote-path"
ignore
=FilePatternMatcher(
"**/*"
"!*.txt"
# ignore everything except files ending with .txt
img.add_local_dir(
...,
ignore
=~FilePatternMatcher(
"**/*.py"
# can be inverted for when inclusion filters are simpler to write
img.add_local_dir(
...,
ignore
"**/*.py"
"!module/*.py"
# ignore all .py files except those in the module directory
img.add_local_dir(
...,
ignore
lambda
: fp.is_relative_to(
"somewhere"
# use a custom callable
Copy
which will add the
./local-dir
directory to the image but ignore all files except
.txt
files
0.68.15 (2024-12-13)
Adds the
requires_proxy_auth
parameter to
web_endpoint
asgi_app
wsgi_app
, and
web_server
decorators. Requests to the app will respond with 407 Proxy Authorization Required if a webhook token is not supplied in the HTTP headers. Protects against DoS attacks that will unnecessarily charge users.
0.68.11 (2024-12-13)
Cls.from_name(...)
now works as a lazy alternative to
Cls.lookup()
that doesn’t perform any IO until a method on the class is used for a .remote() call or similar
0.68.6 (2024-12-12)
Fixed a bug introduced in v0.67.47 that suppressed console output from the
modal deploy
CLI.
0.68.5 (2024-12-12)
We’re removing support for
.spawn()
ing generator functions.
0.68.2 (2024-12-11)
Sandboxes now support a new filesystem API. The
open()
method returns a
FileIO
handle for native file handling in sandboxes.
app = modal.App.lookup(
"sandbox-fs"
create_if_missing
True
sb = modal.Sandbox.create(
=app)
with
sb.open(
"test.txt"
f.write(
"Hello World
f = sb.open(
"test.txt"
"rb"
print
(f.read())
Copy
0.67
0.67.43 (2024-12-11)
modal container exec
modal shell
now work correctly even when a pseudoterminal (PTY) is not present. This means, for example, that you can pipe the output of these commands to a file:
modal shell -c
'uv pip list'
> env.txt
Copy
0.67.39 (2024-12-09)
It is now possible to delete named
NetworkFileSystem
objects via the CLI (
modal nfs delete ...
) or API
(modal.NetworkFileSystem.delete(...)
0.67.38 (2024-12-09)
Sandboxes now support filesystem snapshots. Run
Sandbox.snapshot_filesystem()
to get an Image which can be used to spawn new Sandboxes.
0.67.28 (2024-12-05)
Adds
Image.add_local_python_source
which works similarly to the old and soon-to-be-deprecated
Mount.from_local_python_packages
but for images. One notable difference is that the new
add_local_python_source
only
includes
-files by default
0.67.23 (2024-12-04)
Image build functions that use a
functools.wraps
decorator will now have their global variables included in the cache key. Previously, the cache would use global variables referenced within the wrapper itself. This will force a rebuild for Image layers defined using wrapped functions.
0.67.22 (2024-12-03)
Fixed a bug introduced in v0.67.0 where it was impossible to call
modal.Cls
methods when passing a list of requested GPUs.
0.67.12 (2024-12-02)
Fixed a bug that executes the wrong method when a Modal Cls overrides a
@modal.method
inherited from a parent.
0.67.7 (2024-11-29)
Fixed a bug where pointing
modal run
at a method on a Modal Cls would fail if the method was inherited from a parent.
0.67.0 (2024-11-27)
New minor client version
0.67.x
comes with an internal data model change for how Modal creates functions for Modal classes. There are no breaking or backwards-incompatible changes with this release. All forward lookup scenarios (
.lookup()
of a
0.67
class from a pre
0.67
client) as well as backwards lookup scenarios (
.lookup()
of a pre
0.67
class from a
0.67
client) work, except for a
0.62
client looking up a
0.67
class (this maintains our current restriction of not being able to lookup a
0.63+
class from a
0.62
client).
0.66
0.66.49 (2024-11-26)
modal config set-environment
will now raise if the requested environment does not exist.
0.66.45 (2024-11-26)
modal launch
CLI now accepts a
--detach
flag to run the App in detached mode, such that it will persist after the local client disconnects.
0.66.40 (2024-11-23)
Adds
Image.add_local_file(..., copy=False)
Image.add_local_dir(..., copy=False)
as a unified replacement for the old
Image.copy_local_*()
Mount.add_local_*
methods.
0.66.30 (2024-11-21)
Removed the
aiostream
package from the modal client library dependencies.
0.66.12 (2024-11-19)
Sandbox.exec
now accepts arguments
text
bufsize
for streaming output, which controls text output and line buffering.
0.66.0 (2024-11-15)
Modal no longer supports Python 3.8, which has reached its
official EoL
0.65
0.65.55 (2024-11-13)
Escalates stuck input cancellations to container death. This prevents unresponsive user code from holding up resources.
Input timeouts no longer kill the entire container. Instead, they just cancel the timed-out input, leaving the container and other concurrent inputs running.
0.65.49 (2024-11-12)
Fixed issue in
modal serve
where files used in
Image.copy_*
commands were not watched for changes
0.65.42 (2024-11-07)
Sandbox.exec
can now accept
timeout
workdir
, and
secrets
. See the
Sandbox.create
function for context on how to use these arguments.
0.65.33 (2024-11-06)
Removed the
interactive
parameter from
function
decorators. This parameter has been deprecated since May 2024. Instead of specifying Modal Functions as interactive, use
modal run --interactive
to activate interactive mode.
0.65.30 (2024-11-05)
checkpointing_enabled
option, deprecated in March 2024, has now been removed.
0.65.9 (2024-10-31)
Output from
Sandbox.exec
can now be directed to
/dev/null
stdout
, or stored for consumption. This behavior can be controlled via the new
StreamType
arguments.
0.65.8 (2024-10-31)
Fixed a bug where the
Image.imports
context manager would not correctly propagate ImportError when using a
modal.Cls
0.65.2 (2024-10-30)
Fixed an issue where
modal run
would pause for 10s before exiting if there was a failure during app creation.
0.64
0.64.227 (2024-10-25)
modal container list
CLI command now shows the containers within a specific environment: the active profile’s environment if there is one, otherwise the workspace’s default environment. You can pass
--env
to list containers in other environments.
0.64.223 (2024-10-24)
Fixed
modal serve
not showing progress when reloading apps on file changes since v0.63.79.
0.64.218 (2024-10-23)
Fix a regression introduced in client version 0.64.209, which affects client authentication within a container.
0.64.198 (2024-10-18)
Fixed a bug where
Queue.put
Queue.put_many
would throw
queue.Full
even if
timeout=None
0.64.194 (2024-10-18)
The previously-deprecated
--confirm
flag has been removed from the
modal volume delete
CLI. Use
--yes
to force deletion without a confirmation prompt.
0.64.193 (2024-10-18)
Passing
wait_for_response=False
in Modal webhook decorators is no longer supported. See
the docs
for alternatives.
0.64.187 (2024-10-16)
When writing to a
StreamWriter
that has already had EOF written, a
ValueError
is now raised instead of an
EOFError
0.64.185 (2024-10-15)
Memory snapshotting can now be used with parametrized functions.
0.64.184 (2024-10-15)
StreamWriters now accept strings as input.
0.64.182 (2024-10-15)
Fixed a bug where App rollbacks would not restart a schedule that had been removed in an intervening deployment.
0.64.181 (2024-10-14)
modal shell
CLI command now takes a container ID, allowing you to shell into a running container.
0.64.180 (2024-10-14)
modal shell --cmd
now can be shortened to
modal shell -c
. This means you can use it like
modal shell -c "uname -a"
to quickly run a command within the remote environment.
0.64.168 (2024-10-03)
Image.conda
Image.conda_install
, and
Image.conda_update_from_environment
methods are now fully deprecated. We recommend using
micromamba
(via
Image.micromamba
Image.micromamba_install
) instead, or manually installing and using conda with
Image.run_commands
when strictly necessary.
0.64.153 (2024-09-30)
Breaking Change:
Sandbox.tunnels()
now returns a
Dict
rather than a
List
. This dict is keyed by the container’s port, and it returns a
Tunnel
object, just like
modal.forward
does.
0.64.142 (2024-09-25)
modal.Function
modal.Cls
now support specifying a
list
of GPU configurations, allowing the Function’s container pool to scale across each GPU configuration in preference order.
0.64.139 (2024-09-25)
The deprecated
_experimental_boost
argument is now removed. (Deprecated in late July.)
0.64.123 (2024-09-18)
Sandboxes can now be created without an entrypoint command. If they are created like this, they will stay alive up until their set timeout. This is useful if you want to keep a long-lived sandbox and execute code in it later.
0.64.119 (2024-09-17)
Sandboxes now have a
cidr_allowlist
argument, enabling controlled access to certain IP ranges. When not used (and with
block_network=False
), the sandbox process will have open network access.
0.64.118 (2024-09-17)
Introduce an experimental API to allow users to set the input concurrency for a container locally.
0.64.112 (2024-09-15)
Creating sandboxes without an associated
is deprecated. If you are spawning a
Sandbox
outside a Modal container, you can lookup an
by name to attach to the
Sandbox
app = modal.App.lookup(
'my-app'
create_if_missing
True
modal.Sandbox.create(
'echo'
'hi'
=app)
Copy
0.64.109 (2024-09-13)
App handles can now be looked up by name with
modal.App.lookup(name)
. This can be useful for associating Sandboxes with Apps:
app = modal.App.lookup(
"my-app"
create_if_missing
True
modal.Sandbox.create(
"echo"
"hi"
=app)
Copy
0.64.100 (2024-09-11)
The default timeout for
modal.Image.run_function
has been lowered to 1 hour. Previously it was 24 hours.
0.64.99 (2024-09-11)
Fixes an issue that could cause containers using
enable_memory_snapshot=True
on Python 3.9 and below to shut down prematurely.
0.64.97 (2024-09-11)
Added support for
ASGI lifespan protocol
@app.function
@modal.asgi_app
func
from
fastapi
import
FastAPI, Request
lifespan
wapp
: FastAPI):
print
"Starting"
yield
"foo"
"bar"
print
"Shutting down"
web_app = FastAPI(
lifespan
=lifespan)
@web_app.get
get_state
request
: Request):
return
"message"
"This is the state:
request.state.foo
return
web_app
Copy
which enables support for
gradio>=v4
amongst other libraries using lifespans
0.64.87 (2024-09-05)
Sandboxes now support port tunneling. Ports can be exposed via the
open_ports
argument, and a list of active tunnels can be retrieved via the
.tunnels()
method.
0.64.67 (2024-08-30)
Fixed a regression in
modal launch
to resume displaying output when starting the container.
0.64.48 (2024-08-21)
Introduces new dataclass-style syntax for class parametrization (see updated
docs
@app.cls
class
MyCls
param_a:
= modal.parameter()
MyCls(
param_a
"hello"
# synthesized constructor
Copy
The new syntax enforces types (
for now) on all parameters
When the new syntax is used
, any web endpoints (
web_endpoint
asgi_app
wsgi_app
web_server
) on the app will now also support parametrization through the use of query parameters matching the parameter names, e.g.
https://myfunc.modal.run/?param_a="hello
in the above example.
The old explicit
__init__
constructor syntax is still allowed, but could be deprecated in the future and doesn’t work with web endpoint parametrization
0.64.38 (2024-08-16)
Added a
modal app rollback
CLI command for rolling back an App deployment to a previous version.
0.64.33 (2024-08-16)
Commands in the
modal app
CLI now accept an App name as a positional argument, in addition to an App ID:
modal app history my-app
Copy
Accordingly, the explicit
--name
option has been deprecated. Providing a name that can be confused with an App ID will also now raise an error.
0.64.32 (2024-08-16)
Updated type stubs using generics to allow static type inferrence for functions calls, e.g.
function.remote(...)
0.64.26 (2024-08-15)
ContainerProcess
handles now support
wait()
poll()
, like
Sandbox
objects
0.64.24 (2024-08-14)
Added support for dynamic batching. Functions or class methods decorated with
@modal.batched
will now automatically batch their invocations together, up to a specified
max_batch_size
.  The batch will wait for a maximum of
wait_ms
for more invocations after the first invocation is made. See guide for more details.
@app.function
@modal.batched
max_batch_size
wait_ms
1000
async
batched_multiply
: list[
: list[
]) -> list[
return
[x * y
x, y
(xs, xs)]
@app.cls
class
BatchedClass
@modal.batched
max_batch_size
wait_ms
1000
async
batched_multiply
: list[
: list[
]) -> list[
return
[x * y
x, y
(xs, xs)]
Copy
The batched function is called with individual inputs:
await
batched_multiply.remote.aio(
Copy
0.64.18 (2024-08-12)
Sandboxes now have an
exec()
method that lets you execute a command inside the sandbox container.
exec
returns a
ContainerProcess
handle for input and output streaming.
sandbox = modal.Sandbox.create(
"sleep"
"infinity"
process = sandbox.exec(
"bash"
"-c"
"for i in $(seq 1 10); do echo foo $i; sleep 0.5; done"
line
process.stdout:
print
(line)
Copy
0.64.8 (2024-08-06)
Removed support for the undocumented
modal.apps.list_apps()
function, which was internal and not intended to be part of public API.
0.64.7 (2024-08-05)
Removed client check for CPU core request being at least 0.1, deferring to server-side enforcement.
0.64.2 (2024-08-02)
Volumes can now be mounted to an ad hoc modal shell session:
modal shell --volume my-vol-name
Copy
When the shell starts, the volume will be mounted at
/mnt/my-vol-name
. This may be helpful for shell-based exploration or manipulation of volume contents.
Note that the option can be used multiple times to mount additional models:
modal shell --volume models --volume data
Copy
0.64.0 (2024-07-29)
App deployment events are now atomic, reducing the risk that a failed deploy will leave the App in a bad state.
0.63
0.63.87 (2024-07-24)
_experimental_boost
argument can now be removed. Boost is now enabled on all modal Functions.
0.63.77 (2024-07-18)
Setting
_allow_background_volume_commits
is no longer necessary and has been deprecated. Remove this argument in your decorators.
0.63.36 (2024-07-05)
Image layers defined with a
@modal.build
method will now include the values of any
class variables
that are referenced within the method as part of the layer cache key. That means that the layer will rebuild when the class variables change or are overridden by a subclass.
0.63.22 (2024-07-01)
Fixed an error when running
@modal.build
methods that was introduced in v0.63.19
0.63.20 (2024-07-01)
Fixed bug where
self.method.local()
would re-trigger lifecycle methods in classes
0.63.14 (2024-06-28)
Adds
Cls.lookup()
backwards compatibility with classes created by clients prior to
v0.63
Important
: When updating (to >=v0.63) an app with a Modal
class
that’s accessed using
Cls.lookup()
- make sure to update the client of the app/service
using
Cls.lookup()
first, and
then
update the app containing the class being looked up.
0.63.12 (2024-06-27)
Fixed a bug introduced in 0.63.0 that broke
modal.Cls.with_options
0.63.10 (2024-06-26)
Adds warning about future deprecation of
retries
for generators. Retries are being deprecated as they can lead to nondetermistic generator behavior.
0.63.9 (2024-06-26)
Fixed a bug in
Volume.copy_files()
where some source paths may be ignored if passed as
bytes
Volume.read_file
Volume.read_file_into_fileobj
Volume.remove_file
, and
Volume.copy_files
can no longer take both string or bytes for their paths. They now only accept
0.63.2 (2024-06-25)
Fixes issue with
Cls.lookup
not working (at all) after upgrading to v0.63.0.
Note
: this doesn’t fix the cross-version lookup incompatibility introduced in 0.63.0.
0.63.0 (2024-06-24)
Changes how containers are associated with methods of
@app.cls()
-decorated Modal “classes”.
Previously each
@method
and web endpoint of a class would get its own set of isolated containers and never run in the same container as other sibling methods.
Starting in this version, all
@methods
and web endpoints will be part of the same container pool. Notably, this means all methods will scale up/down together, and options like
keep_warm
concurrency_limit
will affect the total number of containers for all methods in the class combined, rather than individually.
Version incompatibility warning:
Older clients (below 0.63) can’t use classes deployed by new clients (0.63 and above), and vice versa. Apps or standalone clients using
Cls.lookup(...)
to invoke Modal classes need to be upgraded to version
0.63
at the same time as the deployed app that’s being called into.
keep_warm
for classes is now an attribute of the
@app.cls()
decorator rather than individual methods.
0.62
0.62.236 (2024-06-21)
Added support for mounting Volume or CloudBucketMount storage in
Image.run_function
. Note that this is
typically
not necessary, as data downloaded during the Image build can be stored directly in the Image filesystem.
0.62.230 (2024-06-18)
It is now an error to create or lookup Modal objects (
Volume
Dict
Secret
, etc.) with an invalid name. Object names must be shorter than 64 characters and may contain only alphanumeric characters, dashes, periods, and underscores. The name check had inadvertently been removed for a brief time following an internal refactor and then reintroduced as a warning. It is once more a hard error. Please get in touch if this is blocking access to your data.
0.62.224 (2024-06-17)
modal app list
command now reports apps created by
modal app run
modal app serve
as being in an “ephemeral” state rather than a “running” state to reduce confusion with deployed apps that are actively processing inputs.
0.62.223 (2024-06-14)
All modal CLI commands now accept
as a short-form of
--env
0.62.220 (2024-06-12)
Added support for entrypoint and shell for custom containers:
Image.debian_slim().entrypoint([])
can be used interchangeably with
.dockerfile_commands('ENTRYPOINT []')
, and
.shell(["/bin/bash", "-c"])
can be used interchangeably with
.dockerfile_commands('SHELL ["/bin/bash", "-c"]')
0.62.219 (2024-06-12)
Fix an issue with
@web_server
decorator not working on image builder version 2023.12
0.62.208 (2024-06-08)
@web_server
endpoints can now return HTTP headers of up to 64 KiB in length. Previously, they were limited to 8 KiB due to an implementation detail.
0.62.201 (2024-06-04)
modal deploy
now accepts a
--tag
optional parameter that allows you to specify a custom tag for the deployed version, making it easier to identify and manage different deployments of your app.
0.62.199 (2024-06-04)
web_endpoint
s now have the option to include interactive SwaggerUI/redoc docs by setting
docs=True
web_endpoint
s no longer include an OpenAPI JSON spec route by default
0.62.190 (2024-05-29)
modal.Function
now supports requesting ephemeral disk (SSD) via the new
ephemeral_disk
parameter. Intended for use in doing large dataset ingestion and transform.
0.62.186 (2024-05-29)
modal.Volume
background commits are now enabled by default when using
spawn_sandbox
0.62.185 (2024-05-28)
modal app stop
CLI command now accepts a
--name
) option to stop an App by name rather than by ID.
0.62.181 (2024-05-24)
Background committing on
modal.Volume
mounts is now default behavior.
0.62.178 (2024-05-21)
Added a
modal container stop
CLI command that will kill an active container and reassign its current inputs.
0.62.175 (2024-05-17)
modal.CloudBucketMount
now supports writing to Google Cloud Storage buckets.
0.62.174 (2024-05-17)
Using
memory=
to specify the type of
modal.gpu.A100
is deprecated in favor of
size=
. Note that
size
accepts a string type (
"40GB"
"80GB"
) rather than an integer, as this is a request for a specific variant of the A100 GPU.
0.62.173 (2024-05-17)
Added a
version
flag to the
modal.Volume
API and CLI, allow opting in to a new backend implementation.
0.62.172 (2024-05-17)
Fixed a bug where other functions weren’t callable from within an
asgi_app
wsgi_app
constructor function and side effects of
@enter
methods weren’t available in that scope.
0.62.166 (2024-05-14)
Disabling background commits on
modal.Volume
volumes is now deprecated. Background commits will soon become mandatory behavior.
0.62.165 (2024-05-13)
Deprecated
wait_for_response=False
on web endpoints. See
the docs
for alternatives.
0.62.162 (2024-05-13)
A deprecation warning is now raised when using
modal.Stub
, which has been renamed to
modal.App
. Additionally, it is recommended to use
as the variable name rather than
stub
, which matters when using the automatic app discovery feature in the
modal run
CLI command.
0.62.159 (2024-05-10)
Added a
--stream-logs
flag to
modal deploy
that, if True, begins streaming the app logs once deployment is complete.
0.62.156 (2024-05-09)
Added support for looking up a deployed App by its deployment name in
modal app logs
0.62.150 (2024-05-08)
Added validation that App
name
, if provided, is a string.
0.62.149 (2024-05-08)
@app.function
decorator now raises an error when it is used to decorate a class (this was always invalid, but previously produced confusing behavior).
0.62.148 (2024-05-08)
modal app list
output has been improved in several ways:
Persistent storage objects like Volumes or Dicts are no longer included (these objects receive an app ID internally, but this is an implementation detail and subject to future change). You can use the dedicated CLI for each object (e.g.
modal volume list
) instead.
For Apps in a
stopped
state, the output is now limited to those stopped within the past 2 hours.
The number of tasks running for each App is now shown.
0.62.146 (2024-05-07)
Added the
region
parameter to the
modal.App.function
modal.App.cls
decorators. This feature allows the selection of specific regions for function execution. Note that it is available only on some plan types. See our
blog post
for more details.
0.62.144 (2024-05-06)
Added deprecation warnings when using Python 3.8 locally or in a container. Python 3.8 is nearing EOL, and Modal will be dropping support for it soon.
0.62.141 (2024-05-03)
Deprecated the
Image.conda
constructor and the
Image.conda_install
Image.conda_update_from_environment
methods. Conda-based images had a number of tricky issues and were generally slower and heavier than images based on
micromamba
, which offers a similar featureset and can install packages from the same repositories.
Added the
spec_file
parameter to allow
Image.micromamba_install
to install dependencies from a local file. Note that
micromamba
supports conda yaml syntax along with simple text files.
0.62.131 (2024-05-01)
Added a deprecation warning when object names are invalid. This applies to
Dict
NetworkFileSystem
Secret
Queue
, and
Volume
objects. Names must be shorter than 64 characters and may contain only alphanumeric characters, dashes, periods, and underscores. These rules were previously enforced, but the check had inadvertently been dropped in a recent refactor.  Please update the names of your objects and transfer any data to retain access, as invalid names will become an error in a future release.
0.62.130 (2024-05-01)
Added a command-line interface for interacting with
modal.Queue
objects. Run
modal queue --help
in your terminal to see what is available.
0.62.116 (2024-04-26)
Added a command-line interface for interacting with
modal.Dict
objects. Run
modal dict --help
in your terminal to see what is available.
0.62.114 (2024-04-25)
Secret.from_dotenv
now accepts an optional filename keyword argument:
@app.function
secrets
=[modal.Secret.from_dotenv(
filename
".env-dev"
Copy
0.62.110 (2024-04-25)
Passing a glob
argument to the
modal volume get
CLI has been deprecated — instead, simply download the desired directory path, or
for the entire volume.
Volume.listdir()
no longer takes trailing glob arguments. Use
recursive=True
instead.
modal volume get
modal nfs get
performance is improved when downloading a single file. They also now work with multiple files when outputting to stdout.
Fixed a visual bug where
modal volume get
on a single file will incorrectly display the destination path.
0.62.109 (2024-04-24)
Improved feedback for deserialization failures when objects are being transferred between local / remote environments.
0.62.108 (2024-04-24)
Added
Dict.delete
Queue.delete
as API methods for deleting named storage objects:
import
modal
modal.Queue.delete(
"my-job-queue"
Copy
Deprecated invoking
Volume.delete
as an instance method; it should now be invoked as a static method with the name of  the Volume to delete, as with the other methods.
0.62.98 (2024-04-21)
modal.Dict
object now implements a
keys
values
items
API. Note that there are a few differences when compared to standard Python dicts:
The return value is a simple iterator, whereas Python uses a dictionary view object with more features.
The results are unordered.
Additionally, there was no key data stored for items added to a
modal.Dict
prior to this release, so empty strings will be returned for these entries.
0.62.81 (2024-04-18)
We are introducing
modal.App
as a replacement for
modal.Stub
and encouraging the use of “app” terminology over “stub” to reduce confusion between concepts used in the SDK and the Dashboard. Support for
modal.Stub
will be gradually deprecated over the next few months.
0.62.72 (2024-04-16)
Specifying a hard memory limit for a
modal.Function
is now supported. Pass a tuple of
memory=(request, limit)
. Above the
limit
, which is specified in MiB, a Function’s container will be OOM killed.
0.62.70 (2024-04-16)
modal.CloudBucketMount
now supports read-only access to Google Cloud Storage
0.62.69 (2024-04-16)
Iterators passed to
Function.map()
and similar parallel execution primitives are now executed on the main thread, preventing blocking iterators from possibly locking up background Modal API calls, and risking task shutdowns.
0.62.67 (2024-04-15)
The return type of
Volume.listdir()
Volume.iterdir()
NetworkFileSystem.listdir()
, and
NetworkFileSystem.iterdir()
is now a
FileEntry
dataclass from the
modal.volume
module. The fields of this data class are the same as the old protobuf object returned by these methods, so it should be mostly backwards-compatible.
0.62.65 (2024-04-15)
Cloudflare R2 bucket support added to
modal.CloudBucketMount
0.62.55 (2024-04-11)
When Volume reloads fail due to an open file, we now try to identify and report the relevant path. Note that there may be some circumstances in which we are unable to identify the specific file blocking a reload and will report a generic error message in that case.
0.62.53 (2024-04-10)
Values in the
modal.toml
config file that are spelled as
false
"False"
, or
"false"
will now be coerced in Python to
False
, whereas previously only
(as a string) would have the intended effect.
0.62.25 (2024-04-01)
Fixed a recent regression that caused functions using
modal.interact()
to crash.
0.62.15 (2024-03-29)
Queue methods
put_many
get_many
now support an optional
partition
argument (must be specified as a
kwarg
). When specified, users read and write from new partitions of the queue independently.
partition=None
corresponds to the default partition of the queue.
0.62.3 (2024-03-27)
User can now mount S3 buckets using
Requester Pays
. This can be done with
CloudBucketMount(..., requester_pays=True)
0.62.1 (2024-03-27)
Raise an error on
@web_server(startup_timeout=0)
, which is an invalid configuration.
0.62.0 (2024-03-26)
.new()
method has now been deprecated on all Modal objects. It should typically be replaced with
.from_name(...)
in Modal app code, or
.ephemeral()
in scripts that use Modal
Assignment of Modal objects to a
Stub
via subscription (
stub["object"]
) or attribute (
stub.object
) syntax is now deprecated. This syntax was only necessary when using
.new()
0.61
0.61.104 (2024-03-25)
Fixed a bug where images based on
micromamba
could fail to build if requesting Python 3.12 when a different version of Python was being used locally.
0.61.76 (2024-03-19)
Sandbox
LogsReader
is now an asynchronous iterable. It supports the
async for
statement to stream data from the sandbox’s
stdout/stderr
@stub.function
async
my_fn
sandbox = stub.spawn_sandbox(
"bash"
"-c"
"while true; do echo foo; sleep 1; done"
async
message
sandbox.stdout:
print
"Message:
message
Copy
0.61.57 (2024-03-15)
Add the
@web_server
decorator, which exposes a server listening on a container port as a web endpoint.
0.61.56 (2024-03-15)
Allow users to write to the
Sandbox
stdin
with
StreamWriter
@stub.function
my_fn
sandbox = stub.spawn_sandbox(
"bash"
"-c"
"while read line; do echo $line; done"
sandbox.stdin.write(
"foo
sandbox.stdin.write(
"bar
sandbox.stdin.write_eof()
sandbox.stdin.drain()
sandbox.wait()
Copy
0.61.53 (2024-03-15)
Fixed an bug where
Mount
was failing to include symbolic links.
0.61.45 (2024-03-13)
When called from within a container,
modal.experimental.stop_fetching_inputs()
causes it to gracefully exit after the current input has been processed.
0.61.35 (2024-03-12)
@wsgi_app()
decorator now uses a different backend based on
a2wsgi
that streams requests in chunks, rather than buffering the entire request body.
0.61.32 (2024-03-11)
Stubs/apps can now be “composed” from several smaller stubs using
stub.include(...)
. This allows more ergonomic setup of multi-file Modal apps.
0.61.31 (2024-03-08)
Image.extend
method has been deprecated. This is a low-level interface and can be replaced by other
Image
methods that offer more flexibility, such as
Image.from_dockerfile
Image.dockerfile_commands
, or
Image.run_commands
0.61.24 (2024-03-06)
Fixes
modal volume put
to support uploading larger files, beyond 40 GiB.
0.61.22 (2024-03-05)
Modal containers now display a warning message if lingering threads are present at container exit, which prevents runner shutdown.
0.61.17 (2024-03-05)
Bug fix: Stopping an app while a container’s
@exit()
lifecycle methods are being run no longer interrupts the lifecycle methods.
Bug fix: Worker preemptions no longer interrupt a container’s
@exit()
lifecycle method (until 30 seconds later).
Bug fix: Async
@exit()
lifecycle methods are no longer skipped for sync functions.
Bug fix: Stopping a sync function with
allow_concurrent_inputs>1
now actually stops the container. Previously, it would not propagate the signal to worker threads, so they would continue running.
Bug fix: Input-level cancellation no longer skips the
@exit()
lifecycle method.
Improve stability of container entrypoint against race conditions in task cancellation.
0.61.9 (2024-03-05)
Fix issue with pdm where all installed packages would be automounted when using package cache (MOD-2485)
0.61.6 (2024-03-04)
For modal functions/classes with
concurrency_limit < keep_warm
, we’ll raise an exception now. Previously we (silently) respected the
concurrency_limit
parameter.
0.61.1 (2024-03-03)
modal run --interactive
modal run -i
run the app in “interactive mode”. This allows any remote code to connect to the user’s local terminal by calling
modal.interact()
@stub.function
my_fn
modal.interact()
input
print
"Your number is
Copy
This means that you can dynamically start an IPython shell if desired for debugging:
@stub.function
my_fn
modal.interact()
from
IPython
import
embed
embed()
Copy
For convenience, breakpoints automatically call
interact()
@stub.function
my_fn
breakpoint
Copy
0.60
0.60.0 (2024-02-29)
Image.run_function
now allows you to pass args and kwargs to the function. Usage:
my_build_function
name
size
, *,
variant
None
print
"Building
name
size
variant
image = modal.Image.debian_slim().run_function(
my_build_function,
args
"foo"
kwargs
"variant"
"bar"
Copy
0.59
0.59.0 (2024-02-28)
Mounted packages are now deduplicated across functions in the same stub
Mounting of local Python packages are now marked as such in the mount creation output, e.g.
PythonPackage:my_package
Automatic mounting now includes packages outside of the function file’s own directory. Mounted packages are mounted in /root/
0.58
0.58.92 (2024-02-27)
Most errors raised through usage of the CLI will now print a simple error message rather than showing a traceback from inside the
modal
library.
Tracebacks originating from user code will include fewer frames from within
modal
itself.
The new
MODAL_TRACEBACK
environment variable (and
traceback
field in the Modal config file) can override these behaviors so that full tracebacks are always shown.
0.58.90 (2024-02-27)
Fixed a bug that could cause
-based functions to to ignore timeout signals.
0.58.88 (2024-02-26)
volume get
performance is improved for large (> 100MB) files
0.58.79 (2024-02-23)
Support for function parameters in methods decorated with
@exit
has been deprecated. Previously, exit methods were required to accept three arguments containing exception information (akin to
__exit__
in the context manager protocol). However, due to a bug, these arguments were always null. Going forward,
@exit
methods are expected to have no parameters.
0.58.75 (2024-02-23)
Function calls can now be cancelled without killing the container running the inputs. This allows new inputs by different function calls to the same function to be picked up immediately without having to cold-start new containers after cancelling calls.
0.57
0.57.62 (2024-02-21)
InvalidError
is now raised when a lifecycle decorator (
@build
@enter
, or
@exit
) is used in conjunction with
@method
. Previously, this was undefined and could produce confusing failures.
0.57.61 (2024-02-21)
Reduced the amount of context for frames in modal’s CLI framework when showing a traceback.
0.57.60 (2024-02-21)
The “dunder method” approach for class lifecycle management (
__build__
__enter__
__exit__
, etc.) is now deprecated in favor of the modal
@build
@enter
, and
@exit
decorators.
0.57.52 (2024-02-17)
modal token new
modal token set
, the
--no-no-verify
flag has been removed in favor of a
--verify
flag. This remains the default behavior.
0.57.51 (2024-02-17)
Fixes a regression from 0.57.40 where
@enter
methods used a separate event loop.
0.57.42 (2024-02-14)
Adds a new environment variable/config setting,
MODAL_FORCE_BUILD
force_build
, that coerces all images to be built from scratch, rather than loaded from cache.
0.57.40 (2024-02-13)
@enter()
lifecycle method can now be used to run additional setup code prior to function checkpointing (when the class is decorated with
stub.cls(enable_checkpointing=True)
. Note that there are currently some limitations on function checkpointing:
Checkpointing only works for CPU memory; any GPUs attached to the function will not available
Networking is disabled while the checkpoint is being created
Please note that function checkpointing is still a beta feature.
0.57.31 (2024-02-12)
Fixed an issue with displaying deprecation warnings on Windows systems.
0.57.22 (2024-02-09)
Modal client deprecation warnings are now highlighted in the CLI
0.57.16 (2024-02-07)
Fixes a regression in container scheduling. Users on affected versions (
0.57.5
0.57.15
) are encouraged to upgrade immediately.
0.57.15 (2024-02-07)
The legacy
image_python_version
config option has been removed. Use the
python_version=
parameter on your image definition instead.
0.57.13 (2024-02-07)
Adds support for mounting an S3 bucket as a volume.
0.57.9 (2024-02-07)
Support for an implicit ‘default’ profile is now deprecated. If you have more than one profile in your Modal config file, one must be explicitly set to
active
(use
modal profile activate
or edit your
.modal.toml
file to resolve).
An error is now raised when more than one profile is set to
active
0.57.2 (2024-02-06)
Improve error message when generator functions are called with
.map(...)
0.57.0 (2024-02-06)
Greatly improved streaming performance of generators and WebSocket web endpoints.
Breaking change:
You cannot use
.map()
to call a generator function. (In previous versions, this merged the results onto a single stream, but the behavior was undocumented and not widely used.)
Incompatibility:
Generator outputs are now on a different internal system. Modal code on client versions before 0.57 cannot trigger
deployed functions
with
.remote_gen()
that are on client version 0.57, and vice versa.
0.56
Note that in version 0.56 and prior, Modal used a different numbering system for patch releases.
0.56.4964 (2024-02-05)
When using
modal token new
model token set
, the profile containing the new token will now be activated by default. Use the
--no-activate
switch to update the
modal.toml
file without activating the corresponding profile.
0.56.4953 (2024-02-05)
modal profile list
output now indicates when the workspace is determined by a token stored in environment variables.
0.56.4952 (2024-02-05)
Variadic parameters (e.g. *args and **kwargs) can now be used in scheduled functions as long as the function doesn’t have any other parameters without a default value
0.56.4903 (2024-02-01)
modal container exec
--no-tty
flag has been renamed to
--no-pty
0.56.4902 (2024-02-01)
The singular form of the
secret
parameter in
Stub.function
Stub.cls
, and
Image.run_function
has been deprecated. Please update your code to use the plural form instead:
secrets=[Secret(...)]
0.56.4885 (2024-02-01)
modal profile list
, the user’s GitHub username is now shown as the name for the “Personal” workspace.
0.56.4874 (2024-01-31)
modal token new
modal token set
commands now create profiles that are more closely associated with workspaces, and they have more explicit profile activation behavior:
By default, these commands will create/update a profile named after the workspace that the token points to, rather than a profile named “default”
Both commands now have an
--activate
flag that will activate the profile associated with the new token
If no other profiles exist at the time of creation, the new profile will have its
active
metadata set to True
With these changes, we are moving away from the concept of a “default” profile. Implicit usage of the “default” profile will be deprecated in a future update.
0.56.4849 (2024-01-29)
Adds tty support to
modal container exec
for fully-interactive commands. Example:
modal container exec [container-id] /bin/bash
0.56.4792 (2024-01-26)
modal profile list
command now shows the workspace associated with each profile.
0.56.4715 (2024-01-24)
Mount.from_local_python_packages
now places mounted packages at
/root
in the Modal runtime by default (used to be
/pkg
). To override this behavior, the function now takes a
remote_dir: Union[str, PurePosixPath]
argument.
0.56.4707 (2024-01-23)
The Modal client library is now compatible with Python 3.12, although there are a few limitations:
Images that use Python 3.12 without explicitly specifing it through
python_version
add_python
will not build
properly unless the modal client is also running on Python 3.12.
conda
microconda
base images currently do not support Python 3.12 because an upstream dependency is not yet compatible.
0.56.4700 (2024-01-22)
gpu.A100
class now supports specifying GiB memory configuration using a
size: str
parameter. The
memory: int
parameter is deprecated.
0.56.4693 (2024-01-22)
You can now execute commands in running containers with
modal container exec [container-id] [command]
0.56.4691 (2024-01-22)
modal
cli now works more like the
python
cli in regard to script/module loading:
Running
modal my_dir/my_script.py
now puts
my_dir
on the PYTHONPATH.
modal my_package.my_module
will now mount to /root/my_package/my_module.py in your Modal container, regardless if using automounting or not (and any intermediary
__init__.py
files will also be mounted)
0.56.4687 (2024-01-20)
Modal now uses the current profile if
MODAL_PROFILE
is set to the empty string.
0.56.4649 (2024-01-17)
Dropped support for building Python 3.7 based
modal.Image
s. Python 3.7 is end-of-life since late June 2023.
0.56.4620 (2024-01-16)
modal.Stub.function now takes a
block_network
argument.
0.56.4616 (2024-01-16)
modal.Stub now takes a
volumes
argument for setting the default volumes of all the stub’s functions, similarly to the
mounts
secrets
argument.
0.56.4590 (2024-01-13)
modal serve
: Setting MODAL_LOGLEVEL=DEBUG now displays which files cause an app reload during serve
0.56.4570 (2024-01-12)
modal run
cli command now properly propagates
--env
values to object lookups in global scope of user code
Changelog
Latest
1.0.4 (2025-06-13)
1.0.3 (2025-06-05)
1.0.2 (2025-05-26)
1.0.1 (2025-05-19)
1.0.0 (2025-05-16)
0.77
0.77.0 (2025-05-13)
0.76
0.76.3 (2025-05-12)
0.76.0 (2025-05-12)
0.75
0.75.8 (2025-05-12)
0.75.4 (2025-05-09)
0.75.3 (2025-05-08)
0.75.2 (2025-05-08)
0.75.0 (2025-05-08)
0.74
0.74.63 (2025-05-08)
0.74.61 (2025-05-07)
0.74.60 (2025-05-07)
0.74.56 (2025-05-06)
0.74.53 (2025-05-06)
0.74.51 (2025-05-06)
0.74.49 (2025-05-06)
0.74.48 (2025-05-05)
0.74.46 (2025-05-05)
0.74.39 (2025-04-30)
0.74.36 (2025-04-29)
0.74.35 (2025-04-29)
0.74.32 (2025-04-29)
0.74.25 (2025-04-25)
0.74.23 (2025-04-25)
0.74.22 (2025-04-24)
0.74.21 (2025-04-24)
0.74.18 (2025-04-23)
0.74.12 (2025-04-18)
0.74.7 (2025-04-17)
0.74.6 (2025-04-17)
0.74.0 (2025-04-15)
0.73
0.73.173 (2025-04-15)
0.73.170 (2025-04-14)
0.73.165 (2025-04-11)
0.73.160 (2025-04-10)
0.73.159 (2025-04-10)
0.73.158 (2025-04-10)
0.73.148 (2025-04-07)
0.73.147 (2025-04-07)
0.73.144 (2025-04-04)
0.73.139 (2025-04-02)
0.73.135 (2025-03-29)
0.73.132 (2025-03-28)
0.73.131 (2025-03-28)
0.73.121 (2025-03-24)
0.73.119 (2025-03-21)
0.73.115 (2025-03-19)
0.73.107 (2025-03-14)
0.73.105 (2025-03-14)
0.73.95 (2025-03-12)
0.73.89 (2025-03-05)
0.73.84 (2025-03-04)
0.73.82 (2025-03-04)
0.73.81 (2025-03-03)
0.73.78 (2025-03-01)
0.73.77 (2025-03-01)
0.73.76 (2025-02-28)
0.73.75 (2025-02-28)
0.73.73 (2025-02-28)
0.73.69 (2025-02-25)
0.73.68 (2025-02-25)
0.73.60 (2025-02-20)
0.73.58 (2025-02-20)
0.73.54 (2025-02-18)
0.73.51 (2025-02-14)
0.73.44 (2025-02-13)
0.73.40 (2025-02-12)
0.73.31 (2025-02-10)
0.73.26 (2025-02-10)
0.73.25 (2025-02-09)
0.73.18 (2025-02-06)
0.73.14 (2025-02-04)
0.73.11 (2025-02-04)
0.73.10 (2025-02-04)
0.73.1 (2025-01-30)
0.73.0 (2025-01-30)
0.72
0.72.56 (2025-01-28)
0.72.54 (2025-01-28)
0.72.48 (2025-01-24)
0.72.39 (2025-01-22)
0.72.33 (2025-01-20)
0.72.30 (2025-01-18)
0.72.24 (2025-01-17)
0.72.22 (2025-01-17)
0.72.17 (2025-01-16)
0.72.16 (2025-01-16)
0.72.15 (2025-01-15)
0.72.8 (2025-01-10)
0.72.0 (2025-01-09)
0.71
0.71.13 (2025-01-09)
0.71.11 (2025-01-08)
0.71.7 (2025-01-08)
0.71.1 (2025-01-06)
0.70
0.70.1 (2024-12-27)
0.69
0.69.0 (2024-12-21)
0.68
0.68.53 (2024-12-20)
0.68.44 (2024-12-19)
0.68.43 (2024-12-19)
0.68.39 (2024-12-18)
0.68.29 (2024-12-17)
0.68.28 (2024-12-17)
0.68.27 (2024-12-17)
0.68.24 (2024-12-16)
0.68.21 (2024-12-13)
0.68.15 (2024-12-13)
0.68.11 (2024-12-13)
0.68.6 (2024-12-12)
0.68.5 (2024-12-12)
0.68.2 (2024-12-11)
0.67
0.67.43 (2024-12-11)
0.67.39 (2024-12-09)
0.67.38 (2024-12-09)
0.67.28 (2024-12-05)
0.67.23 (2024-12-04)
0.67.22 (2024-12-03)
0.67.12 (2024-12-02)
0.67.7 (2024-11-29)
0.67.0 (2024-11-27)
0.66
0.66.49 (2024-11-26)
0.66.45 (2024-11-26)
0.66.40 (2024-11-23)
0.66.30 (2024-11-21)
0.66.12 (2024-11-19)
0.66.0 (2024-11-15)
0.65
0.65.55 (2024-11-13)
0.65.49 (2024-11-12)
0.65.42 (2024-11-07)
0.65.33 (2024-11-06)
0.65.30 (2024-11-05)
0.65.9 (2024-10-31)
0.65.8 (2024-10-31)
0.65.2 (2024-10-30)
0.64
0.64.227 (2024-10-25)
0.64.223 (2024-10-24)
0.64.218 (2024-10-23)
0.64.198 (2024-10-18)
0.64.194 (2024-10-18)
0.64.193 (2024-10-18)
0.64.187 (2024-10-16)
0.64.185 (2024-10-15)
0.64.184 (2024-10-15)
0.64.182 (2024-10-15)
0.64.181 (2024-10-14)
0.64.180 (2024-10-14)
0.64.168 (2024-10-03)
0.64.153 (2024-09-30)
0.64.142 (2024-09-25)
0.64.139 (2024-09-25)
0.64.123 (2024-09-18)
0.64.119 (2024-09-17)
0.64.118 (2024-09-17)
0.64.112 (2024-09-15)
0.64.109 (2024-09-13)
0.64.100 (2024-09-11)
0.64.99 (2024-09-11)
0.64.97 (2024-09-11)
0.64.87 (2024-09-05)
0.64.67 (2024-08-30)
0.64.48 (2024-08-21)
0.64.38 (2024-08-16)
0.64.33 (2024-08-16)
0.64.32 (2024-08-16)
0.64.26 (2024-08-15)
0.64.24 (2024-08-14)
0.64.18 (2024-08-12)
0.64.8 (2024-08-06)
0.64.7 (2024-08-05)
0.64.2 (2024-08-02)
0.64.0 (2024-07-29)
0.63
0.63.87 (2024-07-24)
0.63.77 (2024-07-18)
0.63.36 (2024-07-05)
0.63.22 (2024-07-01)
0.63.20 (2024-07-01)
0.63.14 (2024-06-28)
0.63.12 (2024-06-27)
0.63.10 (2024-06-26)
0.63.9 (2024-06-26)
0.63.2 (2024-06-25)
0.63.0 (2024-06-24)
0.62
0.62.236 (2024-06-21)
0.62.230 (2024-06-18)
0.62.224 (2024-06-17)
0.62.223 (2024-06-14)
0.62.220 (2024-06-12)
0.62.219 (2024-06-12)
0.62.208 (2024-06-08)
0.62.201 (2024-06-04)
0.62.199 (2024-06-04)
0.62.190 (2024-05-29)
0.62.186 (2024-05-29)
0.62.185 (2024-05-28)
0.62.181 (2024-05-24)
0.62.178 (2024-05-21)
0.62.175 (2024-05-17)
0.62.174 (2024-05-17)
0.62.173 (2024-05-17)
0.62.172 (2024-05-17)
0.62.166 (2024-05-14)
0.62.165 (2024-05-13)
0.62.162 (2024-05-13)
0.62.159 (2024-05-10)
0.62.156 (2024-05-09)
0.62.150 (2024-05-08)
0.62.149 (2024-05-08)
0.62.148 (2024-05-08)
0.62.146 (2024-05-07)
0.62.144 (2024-05-06)
0.62.141 (2024-05-03)
0.62.131 (2024-05-01)
0.62.130 (2024-05-01)
0.62.116 (2024-04-26)
0.62.114 (2024-04-25)
0.62.110 (2024-04-25)
0.62.109 (2024-04-24)
0.62.108 (2024-04-24)
0.62.98 (2024-04-21)
0.62.81 (2024-04-18)
0.62.72 (2024-04-16)
0.62.70 (2024-04-16)
0.62.69 (2024-04-16)
0.62.67 (2024-04-15)
0.62.65 (2024-04-15)
0.62.55 (2024-04-11)
0.62.53 (2024-04-10)
0.62.25 (2024-04-01)
0.62.15 (2024-03-29)
0.62.3 (2024-03-27)
0.62.1 (2024-03-27)
0.62.0 (2024-03-26)
0.61
0.61.104 (2024-03-25)
0.61.76 (2024-03-19)
0.61.57 (2024-03-15)
0.61.56 (2024-03-15)
0.61.53 (2024-03-15)
0.61.45 (2024-03-13)
0.61.35 (2024-03-12)
0.61.32 (2024-03-11)
0.61.31 (2024-03-08)
0.61.24 (2024-03-06)
0.61.22 (2024-03-05)
0.61.17 (2024-03-05)
0.61.9 (2024-03-05)
0.61.6 (2024-03-04)
0.61.1 (2024-03-03)
0.60
0.60.0 (2024-02-29)
0.59
0.59.0 (2024-02-28)
0.58
0.58.92 (2024-02-27)
0.58.90 (2024-02-27)
0.58.88 (2024-02-26)
0.58.79 (2024-02-23)
0.58.75 (2024-02-23)
0.57
0.57.62 (2024-02-21)
0.57.61 (2024-02-21)
0.57.60 (2024-02-21)
0.57.52 (2024-02-17)
0.57.51 (2024-02-17)
0.57.42 (2024-02-14)
0.57.40 (2024-02-13)
0.57.31 (2024-02-12)
0.57.22 (2024-02-09)
0.57.16 (2024-02-07)
0.57.15 (2024-02-07)
0.57.13 (2024-02-07)
0.57.9 (2024-02-07)
0.57.2 (2024-02-06)
0.57.0 (2024-02-06)
0.56
0.56.4964 (2024-02-05)
0.56.4953 (2024-02-05)
0.56.4952 (2024-02-05)
0.56.4903 (2024-02-01)
0.56.4902 (2024-02-01)
0.56.4885 (2024-02-01)
0.56.4874 (2024-01-31)
0.56.4849 (2024-01-29)
0.56.4792 (2024-01-26)
0.56.4715 (2024-01-24)
0.56.4707 (2024-01-23)
0.56.4700 (2024-01-22)
0.56.4693 (2024-01-22)
0.56.4691 (2024-01-22)
0.56.4687 (2024-01-20)
0.56.4649 (2024-01-17)
0.56.4620 (2024-01-16)
0.56.4616 (2024-01-16)
0.56.4590 (2024-01-13)
0.56.4570 (2024-01-12)

=== DOC: 017_guide_webhooks.txt ===
URL: https://modal.com/docs/guide/webhooks
Introduction
Custom container images
Defining Images
Private registries
Fast pull from registry
GPUs and other resources
GPU acceleration
Using CUDA on Modal
Reserving CPU and memory
Scaling out
Scaling out
Input concurrency
Batch processing
Job queues
Dynamic batching (beta)
Dicts and queues
Scheduling and cron jobs
Deployment
Apps, Functions, and entrypoints
Managing deployments
Invoking deployed functions
Continuous deployment
Running untrusted code in Functions
Secrets and environment variables
Secrets
Environment variables
Web endpoints
Web endpoints
Streaming endpoints
Web endpoint URLs
Request timeouts
Webhook tokens (beta)
Networking
Tunnels (beta)
Proxies (beta)
Cluster networking
Data sharing and storage
Passing local data
Volumes
Storing model weights
Dataset ingestion
Cloud bucket mounts
Sandboxes
Sandboxes
Running commands
Networking and security
File access
Snapshots
Performance
Cold start performance
Memory Snapshot (beta)
Geographic latency
Reliability and robustness
Failures and retries
Preemption
Timeouts
Troubleshooting
Security and privacy
Integrations
Using OIDC to authenticate with external services
Connecting Modal to your Datadog account
Connecting Modal to your OpenTelemetry provider
Okta SSO
Slack notifications (beta)
Workspace & account settings
Workspaces
Environments
Modal user account setup
Service users
Other topics
Modal 1.0 migration guide
File and project structure
Developing and debugging
Jupyter notebooks
Asynchronous API usage
Global variables
Region selection
Container lifecycle hooks
Parametrized functions
S3 Gateway endpoints
GPU Metrics
Web endpoints
This guide explains how to set up web endpoints with Modal.
All deployed Modal Functions can be
invoked from any other Python application
using the Modal client library. We additionally provide multiple ways to expose
your Functions over the web for non-Python clients.
You can
turn any Python function into a web endpoint
with a single line
of code, you can
serve a full app
using
frameworks like FastAPI, Django, or Flask, or you can
serve anything that speaks HTTP and listens on a port
Below we walk through each method, assuming you’re familiar with web applications outside of Modal.
For a detailed walkthrough of basic web endpoints on Modal aimed at developers new to web applications,
this tutorial
Simple endpoints
The easiest way to create a web endpoint from an existing Python function is to use the
@modal.fastapi_endpoint
decorator
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
@app.function
image
=image)
@modal.fastapi_endpoint
return
"Hello world!"
Copy
This decorator wraps the Modal Function in a
FastAPI application
Note: Prior to v0.73.82, this function was named
@modal.web_endpoint
Developing with
modal serve
You can run this code as an ephemeral app, by running the command
modal
serve
server_script.py
Copy
Where
server_script.py
is the file name of your code. This will create an
ephemeral app for the duration of your script (until you hit Ctrl-C to stop it).
It creates a temporary URL that you can use like any other REST endpoint. This
URL is on the public internet.
modal serve
command will live-update an app when any of its supporting
files change.
Live updating is particularly useful when working with apps containing web
endpoints, as any changes made to web endpoint handlers will show up almost
immediately, without requiring a manual restart of the app.
Deploying with
modal deploy
You can also deploy your app and create a persistent web endpoint in the cloud
by running
modal deploy
--:--
--:--
Keyboard shortcuts (?)
Fullscreen (f)
Passing arguments to an endpoint
When using
@modal.fastapi_endpoint
, you can add
query parameters
which
will be passed to your Function as arguments. For instance
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
@app.function
image
=image)
@modal.fastapi_endpoint
square
return
"square"
: x**
Copy
If you hit this with a URL-encoded query string with the
parameter present,
the Function will receive the value as an argument:
$ curl https://modal-labs--web-endpoint-square-dev.modal.run?x=42
{"square":1764}
Copy
If you want to use a
POST
request, you can use the
method
argument to
@modal.fastapi_endpoint
to set the HTTP verb. To accept any valid JSON object,
dict
as your type annotation
and FastAPI will handle the rest.
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
@app.function
image
=image)
@modal.fastapi_endpoint
method
"POST"
square
item
dict
return
"square"
: item[
Copy
This now creates an endpoint that takes a JSON body:
$ curl -X POST -H 'Content-Type: application/json' --data-binary '{"x": 42}' https://modal-labs--web-endpoint-square-dev.modal.run
{"square":1764}
Copy
This is often the easiest way to get started, but note that FastAPI recommends
that you use
typed Pydantic models
in order to
get automatic validation and documentation. FastAPI also lets you pass data to
web endpoints in other ways, for instance as
form data
file uploads
How do web endpoints run in the cloud?
Note that web endpoints, like everything else on Modal, only run when they need
to. When you hit the web endpoint the first time, it will boot up the container,
which might take a few seconds. Modal keeps the container alive for a short
period in case there are subsequent requests. If there are a lot of requests,
Modal might create more containers running in parallel.
For the shortcut
@modal.fastapi_endpoint
decorator, Modal wraps your function in a
FastAPI
application. This means that the
Image
your Function uses must have FastAPI installed, and the Functions that you write
need to follow its request and response
semantics
. Web endpoint Functions can use
all of FastAPI’s powerful features, such as Pydantic models for automatic validation,
typed query and path parameters, and response types.
Here’s everything together, combining Modal’s abilities to run functions in
user-defined containers with the expressivity of FastAPI:
import
modal
from
fastapi.responses
import
HTMLResponse
from
pydantic
import
BaseModel
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
"boto3"
app = modal.App(
image
=image)
class
Item
BaseModel
name:
qty:
@app.function
@modal.fastapi_endpoint
method
"POST"
item
: Item):
import
boto3
# do things with boto3...
return
HTMLResponse(
"<html>Hello,
item.name
!</html>"
Copy
This endpoint definition would be called like so:
curl
'{"name": "Erik", "qty": 10}'
"Content-Type: application/json"
POST
https://ecorp--web-demo-f-dev.modal.run
Copy
Or in Python with the
requests
library:
import
requests
data = {
"name"
"Erik"
"qty"
requests.post(
"https://ecorp--web-demo-f-dev.modal.run"
json
=data,
timeout
10.0
Copy
Serving ASGI and WSGI apps
You can also serve any app written in an
ASGI
WSGI
-compatible
web framework on Modal.
ASGI provides support for async web frameworks. WSGI provides support for
synchronous web frameworks.
ASGI apps - FastAPI, FastHTML, Starlette
For ASGI apps, you can create a function decorated with
@modal.asgi_app
that returns a reference to
your web app:
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
@app.function
image
=image)
@modal.concurrent
max_inputs
@modal.asgi_app
fastapi_app
from
fastapi
import
FastAPI, Request
web_app = FastAPI()
@web_app.post
"/echo"
async
echo
request
: Request):
body =
await
request.json()
return
body
return
web_app
Copy
Now, as before, when you deploy this script as a Modal App, you get a URL for
your app that you can hit:
--:--
--:--
Keyboard shortcuts (?)
Fullscreen (f)
@modal.concurrent
decorator enables a single container
to process multiple inputs at once, taking advantage of the asynchronous
event loops in ASGI applications. See
this guide
for details.
ASGI Lifespan
While we recommend using
@modal.enter
for defining container lifecycle hooks, we also support the
ASGI lifespan protocol
. Lifespans begin when containers start, typically at the time of the first request. Here’s an example using
FastAPI
import
modal
app = modal.App(
"fastapi-lifespan-app"
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
@app.function
image
=image)
@modal.asgi_app
fastapi_app_with_lifespan
from
fastapi
import
FastAPI, Request
lifespan
wapp
: FastAPI):
print
"Starting"
yield
print
"Shutting down"
web_app = FastAPI(
lifespan
=lifespan)
@web_app.get
async
hello
request
: Request):
return
"hello"
return
web_app
Copy
WSGI apps - Django, Flask
You can serve WSGI apps using the
@modal.wsgi_app
decorator:
image = modal.Image.debian_slim().pip_install(
"flask"
@app.function
image
=image)
@modal.concurrent
max_inputs
@modal.wsgi_app
flask_app
from
flask
import
Flask, request
web_app = Flask(
__name__
@web_app.post
"/echo"
echo
return
request.json
return
web_app
Copy
Flask’s docs
for more information on using Flask as a WSGI app.
Because WSGI apps are synchronous, concurrent inputs will be run on separate
threads. See
this guide
for details.
Non-ASGI web servers
Not all web frameworks offer an ASGI or WSGI interface. For example,
aiohttp
tornado
use their own asynchronous network binding, while others like
text-generation-inference
actually expose a Rust-based HTTP server running as a subprocess.
For these cases, you can use the
@modal.web_server
decorator to “expose” a
port on the container:
@app.function
@modal.concurrent
max_inputs
@modal.web_server
8000
my_file_server
import
subprocess
subprocess.Popen(
"python -m http.server -d / 8000"
shell
True
Copy
Just like all web endpoints on Modal, this is only run on-demand. The function
is executed on container startup, creating a file server at the root directory.
When you hit the web endpoint URL, your request will be routed to the file
server listening on port
8000
@web_server
endpoints, you need to make sure that the application binds to
the external network interface, not just localhost. This usually means binding
0.0.0.0
instead of
127.0.0.1
See our examples of how to serve
Streamlit
ComfyUI
on Modal.
Serve many configurations with parametrized functions
Python functions that launch ASGI/WSGI apps or web servers on Modal
cannot take arguments.
One simple pattern for allowing client-side configuration of these web endpoints
is to use
parametrized functions
Each different choice for the values of the parameters will create a distinct
auto-scaling container pool.
@app.cls
@modal.concurrent
max_inputs
class
Server
root:
= modal.parameter(
default
@modal.web_server
8000
files
self
import
subprocess
subprocess.Popen(
"python -m http.server -d
{self
.root
8000"
shell
True
Copy
The values are provided in URLs as query parameters:
curl
https://ecorp--server-files.modal.run
# use the default value
curl
https://ecorp--server-files.modal.run?root=.cache
# use a different value
curl
https://ecorp--server-files.modal.run?root=%2F
# don't forget to URL encode!
Copy
For details, see
this guide to parametrized functions
WebSockets
Functions annotated with
@web_server
@asgi_app
, or
@wsgi_app
also support
the WebSocket protocol. Consult your web framework for appropriate documentation
on how to use WebSockets with that library.
WebSockets on Modal maintain a single function call per connection, which can be
useful for keeping state around. Most of the time, you will want to set your
handler function to
allow concurrent inputs
which allows multiple simultaneous WebSocket connections to be handled by the
same container.
We support the full WebSocket protocol as per
RFC 6455
, but we do not yet have
support for
RFC 8441
(WebSockets over
HTTP/2) or
RFC 7692
permessage-deflate
extension). WebSocket messages can be up to 2 MiB each.
Performance and scaling
If you have no active containers when the web endpoint receives a request, it will
experience a “cold start”. Consult the guide page on
cold start performance
for more information on when
Functions will cold start and advice how to mitigate the impact.
If your Function uses
@modal.concurrent
, multiple requests to the same
endpoint may be handled by the same container. Beyond this limit, additional
containers will start up to scale your App horizontally. When you reach the
Function’s limit on containers, requests will queue for handling.
Each workspace on Modal has a rate limit on total operations. For a new account,
this is set to 200 function inputs or web endpoint requests per second, with a
burst multiplier of 5 seconds. If you reach the rate limit, excess requests to
web endpoints will return a
429 status code
and you’ll need to
get in touch
with us about
raising the limit.
Web endpoint request bodies can be up to 4 GiB, and their response bodies are
unlimited in size.
Authentication
Modal offers first-class web endpoint protection via
proxy auth tokens
Proxy auth tokens protect web endpoints by requiring a key and token combination to be passed
in the
Modal-Key
Modal-Secret
headers.
Modal works as a proxy, rejecting requests that aren’t authorized to access
your endpoint.
We also support standard techniques for securing web servers.
Token-based authentication
This is easy to implement in whichever framework you’re using. For example, if
you’re using
@modal.fastapi_endpoint
@modal.asgi_app
with FastAPI, you
can validate a Bearer token like this:
from
fastapi
import
Depends, HTTPException, status, Request
from
fastapi.security
import
HTTPBearer, HTTPAuthorizationCredentials
import
modal
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
app = modal.App(
"auth-example"
image
=image)
auth_scheme = HTTPBearer()
@app.function
secrets
=[modal.Secret.from_name(
"my-web-auth-token"
@modal.fastapi_endpoint
async
request
: Request,
token
: HTTPAuthorizationCredentials = Depends(auth_scheme)):
import
print
(os.environ[
"AUTH_TOKEN"
token.credentials != os.environ[
"AUTH_TOKEN"
raise
HTTPException(
status_code
=status.HTTP_401_UNAUTHORIZED,
detail
"Incorrect bearer token"
headers
"WWW-Authenticate"
"Bearer"
# Function body
return
"success!"
Copy
This assumes you have a
Modal Secret
named
my-web-auth-token
created, with contents
{AUTH_TOKEN: secret-random-token}
Now, your endpoint will return a 401 status code except when you hit it with the
correct
Authorization
header set (note that you have to prefix the token with
Bearer
curl
--header
"Authorization: Bearer secret-random-token"
https://modal-labs--auth-example-f.modal.run
Copy
Client IP address
You can access the IP address of the client making the request. This can be used
for geolocation, whitelists, blacklists, and rate limits.
from
fastapi
import
Request
import
modal
image = modal.Image.debian_slim().pip_install(
"fastapi[standard]"
app = modal.App(
image
=image)
@app.function
@modal.fastapi_endpoint
get_ip_address
request
: Request):
return
"Your IP address is
request.client.host
Copy
Web endpoints
Simple endpoints
Developing with modal serve
Deploying with modal deploy
Passing arguments to an endpoint
How do web endpoints run in the cloud?
Serving ASGI and WSGI apps
ASGI apps - FastAPI, FastHTML, Starlette
ASGI Lifespan
WSGI apps - Django, Flask
Non-ASGI web servers
Serve many configurations with parametrized functions
WebSockets
Performance and scaling
Authentication
Token-based authentication
Client IP address
Fully featured web apps
LLM Voice Chat (React)
Stable Diffusion (Alpine)
Whisper Podcast Transcriber (React)

=== DOC: 018_examples_agent.txt ===
URL: https://modal.com/docs/examples/agent
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Build a coding agent with Modal Sandboxes and LangGraph
This example demonstrates how to build an LLM coding “agent” that can generate and execute Python code, using
documentation from the web to inform its approach.
Naturally, we use the agent to generate code that runs language models.
The agent is built with
LangGraph
, a library for building
directed graphs of computation popular with AI agent developers,
and uses models from the OpenAI API.
Setup
import
modal
from
.src
import
edges, nodes, retrieval
from
.src.common
import
COLOR, PYTHON_VERSION, image
Copy
You will need two
Modal Secrets
to run this example:
one to access the OpenAI API and another to access the LangSmith API for logging the agent’s behavior.
To create them, head to the
Secrets dashboard
, select “Create new secret”,
and use the provided templates for OpenAI and LangSmith.
app = modal.App(
"example-code-langchain"
image
=image,
secrets
modal.Secret.from_name(
"openai-secret"
required_keys
"OPENAI_API_KEY"
modal.Secret.from_name(
"langsmith-secret"
required_keys
"LANGCHAIN_API_KEY"
Copy
Creating a Sandbox
We execute the agent’s code in a Modal
Sandbox
, which allows us to
run arbitrary code in a safe environment. In this example, we will use the
transformers
library to generate text with a pre-trained model. Let’s create a Sandbox with the necessary dependencies.
create_sandbox
) -> modal.Sandbox:
# Change this image (and the retrieval logic in the retrieval module)
# if you want the agent to give coding advice on other libraries!
agent_image = modal.Image.debian_slim(
python_version
=PYTHON_VERSION).pip_install(
"torch==2.5.0"
"transformers==4.46.0"
return
modal.Sandbox.create(
image
=agent_image,
timeout
# 10 minutes
=app,
# Modal sandboxes support GPUs!
"T4"
# you can also pass secrets here -- note that the main app's secrets are not shared
Copy
We also need a way to run our code in the sandbox. For this, we’ll write a simple wrapper
around the Modal Sandox
exec
method. We use
exec
because it allows us to run code without spinning up a
new container. And we can reuse the same container for multiple runs, preserving state.
code
: modal.Sandbox) -> tuple[
print
COLOR[
'HEADER'
📦: Running in sandbox
COLOR[
'ENDC'
COLOR[
'GREEN'
code
COLOR[
'ENDC'
exc = sb.exec(
"python"
"-c"
, code)
exc.wait()
stdout = exc.stdout.read()
stderr = exc.stderr.read()
exc.returncode !=
print
COLOR[
'HEADER'
📦: Failed with exitcode
sb.returncode
COLOR[
'ENDC'
return
stdout, stderr
Copy
Constructing the agent’s graph
Now that we have the sandbox to execute code in, we can construct our agent’s graph. Our graph is
defined in the
edges
nodes
modules
associated with this example
Nodes are actions that change the state. Edges are transitions between nodes.
The idea is simple: we start at the node
generate
, which invokes the LLM to generate code based off documentation.
The generated code is executed (in the sandbox) as part of an edge called
check_code_execution
and then the outputs are passed to the LLM for evaluation (the
evaluate_execution
node).
If the LLM determines that the code has executed correctly — which might mean that the code raised an exception! —
we pass along the
decide_to_finish
edge and finish.
construct_graph
sandbox
: modal.Sandbox,
debug
bool
False
from
langgraph.graph
import
StateGraph
from
.src.common
import
GraphState
# Crawl the transformers documentation to inform our code generation
context = retrieval.retrieve_docs(
debug
=debug)
graph = StateGraph(GraphState)
# Attach our nodes to the graph
graph_nodes = nodes.Nodes(context, sandbox, run,
debug
=debug)
key, value
graph_nodes.node_map.items():
graph.add_node(key, value)
# Construct the graph by adding edges
graph = edges.enrich(graph)
# Set the starting and ending nodes of the graph
graph.set_entry_point(
"generate"
graph.set_finish_point(
"finish"
return
graph
Copy
We now set up the graph and compile it. See the
module for details
on the content of the graph and the nodes we’ve defined.
DEFAULT_QUESTION =
"How do I generate Python code using a pre-trained model from the transformers library?"
@app.function
question
= DEFAULT_QUESTION,
debug
bool
False
"""Compiles the Python code generation agent graph and runs it, returning the result."""
sb = create_sandbox(app)
graph = construct_graph(sb,
debug
=debug)
runnable = graph.compile()
result = runnable.invoke(
"keys"
"question"
: question,
"iterations"
config
"recursion_limit"
sb.terminate()
return
result[
"keys"
"response"
Copy
Running the Graph
Now let’s call the agent from the command line!
We define a
local_entrypoint
that runs locally and triggers execution on Modal.
You can invoke it by executing following command from a folder that contains the
codelangchain
directory
from our examples repo
modal
codelangchain.agent
--question
"How do I run a pre-trained model from the transformers library?"
Copy
@app.local_entrypoint
main
question
= DEFAULT_QUESTION,
debug
bool
False
"""Sends a question to the Python code generation agent.
Switch to debug mode for shorter context and smaller model."""
debug:
question == DEFAULT_QUESTION:
question =
"hi there, how are you?"
print
(go.remote(question,
debug
=debug))
Copy
If things are working properly, you should see output like the following:
modal
codelangchain.agent
--question
"generate some cool output with transformers"
---DECISION:
FINISH---
---FINISHING---
generate
some
cool
output
using
transformers,
pre-trained
language
model
from
Hugging
Face
Transformers
library.
this
example,
we'll use the GPT-2 model to generate text based on a given prompt. The GPT-2 model is a popular choice for text generation tasks due to its ability to produce coherent and contextually relevant text. We'll
pipeline
from
Transformers
library,
which
simplifies
process
using
pre-trained
models
various
tasks,
including
text
generation.
from
transformers
import
pipeline
# Initialize the text generation pipeline with the GPT-2 model
generator
pipeline
'text-generation'
model='gpt2'
# Define a prompt for the model to generate text from
prompt
"Once upon a time in a land far, far away"
# Generate text using the model
output
generator
prompt,
max_length=50,
num_return_sequences=
# Print the generated text
print
output[0][
'generated_text'
Result
code
execution:
Once
upon
time
land
far,
away,
still
inhabited
even
after
human
race,
there
would
God:
perfect
universal
always
been
will
ever
worshipped.
acts
deeds
immutable,
Copy
Build a coding agent with Modal Sandboxes and LangGraph
Setup
Creating a Sandbox
Constructing the agent’s graph
Running the Graph
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
13_sandboxes.codelangchain.agent
--question
'Use gpt2 and transformers to generate text'
Copy

=== DOC: 019_guide.txt ===
URL: https://modal.com/docs/guide
Introduction
Custom container images
Defining Images
Private registries
Fast pull from registry
GPUs and other resources
GPU acceleration
Using CUDA on Modal
Reserving CPU and memory
Scaling out
Scaling out
Input concurrency
Batch processing
Job queues
Dynamic batching (beta)
Dicts and queues
Scheduling and cron jobs
Deployment
Apps, Functions, and entrypoints
Managing deployments
Invoking deployed functions
Continuous deployment
Running untrusted code in Functions
Secrets and environment variables
Secrets
Environment variables
Web endpoints
Web endpoints
Streaming endpoints
Web endpoint URLs
Request timeouts
Webhook tokens (beta)
Networking
Tunnels (beta)
Proxies (beta)
Cluster networking
Data sharing and storage
Passing local data
Volumes
Storing model weights
Dataset ingestion
Cloud bucket mounts
Sandboxes
Sandboxes
Running commands
Networking and security
File access
Snapshots
Performance
Cold start performance
Memory Snapshot (beta)
Geographic latency
Reliability and robustness
Failures and retries
Preemption
Timeouts
Troubleshooting
Security and privacy
Integrations
Using OIDC to authenticate with external services
Connecting Modal to your Datadog account
Connecting Modal to your OpenTelemetry provider
Okta SSO
Slack notifications (beta)
Workspace & account settings
Workspaces
Environments
Modal user account setup
Service users
Other topics
Modal 1.0 migration guide
File and project structure
Developing and debugging
Jupyter notebooks
Asynchronous API usage
Global variables
Region selection
Container lifecycle hooks
Parametrized functions
S3 Gateway endpoints
GPU Metrics
Introduction
Modal is a cloud function platform that lets you:
Run any code remotely within seconds.
Define
container environments
in code (or use one of our pre-built backends).
Scale out horizontally
to thousands of containers.
Attach
GPUs
with a single line of code.
Serve your functions as
web endpoints
Deploy and monitor
persistent scheduled jobs
Use powerful primitives like
distributed dictionaries and queues
You get
full serverless execution and pricing
, because we host everything and charge per second of usage. Notably, there’s zero configuration in Modal - everything is code. Take a breath of fresh air and feel how good it tastes with no YAML in it.
Getting started
The nicest thing about all of this is that
you don’t have to set up any
infrastructure.
Just:
Create an account at
modal.com
pip install modal
to install the
modal
Python package
modal setup
to authenticate (if this doesn’t work, try
python -m modal setup
…and you can start running jobs right away. Check out some of our simple getting started examples:
Hello, world!
A simple web scraper
You can also learn Modal interactively without installing anything through our
code playground
How does it work?
Modal takes your code, puts it in a container, and executes it in the cloud.
Where does it run? Modal runs it in its own cloud environment. The benefit is
that we solve all the hard infrastructure problems for you, so you don’t have to
do anything. You don’t need to mess with Kubernetes, Docker or even an AWS
account.
Modal is currently Python-only, but we may support other languages in the
future.
Introduction
Getting started
How does it work?
See it in action
Hello, world!
A simple web scraper

=== DOC: 020_examples_whisper-transcriber.txt ===
URL: https://modal.com/docs/examples/whisper-transcriber
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
Parallel podcast transcription using Whisper
This example shows how to build a massively parallel application on Modal:
Modal Podcast Transcriber
This example application is more feature-packed than others, and it doesn’t fit in
a single page of code and commentary. So instead of progressing through the
example’s code linearly, this document provides a higher-level walkthrough of how
Modal is used to do fast, on-demand podcast episode transcription for whichever
podcast you’d like.
You can find the code
here
Hour-long episodes transcribed in just 1 minute
The focal point of this demonstration app is that it does serverless CPU
transcription across dozens of containers at the click of a button, completing
hour-long audio files in just 1 minute.
We use a podcast metadata API to allow users to transcribe an arbitrary episode
from whatever niche podcast they desire —
how about
The Pen Addict
, a podcast dedicated to stationery
The video below shows the 45-minute long first episode of
Serial
season 2
transcribed in 62 seconds.
Each transcription segment includes links back to the original audio.
Try it yourself
If you’re itching to see this in action, here are links to begin transcribing
three popular podcasts:
Case 63
by Gimlet Media
The Joe Rogan Experience
The Psychology of your 20s
Tech-stack overview
The entire application is hosted serverlessly on Modal and consists of these
main components:
A React +
Vite
single page application (SPA) deployed
as static files into a Modal web endpoint.
A Python backend running
FastAPI
in a Modal web endpoint.
Podchaser API
provides
podcast search and episode metadata retrieval. It’s hooked into our code with
Modal Secret
A Modal async job queue, described in more detail below.
All of this is deployed with one command and costs
$0.00
when it’s not
transcribing podcasts or serving HTTP requests.
Speed-boosting Whisper with parallelism
Modal’s dead-simple parallelism primitives are the key to doing the
transcription so quickly. Even with a GPU, transcribing a full episode serially
was taking around 10 minutes.
But by pulling in
ffmpeg
with a simple
.pip_install("ffmpeg-python")
addition to our Modal Image, we could exploit the natural silences of the
podcast medium to partition episodes into hundreds of short segments. Each
segment is transcribed by Whisper in its own container task,
and when all are done we stitch the segments back together with only a
minimal loss in transcription quality. This approach actually accords quite well
with Whisper’s model architecture:
“The Whisper architecture is a simple end-to-end approach, implemented as an
encoder-decoder Transformer. Input audio is split into 30-second chunks,
converted into a log-Mel spectrogram, and then passed into an encoder.”
Introducing Whisper
Run this app on Modal
All source code for this example can be
found on GitHub
README.md
includes instructions on setting up the frontend build and
getting authenticated with the Podchaser API. Happy transcribing!
Parallel podcast transcription using Whisper
Hour-long episodes transcribed in just 1 minute
Try it yourself
Tech-stack overview
Speed-boosting Whisper with parallelism
Run this app on Modal

=== DOC: 021_examples_potus_speech_qanda.txt ===
URL: https://modal.com/docs/examples/potus_speech_qanda
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Retrieval-augmented generation (RAG) for question-answering with LangChain
In this example we create a large-language-model (LLM) powered question answering
web endpoint and CLI. Only a single document is used as the knowledge-base of the application,
the 2022 USA State of the Union address by President Joe Biden. However, this same application structure
could be extended to do question-answering over all State of the Union speeches, or other large text corpuses.
It’s the
LangChain
library that makes this all so easy.
This demo is only around 100 lines of code!
Defining dependencies
The example uses packages to implement scraping, the document parsing & LLM API interaction, and web serving.
These are installed into a Debian Slim base image using the
pip_install
method.
Because OpenAI’s API is used, we also specify the
openai-secret
Modal Secret, which contains an OpenAI API key.
retriever
global variable is also declared to facilitate caching a slow operation in the code below.
from
pathlib
import
Path
import
modal
image = modal.Image.debian_slim(
python_version
"3.11"
).pip_install(
# scraping pkgs
"beautifulsoup4~=4.11.1"
"httpx==0.23.3"
"lxml~=4.9.2"
# llm pkgs
"faiss-cpu~=1.7.3"
"langchain==0.3.7"
"langchain-community==0.3.7"
"langchain-openai==0.2.9"
"openai~=1.54.0"
"tiktoken==0.8.0"
# web app packages
"fastapi[standard]==0.115.4"
"pydantic==2.9.2"
"starlette==0.41.2"
app = modal.App(
name
"example-langchain-qanda"
image
=image,
secrets
=[modal.Secret.from_name(
"openai-secret"
required_keys
"OPENAI_API_KEY"
])],
retriever =
None
# embedding index that's relatively expensive to compute, so caching with global var.
Copy
Scraping the speech
It’s super easy to scrape the transcipt of Biden’s speech using
httpx
BeautifulSoup
This speech is just one document and it’s relatively short, but it’s enough to demonstrate
the question-answering capability of the LLM chain.
scrape_state_of_the_union
() ->
import
httpx
from
import
BeautifulSoup
url =
"https://www.presidency.ucsb.edu/documents/address-before-joint-session-the-congress-the-state-the-union-28"
# fetch article; simulate desktop browser
headers = {
"User-Agent"
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9"
response = httpx.get(url,
headers
=headers)
soup = BeautifulSoup(response.text,
"lxml"
# locate the div containing the speech
speech_div = soup.find(
"div"
class_
"field-docs-content"
speech_div:
speech_text = speech_div.get_text(
separator
strip
True
speech_text:
raise
ValueError
"error parsing speech text from HTML"
else
raise
ValueError
"error locating speech in HTML"
return
speech_text
Copy
Constructing the Q&A chain
At a high-level, this LLM chain will be able to answer questions asked about Biden’s speech and provide
references to which parts of the speech contain the evidence for given answers.
The chain combines a text-embedding index over parts of Biden’s speech with an OpenAI LLM.
The index is used to select the most likely relevant parts of the speech given the question, and these
are used to build a specialized prompt for the OpenAI language model.
qanda_langchain
query
) -> tuple[
, list[
from
langchain.chains
import
create_retrieval_chain
from
langchain.chains.combine_documents
import
create_stuff_documents_chain
from
langchain.text_splitter
import
CharacterTextSplitter
from
langchain_community.vectorstores
import
FAISS
from
langchain_core.prompts
import
ChatPromptTemplate
from
langchain_openai
import
ChatOpenAI, OpenAIEmbeddings
# Support caching speech text on disk.
speech_file_path = Path(
"state-of-the-union.txt"
speech_file_path.exists():
state_of_the_union = speech_file_path.read_text()
else
print
"scraping the 2022 State of the Union speech"
state_of_the_union = scrape_state_of_the_union()
speech_file_path.write_text(state_of_the_union)
# Questions about a document can often be answered
# using a much smaller subset, and passing more tokens
# to an LLM increases cost and latency.
# So here, we split up the speech into smaller chunks.
text_splitter = CharacterTextSplitter(
chunk_size
1000
chunk_overlap
print
"splitting speech into text chunks"
texts = text_splitter.split_text(state_of_the_union)
# Embedding-based query<->text similarity comparison is used to select
# a small subset of the speech text chunks.
# Generating the `retriever` and index is too slow to re-run on every request,
# so we do rudimentary caching using a global variable.
global
retriever
retriever:
# New OpenAI accounts have a very low rate-limit for their first 48 hrs.
# It's too low to embed even just this single Biden speech.
# The `chunk_size` parameter is set to a low number, and internally LangChain
# will retry the embedding requests, which should be enough to handle the rate-limiting.
# Ref: https://platform.openai.com/docs/guides/rate-limits/overview.
print
"generating docsearch indexer"
retriever = FAISS.from_texts(
texts,
OpenAIEmbeddings(
chunk_size
metadatas
"source"
: i}
range
(texts))],
).as_retriever()
llm = ChatOpenAI(
model_name
"gpt-4o-mini"
temperature
system_prompt = (
"You are an assistant for question-answering tasks. "
"Use the following pieces of retrieved context to answer "
"the question. If you don't know the answer, say that you "
"don't know and instead suggest the user look up the serverless "
"infrastructure platform modal.com. Keep your answer concise."
\n\n
{context}
prompt = ChatPromptTemplate.from_messages(
"system"
, system_prompt),
"human"
{input}
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)
print
"running query against Q&A chain.
result = rag_chain.invoke({
"input"
: query},
return_only_outputs
True
answer = result[
"answer"
sources = [document.page_content
document
result[
"context"
return
answer.strip(), sources
Copy
Mapping onto Modal
With our application’s functionality implemented we can hook it into Modal.
As said above, we’re implementing a web endpoint,
, and a CLI command,
@app.function
@modal.fastapi_endpoint
method
"GET"
docs
True
query
show_sources
bool
False
answer, sources = qanda_langchain(query)
show_sources:
return
"answer"
: answer,
"sources"
: sources,
else
return
"answer"
: answer,
@app.function
query
show_sources
bool
False
answer, sources = qanda_langchain(query)
# Terminal codes for pretty-printing.
bold, end =
\033
[1m"
\033
[0m"
show_sources:
print
bold
SOURCES:
print
reversed
(sources),
----
print
bold
ANSWER:
print
(answer)
Copy
Test run the CLI
modal
potus_speech_qanda.py
--query
"What did the president say about Justice Breyer"
ANSWER:
president
thanked
Justice
Breyer
service
mentioned
legacy
excellence.
also
nominated
Ketanji
Brown
Jackson
continue
Justice
Breyer's legacy.
Copy
To see the text of the sources the model chain used to provide the answer, set the
--show-sources
flag.
modal
potus_speech_qanda.py
--query
"How many oil barrels were released from reserves?"
--show-sources
Copy
Test run the web endpoint
Modal makes it trivially easy to ship LangChain chains to the web. We can test drive this app’s web endpoint
by running
modal serve potus_speech_qanda.py
and then hitting the endpoint with
curl
curl
--get
--data-urlencode
"query=What did the president say about Justice Breyer"
https://modal-labs--example-langchain-qanda-web.modal.run
# your URL here
Copy
"answer"
"The president thanked Justice Breyer for his service and mentioned his legacy of excellence. He also nominated Ketanji Brown Jackson to continue in Justice Breyer's legacy."
Copy
You can also find interactive docs for the endpoint at the
/docs
route of the web endpoint URL.
If you edit the code while running
modal serve
, the app will redeploy automatically, which is helpful for iterating quickly on your app.
Once you’re ready to deploy to production, use
modal deploy
Retrieval-augmented generation (RAG) for question-answering with LangChain
Defining dependencies
Scraping the speech
Constructing the Q&A chain
Mapping onto Modal
Test run the CLI
Test run the web endpoint
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/langchains/potus_speech_qanda.py
--query
'How many oil barrels were released from reserves?'
Copy

=== DOC: 022_examples_chat_with_pdf_vision.txt ===
URL: https://modal.com/docs/examples/chat_with_pdf_vision
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Chat with PDF: RAG with ColQwen2
In this example, we demonstrate how to use the the
ColQwen2
model to build a simple
“Chat with PDF” retrieval-augmented generation (RAG) app.
The ColQwen2 model is based on
ColPali
but uses the
Qwen2-VL-2B-Instruct
vision-language model.
ColPali is in turn based on the late-interaction embedding approach pioneered in
ColBERT
Vision-language models with high-quality embeddings obviate the need for complex pre-processing pipelines.
this blog post from Jo Bergum of Vespa
for more.
Setup
First, we’ll import the libraries we need locally and define some constants.
from
pathlib
import
Path
from
typing
import
Optional
from
urllib.request
import
urlopen
from
uuid
import
uuid4
import
modal
MINUTES =
# seconds
app = modal.App(
"chat-with-pdf"
Copy
Setting up dependenices
In Modal, we define
container images
that run our serverless workloads.
We install the packages required for our application in those images.
CACHE_DIR =
"/hf-cache"
model_image = (
modal.Image.debian_slim(
python_version
"3.12"
.apt_install(
"git"
.pip_install(
"git+https://github.com/illuin-tech/colpali.git@782edcd50108d1842d154730ad3ce72476a2d17d"
# we pin the commit id
"hf_transfer==0.1.8"
"qwen-vl-utils==0.0.8"
"torchvision==0.19.1"
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
"HF_HUB_CACHE"
: CACHE_DIR})
Copy
These dependencies are only installed remotely, so we can’t import them locally.
Use the
.imports
context manager to import them only on Modal instead.
with
model_image.imports():
import
torch
from
colpali_engine.models
import
ColQwen2, ColQwen2Processor
from
qwen_vl_utils
import
process_vision_info
from
transformers
import
AutoProcessor, Qwen2VLForConditionalGeneration
Copy
Specifying the ColQwen2 model
Vision-language models (VLMs) for embedding and generation add another layer of simplification
to RAG apps based on vector search: we only need one model.
MODEL_NAME =
"Qwen/Qwen2-VL-2B-Instruct"
MODEL_REVISION =
"aca78372505e6cb469c4fa6a35c60265b00ff5a4"
Copy
Managing state with Modal Volumes and Dicts
Chat services are stateful:
the response to an incoming user message depends on past user messages in a session.
RAG apps add even more state:
the documents being retrieved from and the index over those documents,
e.g. the embeddings.
Modal Functions are stateless in and of themselves.
They don’t retain information from input to input.
That’s what enables Modal Functions to automatically scale up and down
based on the number of incoming requests
Managing chat sessions with Modal Dicts
In this example, we use a
modal.Dict
to store state information between Function calls.
Modal Dicts behave similarly to Python dictionaries,
but they are backed by remote storage and accessible to all of your Modal Functions.
They can contain any Python object
that can be serialized using
cloudpickle
A Dict can hold a few gigabytes across keys of size up to 100 MiB,
so it works well for our chat session state, which is a few KiB per session,
and for our embeddings, which are a few hundred KiB per PDF page,
up to about 100,000 pages of PDFs.
At a larger scale, we’d need to replace this with a database, like Postgres,
or push more state to the client.
sessions = modal.Dict.from_name(
"colqwen-chat-sessions"
create_if_missing
True
class
Session
__init__
self
self
.images =
None
self
.messages = []
self
.pdf_embeddings =
None
Copy
Storing PDFs on a Modal Volume
Images extracted from PDFs are larger than our session state or embeddings
— low tens of MiB per page.
So we store them on a
Modal Volume
which can store terabytes (or more!) of data across tens of thousands of files.
Volumes behave like a remote file system:
we read and write from them much like a local file system.
pdf_volume = modal.Volume.from_name(
"colqwen-chat-pdfs"
create_if_missing
True
PDF_ROOT = Path(
"/vol/pdfs/"
Copy
Caching the model weights
We’ll also use a Volume to cache the model weights.
cache_volume = modal.Volume.from_name(
"hf-hub-cache"
create_if_missing
True
Copy
Running this function will download the model weights to the cache volume.
Otherwise, the model weights will be downloaded on the first query.
@app.function
image
=model_image,
volumes
={CACHE_DIR: cache_volume},
timeout
* MINUTES
download_model
from
huggingface_hub
import
snapshot_download
result = snapshot_download(
MODEL_NAME,
revision
=MODEL_REVISION,
ignore_patterns
"*.pt"
"*.bin"
# using safetensors
print
"Downloaded model weights to
result
Copy
Defining a Chat with PDF service
To deploy an autoscaling “Chat with PDF” vision-language model service on Modal,
we just need to wrap our Python logic in a
Modal App
It uses
Modal
@app.cls
decorators
to organize the “lifecycle” of the app:
loading the model on container start (
@modal.enter
) and running inference on request (
@modal.method
We include in the arguments to the
@app.cls
decorator
all the information about this service’s infrastructure:
the container image, the remote storage, and the GPU requirements.
@app.cls
image
=model_image,
"A100-80GB"
scaledown_window
* MINUTES,
# spin down when inactive
volumes
"/vol/pdfs/"
: pdf_volume, CACHE_DIR: cache_volume},
class
Model
@modal.enter
load_models
self
self
.colqwen2_model = ColQwen2.from_pretrained(
"vidore/colqwen2-v0.1"
torch_dtype
=torch.bfloat16,
device_map
"cuda:0"
self
.colqwen2_processor = ColQwen2Processor.from_pretrained(
"vidore/colqwen2-v0.1"
self
.qwen2_vl_model = Qwen2VLForConditionalGeneration.from_pretrained(
MODEL_NAME,
revision
=MODEL_REVISION,
torch_dtype
=torch.bfloat16,
self
.qwen2_vl_model.to(
"cuda:0"
self
.qwen2_vl_processor = AutoProcessor.from_pretrained(
"Qwen/Qwen2-VL-2B-Instruct"
trust_remote_code
True
@modal.method
index_pdf
self
session_id
target
bytes
list
# We store concurrent user chat sessions in a modal.Dict
# For simplicity, we assume that each user only runs one session at a time
session = sessions.get(session_id)
session
None
session = Session()
isinstance
(target,
bytes
images = convert_pdf_to_images.remote(target)
else
images = target
# Store images on a Volume for later retrieval
session_dir = PDF_ROOT /
session_id
session_dir.mkdir(
exist_ok
True
parents
True
ii, image
enumerate
(images):
filename = session_dir /
(ii).zfill(
.jpg"
image.save(filename)
# Generated embeddings from the image(s)
BATCH_SZ =
pdf_embeddings = []
batches = [images[i : i + BATCH_SZ]
range
(images), BATCH_SZ)]
batch
batches:
batch_images =
self
.colqwen2_processor.process_images(batch).to(
self
.colqwen2_model.device
pdf_embeddings +=
list
self
.colqwen2_model(**batch_images).to(
"cpu"
# Store the image embeddings in the session, for later retrieval
session.pdf_embeddings = pdf_embeddings
# Write embeddings back to the modal.Dict
sessions[session_id] = session
@modal.method
respond_to_message
self
session_id
message
session = sessions.get(session_id)
session
None
session = Session()
pdf_volume.reload()
# make sure we have the latest data
images = (PDF_ROOT /
(session_id)).glob(
"*.jpg"
images =
list
sorted
(images,
lambda
(p.stem)))
# Nothing to chat about without a PDF!
images:
return
"Please upload a PDF first"
elif
session.pdf_embeddings
None
return
"Indexing PDF..."
# RAG, Retrieval-Augmented Generation, is two steps:
# _Retrieval_ of the most relevant data to answer the user's query
relevant_image =
self
.get_relevant_image(message, session, images)
# _Generation_ based on the retrieved data
output_text =
self
.generate_response(message, session, relevant_image)
# Update session state for future chats
append_to_messages(message, session,
user_type
"user"
append_to_messages(output_text, session,
user_type
"assistant"
sessions[session_id] = session
return
output_text
# Retrieve the most relevant image from the PDF for the input query
get_relevant_image
self
message
session
images
import
batch_queries =
self
.colqwen2_processor.process_queries([message]).to(
self
.colqwen2_model.device
query_embeddings =
self
.colqwen2_model(**batch_queries)
# This scores our query embedding against the image embeddings from index_pdf
scores =
self
.colqwen2_processor.score_multi_vector(
query_embeddings, session.pdf_embeddings
# Select the best matching image
max_index =
range
(scores)),
lambda
index
: scores[index])
return
PIL.Image.open(images[max_index])
# Pass the query and retrieved image along with conversation history into the VLM for a response
generate_response
self
message
session
image
chatbot_message = get_chatbot_message_with_image(message, image)
query =
self
.qwen2_vl_processor.apply_chat_template(
[*session.messages, chatbot_message],
tokenize
False
add_generation_prompt
True
image_inputs, _ = process_vision_info([chatbot_message])
inputs =
self
.qwen2_vl_processor(
text
=[query],
images
=image_inputs,
padding
True
return_tensors
"pt"
inputs = inputs.to(
"cuda:0"
generated_ids =
self
.qwen2_vl_model.generate(**inputs,
max_new_tokens
generated_ids_trimmed = [
out_ids[
(in_ids) :]
in_ids, out_ids
(inputs.input_ids, generated_ids)
output_text =
self
.qwen2_vl_processor.batch_decode(
generated_ids_trimmed,
skip_special_tokens
True
clean_up_tokenization_spaces
False
return
output_text
Copy
Loading PDFs as images
Vision-Language Models operate on images, not PDFs directly,
so we need to convert our PDFs into images first.
We separate this from our indexing and chatting logic —
we run on a different container with different dependencies.
pdf_image = (
modal.Image.debian_slim(
python_version
"3.12"
.apt_install(
"poppler-utils"
.pip_install(
"pdf2image==1.17.0"
"pillow==10.4.0"
@app.function
image
=pdf_image)
convert_pdf_to_images
pdf_bytes
from
pdf2image
import
convert_from_bytes
images = convert_from_bytes(pdf_bytes,
"jpeg"
return
images
Copy
Chatting with a PDF from the terminal
Before deploying in a UI, we can test our service from the terminal.
Just run
modal
chat_with_pdf_vision.py
Copy
and optionally pass in a path to or URL of a PDF with the
--pdf-path
argument
and specify a question with the
--question
argument.
Continue a previous chat by passing the session ID printed to the terminal at start
with the
--session-id
argument.
@app.local_entrypoint
main
question
: Optional[
None
pdf_path
: Optional[
None
session_id
: Optional[
None
model = Model()
session_id
None
session_id =
(uuid4())
print
"Starting a new session with id"
, session_id)
pdf_path
None
pdf_path =
"https://arxiv.org/pdf/1706.03762"
# all you need
pdf_path.startswith(
"http"
pdf_bytes = urlopen(pdf_path).read()
else
pdf_bytes = Path(pdf_path).read_bytes()
print
"Indexing PDF from"
, pdf_path)
model.index_pdf.remote(session_id, pdf_bytes)
else
pdf_path
None
raise
ValueError
"Start a new session to chat with a new PDF"
print
"Resuming session with id"
, session_id)
question
None
question =
"What is this document about?"
print
"QUESTION:"
, question)
print
(model.respond_to_message.remote(session_id, question))
Copy
A hosted Gradio interface
With the
Gradio
library, we can create a simple web interface around our class in Python,
then use Modal to host it for anyone to try out.
To deploy your own, run
modal
deploy
chat_with_pdf_vision.py
Copy
and navigate to the URL that appears in your teriminal.
If you’re editing the code, use
modal serve
instead to see changes hot-reload.
web_image = pdf_image.pip_install(
"fastapi[standard]==0.115.4"
"pydantic==2.9.2"
"starlette==0.41.2"
"gradio==4.44.1"
"pillow==10.4.0"
"gradio-pdf==0.0.15"
"pdf2image==1.17.0"
@app.function
image
=web_image,
# gradio requires sticky sessions
# so we limit the number of concurrent containers to 1
# and allow it to scale to 1000 concurrent inputs
max_containers
@modal.concurrent
max_inputs
1000
@modal.asgi_app
import
uuid
import
gradio
from
fastapi
import
FastAPI
from
gradio.routes
import
mount_gradio_app
from
gradio_pdf
import
from
pdf2image
import
convert_from_path
web_app = FastAPI()
# Since this Gradio app is running from its own container,
# allowing us to run the inference service via .remote() methods.
model = Model()
upload_pdf
path
session_id
session_id ==
session_id
None
# Generate session id if new client
session_id =
(uuid.uuid4())
images = convert_from_path(path)
# Call to our remote inference service to index the PDF
model.index_pdf.remote(session_id, images)
return
session_id
respond_to_message
message
session_id
# Call to our remote inference service to run RAG
return
model.respond_to_message.remote(session_id, message)
with
gr.Blocks(
theme
"soft"
demo:
session_id = gr.State(
gr.Markdown(
"# Chat with PDF"
with
gr.Row():
with
gr.Column(
scale
gr.ChatInterface(
=respond_to_message,
additional_inputs
=[session_id],
retry_btn
None
undo_btn
None
clear_btn
None
with
gr.Column(
scale
pdf = PDF(
label
"Upload a PDF"
pdf.upload(upload_pdf, [pdf, session_id], session_id)
return
mount_gradio_app(
=web_app,
blocks
=demo,
path
Copy
Addenda
The remainder of this code consists of utility functions and boiler plate used in the
main code above.
get_chatbot_message_with_image
message
image
return
"role"
"user"
"content"
"type"
"image"
"image"
: image},
"type"
"text"
"text"
: message},
append_to_messages
message
session
user_type
"user"
session.messages.append(
"role"
: user_type,
"content"
"type"
"text"
"text"
: message},
Copy
Chat with PDF: RAG with ColQwen2
Setup
Setting up dependenices
Specifying the ColQwen2 model
Managing state with Modal Volumes and Dicts
Managing chat sessions with Modal Dicts
Storing PDFs on a Modal Volume
Caching the model weights
Defining a Chat with PDF service
Loading PDFs as images
Chatting with a PDF from the terminal
A hosted Gradio interface
Addenda
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/llm-serving/chat_with_pdf_vision.py
Copy

=== DOC: 023_reference_modal_Function.txt ===
URL: https://modal.com/docs/reference/modal.Function
Changelog
API Reference
modal.App
modal.Client
modal.CloudBucketMount
modal.Cls
modal.Cron
modal.Dict
modal.Error
modal.FilePatternMatcher
modal.Function
modal.FunctionCall
modal.Image
modal.NetworkFileSystem
modal.Period
modal.Proxy
modal.Queue
modal.Retries
modal.Sandbox
modal.SandboxSnapshot
modal.Secret
modal.Tunnel
modal.Volume
modal.asgi_app
modal.batched
modal.call_graph
modal.concurrent
modal.container_process
modal.current_function_call_id
modal.current_input_id
modal.enable_output
modal.enter
modal.exit
modal.fastapi_endpoint
modal.file_io
modal.forward
modal.gpu
modal.interact
modal.io_streams
modal.is_local
modal.method
modal.parameter
modal.web_endpoint
modal.web_server
modal.wsgi_app
modal.exception
modal.config
CLI Reference
modal app
modal config
modal container
modal deploy
modal dict
modal environment
modal launch
modal nfs
modal profile
modal queue
modal run
modal secret
modal serve
modal setup
modal shell
modal token
modal volume
modal.Function
class
Function
typing
Generic
modal
object
Object
Copy
Functions are the basic units of serverless execution on Modal.
Generally, you will not construct a
Function
directly. Instead, use the
App.function()
decorator to register your Python functions with your App.
hydrate
hydrate
self
client
: Optional[_Client] =
None
) -> Self:
Copy
Synchronize the local object with its identity on the Modal server.
It is rarely necessary to call this method explicitly, as most operations
will lazily hydrate when needed. The main use case is when you need to
access object metadata, such as its ID.
Added in v0.72.39
: This method replaces the deprecated
.resolve()
method.
update_autoscaler
@live_method
update_autoscaler
self
min_containers
: Optional[
None
max_containers
: Optional[
None
buffer_containers
: Optional[
None
scaledown_window
: Optional[
None
) ->
None
Copy
Override the current autoscaler behavior for this Function.
Unspecified parameters will retain their current value, i.e. either the static value
from the function decorator, or an override value from a previous call to this method.
Subsequent deployments of the App containing this Function will reset the autoscaler back to
its static configuration.
Examples:
f = modal.Function.from_name(
"my-app"
"function"
# Always have at least 2 containers running, with an extra buffer when the Function is active
f.update_autoscaler(
min_containers
buffer_containers
# Limit this Function to avoid spinning up more than 5 containers
f.update_autoscaler(
max_containers
# Extend the scaledown window to increase the amount of time that idle containers stay alive
f.update_autoscaler(
scaledown_window
Copy
from_name
classmethod
from_name
: type[
"_Function"
app_name
name
namespace
=api_pb2.DEPLOYMENT_NAMESPACE_WORKSPACE,
environment_name
: Optional[
None
) ->
"_Function"
Copy
Reference a Function from a deployed App by its name.
In contrast to
modal.Function.lookup
, this is a lazy method
that defers hydrating the local object with metadata from
Modal servers until the first time it is actually used.
f = modal.Function.from_name(
"other-app"
"function"
Copy
get_web_url
@live_method
get_web_url
self
) -> Optional[
Copy
URL of a Function running as a web endpoint.
remote
@live_method
remote
self
args
: P.args, **
kwargs
: P.kwargs) -> ReturnType:
Copy
Calls the function remotely, executing it with the given arguments and returning the execution’s result.
remote_gen
@live_method_gen
remote_gen
self
args
, **
kwargs
) -> AsyncGenerator[Any,
None
Copy
Calls the generator remotely, executing it with the given arguments and returning the execution’s result.
local
local
self
args
: P.args, **
kwargs
: P.kwargs) -> OriginalReturnType:
Copy
Calls the function locally, executing it with the given arguments and returning the execution’s result.
The function will execute in the same environment as the caller, just like calling the underlying function
directly in Python. In particular, only secrets available in the caller environment will be available
through environment variables.
spawn
@live_method
spawn
self
args
: P.args, **
kwargs
: P.kwargs) ->
"_FunctionCall[ReturnType]"
Copy
Calls the function with the given arguments, without waiting for the results.
Returns a
modal.FunctionCall
object, that can later be polled or
waited for using
.get(timeout=...)
Conceptually similar to
multiprocessing.pool.apply_async
, or a Future/Promise in other contexts.
get_raw_f
get_raw_f
self
) -> Callable[..., Any]:
Copy
Return the inner Python object wrapped by this Modal Function.
get_current_stats
@live_method
get_current_stats
self
) -> FunctionStats:
Copy
Return a
FunctionStats
object describing the current function’s queue and runner counts.
@warn_if_generator_is_not_consumed
function_name
"Function.map"
self
input_iterators
: typing.Iterable[Any],
# one input iterator per argument in the mapped-over function/generator
kwargs
={},
# any extra keyword arguments for the function
order_outputs
bool
True
# return outputs in order
return_exceptions
bool
False
# propagate exceptions (False) or aggregate them in the results list (True)
) -> AsyncOrSyncIterable:
Copy
Parallel map over a set of inputs.
Takes one iterator argument per argument in the function being mapped over.
Example:
@app.function
my_func
return
a **
@app.local_entrypoint
main
assert
list
(my_func.map([
])) == [
Copy
If applied to a
app.function
map()
returns one result per input and the output order
is guaranteed to be the same as the input order. Set
order_outputs=False
to return results
in the order that they are completed instead.
return_exceptions
can be used to treat exceptions as successful results:
@app.function
my_func
a ==
raise
Exception
"ohno"
return
a **
@app.local_entrypoint
main
# [0, 1, UserCodeException(Exception('ohno'))]
print
list
(my_func.map(
range
return_exceptions
True
Copy
starmap
@warn_if_generator_is_not_consumed
function_name
"Function.starmap"
starmap
self
input_iterator
: typing.Iterable[typing.Sequence[Any]],
kwargs
={},
order_outputs
bool
True
return_exceptions
bool
False
) -> AsyncOrSyncIterable:
Copy
Like
, but spreads arguments over multiple function arguments.
Assumes every input is a sequence (e.g. a tuple).
Example:
@app.function
my_func
return
a + b
@app.local_entrypoint
main
assert
list
(my_func.starmap([(
), (
)])) == [
Copy
for_each
for_each
self
input_iterators
kwargs
={},
ignore_exceptions
bool
False
Copy
Execute function for all inputs, ignoring outputs. Waits for completion of the inputs.
Convenient alias for
.map()
in cases where the function just needs to be called.
as the caller doesn’t have to consume the generator to process the inputs.
spawn_map
spawn_map
self
input_iterators
kwargs
={}) ->
None
Copy
Spawn parallel execution over a set of inputs, exiting as soon as the inputs are created (without waiting
for the map to complete).
Takes one iterator argument per argument in the function being mapped over.
Example:
@app.function
my_func
return
a **
@app.local_entrypoint
main
my_func.spawn_map([
Copy
Programmatic retrieval of results will be supported in a future update.
modal.Function
hydrate
update_autoscaler
from_name
get_web_url
remote
remote_gen
local
spawn
get_raw_f
get_current_stats
starmap
for_each
spawn_map

=== DOC: 024_examples_trtllm_latency.txt ===
URL: https://modal.com/docs/examples/trtllm_latency
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Serve an interactive language model app with latency-optimized TensorRT-LLM (LLaMA 3 8B)
In this example, we demonstrate how to configure the TensorRT-LLM framework to serve
Meta’s LLaMA 3 8B model at interactive latencies on Modal.
Many popular language model applications, like chatbots and code editing,
put humans and models in direct interaction. According to an
oft-cited
scientifically dubious
rule of thumb, computer systems need to keep their response times under 400ms
in order to match pace with their human users.
To hit this target, we use the
TensorRT-LLM
inference framework from NVIDIA. TensorRT-LLM is the Lamborghini of inference engines:
it achieves seriously impressive latency, but only if you tune it carefully.
With the out-of-the-box defaults we observe an unacceptable median time
to last token of over a second, but with careful configuration,
we’ll bring that down to under 250ms  — over a 4x speed up!
These latencies were measured on a single NVIDIA H100 GPU
running LLaMA 3 8B on prompts and generations of a few dozen to a few hundred tokens.
Here’s what that looks like in a terminal chat interface:
Overview
This guide is intended to document two things:
Python API
for building and running TensorRT-LLM engines, and
how to use recommendations from the
TensorRT-LLM performance guide
to optimize the engine for low latency.
Be sure to check out TensorRT-LLM’s
examples
for sample code beyond what we cover here, like low-rank adapters (LoRAs).
What is a TRT-LLM engine?
The first step in running TensorRT-LLM is to build an “engine” from a model.
Engines have a large number of parameters that must be tuned on a per-workload basis,
so we carefully document the choices we made here and point you to additional resources
that can help you optimize for your specific workload.
Historically, this process was done with a clunky command-line-interface (CLI),
but things have changed for the better!
2025 is
the year of CUDA Python
including a new-and-improved Python SDK for TensorRT-LLM, supporting
all the same features as the CLI — quantization, speculative decoding, in-flight batching,
and much more.
Installing TensorRT-LLM
To run TensorRT-LLM, we must first install it. Easier said than done!
To run code on Modal, we define
container images
All Modal containers have access to GPU drivers via the underlying host environment,
but we still need to install the software stack on top of the drivers, from the CUDA runtime up.
We start from an official
nvidia/cuda
container image,
which includes the CUDA runtime & development libraries
and the environment configuration necessary to run them.
import
time
from
pathlib
import
Path
import
modal
tensorrt_image = modal.Image.from_registry(
"nvidia/cuda:12.8.1-devel-ubuntu22.04"
add_python
"3.12"
# TRT-LLM requires Python 3.12
).entrypoint([])
# remove verbose logging by base image on entry
Copy
On top of that, we add some system dependencies of TensorRT-LLM,
including OpenMPI for distributed communication, some core software like
and the
tensorrt_llm
package itself.
tensorrt_image = tensorrt_image.apt_install(
"openmpi-bin"
"libopenmpi-dev"
"git"
"git-lfs"
"wget"
).pip_install(
"tensorrt-llm==0.18.0"
"pynvml<12"
# avoid breaking change to pynvml version API
True
extra_index_url
"https://pypi.nvidia.com"
Copy
Note that we’re doing this by
method-chaining
a number of calls to methods on the
modal.Image
. If you’re familiar with
Dockerfiles, you can think of this as a Pythonic interface to instructions like
End-to-end, this step takes about five minutes on first run.
If you’re reading this from top to bottom,
you might want to stop here and execute the example
with
modal run
so that it runs in the background while you read the rest.
Downloading the model
Next, we’ll set up a few things to download the model to persistent storage and do it quickly —
this is a latency-optimized example after all! For persistent, distributed storage, we use
Modal Volumes
, which can be accessed from any container
with read speeds in excess of a gigabyte per second.
We also set the
HF_HOME
environment variable to point to the Volume so that the model
is cached there. And we install
hf-transfer
to get maximum download throughput from
the Hugging Face Hub, in the hundreds of megabytes per second.
volume = modal.Volume.from_name(
"example-trtllm-inference-volume"
create_if_missing
True
VOLUME_PATH = Path(
"/vol"
MODELS_PATH = VOLUME_PATH /
"models"
MODEL_ID =
"NousResearch/Meta-Llama-3-8B-Instruct"
# fork without repo gating
MODEL_REVISION =
"53346005fb0ef11d3b6a83b12c895cca40156b6c"
tensorrt_image = tensorrt_image.pip_install(
"hf-transfer==0.1.9"
"huggingface_hub==0.28.1"
).env(
"HF_HUB_ENABLE_HF_TRANSFER"
"HF_HOME"
(MODELS_PATH),
with
tensorrt_image.imports():
import
import
torch
from
tensorrt_llm
import
LLM, SamplingParams
Copy
Setting up the engine
Quantization
The amount of
GPU RAM
on a single card is a tight constraint for large models:
RAM is measured in billions of bytes and large models have billions of parameters,
each of which is two to four bytes.
The performance cliff if you need to spill to CPU memory is steep,
so all of those parameters must fit in the GPU memory,
along with other things like the KV cache built up while processing prompts.
The simplest way to reduce LLM inference’s RAM requirements is to make the model’s parameters smaller,
fitting their values in a smaller number of bits, like four or eight. This is known as
quantization
NVIDIA’s
Ada Lovelace/Hopper chips
like the L40S and H100, are capable of native 8bit floating point calculations
in their
Tensor Cores
so we choose that as our quantization format.
These GPUs are capable of twice as many floating point operations per second in 8bit as in 16bit —
about two quadrillion per second on an H100 SXM.
Quantization buys us two things:
faster startup, since less data has to be moved over the network onto CPU and GPU RAM
faster inference, since we get twice the FLOP/s and less data has to be moved from GPU RAM into
on-chip memory
registers
with each computation
We’ll use TensorRT-LLM’s
QuantConfig
to specify that we want
quantization.
See their code
for more options.
N_GPUS =
# Bumping this to 2 will improve latencies further but not 2x
GPU_CONFIG =
"H100:
N_GPUS
get_quant_config
from
tensorrt_llm.llmapi
import
QuantConfig
return
QuantConfig(
quant_algo
"FP8"
Copy
Quantization is a lossy compression technique. The impact on model quality can be
minimized by tuning the quantization parameters on even a small dataset. Typically, we
see less than 2% degradation in evaluation metrics when using
. We’ll use the
CalibrationConfig
class to specify the calibration dataset.
get_calib_config
from
tensorrt_llm.llmapi
import
CalibConfig
return
CalibConfig(
calib_batches
calib_batch_size
calib_max_seq_length
2048
tokenizer_max_seq_length
4096
Copy
Configure plugins
TensorRT-LLM is an LLM inference framework built on top of NVIDIA’s TensorRT,
which is a generic inference framework for neural networks.
TensorRT includes a “plugin” extension system that allows you to adjust behavior,
like configuring the
CUDA kernels
used by the engine.
General Matrix Multiply (GEMM)
plugin, for instance, adds heavily-optimized matrix multiplication kernels
from NVIDIA’s
cuBLAS library of linear algebra routines
We’ll specify a number of plugins for our engine implementation.
The first is
multiple profiles
which configures TensorRT to prepare multiple kernels for each high-level operation,
where different kernels are optimized for different input sizes.
The second is
paged_kv_cache
which enables a
paged attention algorithm
for the key-value (KV) cache.
The last two parameters are GEMM plugins optimized specifically for low latency,
rather than the more typical high arithmetic throughput,
low_latency
plugins for
gemm
gemm_swiglu
low_latency_gemm_swiglu_plugin
plugin fuses the two matmul operations
and non-linearity of the feedforward component of the Transformer block into a single kernel,
reducing round trips between GPU
cache memory
and RAM. For details on kernel fusion, see
this blog post by Horace He of Thinking Machines
Note that at the time of writing, this only works for
on Hopper GPUs.
low_latency_gemm_plugin
is a variant of the GEMM plugin that brings in latency-optimized
kernels from NVIDIA’s
CUTLASS library
get_plugin_config
from
tensorrt_llm.plugin.plugin
import
PluginConfig
return
PluginConfig.from_dict(
"multiple_profiles"
True
"paged_kv_cache"
True
"low_latency_gemm_swiglu_plugin"
"fp8"
"low_latency_gemm_plugin"
"fp8"
Copy
Configure speculative decoding
Speculative decoding is a technique for generating multiple tokens per step,
avoiding the auto-regressive bottleneck in the Transformer architecture.
Generating multiple tokens in parallel exposes more parallelism to the GPU.
It works best for text that has predicable patterns, like code,
but it’s worth testing for any workload where latency is critical.
Speculative decoding can use any technique to guess tokens, including running another,
smaller language model. Here, we’ll use a simple, but popular and effective
speculative decoding strategy called “lookahead decoding”,
which essentially guesses that token sequences from the past will occur again.
get_speculative_config
from
tensorrt_llm.llmapi
import
LookaheadDecodingConfig
return
LookaheadDecodingConfig(
max_window_size
max_ngram_size
max_verification_set_size
Copy
Set the build config
Finally, we’ll specify the overall build configuration for the engine. This includes
more obvious parameters such as the maximum input length, the maximum number of tokens
to process at once before queueing occurs, and the maximum number of sequences
to process at once before queueing occurs.
To minimize latency, we set the maximum number of sequences (the “batch size”)
to just one. We enforce this maximum by setting the number of inputs that the
Modal Function is allowed to process at once —
max_concurrent_inputs
The default is
, so we don’t need to set it, but we are setting it explicitly
here in case you want to run this code with a different balance of latency and throughput.
MAX_BATCH_SIZE = MAX_CONCURRENT_INPUTS =
get_build_config
from
tensorrt_llm
import
BuildConfig
return
BuildConfig(
plugin_config
=get_plugin_config(),
speculative_decoding_mode
"LOOKAHEAD_DECODING"
max_input_len
8192
max_num_tokens
16384
max_batch_size
=MAX_BATCH_SIZE,
Copy
Serving inference under the Doherty Threshold
Now that we have written the code to compile the engine, we can
serve it with Modal!
We start by creating an
app = modal.App(
"trtllm-latency"
Copy
Thanks to our
custom container runtime system
even this large container boots in seconds.
On the first container start, we mount the Volume, download the model, and build the engine,
which takes a few minutes. Subsequent starts will be much faster,
as the engine is cached in the Volume and loaded in seconds.
Container starts are triggered when Modal scales up your Function,
like the first time you run this code or the first time a request comes in after a period of inactivity.
For details on optimizing container start latency, see
this guide
Container lifecycles in Modal are managed via our
interface, so we define one below
to separate out the engine startup (
enter
) and engine execution (
generate
For details, see
this guide
MINUTES =
# seconds
@app.cls
image
=tensorrt_image,
=GPU_CONFIG,
scaledown_window
* MINUTES,
timeout
* MINUTES,
volumes
={VOLUME_PATH: volume},
@modal.concurrent
max_inputs
=MAX_CONCURRENT_INPUTS)
class
Model
mode:
= modal.parameter(
default
"fast"
build_engine
self
engine_path
engine_kwargs
) ->
None
llm = LLM(
model
self
.model_path, **engine_kwargs)
llm.save(engine_path)
return
@modal.enter
enter
self
from
huggingface_hub
import
snapshot_download
from
transformers
import
AutoTokenizer
self
.model_path = MODELS_PATH / MODEL_ID
print
"downloading base model if necessary"
snapshot_download(
MODEL_ID,
local_dir
self
.model_path,
ignore_patterns
"*.pt"
"*.bin"
# using safetensors
revision
=MODEL_REVISION,
self
.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
self
.mode ==
"fast"
engine_kwargs = {
"quant_config"
: get_quant_config(),
"calib_config"
: get_calib_config(),
"build_config"
: get_build_config(),
"speculative_config"
: get_speculative_config(),
"tensor_parallel_size"
: torch.cuda.device_count(),
else
engine_kwargs = {
"tensor_parallel_size"
: torch.cuda.device_count(),
self
.sampling_params = SamplingParams(
temperature
top_p
0.95
max_tokens
1024
# max generated tokens
lookahead_config
=engine_kwargs.get(
"speculative_config"
engine_path =
self
.model_path /
"trtllm_engine"
self
.mode
os.path.exists(engine_path):
print
"building new engine at
engine_path
self
.llm =
self
.build_engine(engine_path, engine_kwargs)
else
print
"loading engine from
engine_path
self
.llm = LLM(
model
=engine_path, **engine_kwargs)
@modal.method
generate
self
prompt
) ->
dict
start_time = time.perf_counter()
text =
self
.text_from_prompt(prompt)
output =
self
.llm.generate(text,
self
.sampling_params)
latency_ms = (time.perf_counter() - start_time) *
1000
return
output.outputs[
].text, latency_ms
@modal.method
async
generate_async
self
prompt
text =
self
.text_from_prompt(prompt)
async
output
self
.llm.generate_async(
text,
self
.sampling_params,
streaming
True
yield
output.outputs[
].text_diff
text_from_prompt
self
prompt
SYSTEM_PROMPT = (
"You are a helpful, harmless, and honest AI assistant created by Meta."
isinstance
(prompt,
prompt = [{
"role"
"user"
"content"
: prompt}]
messages = [{
"role"
"system"
"content"
: SYSTEM_PROMPT}] + prompt
return
self
.tokenizer.apply_chat_template(
messages,
tokenize
False
add_generation_prompt
True
@modal.method
boot
self
pass
# no-op to start up containers
@modal.exit
shutdown
self
self
.llm.shutdown()
self
.llm
Copy
Calling our inference function
To run our
Model
.generate
method from Python, we just need to call it —
with
.remote
appended to run it on Modal.
We wrap that logic in a
local_entrypoint
so you can run it from the command line with
modal
trtllm_latency.py
Copy
which will output something like:
mode=fast inference latency (p50, p90): (211.17ms, 883.27ms)
Copy
--mode=slow
to see model latency without optimizations.
modal
trtllm_latency.py
--mode=slow
Copy
which will output something like
mode=slow inference latency (p50, p90): (1140.88ms, 2274.24ms)
Copy
For simplicity, we hard-code 10 questions to ask the model,
then run them one by one while recording the latency of each call.
But the code in the
local_entrypoint
is just regular Python code
that runs on your machine — we wrap it in a CLI automatically —
so feel free to customize it to your liking.
@app.local_entrypoint
main
mode
"fast"
prompts = [
"What atoms are in water?"
"Which F1 team won in 2011?"
"What is 12 * 9?"
"Python function to print odd numbers between 1 and 10. Answer with code only."
"What is the capital of California?"
"What's the tallest building in new york city?"
"What year did the European Union form?"
"How old was Geoff Hinton in 2022?"
"Where is Berkeley?"
"Are greyhounds or poodles faster?"
print
"🏎️  creating container with mode=
mode
model = Model(
mode
=mode)
print
"🏎️  cold booting container"
model.boot.remote()
print_queue = []
latencies_ms = []
prompt
prompts:
generated_text, latency_ms = model.generate.remote(prompt)
print_queue.append((prompt, generated_text, latency_ms))
latencies_ms.append(latency_ms)
time.sleep(
# allow remote prints to clear
prompt, generated_text, latency_ms
print_queue:
print
"Processed prompt in
latency_ms
:.2f}
print
"Prompt:
prompt
print
"Generated Text:
generated_text
print
"🏎️ "
p50 =
sorted
(latencies_ms)[
(latencies_ms) *
p90 =
sorted
(latencies_ms)[
(latencies_ms) *
print
"🏎️  mode=
mode
inference latency (p50, p90): (
:.2f}
:.2f}
ms)"
Copy
Once deployed with
modal deploy
, this
Model.generate
function
can be called from other Python code. It can also be converted to an HTTP endpoint
for invocation over the Internet by any client.
For details, see
this guide
As a quick demo, we’ve included some sample chat client code in the
Python main entrypoint below. To use it, first deploy with
modal
deploy
trtllm_latency.py
Copy
and then run the client with
python trtllm_latency.py
Copy
__name__
"__main__"
import
Model = modal.Cls.from_name(
"trtllm-latency"
"Model"
print
"🏎️  connecting to model"
model = Model(
mode
=sys.argv[
(sys.argv) >
else
"fast"
model.boot.remote()
except
modal.exception.NotFoundError
raise
SystemError
"Deploy this app first with modal deploy"
from
print
"🏎️  starting chat. exit with :q, ctrl+C, or ctrl+D"
prompt = []
while
(nxt :=
input
"🏎️  > "
)) !=
":q"
prompt.append({
"role"
"user"
"content"
: nxt})
resp =
model.generate_async.remote_gen(prompt):
print
(out,
flush
True
resp += out
print
prompt.append({
"role"
"assistant"
"content"
: resp})
except
KeyboardInterrupt
pass
except
SystemExit
pass
finally
print
sys.exit(
Copy
Serve an interactive language model app with latency-optimized TensorRT-LLM (LLaMA 3 8B)
Overview
What is a TRT-LLM engine?
Installing TensorRT-LLM
Downloading the model
Setting up the engine
Quantization
Configure plugins
Configure speculative decoding
Set the build config
Serving inference under the Doherty Threshold
Calling our inference function
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/llm-serving/trtllm_latency.py
Copy

=== DOC: 025_examples_image_to_video.txt ===
URL: https://modal.com/docs/examples/image_to_video
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Animate images with Lightricks LTX-Video via CLI, API, and web UI
This example shows how to run
LTX-Video
on Modal
to generate videos from your local command line, via an API, and in a web UI.
Generating a 5 second video takes ~1 minute from cold start.
Once the container is warm, a 5 second video takes ~15 seconds.
Here is a sample we generated:
Basic setup
import
import
random
import
time
from
pathlib
import
Path
from
typing
import
Annotated, Optional
import
fastapi
import
modal
Copy
All Modal programs need an
an object that acts as a recipe for the application.
app = modal.App(
"example-image-to-video"
Copy
Configuring dependencies
The model runs remotely, on Modal’s cloud, which means we need to
define the environment it runs in
Below, we start from a lightweight base Linux image
and then install our system and Python dependencies,
like Hugging Face’s
diffusers
library and
torch
image = (
modal.Image.debian_slim(
python_version
"3.12"
.apt_install(
"python3-opencv"
.pip_install(
"accelerate==1.4.0"
"diffusers==0.32.2"
"fastapi[standard]==0.115.8"
"huggingface-hub[hf_transfer]==0.29.1"
"imageio==2.37.0"
"imageio-ffmpeg==0.6.0"
"opencv-python==4.11.0.86"
"pillow==11.1.0"
"sentencepiece==0.2.0"
"torch==2.6.0"
"torchvision==0.21.0"
"transformers==4.49.0"
Copy
Storing model weights on Modal
We also need the parameters of the model remotely.
They can be loaded at runtime from Hugging Face,
based on a repository ID and a revision (aka a commit SHA).
MODEL_ID =
"Lightricks/LTX-Video"
MODEL_REVISION_ID =
"a6d59ee37c13c58261aa79027d3e41cd41960925"
Copy
Hugging Face will also cache the weights to disk once they’re downloaded.
But Modal Functions are serverless, and so even disks are ephemeral,
which means the weights would get re-downloaded every time we spin up a new instance.
We can fix this — without any modifications to Hugging Face’s model loading code! —
by pointing the Hugging Face cache at a
Modal Volume
model_volume = modal.Volume.from_name(
"hf-hub-cache"
create_if_missing
True
MODEL_PATH =
"/models"
# where the Volume will appear on our Functions' filesystems
image = image.env(
"HF_HUB_ENABLE_HF_TRANSFER"
# faster downloads
"HF_HUB_CACHE"
: MODEL_PATH,
Copy
Storing model outputs on Modal
Contemporary video models can take a long time to run and they produce large outputs.
That makes them a great candidate for storage on Modal Volumes as well.
Python code running outside of Modal can also access this storage, as we’ll see below.
OUTPUT_PATH =
"/outputs"
output_volume = modal.Volume.from_name(
"outputs"
create_if_missing
True
Copy
Implementing LTX-Video inference on Modal
We wrap the inference logic in a Modal
that ensures models are loaded and then moved to the GPU once when a new instance
starts, rather than every time we run it.
function just wraps a
diffusers
pipeline.
It saves the generated video to a Modal Volume, and returns the filename.
We also include a
wrapper that makes it possible
to trigger inference via an API call.
For details, see the
/docs
route of the URL ending in
inference-web.modal.run
that appears when you deploy the app.
with
image.imports():
# loaded on all of our remote Functions
import
diffusers
import
torch
from
import
Image
MINUTES =
@app.cls
image
=image,
"H100"
timeout
* MINUTES,
scaledown_window
* MINUTES,
volumes
={MODEL_PATH: model_volume, OUTPUT_PATH: output_volume},
class
Inference
@modal.enter
load_pipeline
self
self
.pipe = diffusers.LTXImageToVideoPipeline.from_pretrained(
MODEL_ID,
revision
=MODEL_REVISION_ID,
torch_dtype
=torch.bfloat16,
).to(
"cuda"
@modal.method
self
image_bytes
bytes
prompt
negative_prompt
: Optional[
None
num_frames
: Optional[
None
num_inference_steps
: Optional[
None
seed
: Optional[
None
) ->
negative_prompt = (
negative_prompt
"worst quality, inconsistent motion, blurry, jittery, distorted"
width =
height =
num_frames = num_frames
num_inference_steps = num_inference_steps
seed = seed
random.randint(
print
"Seeding RNG with:
seed
torch.manual_seed(seed)
image = diffusers.utils.load_image(Image.open(io.BytesIO(image_bytes)))
video =
self
.pipe(
image
=image,
prompt
=prompt,
negative_prompt
=negative_prompt,
width
=width,
height
=height,
num_frames
=num_frames,
num_inference_steps
=num_inference_steps,
).frames[
mp4_name = (
seed
.join(c
c.isalnum()
else
prompt[:
.mp4"
diffusers.utils.export_to_video(
video,
Path(OUTPUT_PATH) / mp4_name
output_volume.commit()
torch.cuda.empty_cache()
# reduce fragmentation
return
mp4_name
@modal.fastapi_endpoint
method
"POST"
docs
True
self
image_bytes
: Annotated[
bytes
, fastapi.File()],
prompt
negative_prompt
: Optional[
None
num_frames
: Optional[
None
num_inference_steps
: Optional[
None
seed
: Optional[
None
) -> fastapi.Response:
mp4_name =
self
.run.local(
# run in the same container
image_bytes
=image_bytes,
prompt
=prompt,
negative_prompt
=negative_prompt,
num_frames
=num_frames,
num_inference_steps
=num_inference_steps,
seed
=seed,
return
fastapi.responses.FileResponse(
path
Path(OUTPUT_PATH) / mp4_name
media_type
"video/mp4"
filename
=mp4_name,
Copy
Generating videos from the command line
We add a
local entrypoint
that calls the
Inference.run
method to run inference from the command line.
The function’s parameters are automatically turned into a CLI.
Run it with
modal
image_to_video.py
--prompt
"A cat looking out the window at a snowy mountain"
--image-path
/path/to/cat.jpg
Copy
You can also pass
--help
to see the full list of arguments.
@app.local_entrypoint
entrypoint
image_path
prompt
negative_prompt
: Optional[
None
num_frames
: Optional[
None
num_inference_steps
: Optional[
None
seed
: Optional[
None
twice
bool
True
import
import
urllib.request
print
"🎥 Generating a video from the image at
image_path
print
"🎥 using the prompt
prompt
image_path.startswith((
"http://"
"https://"
image_bytes = urllib.request.urlopen(image_path).read()
elif
os.path.isfile(image_path):
image_bytes = Path(image_path).read_bytes()
else
raise
ValueError
image_path
is not a valid file or URL."
inference_service = Inference()
range
+ twice):
start = time.time()
mp4_name = inference_service.run.remote(
image_bytes
=image_bytes,
prompt
=prompt,
negative_prompt
=negative_prompt,
num_frames
=num_frames,
seed
=seed,
duration = time.time() - start
print
"🎥 Generated video in
duration
:.3f}
output_dir = Path(
"/tmp/image_to_video"
output_dir.mkdir(
exist_ok
True
parents
True
output_path = output_dir / mp4_name
# read in the file from the Modal Volume, then write it to the local disk
output_path.write_bytes(
.join(output_volume.read_file(mp4_name)))
print
"🎥 Video saved to
output_path
Copy
Generating videos via an API
The Modal
above also included a
fastapi_endpoint
which adds a simple web API to the inference method.
To try it out, run
modal
deploy
image_to_video.py
Copy
copy the printed URL ending in
inference-web.modal.run
and add
/docs
to the end. This will bring up the interactive
Swagger/OpenAPI docs for the endpoint.
Generating videos in a web UI
Lastly, we add a simple front-end web UI (written in Alpine.js) for
our image to video backend.
This is also deployed when you run
modal
deploy
image_to_video.py.
Copy
Inference
class will serve multiple users from its own auto-scaling pool of warm GPU containers automatically,
and they will spin down when there are no requests.
frontend_path = Path(
__file__
).parent /
"frontend"
web_image = (
modal.Image.debian_slim(
python_version
"3.12"
.pip_install(
"jinja2==3.1.5"
"fastapi[standard]==0.115.8"
.add_local_dir(
# mount frontend/client code
frontend_path,
remote_path
"/assets"
@app.function
image
=web_image)
@modal.concurrent
max_inputs
1000
@modal.asgi_app
import
fastapi.staticfiles
import
fastapi.templating
web_app = fastapi.FastAPI()
templates = fastapi.templating.Jinja2Templates(
directory
"/assets"
@web_app.get
async
read_root
request
: fastapi.Request):
return
templates.TemplateResponse(
"index.html"
"request"
: request,
"inference_url"
: Inference().web.get_web_url(),
"model_name"
"LTX-Video Image to Video"
"default_prompt"
"A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background."
web_app.mount(
"/static"
fastapi.staticfiles.StaticFiles(
directory
"/assets"
name
"static"
return
web_app
Copy
Animate images with Lightricks LTX-Video via CLI, API, and web UI
Basic setup
Configuring dependencies
Storing model weights on Modal
Storing model outputs on Modal
Implementing LTX-Video inference on Modal
Generating videos from the command line
Generating videos via an API
Generating videos in a web UI
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/image-to-video/image_to_video.py
--prompt
'A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background.'
--image-path
https
//modal-cdn.com/example_image_to_video_image.png
Copy

=== DOC: 026_reference_modal_App.txt ===
URL: https://modal.com/docs/reference/modal.App
Changelog
API Reference
modal.App
modal.Client
modal.CloudBucketMount
modal.Cls
modal.Cron
modal.Dict
modal.Error
modal.FilePatternMatcher
modal.Function
modal.FunctionCall
modal.Image
modal.NetworkFileSystem
modal.Period
modal.Proxy
modal.Queue
modal.Retries
modal.Sandbox
modal.SandboxSnapshot
modal.Secret
modal.Tunnel
modal.Volume
modal.asgi_app
modal.batched
modal.call_graph
modal.concurrent
modal.container_process
modal.current_function_call_id
modal.current_input_id
modal.enable_output
modal.enter
modal.exit
modal.fastapi_endpoint
modal.file_io
modal.forward
modal.gpu
modal.interact
modal.io_streams
modal.is_local
modal.method
modal.parameter
modal.web_endpoint
modal.web_server
modal.wsgi_app
modal.exception
modal.config
CLI Reference
modal app
modal config
modal container
modal deploy
modal dict
modal environment
modal launch
modal nfs
modal profile
modal queue
modal run
modal secret
modal serve
modal setup
modal shell
modal token
modal volume
modal.App
class
object
Copy
A Modal App is a group of functions and classes that are deployed together.
The app serves at least three purposes:
A unit of deployment for functions and classes.
Syncing of identities of (primarily) functions and classes across processes
(your local Python interpreter and every Modal container active in your application).
Manage log collection for everything that happens inside your code.
Registering functions with an app
The most common way to explicitly register an Object with an app is through the
@app.function()
decorator. It both registers the annotated function itself and
other passed objects, like schedules and secrets, with the app:
import
modal
app = modal.App()
@app.function
secrets
=[modal.Secret.from_name(
"some_secret"
schedule
=modal.Period(
days
pass
Copy
In this example, the secret and schedule are registered with the app.
__init__
self
name
: Optional[
None
image
: Optional[_Image] =
None
# default image for all functions (default is `modal.Image.debian_slim()`)
secrets
: Sequence[_Secret] = [],
# default secrets for all functions
volumes
: dict[Union[
, PurePosixPath], _Volume] = {},
# default volumes for all functions
include_source
: Optional[
bool
None
) ->
None
Copy
Construct a new app, optionally with default image, mounts, secrets, or volumes.
image = modal.Image.debian_slim().pip_install(...)
secret = modal.Secret.from_name(
"my-secret"
volume = modal.Volume.from_name(
"my-data"
app = modal.App(
image
=image,
secrets
=[secret],
volumes
"/mnt/data"
: volume})
Copy
name
property
name
self
) -> Optional[
Copy
The user-provided name of the App.
is_interactive
property
is_interactive
self
) ->
bool
Copy
Whether the current app for the app is running in interactive mode.
app_id
property
app_id
self
) -> Optional[
Copy
Return the app_id of a running or stopped app.
description
property
description
self
) -> Optional[
Copy
The App’s
name
, if available, or a fallback descriptive identifier.
lookup
staticmethod
lookup
name
client
: Optional[_Client] =
None
environment_name
: Optional[
None
create_if_missing
bool
False
) ->
"_App"
Copy
Look up an App with a given name, creating a new App if necessary.
Note that Apps created through this method will be in a deployed state,
but they will not have any associated Functions or Classes. This method
is mainly useful for creating an App to associate with a Sandbox:
app = modal.App.lookup(
"my-app"
create_if_missing
True
modal.Sandbox.create(
"echo"
"hi"
=app)
Copy
set_description
set_description
self
description
Copy
image
property
image
self
) -> _Image:
Copy
@contextmanager
self
client
: Optional[_Client] =
None
detach
bool
False
interactive
bool
False
environment_name
: Optional[
None
) -> AsyncGenerator[
"_App"
None
Copy
Context manager that runs an ephemeral app on Modal.
Use this as the main entry point for your Modal application. All calls
to Modal Functions should be made within the scope of this context
manager, and they will correspond to the current App.
Example
with
app.run():
some_modal_function.remote()
Copy
To enable output printing (i.e., to see App logs), use
modal.enable_output()
with
modal.enable_output():
with
app.run():
some_modal_function.remote()
Copy
Note that you should not invoke this in global scope of a file where you have
Modal Functions or Classes defined, since that would run the block when the Function
or Cls is imported in your containers as well. If you want to run it as your entrypoint,
consider protecting it:
__name__
"__main__"
with
app.run():
some_modal_function.remote()
Copy
You can then run your script with:
python
app_module.py
Copy
deploy
deploy
self
name
: Optional[
None
# Name for the deployment, overriding any set on the App
environment_name
: Optional[
None
# Environment to deploy the App in
# Optional metadata that will be visible in the deployment history
client
: Optional[_Client] =
None
# Alternate client to use for RPCs
) -> typing_extensions.Self:
Copy
Deploy the App so that it is available persistently.
Deployed Apps will be avaible for lookup or web-based invocations until they are stopped.
Unlike with
App.run
, this method will return as soon as the deployment completes.
This method is a programmatic alternative to the
modal deploy
CLI command.
Examples:
app = App(
"my-app"
app.deploy()
Copy
To enable output printing (i.e., to see build logs), use
modal.enable_output()
app = App(
"my-app"
with
modal.enable_output():
app.deploy()
Copy
Unlike with
App.run
, Function logs will not stream back to the local client after the
App is deployed.
Note that you should not invoke this method in global scope, as that would redeploy
the App every time the file is imported. If you want to write a programmatic deployment
script, protect this call so that it only runs when the file is executed directly:
__name__
"__main__"
with
modal.enable_output():
app.deploy()
Copy
Then you can deploy your app with:
python
app_module.py
Copy
registered_functions
property
registered_functions
self
) -> dict[
, _Function]:
Copy
All modal.Function objects registered on the app.
registered_classes
property
registered_classes
self
) -> dict[
, _Cls]:
Copy
All modal.Cls objects registered on the app.
registered_entrypoints
property
registered_entrypoints
self
) -> dict[
, _LocalEntrypoint]:
Copy
All local CLI entrypoints registered on the app.
registered_web_endpoints
property
registered_web_endpoints
self
) -> list[
Copy
Names of web endpoint (ie. webhook) functions registered on the app.
local_entrypoint
local_entrypoint
self
_warn_parentheses_missing
: Any =
None
, *,
name
: Optional[
None
) -> Callable[[Callable[..., Any]], _LocalEntrypoint]:
Copy
Decorate a function to be used as a CLI entrypoint for a Modal App.
These functions can be used to define code that runs locally to set up the app,
and act as an entrypoint to start Modal functions from. Note that regular
Modal functions can also be used as CLI entrypoints, but unlike
local_entrypoint
those functions are executed remotely directly.
Example
@app.local_entrypoint
main
some_modal_function.remote()
Copy
You can call the function using
modal run
directly from the CLI:
modal
app_module.py
Copy
Note that an explicit
app.run()
is not needed, as an
is automatically created for you.
Multiple Entrypoints
If you have multiple
local_entrypoint
functions, you can qualify the name of your app and function:
modal
app_module.py::app.some_other_function
Copy
Parsing Arguments
If your entrypoint function take arguments with primitive types,
modal run
automatically parses them as
CLI options.
For example, the following function can be called with
modal run app_module.py --foo 1 --bar "hello"
@app.local_entrypoint
main
some_modal_function.call(foo, bar)
Copy
Currently,
float
bool
, and
datetime.datetime
are supported.
modal run app_module.py --help
for more information on usage.
function
@warn_on_renamed_autoscaler_settings
function
self
_warn_parentheses_missing
: Any =
None
image
: Optional[_Image] =
None
# The image to run as the container for the function
schedule
: Optional[Schedule] =
None
# An optional Modal Schedule for the function
secrets
: Sequence[_Secret] = (),
# Optional Modal Secret objects with environment variables for the container
: Union[
GPU_T, list[GPU_T]
None
# GPU request as string ("any", "T4", ...), object (`modal.GPU.A100()`, ...), or a list of either
serialized
bool
False
# Whether to send the function over using cloudpickle.
network_file_systems
: dict[
Union[
, PurePosixPath], _NetworkFileSystem
] = {},
# Mountpoints for Modal NetworkFileSystems
volumes
: dict[
Union[
, PurePosixPath], Union[_Volume, _CloudBucketMount]
] = {},
# Mount points for Modal Volumes & CloudBucketMounts
# Specify, in fractional CPU cores, how many CPU cores to request.
# Or, pass (request, limit) to additionally specify a hard limit in fractional CPU cores.
# CPU throttling will prevent a container from exceeding its specified limit.
: Optional[Union[
float
, tuple[
float
float
]]] =
None
# Specify, in MiB, a memory request which is the minimum memory required.
# Or, pass (request, limit) to additionally specify a hard limit in MiB.
memory
: Optional[Union[
, tuple[
]]] =
None
ephemeral_disk
: Optional[
None
# Specify, in MiB, the ephemeral disk size for the Function.
min_containers
: Optional[
None
# Minimum number of containers to keep warm, even when Function is idle.
max_containers
: Optional[
None
# Limit on the number of containers that can be concurrently running.
buffer_containers
: Optional[
None
# Number of additional idle containers to maintain under active load.
scaledown_window
: Optional[
None
# Max time (in seconds) a container can remain idle while scaling down.
proxy
: Optional[_Proxy] =
None
# Reference to a Modal Proxy to use in front of this function.
retries
: Optional[Union[
, Retries]] =
None
# Number of times to retry each input in case of failure.
timeout
: Optional[
None
# Maximum execution time of the function in seconds.
name
: Optional[
None
# Sets the Modal name of the function within the app
is_generator
: Optional[
bool
None
# Set this to True if it's a non-generator function returning a [sync/async] generator object
cloud
: Optional[
None
# Cloud provider to run the function on. Possible values are aws, gcp, oci, auto.
region
: Optional[Union[
, Sequence[
]]] =
None
# Region or regions to run the function on.
enable_memory_snapshot
bool
False
# Enable memory checkpointing for faster cold starts.
block_network
bool
False
# Whether to block network access
restrict_modal_access
bool
False
# Whether to allow this function access to other Modal resources
# Maximum number of inputs a container should handle before shutting down.
# With `max_inputs = 1`, containers will be single-use.
max_inputs
: Optional[
None
i6pn
: Optional[
bool
None
# Whether to enable IPv6 container networking within the region.
# Whether the function's home package should be included in the image - defaults to True
include_source
: Optional[
bool
None
# When `False`, don't automatically add the App source to the container.
experimental_options
: Optional[dict[
, Any]] =
None
# Parameters below here are experimental. Use with caution!
_experimental_scheduler_placement
: Optional[
SchedulerPlacement
None
# Experimental controls over fine-grained scheduling (alpha).
_experimental_proxy_ip
: Optional[
None
# IP address of proxy
_experimental_custom_scaling_factor
: Optional[
float
None
# Custom scaling factor
_experimental_enable_gpu_snapshot
bool
False
# Experimentally enable GPU memory snapshots.
# Parameters below here are deprecated. Please update your code as suggested
keep_warm
: Optional[
None
# Replaced with `min_containers`
concurrency_limit
: Optional[
None
# Replaced with `max_containers`
container_idle_timeout
: Optional[
None
# Replaced with `scaledown_window`
allow_concurrent_inputs
: Optional[
None
# Replaced with the `@modal.concurrent` decorator
_experimental_buffer_containers
: Optional[
None
# Now stable API with `buffer_containers`
allow_cross_region_volumes
: Optional[
bool
None
# Always True on the Modal backend now
) -> _FunctionDecoratorType:
Copy
Decorator to register a new Modal
Function
with this App.
@typing_extensions.dataclass_transform
field_specifiers
=(parameter,),
kw_only_default
True
@warn_on_renamed_autoscaler_settings
self
_warn_parentheses_missing
: Optional[
bool
None
image
: Optional[_Image] =
None
# The image to run as the container for the function
secrets
: Sequence[_Secret] = (),
# Optional Modal Secret objects with environment variables for the container
: Union[
GPU_T, list[GPU_T]
None
# GPU request as string ("any", "T4", ...), object (`modal.GPU.A100()`, ...), or a list of either
serialized
bool
False
# Whether to send the function over using cloudpickle.
network_file_systems
: dict[
Union[
, PurePosixPath], _NetworkFileSystem
] = {},
# Mountpoints for Modal NetworkFileSystems
volumes
: dict[
Union[
, PurePosixPath], Union[_Volume, _CloudBucketMount]
] = {},
# Mount points for Modal Volumes & CloudBucketMounts
# Specify, in fractional CPU cores, how many CPU cores to request.
# Or, pass (request, limit) to additionally specify a hard limit in fractional CPU cores.
# CPU throttling will prevent a container from exceeding its specified limit.
: Optional[Union[
float
, tuple[
float
float
]]] =
None
# Specify, in MiB, a memory request which is the minimum memory required.
# Or, pass (request, limit) to additionally specify a hard limit in MiB.
memory
: Optional[Union[
, tuple[
]]] =
None
ephemeral_disk
: Optional[
None
# Specify, in MiB, the ephemeral disk size for the Function.
min_containers
: Optional[
None
# Minimum number of containers to keep warm, even when Function is idle.
max_containers
: Optional[
None
# Limit on the number of containers that can be concurrently running.
buffer_containers
: Optional[
None
# Number of additional idle containers to maintain under active load.
scaledown_window
: Optional[
None
# Max time (in seconds) a container can remain idle while scaling down.
proxy
: Optional[_Proxy] =
None
# Reference to a Modal Proxy to use in front of this function.
retries
: Optional[Union[
, Retries]] =
None
# Number of times to retry each input in case of failure.
timeout
: Optional[
None
# Maximum execution time of the function in seconds.
cloud
: Optional[
None
# Cloud provider to run the function on. Possible values are aws, gcp, oci, auto.
region
: Optional[Union[
, Sequence[
]]] =
None
# Region or regions to run the function on.
enable_memory_snapshot
bool
False
# Enable memory checkpointing for faster cold starts.
block_network
bool
False
# Whether to block network access
restrict_modal_access
bool
False
# Whether to allow this class access to other Modal resources
# Limits the number of inputs a container handles before shutting down.
# Use `max_inputs = 1` for single-use containers.
max_inputs
: Optional[
None
include_source
: Optional[
bool
None
# When `False`, don't automatically add the App source to the container.
experimental_options
: Optional[dict[
, Any]] =
None
# Parameters below here are experimental. Use with caution!
_experimental_scheduler_placement
: Optional[
SchedulerPlacement
None
# Experimental controls over fine-grained scheduling (alpha).
_experimental_proxy_ip
: Optional[
None
# IP address of proxy
_experimental_custom_scaling_factor
: Optional[
float
None
# Custom scaling factor
_experimental_enable_gpu_snapshot
bool
False
# Experimentally enable GPU memory snapshots.
# Parameters below here are deprecated. Please update your code as suggested
keep_warm
: Optional[
None
# Replaced with `min_containers`
concurrency_limit
: Optional[
None
# Replaced with `max_containers`
container_idle_timeout
: Optional[
None
# Replaced with `scaledown_window`
allow_concurrent_inputs
: Optional[
None
# Replaced with the `@modal.concurrent` decorator
_experimental_buffer_containers
: Optional[
None
# Now stable API with `buffer_containers`
allow_cross_region_volumes
: Optional[
bool
None
# Always True on the Modal backend now
) -> Callable[[Union[CLS_T, _PartialFunction]], CLS_T]:
Copy
Decorator to register a new Modal
with this App.
include
include
self
, /,
other_app
"_App"
) -> typing_extensions.Self:
Copy
Include another App’s objects in this one.
Useful for splitting up Modal Apps across different self-contained files.
app_a = modal.App(
@app.function
app_b = modal.App(
@app.function
app_a.include(app_b)
@app_a.local_entrypoint
main
# use function declared on the included app
bar.remote()
Copy
modal.App
name
is_interactive
app_id
description
lookup
set_description
image
deploy
registered_functions
registered_classes
registered_entrypoints
registered_web_endpoints
local_entrypoint
function
include

=== DOC: 027_examples_s3_bucket_mount.txt ===
URL: https://modal.com/docs/examples/s3_bucket_mount
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Analyze NYC yellow taxi data with DuckDB on Parquet files from S3
This example shows how to use Modal for a classic data science task: loading table-structured data into cloud stores,
analyzing it, and plotting the results.
In particular, we’ll load public NYC taxi ride data into S3 as Parquet files,
then run SQL queries on it with DuckDB.
We’ll mount the S3 bucket in a Modal app with
CloudBucketMount
We will write to and then read from that bucket, in each case using
Modal’s
parallel execution features
to handle many files at once.
Basic setup
You will need to have an S3 bucket and AWS credentials to run this example. Refer to the documentation
for the exact
IAM permissions
your credentials will need.
After you are done creating a bucket and configuring IAM settings,
you now need to create a
Secret
to share
the relevant AWS credentials with your Modal apps.
from
datetime
import
datetime
from
pathlib
import
Path, PosixPath
import
modal
image = modal.Image.debian_slim(
python_version
"3.12"
).pip_install(
"requests==2.31.0"
"duckdb==0.10.0"
"matplotlib==3.8.3"
app = modal.App(
image
=image)
secret = modal.Secret.from_name(
"s3-bucket-secret"
required_keys
"AWS_ACCESS_KEY_ID"
"AWS_SECRET_ACCESS_KEY"
MOUNT_PATH = PosixPath(
"/bucket"
YELLOW_TAXI_DATA_PATH = MOUNT_PATH /
"yellow_taxi"
Copy
The dependencies installed above are not available locally. The following block instructs Modal
to only import them inside the container.
with
image.imports():
import
duckdb
import
requests
Copy
Download New York City’s taxi data
NYC makes data about taxi rides publicly available. The city’s
Taxi & Limousine Commission (TLC)
publishes files in the Parquet format. Files are organized by year and month.
We are going to download all available files and store them in an S3 bucket. We do this by
attaching a
modal.CloudBucketMount
with the S3 bucket name and its respective credentials.
The files in the bucket will then be available at
MOUNT_PATH
As we’ll see below, this operation can be massively sped up by running it in parallel on Modal.
@app.function
volumes
MOUNT_PATH: modal.CloudBucketMount(
"modal-s3mount-test-bucket"
secret
=secret),
download_data
year
month
) ->
filename =
"yellow_tripdata_
year
month
:02d}
.parquet"
url =
"https://d37ci6vzurychx.cloudfront.net/trip-data/
filename
s3_path = MOUNT_PATH / filename
# Skip downloading if file exists.
s3_path.exists():
YELLOW_TAXI_DATA_PATH.exists():
YELLOW_TAXI_DATA_PATH.mkdir(
parents
True
exist_ok
True
with
requests.get(url,
stream
True
r.raise_for_status()
print
"downloading =>
s3_path
# It looks like we writing locally, but this is actually writing to S3!
with
open
(s3_path,
"wb"
file:
chunk
r.iter_content(
chunk_size
8192
file.write(chunk)
return
s3_path.as_posix()
Copy
Analyze data with DuckDB
DuckDB
is an analytical database with rich support for Parquet files.
It is also very fast. Below, we define a Modal Function that aggregates yellow taxi trips
within a month (each file contains all the rides from a specific month).
@app.function
volumes
MOUNT_PATH: modal.CloudBucketMount(
"modal-s3mount-test-bucket"
secret
=modal.Secret.from_name(
"s3-bucket-secret"
aggregate_data
path
) -> list[tuple[datetime,
print
"processing =>
path
# Parse file.
year_month_part = path.split(
"yellow_tripdata_"
year, month = year_month_part.split(
month = month.replace(
".parquet"
# Make DuckDB query using in-memory storage.
con = duckdb.connect(
database
":memory:"
with sub as (
select tpep_pickup_datetime::date d, count(1) c
from read_parquet(?)
group by 1
select d, c from sub
where date_part('year', d) = ?  -- filter out garbage
and date_part('month', d) = ?   -- same
con.execute(q, (path, year, month))
return
list
(con.fetchall())
Copy
Plot daily taxi rides
Finally, we want to plot our results.
The plot created shows the number of yellow taxi rides per day in NYC.
This function runs remotely, on Modal, so we don’t need to install plotting libraries locally.
@app.function
plot
dataset
) ->
bytes
import
import
matplotlib.pyplot
# Sorting data by date
dataset.sort(
lambda
: x[
# Unpacking dates and values
dates, values =
(*dataset)
# Plotting
plt.figure(
figsize
plt.plot(dates, values)
plt.title(
"Number of NYC yellow taxi trips by weekday, 2018-2023"
plt.ylabel(
"Number of daily trips"
plt.grid(
True
plt.tight_layout()
# Saving plot as raw bytes to send back
buf = io.BytesIO()
plt.savefig(buf,
format
"png"
buf.seek(
return
buf.getvalue()
Copy
Run everything
@app.local_entrypoint()
defines what happens when we run our Modal program locally.
We invoke it from the CLI by calling
modal run s3_bucket_mount.py
We first call
download_data()
starmap
(named because it’s kind of like
map(*args)
on tuples of inputs
(year, month)
. This will download, in parallel,
all yellow taxi data files into our locally mounted S3 bucket and return a list of
Parquet file paths. Then, we call
aggregate_data()
with
on that list. These files are
also read from our S3 bucket. So one function writes files to S3 and the other
reads files from S3 in; both run across many files in parallel.
Finally, we call
plot
to generate the following figure:
This program should run in less than 30 seconds.
@app.local_entrypoint
main
# List of tuples[year, month].
inputs = [(year, month)
year
range
2018
2023
month
range
# List of file paths in S3.
parquet_files: list[
] = []
path
download_data.starmap(inputs):
print
"done =>
path
parquet_files.append(path)
# List of datetimes and number of yellow taxi trips.
dataset = []
aggregate_data.map(parquet_files):
dataset += r
= Path(
"/tmp"
"s3_bucket_mount"
.exists():
.mkdir(
exist_ok
True
parents
True
figure = plot.remote(dataset)
path =
"nyc_yellow_taxi_trips_s3_mount.png"
with
open
(path,
"wb"
file:
print
"Saving figure to
path
file.write(figure)
Copy
Analyze NYC yellow taxi data with DuckDB on Parquet files from S3
Basic setup
Download New York City’s taxi data
Analyze data with DuckDB
Plot daily taxi rides
Run everything
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
10_integrations/s3_bucket_mount.py
Copy

=== DOC: 028_examples_vllm_inference.txt ===
URL: https://modal.com/docs/examples/vllm_inference
Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Run OpenAI-compatible LLM inference with LLaMA 3.1-8B and vLLM
LLMs do more than just model language: they chat, they produce JSON and XML, they run code, and more.
This has complicated their interface far beyond “text-in, text-out”.
OpenAI’s API has emerged as a standard for that interface,
and it is supported by open source LLM serving frameworks like
vLLM
In this example, we show how to run a vLLM server in OpenAI-compatible mode on Modal.
Our examples repository also includes scripts for running clients and load-testing for OpenAI-compatible APIs
here
You can find a (somewhat out-of-date) video walkthrough of this example and the related scripts on the Modal YouTube channel
here
Set up the container image
Our first order of business is to define the environment our server will run in:
container
Image
vLLM can be installed with
, since Modal
provides the CUDA drivers
To take advantage of optimized kernels for CUDA 12.8, we install PyTorch, flashinfer, and their dependencies
via an
extra
Python package index.
import
json
from
typing
import
import
aiohttp
import
modal
vllm_image = (
modal.Image.debian_slim(
python_version
"3.12"
.pip_install(
"vllm==0.9.1"
"huggingface_hub[hf_transfer]==0.32.0"
"flashinfer-python==0.2.6.post1"
extra_index_url
"https://download.pytorch.org/whl/cu128"
.env({
"HF_HUB_ENABLE_HF_TRANSFER"
# faster model transfers
Copy
Download the model weights
We’ll be running a pretrained foundation model — Meta’s LLaMA 3.1 8B
in the Instruct variant that’s trained to chat and follow instructions.
Model parameters are often quantized to a lower precision during training
than they are run at during inference.
We’ll use an eight bit floating point quantization from Neural Magic/Red Hat.
Native hardware support for FP8 formats in
Tensor Cores
is limited to the latest
Streaming Multiprocessor architectures
like those of Modal’s
Hopper H100/H200 and Blackwell B200 GPUs
You can swap this model out for another by changing the strings below.
A single B200 GPUs has enough VRAM to store a 70,000,000,000 parameter model,
like Llama 3.3, in eight bit precision, along with a very large KV cache.
MODEL_NAME =
"RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8"
MODEL_REVISION =
"12fd6884d2585dd4d020373e7f39f74507b31866"
# avoid nasty surprises when repos update!
Copy
Although vLLM will download weights from Hugging Face on-demand,
we want to cache them so we don’t do it every time our server starts.
We’ll use
Modal Volumes
for our cache.
Modal Volumes are essentially a “shared disk” that all Modal Functions can access like it’s a regular disk.
hf_cache_vol = modal.Volume.from_name(
"huggingface-cache"
create_if_missing
True
Copy
We’ll also cache some of vLLM’s JIT compilation artifacts in a Modal Volume.
vllm_cache_vol = modal.Volume.from_name(
"vllm-cache"
create_if_missing
True
Copy
Configuring vLLM
The V1 engine
In its 0.7 release, in early 2025, vLLM added a new version of its backend infrastructure,
V1 Engine
Using this new engine can lead to some
impressive speedups
It was made the default in version 0.8 and is
slated for complete removal by 0.11
in late summer of 2025.
A small number of features, described in the RFC above, may still require the V0 engine prior to removal.
Until deprecation, you can use it by setting the below environment variable to
vllm_image = vllm_image.env({
"VLLM_USE_V1"
Copy
Trading off fast boots and token generation performance
vLLM has embraced dynamic and just-in-time compilation to eke out additional performance without having to write too many custom kernels,
e.g. via the Torch compiler and CUDA graph capture.
These compilation features incur latency at startup in exchange for lowered latency and higher throughput during generation.
We make this trade-off controllable with the
FAST_BOOT
variable below.
FAST_BOOT =
True
Copy
If you’re running an LLM service that frequently scales from 0 (frequent
“cold starts”
then you’ll want to set this to
True
If you’re running an LLM service that usually has multiple replicas running, then set this to
False
for improved performance.
See the code below for details on the parameters that
FAST_BOOT
controls.
For more on the performance you can expect when serving your own LLMs, see
our LLM engine performance benchmarks
Build a vLLM engine and serve it
The function below spawns a vLLM instance listening at port 8000, serving requests to our model.
We wrap it in the
@modal.web_server
decorator
to connect it to the Internet.
The server runs in an independent process, via
subprocess.Popen
, and only starts accepting requests
once the model is spun up and the
serve
function returns.
app = modal.App(
"example-vllm-openai-compatible"
N_GPU =
MINUTES =
# seconds
VLLM_PORT =
8000
@app.function
image
=vllm_image,
"B200:
N_GPU
scaledown_window
* MINUTES,
# how long should we stay up with no requests?
timeout
* MINUTES,
# how long should we wait for container start?
volumes
"/root/.cache/huggingface"
: hf_cache_vol,
"/root/.cache/vllm"
: vllm_cache_vol,
@modal.concurrent
# how many requests can one replica handle? tune carefully!
max_inputs
@modal.web_server
port
=VLLM_PORT,
startup_timeout
* MINUTES)
serve
import
subprocess
cmd = [
"vllm"
"serve"
"--uvicorn-log-level=info"
MODEL_NAME,
"--revision"
MODEL_REVISION,
"--served-model-name"
MODEL_NAME,
"llm"
"--host"
"0.0.0.0"
"--port"
(VLLM_PORT),
# enforce-eager disables both Torch compilation and CUDA graph capture
# default is no-enforce-eager. see the --compilation-config flag for tighter control
cmd += [
"--enforce-eager"
FAST_BOOT
else
"--no-enforce-eager"
# assume multiple GPUs are for splitting up large matrix multiplications
cmd += [
"--tensor-parallel-size"
(N_GPU)]
print
(cmd)
subprocess.Popen(
.join(cmd),
shell
True
Copy
Deploy the server
To deploy the API on Modal, just run
modal
deploy
vllm_inference.py
Copy
This will create a new app on Modal, build the container image for it if it hasn’t been built yet,
and deploy the app.
Interact with the server
Once it is deployed, you’ll see a URL appear in the command line,
something like
https://your-workspace-name--example-vllm-openai-compatible-serve.modal.run
You can find
interactive Swagger UI docs
at the
/docs
route of that URL, i.e.
https://your-workspace-name--example-vllm-openai-compatible-serve.modal.run/docs
These docs describe each route and indicate the expected input and output
and translate requests into
curl
commands.
For simple routes like
/health
, which checks whether the server is responding,
you can even send a request directly from the docs.
To interact with the API programmatically in Python, we recommend the
openai
library.
See the
client.py
script in the examples repository
here
to take it for a spin:
# pip install openai==1.76.0
python
openai_compatible/client.py
Copy
Testing the server
To make it easier to test the server setup, we also include a
local_entrypoint
that does a healthcheck and then hits the server.
If you execute the command
modal
vllm_inference.py
Copy
a fresh replica of the server will be spun up on Modal while
the code below executes on your local machine.
Think of this like writing simple tests inside of the
if __name__ == "__main__"
block of a Python script, but for cloud deployments!
@app.local_entrypoint
async
test
test_timeout
* MINUTES,
content
None
twice
True
url = serve.get_web_url()
system_prompt = {
"role"
"system"
"content"
"You are a pirate who can't help but drop sly reminders that he went to Harvard."
content
None
content =
"Explain the singular value decomposition."
messages = [
# OpenAI chat format
system_prompt,
"role"
"user"
"content"
: content},
async
with
aiohttp.ClientSession(
base_url
=url)
session:
print
"Running health check for server at
async
with
session.get(
"/health"
timeout
=test_timeout -
* MINUTES)
resp:
up = resp.status ==
assert
"Failed health check for server at
print
"Successful health check for server at
print
"Sending messages to
, *messages,
\n\t
await
_send_request(session,
"llm"
, messages)
twice:
messages[
"content"
"You are Jar Jar Binks."
print
"Sending messages to
, *messages,
\n\t
await
_send_request(session,
"llm"
, messages)
async
_send_request
session
: aiohttp.ClientSession,
model
messages
list
) ->
None
# `stream=True` tells an OpenAI-compatible backend to stream chunks
payload: dict[
, Any] = {
"messages"
: messages,
"model"
: model,
"stream"
True
headers = {
"Content-Type"
"application/json"
"Accept"
"text/event-stream"
async
with
session.post(
"/v1/chat/completions"
json
=payload,
headers
=headers,
timeout
* MINUTES
resp:
async
resp.content:
resp.raise_for_status()
# extract new content and stream it
line = raw.decode().strip()
line
line ==
"data: [DONE]"
continue
line.startswith(
"data: "
# SSE prefix
line = line[
"data: "
) :]
chunk = json.loads(line)
assert
chunk[
"object"
] ==
"chat.completion.chunk"
# or something went horribly wrong
print
(chunk[
"choices"
"delta"
"content"
print
Copy
We also include a basic example of a load-testing setup using
locust
in the
load_test.py
script
here
modal
openai_compatible/load_test.py
Copy
Run OpenAI-compatible LLM inference with LLaMA 3.1-8B and vLLM
Set up the container image
Download the model weights
Configuring vLLM
The V1 engine
Trading off fast boots and token generation performance
Build a vLLM engine and serve it
Deploy the server
Interact with the server
Testing the server
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
06_gpu_and_ml/llm-serving/vllm_inference.py
Copy


=== CATEGORY: GETTING_STARTED ===

=== GITHUB: 01_getting_started/get_started.py ===
import modal

app = modal.App("example-get-started")


@app.function()
def square(x):
    print("This code is running on a remote worker!")
    return x**2


@app.local_entrypoint()
def main():
    print("the square is", square.remote(42))


=== GITHUB: 01_getting_started/hello_world.py ===
# # Hello, world!

# This tutorial demonstrates some core features of Modal:

# * You can run functions on Modal just as easily as you run them locally.
# * Running functions in parallel on Modal is simple and fast.
# * Logs and errors show up immediately, even for functions running on Modal.

# ## Importing Modal and setting up

# We start by importing `modal` and creating a `App`.
# We build up this `App` to [define our application](https://modal.com/docs/guide/apps).

import sys

import modal

app = modal.App("example-hello-world")

# ## Defining a function

# Modal takes code and runs it in the cloud.

# So first we've got to write some code.

# Let's write a simple function that takes in an input,
# prints a log or an error to the console,
# and then returns an output.

# To make this function work with Modal, we just wrap it in a decorator,
# [`@app.function`](https://modal.com/docs/reference/modal.App#function).


@app.function()
def f(i):
    if i % 2 == 0:
        print("hello", i)
    else:
        print("world", i, file=sys.stderr)

    return i * i


# ## Running our function locally, remotely, and in parallel

# Now let's see three different ways we can call that function:

# 1. As a regular call on your `local` machine, with `f.local`

# 2. As a `remote` call that runs in the cloud, with `f.remote`

# 3. By `map`ping many copies of `f` in the cloud over many inputs, with `f.map`

# We call `f` in each of these ways inside the `main` function below.


@app.local_entrypoint()
def main():
    # run the function locally
    print(f.local(1000))

    # run the function remotely on Modal
    print(f.remote(1000))

    # run the function in parallel and remotely on Modal
    total = 0
    for ret in f.map(range(200)):
        total += ret

    print(total)


# Enter `modal run hello_world.py` in a shell, and you'll see a Modal app initialize.
# You'll then see the `print`ed logs of
# the `main` function and, mixed in with them, all the logs of `f` as it is run
# locally, then remotely, and then remotely and in parallel.

# That's all triggered by adding the
# [`@app.local_entrypoint`](https://modal.com/docs/reference/modal.App#local_entrypoint)
# decorator on `main`, which defines it as the function to start from locally when we invoke `modal run`.

# ## What just happened?

# When we called `.remote` on `f`, the function was executed
# _in the cloud_, on Modal's infrastructure, not on the local machine.

# In short, we took the function `f`, put it inside a container,
# sent it the inputs, and streamed back the logs and outputs.

# ## But why does this matter?

# Try one of these things next to start seeing the full power of Modal!

# ### You can change the code and run it again

# For instance, change the `print` statement in the function `f`
# to print `"spam"` and `"eggs"` instead and run the app again.
# You'll see that that your new code is run with no extra work from you --
# and it should even run faster!

# Modal's goal is to make running code in the cloud feel like you're
# running code locally. That means no waiting for long image builds when you've just moved a comma,
# no fiddling with container image pushes, and no context-switching to a web UI to inspect logs.

# ### You can map over more data

# Change the `map` range from `200` to some large number, like `1170`. You'll see
# Modal create and run even more containers in parallel this time.

# And it'll happen lightning fast!

# ### You can run a more interesting function

# The function `f` is a bit silly and doesn't do much, but in its place
# imagine something that matters to you, like:

# * Running [language model inference](https://modal.com/docs/examples/vllm_inference)
# or [fine-tuning](https://modal.com/docs/examples/slack-finetune)
# * Manipulating [audio](https://modal.com/docs/examples/musicgen)
# or [images](https://modal.com/docs/examples/diffusers_lora_finetune)
# * [Embedding huge text datasets](https://modal.com/docs/examples/amazon_embeddings) at lightning fast speeds

# Modal lets you parallelize that operation effortlessly by running hundreds or
# thousands of containers in the cloud.


=== GITHUB: 01_getting_started/generators.py ===
# # Run a generator function on Modal

# This example shows how you can run a generator function on Modal. We define a
# function that `yields` values and then call it with the [`remote_gen`](https://modal.com/docs/reference/modal.Function#remote_gen) method. The
# `remote_gen` method returns a generator object that can be used to iterate over
# the values produced by the function.

import modal

app = modal.App("example-generators")


@app.function()
def f(i):
    for j in range(i):
        yield j


@app.local_entrypoint()
def main():
    for r in f.remote_gen(10):
        print(r)



=== CATEGORY: CONTAINERS ===

=== GITHUB: 02_building_containers/import_sklearn.py ===
# # Install scikit-learn in a custom image
#
# This builds a custom image which installs the sklearn (scikit-learn) Python package in it.
# It's an example of how you can use packages, even if you don't have them installed locally.
#
# First, the imports

import time

import modal

# Next, define an app, with a custom image that installs `sklearn`.

app = modal.App(
    "import-sklearn",
    image=modal.Image.debian_slim().apt_install("libgomp1").pip_install("scikit-learn"),
)

# The `app.image.imports()` lets us conditionally import in the global scope.
# This is needed because we might not have sklearn and numpy installed locally,
# but we know they are installed inside the custom image.

with app.image.imports():
    import numpy as np
    from sklearn import datasets, linear_model

# Now, let's define a function that uses one of scikit-learn's built-in datasets
# and fits a very simple model (linear regression) to it


@app.function()
def fit():
    print("Inside run!")
    t0 = time.time()
    diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)
    diabetes_X = diabetes_X[:, np.newaxis, 2]
    regr = linear_model.LinearRegression()
    regr.fit(diabetes_X, diabetes_y)
    return time.time() - t0


# Finally, let's trigger the run locally. We also time this. Note that the first time we run this,
# it will build the image. This might take 1-2 min. When we run this subsequent times, the image
# is already build, and it will run much much faster.


if __name__ == "__main__":
    t0 = time.time()
    with app.run():
        t = fit.remote()
        print("Function time spent:", t)
    print("Full time spent:", time.time() - t0)


=== GITHUB: 02_building_containers/install_cuda.py ===
# # Installing the CUDA Toolkit on Modal

# This code sample is intended to quickly show how different layers of the CUDA stack are used on Modal.
# For greater detail, see our [guide to using CUDA on Modal](https://modal.com/docs/guide/cuda).

# All Modal Functions with GPUs already have the NVIDIA CUDA drivers,
# NVIDIA System Management Interface, and CUDA Driver API installed.

import modal

app = modal.App("example-install-cuda")


@app.function(gpu="T4")
def nvidia_smi():
    import subprocess

    subprocess.run(["nvidia-smi"], check=True)


# This is enough to install and use many CUDA-dependent libraries, like PyTorch.


@app.function(gpu="T4", image=modal.Image.debian_slim().pip_install("torch"))
def torch_cuda():
    import torch

    print(torch.cuda.get_device_properties("cuda:0"))


# If your application or its dependencies need components of the CUDA toolkit,
# like the `nvcc` compiler driver, installed as system libraries or command-line tools,
# you'll need to install those manually.

# We recommend the official NVIDIA CUDA Docker images from Docker Hub.
# You'll need to add Python 3 and pip with the `add_python` option because the image
# doesn't have these by default.


ctk_image = modal.Image.from_registry(
    "nvidia/cuda:12.4.0-devel-ubuntu22.04", add_python="3.11"
).entrypoint([])  # removes chatty prints on entry


@app.function(gpu="T4", image=ctk_image)
def nvcc_version():
    import subprocess

    return subprocess.run(["nvcc", "--version"], check=True)


# You can check that all these functions run by invoking this script with `modal run`.


@app.local_entrypoint()
def main():
    nvidia_smi.remote()
    torch_cuda.remote()
    nvcc_version.remote()


=== GITHUB: 02_building_containers/install_flash_attn.py ===
# # Install Flash Attention on Modal

# FlashAttention is an optimized CUDA library for Transformer
# scaled-dot-product attention. Dao AI Lab now publishes pre-compiled
# wheels, which makes installation quick.  This script shows how to
# 1. Pin an exact wheel that matches CUDA 12 / PyTorch 2.6 / Python 3.13.
# 2. Build a Modal image that installs torch, numpy, and FlashAttention.
# 3. Launch a GPU function to confirm the kernel runs on a GPU.

import modal

app = modal.App("example-install-flash-attn")

# You need to specify an exact release wheel. You can find
# [more on their github](https://github.com/Dao-AILab/flash-attention/releases).

flash_attn_release = (
    "https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/"
    "flash_attn-2.7.4.post1+cu12torch2.6cxx11abiFALSE-cp313-cp313-linux_x86_64.whl"
)

image = modal.Image.debian_slim(python_version="3.13").pip_install(
    "torch==2.6.0", "numpy==2.2.4", flash_attn_release
)


# And here is a demo verifying that it works:


@app.function(gpu="L40S", image=image)
def run_flash_attn():
    import torch
    from flash_attn import flash_attn_func

    batch_size, seqlen, nheads, headdim, nheads_k = 2, 4, 3, 16, 3

    q = torch.randn(batch_size, seqlen, nheads, headdim, dtype=torch.float16).to("cuda")
    k = torch.randn(batch_size, seqlen, nheads_k, headdim, dtype=torch.float16).to(
        "cuda"
    )
    v = torch.randn(batch_size, seqlen, nheads_k, headdim, dtype=torch.float16).to(
        "cuda"
    )

    out = flash_attn_func(q, k, v)
    assert out.shape == (batch_size, seqlen, nheads, headdim)


=== GITHUB: 02_building_containers/urls.txt ===
adobe.com
alibaba.com
aliexpress.com
amazon.com
apple.com
baidu.com
bbc.co.uk
bing.com
blogspot.com
booking.com
craigslist.org
dailymail.co.uk
dropbox.com
ebay.com
facebook.com
github.com
google.com
imdb.com
imgur.com
instagram.com


=== GITHUB: 02_building_containers/screenshot.py ===
# # Screenshot with Chromium

# In this example, we use Modal functions and the `playwright` package to take screenshots
# of websites from a list of URLs in parallel.

# You can run this example on the command line with

# ```
# modal run 02_building_containers/screenshot.py --url 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'
# ```

# This should take a few seconds then create a `/tmp/screenshots/screenshot.png` file, shown below.

# ![screenshot](./screenshot.png)

# ## Setup

# First we import the Modal client library.

import pathlib

import modal

app = modal.App("example-screenshot")

# ## Define a custom image

# We need an image with the `playwright` Python package as well as its `chromium` plugin pre-installed.
# This requires intalling a few Debian packages, as well as setting up a new Debian repository.
# Modal lets you run arbitrary commands, just like in Docker:


image = modal.Image.debian_slim(python_version="3.12").run_commands(
    "apt-get update",
    "apt-get install -y software-properties-common",
    "apt-add-repository non-free",
    "apt-add-repository contrib",
    "pip install playwright==1.42.0",
    "playwright install-deps chromium",
    "playwright install chromium",
)

# ## The screenshot function

# Next, the scraping function which runs headless Chromium, goes to a website, and takes a screenshot.
# This is a Modal function which runs inside the remote container.


@app.function(image=image)
async def screenshot(url):
    from playwright.async_api import async_playwright

    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.goto(url, wait_until="networkidle")
        await page.screenshot(path="screenshot.png")
        await browser.close()
        data = open("screenshot.png", "rb").read()
        print("Screenshot of size %d bytes" % len(data))
        return data


# ## Entrypoint code

# Let's kick it off by reading a bunch of URLs from a txt file and scrape some of those.


@app.local_entrypoint()
def main(url: str = "https://modal.com"):
    filename = pathlib.Path("/tmp/screenshots/screenshot.png")
    data = screenshot.remote(url)
    filename.parent.mkdir(exist_ok=True)
    with open(filename, "wb") as f:
        f.write(data)
    print(f"wrote {len(data)} bytes to {filename}")


# And we're done! Please also see our
# [introductory guide](https://modal.com/docs/examples/web-scraper)
# for another example of a web scraper, with more in-depth logic.



=== CATEGORY: SCALING ===

=== GITHUB: 03_scaling_out/basic_grid_search.py ===
# # Hyperparameter search
#
# This example showcases a simple grid search in one dimension, where we try different
# parameters for a model and pick the one with the best results on a holdout set.
#
# ## Defining the image
#
# First, let's build a custom image and install scikit-learn in it.

import modal

app = modal.App(
    "example-basic-grid-search",
    image=modal.Image.debian_slim().pip_install("scikit-learn~=1.5.0"),
)

# ## The Modal function
#
# Next, define the function. Note that we use the custom image with scikit-learn in it.
# We also take the hyperparameter `k`, which is how many nearest neighbors we use.


@app.function()
def fit_knn(k):
    from sklearn.datasets import load_digits
    from sklearn.model_selection import train_test_split
    from sklearn.neighbors import KNeighborsClassifier

    X, y = load_digits(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

    clf = KNeighborsClassifier(k)
    clf.fit(X_train, y_train)
    score = float(clf.score(X_test, y_test))
    print("k = %3d, score = %.4f" % (k, score))
    return score, k


# ## Parallel search
#
# To do a hyperparameter search, let's map over this function with different values
# for `k`, and then select for the best score on the holdout set:


@app.local_entrypoint()
def main():
    # Do a basic hyperparameter search
    best_score, best_k = max(fit_knn.map(range(1, 100)))
    print("Best k = %3d, score = %.4f" % (best_k, best_score))


=== GITHUB: 03_scaling_out/dynamic_batching.py ===
# # Dynamic batching for ASCII and character conversion

# This example demonstrates how to dynamically batch a simple
# application that converts ASCII codes to characters and vice versa.

# For more details about using dynamic batching and optimizing
# the batching configurations for your application, see
# the [dynamic batching guide](https://modal.com/docs/guide/dynamic-batching).

# ## Setup

# Let's start by defining the image for the application.

import modal

app = modal.App(
    "example-dynamic-batching-ascii-conversion",
    image=modal.Image.debian_slim(python_version="3.11"),
)


# ## Defining a Batched Function

# Now, let's define a function that converts ASCII codes to characters. This
# async Batched Function allows us to convert up to four ASCII codes at once.


@app.function()
@modal.batched(max_batch_size=4, wait_ms=1000)
async def asciis_to_chars(asciis: list[int]) -> list[str]:
    return [chr(ascii) for ascii in asciis]


# If there are fewer than four ASCII codes in the batch, the Function will wait
# for one second, as specified by `wait_ms`, to allow more inputs to arrive before
# returning the result.

# The input `asciis` to the Function is a list of integers, and the
# output is a list of strings. To allow batching, the input list `asciis`
# and the output list must have the same length.

# You must invoke the Function with an individual ASCII input, and a single
# character will be returned in response.

# ## Defining a class with a Batched Method

# Next, let's define a class that converts characters to ASCII codes. This
# class has an async Batched Method `chars_to_asciis` that converts characters
# to ASCII codes.

# Note that if a class has a Batched Method, it cannot have other Batched Methods
# or Methods.


@app.cls()
class AsciiConverter:
    @modal.batched(max_batch_size=4, wait_ms=1000)
    async def chars_to_asciis(self, chars: list[str]) -> list[int]:
        asciis = [ord(char) for char in chars]
        return asciis


# ## ASCII and character conversion

# Finally, let's define the `local_entrypoint` that uses the Batched Function
# and Class Method to convert ASCII codes to characters and
# vice versa.

# We use [`map.aio`](https://modal.com/docs/reference/modal.Function#map) to asynchronously map
# over the ASCII codes and characters. This allows us to invoke the Batched
# Function and the Batched Method over a range of ASCII codes and characters
# in parallel.
#
# Run this script to see which characters correspond to ASCII codes 33 through 38!


@app.local_entrypoint()
async def main():
    ascii_converter = AsciiConverter()
    chars = []
    async for char in asciis_to_chars.map.aio(range(33, 39)):
        chars.append(char)

    print("Characters:", chars)

    asciis = []
    async for ascii in ascii_converter.chars_to_asciis.map.aio(chars):
        asciis.append(ascii)

    print("ASCII codes:", asciis)



=== CATEGORY: SECRETS ===

=== GITHUB: 04_secrets/db_to_sheet.py ===
# ---
# deploy: true
# ---

# # Write to Google Sheets from Postgres

# In this tutorial, we'll show how to use Modal to schedule a daily report in a spreadsheet on Google Sheets
# that combines data from a PostgreSQL database with data from an external API.

# In particular, we'll extract the city of each user from the database, look up the current weather in that city,
# and then build a count/histogram of how many users are experiencing each type of weather.

# ## Entering credentials

# We begin by setting up some credentials that we'll need in order to access our database and output
# spreadsheet. To do that in a secure manner, we log in to our Modal account on the web and go to
# the [Secrets](https://modal.com/secrets) section.

# ### Database

# First we will enter our database credentials. The easiest way to do this is to click **New
# secret** and select the **Postgres compatible** Secret preset and fill in the requested
# information. Then we press **Next** and name our Secret `postgres-secret` and click **Create**.

# ### Google Sheets/GCP

# We'll now add another Secret for Google Sheets access through Google Cloud Platform. Click **New
# secret** and select the Google Sheets preset.

# In order to access the Google Sheets API, we'll need to create a *Service Account* in Google Cloud
# Platform. You can skip this step if you already have a Service Account json file.

# 1. Sign up to Google Cloud Platform or log in if you haven't
#    ([https://cloud.google.com/](https://cloud.google.com/)).

# 2. Go to [https://console.cloud.google.com/](https://console.cloud.google.com/).

# 3. In the navigation pane on the left, go to **IAM & Admin** > **Service Accounts**.

# 4. Click the **+ CREATE SERVICE ACCOUNT** button.

# 5. Give the service account a suitable name, like "sheet-access-bot". Click **Done**. You don't
#    have to grant it any specific access privileges at this time.

# 6. Click your new service account in the list view that appears and navigate to the **Keys**
#    section.

# 7. Click **Add key** and choose **Create new key**. Use the **JSON** key type and confirm by
#    clicking **Create**.

# 8. A json key file should be downloaded to your computer at this point. Copy the contents of that
#    file and use it as the value for the `SERVICE_ACCOUNT_JSON` field in your new secret.

# We'll name this other Secret `"gsheets-secret"`.

# Now you can access the values of your Secrets from Modal Functions that you annotate with the
# corresponding `modal.Secret`s, e.g.:

import os

import modal

app = modal.App("example-db-to-sheet")


@app.function(secrets=[modal.Secret.from_name("postgres-secret")])
def show_host():
    # automatically filled from the specified secret
    print("Host is " + os.environ["PGHOST"])


# Because these Secrets are Python objects, you can construct and manipulate them in your code.
# We'll do that below by defining a variable to hold our Secret for accessing Postgres

# You can additionally specify

pg_secret = modal.Secret.from_name(
    "postgres-secret",
    required_keys=["PGHOST", "PGPORT", "PGDATABASE", "PGUSER", "PGPASSWORD"],
)


# In order to connect to the database, we'll use the `psycopg2` Python package. To make it available
# to your Modal Function you need to supply it with an `image` argument that tells Modal how to
# build the container image that contains that package. We'll base it off of the `Image.debian_slim` base
# image that's built into Modal, and make sure to install the required binary packages as well as
# the `psycopg2` package itself:

pg_image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("libpq-dev")
    .pip_install("psycopg2~=2.9.9")
)

# Since the default keynames for a **Postgres compatible** secret correspond to the environment
# variables that `psycopg2` looks for, we can now easily connect to the database even without
# explicit credentials in your code. We'll create a simple function that queries the city for each
# user in the `users` table.


@app.function(image=pg_image, secrets=[pg_secret])
def get_db_rows(verbose=True):
    import psycopg2

    conn = psycopg2.connect()  # no explicit credentials needed
    cur = conn.cursor()
    cur.execute("SELECT city FROM users")
    results = [row[0] for row in cur.fetchall()]
    if verbose:
        print(results)
    return results


# Note that we import `psycopg2` inside our function instead of the global scope. This allows us to
# run this Modal Function even from an environment where `psycopg2` is not installed. We can test run
# this function using the `modal run` shell command: `modal run db_to_sheet.py::app.get_db_rows`.

# To run this function, make sure there is a table called `users` in your database with a column called `city`.
# You can populate the table with some example data using the following SQL commands:

# ```sql
# CREATE TABLE users (city TEXT);
# INSERT INTO users VALUES ('Stockholm,,Sweden');
# INSERT INTO users VALUES ('New York,NY,USA');
# INSERT INTO users VALUES ('Tokyo,,Japan');
# ```

# ## Applying Python logic

# For each row in our source data we'll run an online lookup of the current weather using the
# [http://openweathermap.org](http://openweathermap.org) API. To do this, we'll add the API key to
# another Modal Secret. We'll use a custom secret called "weather-secret" with the key
# `OPENWEATHER_API_KEY` containing our API key for OpenWeatherMap.

requests_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "requests~=2.31.0"
)


@app.function(
    image=requests_image,
    secrets=[
        modal.Secret.from_name("weather-secret", required_keys=["OPENWEATHER_API_KEY"])
    ],
)
def city_weather(city):
    import requests

    url = "https://api.openweathermap.org/data/2.5/weather"
    params = {"q": city, "appid": os.environ["OPENWEATHER_API_KEY"]}
    response = requests.get(url, params=params)
    weather_label = response.json()["weather"][0]["main"]
    return weather_label


# We'll make use of Modal's built-in `function.map` method to create our report. `function.map`
# makes it really easy to parallelize work by executing a Function on every element in a sequence of
# data. For this example we'll just do a simple count of rows per weather type --
# answering the question "how many of our users are experiencing each type of weather?".

from collections import Counter


@app.function()
def create_report(cities):
    # run city_weather for each city in parallel
    user_weather = city_weather.map(cities)
    count_users_by_weather = Counter(user_weather).items()
    return count_users_by_weather


# Let's try to run this! To make it simple to trigger the function with some
# predefined input data, we create a "local entrypoint" that can be
# run from the command line with

# ```bash
# modal run db_to_sheet.py
# ```


@app.local_entrypoint()
def main():
    cities = [
        "Stockholm,,Sweden",
        "New York,NY,USA",
        "Tokyo,,Japan",
    ]
    print(create_report.remote(cities))


# Running the local entrypoint using `modal run db_to_sheet.py` should print something like:
# `dict_items([('Clouds', 3)])`.
# Note that since this file only has a single app, and the app has only one local entrypoint
# we only have to specify the file to run it - the function/entrypoint is inferred.

# In this case the logic is quite simple, but in a real world context you could have applied a
# machine learning model or any other tool you could build into a container to transform the data.

# ## Sending output to a Google Sheet

# We'll set up a new Google Sheet to send our report to. Using the "Sharing" dialog in Google
# Sheets, share the document to the service account's email address (the value of the `client_email` field in the json file)
# and make the service account an editor of the document.

# You may also need to enable the Google Sheets API for your project in the Google Cloud Platform console.
# If so, the URL will be printed inside the message of a 403 Forbidden error when you run the function.
# It begins with https://console.developers.google.com/apis/api/sheets.googleapis.com/overview.

# Lastly, we need to point our code to the correct Google Sheet. We'll need the *key* of the document.
# You can find the key in the URL of the Google Sheet. It appears after the `/d/` in the URL, like:
# `https://docs.google.com/spreadsheets/d/1wOktal......IJR77jD8Do`.

# We'll make use of the `pygsheets` python package to authenticate with
# Google Sheets and then update the spreadsheet with information from the report we just created:

pygsheets_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "pygsheets~=2.0.6"
)


@app.function(
    image=pygsheets_image,
    secrets=[
        modal.Secret.from_name("gsheets-secret", required_keys=["SERVICE_ACCOUNT_JSON"])
    ],
)
def update_sheet_report(rows):
    import pygsheets

    gc = pygsheets.authorize(service_account_env_var="SERVICE_ACCOUNT_JSON")
    document_key = "1JxhGsht4wltyPFFOd2hP0eIv6lxZ5pVxJN_ZwNT-l3c"
    sh = gc.open_by_key(document_key)
    worksheet = sh.sheet1
    worksheet.clear("A2")

    worksheet.update_values("A2", [list(row) for row in rows])


# At this point, we have everything we need in order to run the full program. We can put it all together in
# another Modal Function, and add a [`schedule`](https://modal.com/docs/guide/cron) argument so it runs every day automatically:


@app.function(schedule=modal.Period(days=1))
def db_to_sheet():
    rows = get_db_rows.remote()
    report = create_report.remote(rows)
    update_sheet_report.remote(report)
    print("Updated sheet with new weather distribution")
    for weather, count in report:
        print(f"{weather}: {count}")


# This entire app can now be deployed using `modal deploy db_to_sheet.py`. The [apps page](https://modal.com/apps)
# shows our cron job's execution history and lets you navigate to each invocation's logs.
# To trigger a manual run from your local code during development, you can also trigger this function using the cli:
# `modal run db_to_sheet.py::db_to_sheet`

# Note that all of the `@app.function()` annotated functions above run remotely in isolated containers that are specified per
# function, but they are called as seamlessly as if we were using regular Python functions. This is a simple
# showcase of how you can mix and match Modal Functions that use different environments and have them feed
# into each other or even call each other as if they were all functions in the same local program.



=== CATEGORY: SCHEDULING ===

=== GITHUB: 05_scheduling/schedule_simple.py ===
# ---
# cmd: ["python", "-m", "05_scheduling.schedule_simple"]
# ---

# # Scheduling remote jobs

# This example shows how you can schedule remote jobs on Modal.
# You can do this either with:
#
# - [`modal.Period`](https://modal.com/docs/reference/modal.Period) - a time interval between function calls.
# - [`modal.Cron`](https://modal.com/docs/reference/modal.Cron) - a cron expression to specify the schedule.

# In the code below, the first function runs every
# 5 seconds, and the second function runs every minute. We use the `schedule`
# argument to specify the schedule for each function. The `schedule` argument can
# take a `modal.Period` object to specify a time interval or a `modal.Cron` object
# to specify a cron expression.

import time
from datetime import datetime

import modal

app = modal.App("example-schedule-simple")


@app.function(schedule=modal.Period(seconds=5))
def print_time_1():
    print(
        f"Printing with period 5 seconds: {datetime.now().strftime('%m/%d/%Y, %H:%M:%S')}"
    )


@app.function(schedule=modal.Cron("* * * * *"))
def print_time_2():
    print(
        f"Printing with cron every minute: {datetime.now().strftime('%m/%d/%Y, %H:%M:%S')}"
    )


if __name__ == "__main__":
    with modal.enable_output():
        with app.run():
            time.sleep(60)


=== GITHUB: 05_scheduling/hackernews_alerts.py ===
# ---
# lambda-test: false  # missing-secret
# ---

# # Run cron jobs in the cloud to search Hacker News

# In this example, we use Modal to deploy a cron job that periodically queries Hacker News for
# new posts matching a given search term, and posts the results to Slack.

# ## Import and define the app

# Let's start off with imports, and defining a Modal app.

import os
from datetime import datetime, timedelta

import modal

app = modal.App("example-hn-bot")

# Now, let's define an image that has the `slack-sdk` package installed, in which we can run a function
# that posts a slack message.

slack_sdk_image = modal.Image.debian_slim().pip_install("slack-sdk")

# ## Defining the function and importing the secret

# Our Slack bot will need access to a bot token.
# We can use Modal's [Secrets](https://modal.com/secrets) interface to accomplish this.
# To quickly create a Slack bot secret, click the "Create new secret" button.
# Then, select the Slack secret template from the list options,
# and follow the instructions in the "Where to find the credentials?" panel.
# Name your secret `hn-bot-slack.`

# Now, we define the function `post_to_slack`, which simply instantiates the Slack client using our token,
# and then uses it to post a message to a given channel name.


@app.function(
    image=slack_sdk_image,
    secrets=[modal.Secret.from_name("hn-bot-slack", required_keys=["SLACK_BOT_TOKEN"])],
)
async def post_to_slack(message: str):
    import slack_sdk

    client = slack_sdk.WebClient(token=os.environ["SLACK_BOT_TOKEN"])
    client.chat_postMessage(channel="hn-alerts", text=message)


# ## Searching Hacker News

# We are going to use Algolia's [Hacker News Search API](https://hn.algolia.com/api) to query for posts
# matching a given search term in the past X days. Let's define our search term and query period.

QUERY = "serverless"
WINDOW_SIZE_DAYS = 1

# Let's also define an image that has the `requests` package installed, so we can query the API.

requests_image = modal.Image.debian_slim().pip_install("requests")

# We can now define our main entrypoint, that queries Algolia for the term, and calls `post_to_slack`
# on all the results. We specify a [schedule](https://modal.com/docs/guide/cron)
# in the function decorator, which means that our function will run automatically at the given interval.


@app.function(image=requests_image)
def search_hackernews():
    import requests

    url = "http://hn.algolia.com/api/v1/search"

    threshold = datetime.utcnow() - timedelta(days=WINDOW_SIZE_DAYS)

    params = {
        "query": QUERY,
        "numericFilters": f"created_at_i>{threshold.timestamp()}",
    }

    response = requests.get(url, params, timeout=10).json()
    urls = [item["url"] for item in response["hits"] if item.get("url")]

    print(f"Query returned {len(urls)} items.")

    post_to_slack.for_each(urls)


# ## Test running

# We can now test run our scheduled function as follows: `modal run hackernews_alerts.py::app.search_hackernews`

# ## Defining the schedule and deploying

# Let's define a function that will be called by Modal every day


@app.function(schedule=modal.Period(days=1))
def run_daily():
    search_hackernews.remote()


# In order to deploy this as a persistent cron job, you can run `modal deploy hackernews_alerts.py`,

# Once the job is deployed, visit the [apps page](https://modal.com/apps) page to see
# its execution history, logs and other stats.



=== CATEGORY: GPU_ML ===

=== GITHUB: 06_gpu_and_ml/torch_profiling.py ===
# # Tracing and profiling GPU-accelerated PyTorch programs on Modal

# ![A PyTorch trace loaded into ui.perfetto.dev](https://modal-public-assets.s3.amazonaws.com/tmpx_2c9bl5_c5aa7ab0.webp)

# GPUs are high-performance computing devices. For high-performance computing,
# tools for measuring and investigating performance are as critical
# as tools for testing and confirming correctness in typical software.

# In this example, we demonstrate how to wrap a Modal Function with PyTorch's
# built-in profiler, which captures events on both CPUs & GPUs. We also show
# how to host TensorBoard, which includes useful visualizations and
# performance improvement suggestions.

# For a live walkthrough, check out
# [this video on our YouTube channel](https://www.youtube.com/watch?v=4cesQJLyHA8).

# ## Saving traces to a Modal Volume

# Most tracing tools, including PyTorch's profiler, produce results as files on disk.
# Modal Functions run in ephemeral containers in Modal's cloud infrastructure,
# so by default these files disappear as soon as the Function finishes running.

# We can ensure these files persist by saving them to a
# [Modal Volume](https://modal.com/docs/guide/volumes).
# Volumes are a distributed file system: files can be read or written from
# by many machines across a network, in this case from inside any Modal Function.

# To start, we just create a Volume with a specific name.
# We'll also set a particular directory that we'll use for it
# in our Functions below, for convenience.


from pathlib import Path
from typing import Optional

import modal

traces = modal.Volume.from_name("example-traces", create_if_missing=True)
TRACE_DIR = Path("/traces")

# ## Setting up a Modal App with a GPU-accelerated PyTorch Function

# We next set up the Modal Function that we wish to profile.

# In general, we want to attach profiling tools to code that's already in place
# and measure or debug its performance, and then detach it as easily as possible
# so that we can be confident that the same performance characteristics pertain in production.

# In keeping with that workflow, in this example we first define the Modal Function we want to profile,
# without including any of the profiling logic.

# That starts with the Function's environment: the Modal [App](https://modal.com/docs/guide/apps)
# the Function is attached to, the container [Image](https://modal.com/docs/guide/custom-container)
# with the Function's dependencies, and the hardware requirements of the Function, like a
# [GPU](https://modal.com/docs/guide/cuda).


app = modal.App("example-torch-profiling")  # create an App

image = modal.Image.debian_slim(  # define dependencies
    python_version="3.11"
).pip_install("torch==2.5.1", "numpy==2.1.3")

with image.imports():  # set up common imports
    import torch

# Here, we define the config as a dictionary so that we can re-use it here
# and later, when we attach the profiler. We want to make sure the profiler is in the same environment!

config = {"gpu": "a10g", "image": image}

# The Function we target for profiling appears below. It's just some simple PyTorch logic
# that repeatedly multiplies a random matrix with itself.

# The logic is simple, but it demonstrates two common issues with
# GPU-accelerated Python code that are relatively easily fixed:
# 1. Slowing down the issuance of work to the GPU
# 2. Providing insufficient work for the GPU to complete

# We'll cover these in more detail once we have the profiler set up.


@app.function(**config)
def underutilize(scale=1):
    records = []

    x = torch.randn(  # 🐌 2: not enough work to keep the GPU busy
        scale * 100, scale * 100, device="cuda"
    )

    for ii in range(10):
        x = x @ x

        class Record:  # 🐌 1: heavy Python work in the hot loop
            def __init__(self, value):
                self.value = value

        records.append(Record(ii))

    x[0][0].cpu()  # force a host sync for accurate timing


# ## Wrapping a Modal Function with a profiler

# Now, let's wrap our `underutilize` Function with another Modal Function
# that runs PyTorch's profiler while executing it.

# This Function has the same environment `config` as `underutilize`,
# but it also attaches a remote Modal Volume to save profiler outputs.

# To increase the flexibility of this approach, we allow it to take the target Function's name
# as an argument. That's not much use here where there's only one Function,
# but it makes it easier to copy-paste this code into your projects to add profiling.


@app.function(volumes={TRACE_DIR: traces}, **config)
def profile(
    function,
    label: Optional[str] = None,
    steps: int = 3,
    schedule=None,
    record_shapes: bool = False,
    profile_memory: bool = False,
    with_stack: bool = False,
    print_rows: int = 0,
    **kwargs,
):
    from uuid import uuid4

    if isinstance(function, str):
        try:
            function = app.registered_functions[function]
        except KeyError:
            raise ValueError(f"Function {function} not found")
    function_name = function.tag

    output_dir = (
        TRACE_DIR / (function_name + (f"_{label}" if label else "")) / str(uuid4())
    )
    output_dir.mkdir(parents=True, exist_ok=True)

    if schedule is None:
        if steps < 3:
            raise ValueError("Steps must be at least 3 when using default schedule")
        schedule = {"wait": 1, "warmup": 1, "active": steps - 2, "repeat": 0}

    schedule = torch.profiler.schedule(**schedule)

    with torch.profiler.profile(
        activities=[
            torch.profiler.ProfilerActivity.CPU,
            torch.profiler.ProfilerActivity.CUDA,
        ],
        schedule=schedule,
        record_shapes=record_shapes,
        profile_memory=profile_memory,
        with_stack=with_stack,
        on_trace_ready=torch.profiler.tensorboard_trace_handler(output_dir),
    ) as prof:
        for _ in range(steps):
            function.local(**kwargs)  # <-- here we wrap the target Function
            prof.step()

    if print_rows:
        print(
            prof.key_averages().table(sort_by="cuda_time_total", row_limit=print_rows)
        )

    trace_path = sorted(
        output_dir.glob("**/*.pt.trace.json"),
        key=lambda pth: pth.stat().st_mtime,
        reverse=True,
    )[0]

    print(f"trace saved to {trace_path.relative_to(TRACE_DIR)}")

    return trace_path.read_text(), trace_path.relative_to(TRACE_DIR)


# ## Triggering profiled execution from the command line and viewing in Perfetto

# We wrap one more layer to make this executable from the command line:
# a `local_entrypoint` that runs

# ```bash
# modal run torch_profiling.py --function underutilize --print-rows 10
# ```


@app.local_entrypoint()
def main(
    function: str = "underutilize",
    label: Optional[str] = None,
    steps: int = 3,
    schedule=None,
    record_shapes: bool = False,
    profile_memory: bool = False,
    with_stack: bool = False,
    print_rows: int = 10,
    kwargs_json_path: Optional[str] = None,
):
    if kwargs_json_path is not None:  # use to pass arguments to function
        import json

        kwargs = json.loads(Path(kwargs_json_path).read_text())
    else:
        kwargs = {}

    results, remote_path = profile.remote(
        function,
        label=label,
        steps=steps,
        schedule=schedule,
        record_shapes=record_shapes,
        profile_memory=profile_memory,
        with_stack=with_stack,
        print_rows=print_rows,
        **kwargs,
    )

    output_path = Path("/tmp") / remote_path.name
    output_path.write_text(results)
    print(f"trace saved locally at {output_path}")


# Underneath the profile results, you'll also see the path at which the trace was saved on the Volume
# and the path at which it was saved locally.

# You can view the trace in the free online [Perfetto UI](https://ui.perfetto.dev).

# ### Improving the performance of our dummy test code

# The `underutilize` demonstrates two common patterns that leads to unnecessarily low GPU utilization:
# 1. Slowing down the issuance of work to the GPU
# 2. Providing insufficient work for the GPU to complete

# We simulated 1 in `underutilize` by defining a Python class in the middle of the matrix multiplication loop.
# This takes on the order of 10 microseconds, roughly the same time it takes our A10 GPU to do the matrix multiplication.
# Move it out of the loop to observe a small improvement in utilization. In a real setting,
# this code might be useful logging or data processing logic, which we must carefully keep
# out of the way of the code driving work on the GPU.

# We simulated 2 in `underutilize` by providing a matrix that is too small to occupy the GPU for long.
# Increase the size of the matrix by a factor of 4 in each dimension (a factor of 16 total),
# to increase the utilization without increasing the execution time.

# This is an untuitive feature of GPU programming in general: much work is done concurrently
# and bottlenecks are non-obvious, so sometimes more work can be done for free or on the cheap.
# In a server for large generative models, this might mean producing multiple outputs per user
# or handling multiple users at the same time is more economical than it at first seems!

# ## Serving TensorBoard on Modal to view PyTorch profiles and traces

# The TensorBoard experiment monitoring server also includes a plugin
# for viewing and interpreting the results of PyTorch profiler runs:
# the `torch_tb_profiler` plugin.


tb_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "tensorboard==2.18.0", "torch_tb_profiler==0.4.3"
)

# Because TensorBoard is a WSGI app, we can [host it on Modal](https://modal.com/docs/guide/webhooks)
# with the `modal.wsgi_app` decorator.

# Making this work with Modal requires one extra step:
# we add some [WSGI Middleware](https://peps.python.org/pep-3333/) that checks the Modal Volume for updates
# whenever the whole page is reloaded.


class VolumeMiddleware:
    def __init__(self, app):
        self.app = app

    def __call__(self, environ, start_response):
        if (route := environ.get("PATH_INFO")) in ["/", "/modal-volume-reload"]:
            try:
                traces.reload()
            except Exception as e:
                print("Exception while re-loading traces: ", e)
            if route == "/modal-volume-reload":
                environ["PATH_INFO"] = "/"  # redirect
        return self.app(environ, start_response)


# You can deploy the TensorBoard server defined below with the following command:
# ```bash
# modal deploy torch_profiling
# ```

# and you can find your server at the URL printed to the terminal.


@app.function(
    volumes={TRACE_DIR: traces},
    image=tb_image,
    max_containers=1,  # single replica
    scaledown_window=5 * 60,  # five minute idle time
)
@modal.concurrent(max_inputs=100)  # 100 concurrent request threads
@modal.wsgi_app()
def tensorboard():
    import tensorboard

    board = tensorboard.program.TensorBoard()
    board.configure(logdir=str(TRACE_DIR))
    (data_provider, deprecated_multiplexer) = board._make_data_provider()
    wsgi_app = tensorboard.backend.application.TensorBoardWSGIApp(
        board.flags,
        board.plugin_loaders,
        data_provider,
        board.assets_zip_provider,
        deprecated_multiplexer,
        experimental_middlewares=[VolumeMiddleware],
    )

    return wsgi_app._create_wsgi_app()


=== GITHUB: 06_gpu_and_ml/long-training.py ===
# ---
# cmd: ["modal", "run", "--detach", "06_gpu_and_ml/long-training.py"]
# mypy: ignore-errors
# ---

# # Run long, resumable training jobs on Modal

# Individual Modal Function calls have a [maximum timeout of 24 hours](https://modal.com/docs/guide/timeouts).
# You can still run long training jobs on Modal by making them interruptible and resumable
# (aka [_reentrant_](https://en.wikipedia.org/wiki/Reentrancy_%28computing%29)).

# This is usually done via checkpointing: saving the model state to disk at regular intervals.
# We recommend implementing checkpointing logic regardless of the duration of your training jobs.
# This prevents loss of progress in case of interruptions or [preemptions](https://modal.com/docs/guide/preemption).

# In this example, we'll walk through how to implement this pattern in
# [PyTorch Lightning](https://lightning.ai/docs/pytorch/2.4.0/).

# But the fundamental pattern is simple and can be applied to any training framework:

# 1. Periodically save checkpoints to a Modal [Volume](https://modal.com/docs/guide/volumes)
# 2. When your training function starts, check the Volume for the latest checkpoint
# 3. Add [retries](https://modal.com/docs/guide/retries) to your training function

# ## Resuming from checkpoints in a training loop

# The `train` function below shows some very simple training logic
# using the built-in checkpointing features of PyTorch Lightning.

# Lightning uses a special filename, `last.ckpt`,
# to indicate which checkpoint is the most recent.
# We check for this file and resume training from it if it exists.

from pathlib import Path
from typing import Optional

import modal


def train(experiment):
    experiment_dir = CHECKPOINTS_PATH / experiment
    last_checkpoint = experiment_dir / "last.ckpt"

    if last_checkpoint.exists():
        print(f"⚡️ resuming training from the latest checkpoint: {last_checkpoint}")
        train_model(
            DATA_PATH,
            experiment_dir,
            resume_from_checkpoint=last_checkpoint,
        )
        print("⚡️ training finished successfully")
    else:
        print("⚡️ starting training from scratch")
        train_model(DATA_PATH, experiment_dir)


# This implementation works fine in a local environment.
# Running it serverlessly and durably on Modal -- with access to auto-scaling cloud GPU infrastructure
# -- does not require any adjustments to the code.
# We just need to ensure that data and checkpoints are saved in Modal _Volumes_.

# ## Modal Volumes are distributed file systems

# Modal [Volumes](https://modal.com/docs/guide/volumes) are distributed file systems --
# you can read and write files from them just like local disks,
# but they are accessible to all of your Modal Functions.
# Their performance is tuned for [Write-Once, Read-Many](https://en.wikipedia.org/wiki/Write_once_read_many) workloads
# with small numbers of large files.

# You can attach them to any Modal Function that needs access.

# But first, you need to create them:

volume = modal.Volume.from_name("example-long-training", create_if_missing=True)

# ## Porting training to Modal

# To attach a Modal Volume to our training function, we need to port it over to run on Modal.

# That means we need to define our training function's dependencies
# (as a [container image](https://modal.com/docs/guide/custom-container))
# and attach it to an application (a [`modal.App`](https://modal.com/docs/guide/apps)).

# Modal Functions that run on GPUs [already have CUDA drivers installed](https://modal.com/docs/guide/cuda),
# so dependency specification is straightforward.
# We just `pip_install` PyTorch and PyTorch Lightning.

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "lightning~=2.4.0", "torch~=2.4.0", "torchvision==0.19.0"
)

app = modal.App("example-long-training-lightning", image=image)

# Next, we attach our training function to this app with `app.function`.

# We define all of the serverless infrastructure-specific details of our training at this point.
# For resumable training, there are three key pieces: attaching volumes, adding retries, and setting the timeout.

# We want to attach the Volume to our Function so that the data and checkpoints are saved into it.
# In this sample code, we set these paths via global variables, but in another setting,
# these might be set via environment variables or other configuration mechanisms.

volume_path = Path("/experiments")
DATA_PATH = volume_path / "data"
CHECKPOINTS_PATH = volume_path / "checkpoints"

volumes = {volume_path: volume}

# Then, we define how we want to restart our training in case of interruption.
# We can use `modal.Retries` to add automatic retries to our Function.
# We set the delay time to `0.0` seconds, because on pre-emption or timeout we want to restart immediately.
# We set `max_retries` to the current maximum, which is `10`.

retries = modal.Retries(initial_delay=0.0, max_retries=10)

# Timeouts on Modal are set in seconds, with a minimum of 10 seconds and a maximum of 24 hours.
# When running training jobs that last up to week, we'd set that timeout to 24 hours,
# which would give our training job a maximum of 10 days to complete before we'd need to manually restart.

# For this example, we'll set it to 30 seconds. When running the example, you should observe a few interruptions.

timeout = 30  # seconds

# Now, we put all of this together by wrapping `train` and decorating it
# with `app.function` to add all the infrastructure.


@app.function(volumes=volumes, gpu="a10g", timeout=timeout, retries=retries)
def train_interruptible(*args, **kwargs):
    train(*args, **kwargs)


# ## Kicking off interruptible training

# We define a [`local_entrypoint`](https://modal.com/docs/guide/apps#entrypoints-for-ephemeral-apps)
# to kick off the training job from the local Python environment.


@app.local_entrypoint()
def main(experiment: Optional[str] = None):
    if experiment is None:
        from uuid import uuid4

        experiment = uuid4().hex[:8]
    print(f"⚡️ starting interruptible training experiment {experiment}")
    train_interruptible.remote(experiment)


# You can run this with
# ```bash
# modal run --detach 06_gpu_and_ml/long-training.py
# ```

# You should see the training job start and then be interrupted,
# producing a large stack trace in the terminal in red font.
# The job will restart within a few seconds.

# The `--detach` flag ensures training will continue even if you close your terminal or turn off your computer.
# Try detaching and then watch the logs in the [Modal dashboard](https://modal.com/apps).


# ## Details of PyTorch Lightning implementation

# This basic pattern works for any training framework or for custom training jobs --
# or for any reentrant work that can save state to disk.

# But to make the example complete, we include all the details of the PyTorch Lightning implementation below.

# PyTorch Lightning offers [built-in checkpointing](https://pytorch-lightning.readthedocs.io/en/1.2.10/common/weights_loading.html).
# You can specify the checkpoint file path that you want to resume from using the `ckpt_path` parameter of
# [`trainer.fit`](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.trainer.trainer.Trainer.html)
# Additionally, you can specify the checkpointing interval with the `every_n_epochs` parameter of
# [`ModelCheckpoint`](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html).


def get_checkpoint(checkpoint_dir):
    from lightning.pytorch.callbacks import ModelCheckpoint

    return ModelCheckpoint(
        dirpath=checkpoint_dir,
        save_last=True,
        every_n_epochs=10,
        filename="{epoch:02d}",
    )


def train_model(data_dir, checkpoint_dir, resume_from_checkpoint=None):
    import lightning as L

    autoencoder = get_autoencoder()
    train_loader = get_train_loader(data_dir=data_dir)
    checkpoint_callback = get_checkpoint(checkpoint_dir)

    trainer = L.Trainer(
        limit_train_batches=100, max_epochs=100, callbacks=[checkpoint_callback]
    )
    if resume_from_checkpoint is not None:
        trainer.fit(
            model=autoencoder,
            train_dataloaders=train_loader,
            ckpt_path=resume_from_checkpoint,
        )
    else:
        trainer.fit(autoencoder, train_loader)


def get_autoencoder(checkpoint_path=None):
    import lightning as L
    from torch import nn, optim

    class LitAutoEncoder(L.LightningModule):
        def __init__(self):
            super().__init__()
            self.encoder = nn.Sequential(
                nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3)
            )
            self.decoder = nn.Sequential(
                nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28)
            )

        def training_step(self, batch, batch_idx):
            x, _ = batch
            x = x.view(x.size(0), -1)
            z = self.encoder(x)
            x_hat = self.decoder(z)
            loss = nn.functional.mse_loss(x_hat, x)
            self.log("train_loss", loss)
            return loss

        def configure_optimizers(self):
            optimizer = optim.Adam(self.parameters(), lr=1e-3)
            return optimizer

    return LitAutoEncoder()


def get_train_loader(data_dir):
    from torch import utils
    from torchvision.datasets import MNIST
    from torchvision.transforms import ToTensor

    print("⚡ setting up data")
    dataset = MNIST(data_dir, download=True, transform=ToTensor())
    train_loader = utils.data.DataLoader(dataset, num_workers=4)
    return train_loader


=== GITHUB: 06_gpu_and_ml/gpu_fallbacks.py ===
# # Set "fallback" GPUs
#
# GPU availabilities on Modal can fluctuate, especially for
# tightly-constrained requests, like for eight co-located GPUs
# in a specific region.
#
# If your code can run on multiple different GPUs, you can specify
# your GPU request as a list, in order of preference, and whenever
# your Function scales up, we will try to schedule it on each requested GPU type in order.
#
# The code below demonstrates the usage of the `gpu` parameter with a list of GPUs.

import subprocess

import modal

app = modal.App("example-gpu-fallbacks")


@app.function(
    gpu=["h100", "a100", "any"],  # "any" means any of L4, A10, or T4
    max_inputs=1,  # new container each input, so we re-roll the GPU dice every time
)
async def remote(_idx):
    gpu = subprocess.run(
        ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"],
        check=True,
        text=True,
        stdout=subprocess.PIPE,
    ).stdout.strip()
    print(gpu)
    return gpu


@app.local_entrypoint()
def local(count: int = 32):
    from collections import Counter

    gpu_counter = Counter(remote.map([i for i in range(count)], order_outputs=False))
    print(f"ran {gpu_counter.total()} times")
    print(f"on the following {len(gpu_counter.keys())} GPUs:", end="\n")
    print(
        *[f"{gpu.rjust(32)}: {'🔥' * ct}" for gpu, ct in gpu_counter.items()],
        sep="\n",
    )


=== GITHUB: 06_gpu_and_ml/import_torch.py ===
import modal

app = modal.App("example-import-torch")


torch_image = modal.Image.debian_slim().pip_install(
    "torch==2.7",
    extra_index_url="https://download.pytorch.org/whl/cu128",
    force_build=True,  # trigger a build every time, just for demonstration purposes
    # remove if you're using this in production!
)


@app.function(gpu="B200", image=torch_image)
def torch() -> list[list[int]]:
    import math

    import torch

    print(torch.cuda.get_device_properties("cuda:0"))

    matrix = torch.randn(1024, 1024) / math.sqrt(1024)
    matrix = matrix @ matrix

    return matrix.detach().cpu().tolist()


@app.local_entrypoint()
def main():
    print(torch.remote()[:1])


=== GITHUB: 06_gpu_and_ml/gpu_packing.py ===
# ---
# mypy: ignore-errors
# ---
# # Run multiple instances of a model on a single GPU
#
# Many models are small enough to fit multiple instances onto a single GPU.
# Doing so can dramatically reduce the number of GPUs needed to handle demand.
#
# We use `@modal.concurrent` to allow multiple connections into the container
# We load the model instances into a FIFO queue to ensure only one http handler can access it at once

import asyncio
import time
from contextlib import asynccontextmanager

import modal

MODEL_PATH = "/model.bge"


def download_model():
    from sentence_transformers import SentenceTransformer

    model = SentenceTransformer("BAAI/bge-small-en-v1.5")
    model.save(MODEL_PATH)


image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install("sentence-transformers==3.2.0")
    .run_function(download_model)
)

app = modal.App("gpu-packing", image=image)


# ModelPool holds multiple instances of the model, using a queue
class ModelPool:
    def __init__(self):
        self.pool: asyncio.Queue = asyncio.Queue()

    async def put(self, model):
        await self.pool.put(model)

    # We provide a context manager to easily acquire and release models from the pool
    @asynccontextmanager
    async def acquire_model(self):
        model = await self.pool.get()
        try:
            yield model
        finally:
            await self.pool.put(model)


with image.imports():
    from sentence_transformers import SentenceTransformer


@app.cls(
    gpu="A10G",
    max_containers=1,  # Max one container for this app, for the sake of demoing concurrent_inputs
)
@modal.concurrent(max_inputs=100)  # Allow concurrent inputs into our single container.
class Server:
    n_models: int = modal.parameter(default=10)

    @modal.enter()
    def init(self):
        self.model_pool = ModelPool()

    @modal.enter()
    async def load_models(self):
        # Boot N models onto the gpu, and place into the pool
        t0 = time.time()
        for i in range(self.n_models):
            model = SentenceTransformer("/model.bge", device="cuda")
            await self.model_pool.put(model)

        print(f"Loading {self.n_models} models took {time.time() - t0:.4f}s")

    @modal.method()
    def prewarm(self):
        pass

    @modal.method()
    async def predict(self, sentence):
        # Block until a model is available
        async with self.model_pool.acquire_model() as model:
            # We now have exclusive access to this model instance
            embedding = model.encode(sentence)
            await asyncio.sleep(
                0.2
            )  # Simulate extra inference latency, for demo purposes
        return embedding.tolist()


@app.local_entrypoint()
async def main(n_requests: int = 100):
    # We benchmark with 100 requests in parallel.
    # Thanks to @modal.concurrent(), 100 requests will enter .predict() at the same time.

    sentences = ["Sentence {}".format(i) for i in range(n_requests)]

    # Baseline: a server with a pool size of 1 model
    print("Testing Baseline (1 Model)")
    t0 = time.time()
    server = Server(n_models=1)
    server.prewarm.remote()
    print("Container boot took {:.4f}s".format(time.time() - t0))

    t0 = time.time()
    async for result in server.predict.map.aio(sentences):
        pass
    print(f"Inference took {time.time() - t0:.4f}s\n")

    # Packing: a server with a pool size of 10 models
    # Note: this increases boot time, but reduces inference time
    print("Testing Packing (10 Models)")
    t0 = time.time()
    server = Server(n_models=10)
    server.prewarm.remote()
    print("Container boot took {:.4f}s".format(time.time() - t0))

    t0 = time.time()
    async for result in server.predict.map.aio(sentences):
        pass
    print(f"Inference took {time.time() - t0:.4f}s\n")


=== GITHUB: 06_gpu_and_ml/text-to-video/mochi.py ===
# ---
# cmd: ["modal", "run", "--detach", "06_gpu_and_ml/text-to-video/mochi.py", "--num-inference-steps", "64"]
# ---

# # Text-to-video generation with Mochi

# This example demonstrates how to run the [Mochi 1](https://github.com/genmoai/models)
# video generation model by [Genmo](https://www.genmo.ai/) on Modal.

# Here's one that we generated, inspired by our logo:

# <center>
# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/modal-logo-splat.mp4" type="video/mp4" />
# </video>
# </center>

# Note that the Mochi model, at time of writing,
# requires several minutes on one H100 to produce
# a high-quality clip of even a few seconds.
# So a single video generation therefore costs about $0.33
# at our ~$5/hr rate for H100s.

# Keep your eyes peeled for improved efficiency
# as the open source community works on this new model.
# We welcome PRs to improve the performance of this example!

# ## Setting up the environment for Mochi

# At the time of writing, Mochi is supported natively in the [`diffusers`](https://github.com/huggingface/diffusers) library,
# but only in a pre-release version.
# So we'll need to install `diffusers` and `transformers` from GitHub.

import string
import time
from pathlib import Path

import modal

app = modal.App()

image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("git")
    .pip_install(
        "torch==2.5.1",
        "accelerate==1.1.1",
        "hf_transfer==0.1.8",
        "sentencepiece==0.2.0",
        "imageio==2.36.0",
        "imageio-ffmpeg==0.5.1",
        "git+https://github.com/huggingface/transformers@30335093276212ce74938bdfd85bfd5df31a668a",
        "git+https://github.com/huggingface/diffusers@99c0483b67427de467f11aa35d54678fd36a7ea2",
    )
    .env(
        {
            "HF_HUB_ENABLE_HF_TRANSFER": "1",
            "HF_HOME": "/models",
        }
    )
)

# ## Saving outputs

# On Modal, we save large or expensive-to-compute data to
# [distributed Volumes](https://modal.com/docs/guide/volumes)

# We'll use this for saving our Mochi weights, as well as our video outputs.

VOLUME_NAME = "mochi-outputs"
outputs = modal.Volume.from_name(VOLUME_NAME, create_if_missing=True)
OUTPUTS_PATH = Path("/outputs")  # remote path for saving video outputs

MODEL_VOLUME_NAME = "mochi-model"
model = modal.Volume.from_name(MODEL_VOLUME_NAME, create_if_missing=True)
MODEL_PATH = Path("/models")  # remote path for saving model weights

MINUTES = 60
HOURS = 60 * MINUTES

# ## Downloading the model

# We download the model weights into Volume cache to speed up cold starts.

# This download takes five minutes or more, depending on traffic
# and network speed.

# If you want to launch the download first,
# before running the rest of the code,
# use the following command from the folder containing this file:

# ```bash
# modal run --detach mochi::download_model
# ```

# The `--detach` flag ensures the download will continue
# even if you close your terminal or shut down your computer
# while it's running.


with image.imports():
    import torch
    from diffusers import MochiPipeline
    from diffusers.utils import export_to_video


@app.function(
    image=image,
    volumes={
        MODEL_PATH: model,
    },
    timeout=20 * MINUTES,
)
def download_model(revision="83359d26a7e2bbe200ecbfda8ebff850fd03b545"):
    # uses HF_HOME to point download to the model volume
    MochiPipeline.from_pretrained(
        "genmo/mochi-1-preview",
        torch_dtype=torch.bfloat16,
        revision=revision,
    )


# ## Setting up our Mochi class


# We'll use the `@cls` decorator to define a [Modal Class](https://modal.com/docs/guide/lifecycle-functions)
# which we use to control the lifecycle of our cloud container.
#
# We configure it to use our image, the distributed volume, and a single H100 GPU.
@app.cls(
    image=image,
    volumes={
        OUTPUTS_PATH: outputs,  # videos will be saved to a distributed volume
        MODEL_PATH: model,
    },
    gpu="H100",
    timeout=1 * HOURS,
)
class Mochi:
    @modal.enter()
    def load_model(self):
        # our HF_HOME env var points to the model volume as the cache
        self.pipe = MochiPipeline.from_pretrained(
            "genmo/mochi-1-preview",
            torch_dtype=torch.bfloat16,
        )
        self.pipe.enable_model_cpu_offload()
        self.pipe.enable_vae_tiling()

    @modal.method()
    def generate(
        self,
        prompt,
        negative_prompt="",
        num_inference_steps=200,
        guidance_scale=4.5,
        num_frames=19,
    ):
        frames = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_frames=num_frames,
        ).frames[0]

        # save to disk using prompt as filename
        mp4_name = slugify(prompt)
        export_to_video(frames, Path(OUTPUTS_PATH) / mp4_name)
        outputs.commit()
        return mp4_name


# ## Running Mochi inference

# We can trigger Mochi inference from our local machine by running the code in
# the local entrypoint below.

# It ensures the model is downloaded to a remote volume,
# spins up a new replica to generate a video, also saved remotely,
# and then downloads the video to the local machine.

# You can trigger it with:
# ```bash
# modal run --detach mochi
# ```

# Optional command line flags can be viewed with:
# ```bash
# modal run mochi --help
# ```

# Using these flags, you can tweak your generation from the command line:
# ```bash
# modal run --detach mochi --prompt="a cat playing drums in a jazz ensemble" --num-inference-steps=64
# ```


@app.local_entrypoint()
def main(
    prompt="Close-up of a chameleon's eye, with its scaly skin changing color. Ultra high resolution 4k.",
    negative_prompt="",
    num_inference_steps=200,
    guidance_scale=4.5,
    num_frames=19,  # produces ~1s of video
):
    mochi = Mochi()
    mp4_name = mochi.generate.remote(
        prompt=str(prompt),
        negative_prompt=str(negative_prompt),
        num_inference_steps=int(num_inference_steps),
        guidance_scale=float(guidance_scale),
        num_frames=int(num_frames),
    )
    print(f"🍡 video saved to volume at {mp4_name}")

    local_dir = Path("/tmp/mochi")
    local_dir.mkdir(exist_ok=True, parents=True)
    local_path = local_dir / mp4_name
    local_path.write_bytes(b"".join(outputs.read_file(mp4_name)))
    print(f"🍡 video saved locally at {local_path}")


# ## Addenda

# The remainder of the code in this file is utility code.


def slugify(prompt):
    for char in string.punctuation:
        prompt = prompt.replace(char, "")
    prompt = prompt.replace(" ", "_")
    prompt = prompt[:230]  # since filenames can't be longer than 255 characters
    mp4_name = str(int(time.time())) + "_" + prompt + ".mp4"
    return mp4_name


=== GITHUB: 06_gpu_and_ml/text-to-video/ltx.py ===
# # Generate videos from prompts with Lightricks LTX-Video

# This example demonstrates how to run the [LTX-Video](https://github.com/Lightricks/LTX-Video)
# video generation model by [Lightricks](https://www.lightricks.com/) on Modal.

# LTX-Video is fast! Generating a twenty second 480p video at moderate quality
# takes as little as two seconds on a warm container.

# Here's one that we generated:

# <center>
# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/blonde-woman-blinking.mp4" type="video/mp4" />
# </video>
# </center>

# ## Setup

# We start by importing dependencies we need locally,
# defining a Modal [App](https://modal.com/docs/guide/apps),
# and defining the container [Image](https://modal.com/docs/guide/images)
# that our video model will run in.


import string
import time
from pathlib import Path
from typing import Optional

import modal

app = modal.App("example-ltx-video")

image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "accelerate==1.6.0",
        "diffusers==0.33.1",
        "hf_transfer==0.1.9",
        "imageio==2.37.0",
        "imageio-ffmpeg==0.5.1",
        "sentencepiece==0.2.0",
        "torch==2.7.0",
        "transformers==4.51.3",
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
)

# ## Storing data on Modal Volumes

# On Modal, we save large or expensive-to-compute data to
# [distributed Volumes](https://modal.com/docs/guide/volumes)
# that are accessible both locally and remotely.

# We'll store the LTX-Video model's weights and the outputs we generate
# on Modal Volumes.

# We store the outputs on a Modal Volume so that clients
# don't need to sit around waiting for the video to be generated.

VOLUME_NAME = "ltx-outputs"
outputs = modal.Volume.from_name(VOLUME_NAME, create_if_missing=True)
OUTPUTS_PATH = Path("/outputs")

# We store the weights on a Modal Volume so that we don't
# have to fetch them from the Hugging Face Hub every time
# a container boots. This download takes about two minutes,
# depending on traffic and network speed.

MODEL_VOLUME_NAME = "ltx-model"
model = modal.Volume.from_name(MODEL_VOLUME_NAME, create_if_missing=True)

# We don't have to change any of the Hugging Face code to do this --
# we just set the location of Hugging Face's cache to be on a Volume
# using the `HF_HOME` environment variable.

MODEL_PATH = Path("/models")
image = image.env({"HF_HOME": str(MODEL_PATH)})

# For more on storing Modal weights on Modal, see
# [this guide](https://modal.com/docs/guide/model-weights).


# ## Setting up our LTX class

# We use the `@cls` decorator to specify the infrastructure our inference function needs,
# as defined above.

# That decorator also gives us control over the
# [lifecycle](https://modal.com/docs/guide/lifecycle-functions)
# of our cloud container.

# Specifically, we use the `enter` method to load the model into GPU memory
# (from the Volume if it's present or the Hub if it's not)
# before the container is marked ready for inputs.

# This helps reduce tail latencies caused by cold starts.
# For details and more tips, see [this guide](https://modal.com/docs/guide/cold-start#cold-start-performance).

# The actual inference code is in a `modal.method` of the class.


MINUTES = 60  # seconds


@app.cls(
    image=image,  # use our container Image
    volumes={OUTPUTS_PATH: outputs, MODEL_PATH: model},  # attach our Volumes
    gpu="H100",  # use a big, fast GPU
    timeout=10 * MINUTES,  # run inference for up to 10 minutes
    scaledown_window=15 * MINUTES,  # stay idle for 15 minutes before scaling down
)
class LTX:
    @modal.enter()
    def load_model(self):
        import torch
        from diffusers import DiffusionPipeline

        self.pipe = DiffusionPipeline.from_pretrained(
            "Lightricks/LTX-Video", torch_dtype=torch.bfloat16
        )
        self.pipe.to("cuda")

    @modal.method()
    def generate(
        self,
        prompt,
        negative_prompt="",
        num_inference_steps=200,
        guidance_scale=4.5,
        num_frames=19,
        width=704,
        height=480,
    ):
        from diffusers.utils import export_to_video

        frames = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_frames=num_frames,
            width=width,
            height=height,
        ).frames[0]

        # save to disk using prompt as filename
        mp4_name = slugify(prompt)
        export_to_video(frames, Path(OUTPUTS_PATH) / mp4_name)
        outputs.commit()
        return mp4_name


# ## Generate videos from the command line

# We trigger LTX-Video inference from our local machine by running the code in
# the local entrypoint below with `modal run`.

# It will spin up a new replica to generate a video.
# Then it will, by default, generate a second video to demonstrate
# the lower latency when hitting a warm container.

# You can trigger inference with:

# ```bash
# modal run ltx
# ```

# All outputs are saved both locally and on a Modal Volume.
# You can explore the contents of Modal Volumes from your Modal Dashboard
# or from the command line with the `modal volume` command.

# ```bash
# modal volume ls ltx-outputs
# ```

# See `modal volume --help` for details.

# Optional command line flags for the script can be viewed with:

# ```bash
# modal run ltx --help
# ```

# Using these flags, you can tweak your generation from the command line:

# ```bash
# modal run --detach ltx --prompt="a cat playing drums in a jazz ensemble" --num-inference-steps=64
# ```


@app.local_entrypoint()
def main(
    prompt: Optional[str] = None,
    negative_prompt="worst quality, blurry, jittery, distorted",
    num_inference_steps: int = 10,  # 10 when testing, 100 or more when generating
    guidance_scale: float = 2.5,
    num_frames: int = 150,  # produces ~10s of video
    width: int = 704,
    height: int = 480,
    twice: bool = True,  # run twice to show cold start latency
):
    if prompt is None:
        prompt = DEFAULT_PROMPT

    ltx = LTX()

    def run():
        print(f"🎥 Generating a video from the prompt '{prompt}'")
        start = time.time()
        mp4_name = ltx.generate.remote(
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            num_frames=num_frames,
            width=width,
            height=height,
        )
        duration = time.time() - start
        print(f"🎥 Client received video in {int(duration)}s")
        print(f"🎥 LTX video saved to Modal Volume at {mp4_name}")

        local_dir = Path("/tmp/ltx")
        local_dir.mkdir(exist_ok=True, parents=True)
        local_path = local_dir / mp4_name
        local_path.write_bytes(b"".join(outputs.read_file(mp4_name)))
        print(f"🎥 LTX video saved locally at {local_path}")

    run()

    if twice:
        print("🎥 Generating a video from a warm container")
        run()


# ## Addenda

# The remainder of the code in this file is utility code.

DEFAULT_PROMPT = (
    "The camera pans over a snow-covered mountain range,"
    " revealing a vast expanse of snow-capped peaks and valleys."
    " The mountains are covered in a thick layer of snow,"
    " with some areas appearing almost white while others have a slightly darker, almost grayish hue."
    " The peaks are jagged and irregular, with some rising sharply into the sky"
    " while others are more rounded."
    " The valleys are deep and narrow, with steep slopes that are also covered in snow."
    " The trees in the foreground are mostly bare, with only a few leaves remaining on their branches."
)


def slugify(prompt):
    for char in string.punctuation:
        prompt = prompt.replace(char, "")
    prompt = prompt.replace(" ", "_")
    prompt = prompt[:230]  # some OSes limit filenames to <256 chars
    mp4_name = str(int(time.time())) + "_" + prompt + ".mp4"
    return mp4_name


=== GITHUB: 06_gpu_and_ml/controlnet/controlnet_gradio_demos.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/controlnet/controlnet_gradio_demos.py"]
# ---

# # Play with the ControlNet demos

# This example allows you to play with all 10 demonstration Gradio apps from the new and amazing ControlNet project.
# ControlNet provides a minimal interface allowing users to use images to constrain StableDiffusion's generation process.
# With ControlNet, users can easily condition the StableDiffusion image generation with different spatial contexts
# including a depth maps, segmentation maps, scribble drawings, and keypoints!

# <center>
# <video controls autoplay loop muted>
# <source src="https://user-images.githubusercontent.com/12058921/222927911-3ab52dd1-f2ee-4fb8-97e8-dafbf96ed5c5.mp4" type="video/mp4">
# </video>
# </center>

# ## Imports and config preamble

import importlib
import os
import pathlib
from dataclasses import dataclass, field

import modal
from fastapi import FastAPI

# Below are the configuration objects for all **10** demos provided in the original [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) repo.
# The demos each depend on their own custom pretrained StableDiffusion model, and these models are 5-6GB each.
# We can only run one demo at a time, so this module avoids downloading the model and 'detector' dependencies for
# all 10 demos and instead uses the demo configuration object to download only what's necessary for the chosen demo.

# Even just limiting our dependencies setup to what's required for one demo, the resulting container image is *huge*.


@dataclass(frozen=True)
class DemoApp:
    """Config object defining a ControlNet demo app's specific dependencies."""

    name: str
    model_files: list[str]
    detector_files: list[str] = field(default_factory=list)


demos = [
    DemoApp(
        name="canny2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_canny.pth"
        ],
    ),
    DemoApp(
        name="depth2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_depth.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/dpt_hybrid-midas-501f0c75.pt"
        ],
    ),
    DemoApp(
        name="fake_scribble2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_scribble.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/network-bsds500.pth"
        ],
    ),
    DemoApp(
        name="hed2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_hed.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/network-bsds500.pth"
        ],
    ),
    DemoApp(
        name="hough2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_mlsd.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/mlsd_large_512_fp32.pth",
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/mlsd_tiny_512_fp32.pth",
        ],
    ),
    DemoApp(
        name="normal2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_normal.pth"
        ],
    ),
    DemoApp(
        name="pose2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_openpose.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/body_pose_model.pth",
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/hand_pose_model.pth",
        ],
    ),
    DemoApp(
        name="scribble2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_scribble.pth"
        ],
    ),
    DemoApp(
        name="scribble2image_interactive",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_scribble.pth"
        ],
    ),
    DemoApp(
        name="seg2image",
        model_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/models/control_sd15_seg.pth"
        ],
        detector_files=[
            "https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/upernet_global_small.pth"
        ],
    ),
]
demos_map: dict[str, DemoApp] = {d.name: d for d in demos}

# ## Pick a demo, any demo

# Simply by changing the `DEMO_NAME` below, you can change which ControlNet demo app is setup
# and run by this Modal script.

DEMO_NAME = "scribble2image"  # Change this value to change the active demo app.
selected_demo = demos_map[DEMO_NAME]

# ## Setting up the dependencies

# ControlNet requires *a lot* of dependencies which could be fiddly to setup manually, but Modal's programmatic
# container image building Python APIs handle this complexity straightforwardly and automatically.

# To run any of the 10 demo apps, we need the following:

# 1. a base Python 3 Linux image (we use Debian Slim)
# 2. a bunch of third party PyPi packages
# 3. `git`, so that we can download the ControlNet source code (there's no `controlnet` PyPi package)
# 4. some image process Linux system packages, including `ffmpeg`
# 5. and demo specific pre-trained model and detector `.pth` files

# That's a lot! Fortunately, the code below is already written for you that stitches together a working container image
# ready to produce remarkable ControlNet images.

# **Note:** a ControlNet model pipeline is [now available in Huggingface's `diffusers` package](https://huggingface.co/blog/controlnet). But this does not contain the demo apps.


def download_file(url: str, output_path: pathlib.Path):
    import httpx
    from tqdm import tqdm

    with open(output_path, "wb") as download_file:
        with httpx.stream("GET", url, follow_redirects=True) as response:
            total = int(response.headers["Content-Length"])
            with tqdm(
                total=total, unit_scale=True, unit_divisor=1024, unit="B"
            ) as progress:
                num_bytes_downloaded = response.num_bytes_downloaded
                for chunk in response.iter_bytes():
                    download_file.write(chunk)
                    progress.update(
                        response.num_bytes_downloaded - num_bytes_downloaded
                    )
                    num_bytes_downloaded = response.num_bytes_downloaded


def download_demo_files() -> None:
    """
    The ControlNet repo instructs: 'Make sure that SD models are put in "ControlNet/models".'
    'ControlNet' is just the repo root, so we place in /root/models.

    The ControlNet repo also instructs: 'Make sure that... detectors are put in "ControlNet/annotator/ckpts".'
    'ControlNet' is just the repo root, so we place in /root/annotator/ckpts.
    """
    demo = demos_map[os.environ["DEMO_NAME"]]
    models_dir = pathlib.Path("/root/models")
    for url in demo.model_files:
        filepath = pathlib.Path(url).name
        download_file(url=url, output_path=models_dir / filepath)
        print(f"download complete for {filepath}")

    detectors_dir = pathlib.Path("/root/annotator/ckpts")
    for url in demo.detector_files:
        filepath = pathlib.Path(url).name
        download_file(url=url, output_path=detectors_dir / filepath)
        print(f"download complete for {filepath}")
    print("🎉 finished baking demo file(s) into image.")


image = (
    modal.Image.debian_slim(python_version="3.10")
    .pip_install(
        "fastapi[standard]==0.115.4",
        "pydantic==2.9.1",
        "starlette==0.41.2",
        "gradio==3.16.2",
        "albumentations==1.3.0",
        "opencv-contrib-python",
        "imageio==2.9.0",
        "imageio-ffmpeg==0.4.2",
        "pytorch-lightning==1.5.0",
        "omegaconf==2.1.1",
        "test-tube>=0.7.5",
        "streamlit==1.12.1",
        "einops==0.3.0",
        "transformers==4.19.2",
        "webdataset==0.2.5",
        "kornia==0.6",
        "open_clip_torch==2.0.2",
        "invisible-watermark>=0.1.5",
        "streamlit-drawable-canvas==0.8.0",
        "torchmetrics==0.6.0",
        "timm==0.6.12",
        "addict==2.4.0",
        "yapf==0.32.0",
        "prettytable==3.6.0",
        "safetensors==0.2.7",
        "basicsr==1.4.2",
        "tqdm~=4.64.1",
    )
    # xformers library offers performance improvement.
    .pip_install("xformers", pre=True)
    .apt_install("git")
    # Here we place the latest ControlNet repository code into /root.
    # Because /root is almost empty, but not entirely empty, `git clone` won't work,
    # so this `init` then `checkout` workaround is used.
    .run_commands(
        "cd /root && git init .",
        "cd /root && git remote add --fetch origin https://github.com/lllyasviel/ControlNet.git",
        "cd /root && git checkout main",
    )
    .apt_install("ffmpeg", "libsm6", "libxext6")
    .run_function(
        download_demo_files,
        secrets=[modal.Secret.from_dict({"DEMO_NAME": DEMO_NAME})],
    )
)
app = modal.App(name="example-controlnet", image=image)

web_app = FastAPI()

# ## Serving the Gradio web UI

# Each ControlNet gradio demo module exposes a `block` Gradio interface running in queue-mode,
# which is initialized in module scope on import and served on `0.0.0.0`. We want the block interface object,
# but the queueing and launched webserver aren't compatible with Modal's serverless web endpoint interface,
# so in the `import_gradio_app_blocks` function we patch out these behaviors.


def import_gradio_app_blocks(demo: DemoApp):
    from gradio import blocks

    # The ControlNet repo demo scripts are written to be run as
    # standalone scripts, and have a lot of code that executes
    # in global scope on import, including the launch of a Gradio web server.
    # We want Modal to control the Gradio web app serving, so we
    # monkeypatch the .launch() function to be a no-op.
    blocks.Blocks.launch = lambda self, server_name: print(
        "launch() has been monkeypatched to do nothing."
    )

    # each demo app module is a file like gradio_{name}.py
    module_name = f"gradio_{demo.name}"
    mod = importlib.import_module(module_name)
    blocks = mod.block
    # disable queueing mode, which is incompatible with our Modal web app setup.
    blocks.enable_queue = False
    return blocks


# Because the ControlNet gradio apps are so time and compute intensive to cold-start,
# the web app function is limited to running just 1 warm container (max_containers=1).
# This way, while playing with the demos we can pay the cold-start cost once and have
# all web requests hit the same warm container.
# Spinning up extra containers to handle additional requests would not be efficient
# given the cold-start time.
# We set the scaledown_window to 600 seconds so the container will be kept
# running for 10 minutes after the last request, to keep the app responsive in case
# of continued experimentation.


@app.function(
    gpu="A10G",
    max_containers=1,
    scaledown_window=600,
)
@modal.asgi_app()
def run():
    from gradio.routes import mount_gradio_app

    # mount for execution on Modal
    return mount_gradio_app(
        app=web_app,
        blocks=import_gradio_app_blocks(demo=selected_demo),
        path="/",
    )


# ## Have fun!

# Serve your chosen demo app with `modal serve controlnet_gradio_demos.py`. If you don't have any images ready at hand,
# try one that's in the `06_gpu_and_ml/controlnet/demo_images/` folder.

# StableDiffusion was already impressive enough, but ControlNet's ability to so accurately and intuitively constrain
# the image generation process is sure to put a big, dumb grin on your face.


=== GITHUB: 06_gpu_and_ml/embeddings/qdrant.py ===
from typing import Optional

import modal

app = modal.App("example-qdrant-in-memory")

image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "qdrant-client[fastembed-gpu]==1.13.3"
)


@app.function(image=image, gpu="any")
def query(inpt):
    from qdrant_client import QdrantClient

    client = QdrantClient(":memory:")

    docs = [
        "Qdrant has Langchain integrations",
        "Qdrant also has Llama Index integrations",
    ]

    print("querying documents:", *docs, sep="\n\t")

    client.add(collection_name="demo_collection", documents=docs)

    print("query:", inpt, sep="\n\t")

    search_results = client.query(
        collection_name="demo_collection",
        query_text=inpt,
        limit=1,
    )

    print("result:", search_results[0], sep="\n\t")

    return search_results[0].document


@app.local_entrypoint()
def main(inpt: Optional[str] = None):
    if not inpt:
        inpt = "alpaca"

    print(query.remote(inpt))


=== GITHUB: 06_gpu_and_ml/embeddings/embedding_racetrack.py ===
# ---
# cmd: ["modal", "run", "06_gpu_and_ml/embeddings/embedding_racetrack.py::main"]
# ---

# # Modal Cookbook: Recipe for Inference Throughput Maximization
# In certain applications, the bottom line comes to throughput: process a set of inputs as fast as possible.
# Let's explore how to maximize throughput by using Modal on an embedding example, and see just how fast
# we can encode the [Microsoft Cats & Dogs dataset](https://huggingface.co/datasets/microsoft/cats_vs_dogs)
# using the [Infinity inference engine](https://github.com/michaelfeil/infinity "github/michaelfeil/infinity").

# ## Conclusions
# ### BLUF (Bottom Line Up Front)
# Set concurrency (`max_concurrent_inputs`) to 4, and set `batch_size` between 50-500.
# To set `max_containers`, divide the total number of inputs by `max_concurrent_inputs*batchsize`
# (note: if you have a massive dataset, keep an eye out for diminishing returns on `max_containers`; but
# Modal should handle that for you!).
# Be sure to preprocess your data in the same manner that the model is expecting (e.g., resizing images).
# If you only want to use one container, increase `batch_size` until you are maxing
# out the GPU (but keep concurrency, `max_concurrent_inputs`, capped around 4). The example herein achieves
# upward of 750 images / second overall throughput (not including initial Volume setup time).

# ### Why?
# While batchsize maximizes GPU utilization, the time to form a batch (ie reading images)
# will ultimately overtake inference, whether due to I/O, sending data across a wire, etc.
# We can make up for this by using idle GPU cores to store additional copies of the model:
# this _GPU packing_ is achieved via an async queue and the [@modal.concurrent(max_inputs:int) ](https://modal.com/docs/guide/concurrent-inputs#input-concurrency "Modal: input concurrency")
# decorator. Once you nail down `batch_size` you can crank up the number of containers to distribute the
# computational load. High values of concurrency has diminishing returns, we believe,
# because we are already throttling the CPU with multi-threaded dataloading. The demo herein
# achieves upward of 750 images / second, and that will increase for larger datasets where the model loading
# time becomes increasingly negligable.

# ## Local env imports
# Import everything we need for the locally-run Python (everything in our local_entrypoint function at the bottom).
import asyncio
import os
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from time import perf_counter
from typing import Iterator, TypeVar

import modal

# ## Key Parameters
# There are three ways to parallelize inference for this usecase: via batching (which happens internal to Infinity),
# by packing individual GPU(s) with multiple copies of the model, and by fanning out across multiple containers.
# Here are some parameters for controlling these factors:
# * `max_concurrent_inputs` sets the [@modal.concurrent(max_inputs:int) ](https://modal.com/docs/guide/concurrent-inputs#input-concurrency "Modal: input concurrency") argument for the inference app. This takes advantage of the asynchronous nature of the Infinity embedding inference app.
# * `gpu` is a string specifying the GPU to be used.
# * `max_containers` caps the number of containers allowed to spin-up.
# * `memory_request` amount of RAM requested per container
# * `core_request` number of logical cores requested per container
# * `threads_per_core` oversubscription factor for parallelized I/O (image reading)
# * `batch_size` is a parameter passed to the [Infinity inference engine](https://github.com/michaelfeil/infinity "github/michaelfeil/infinity"), and it means the usual thing for machine learning inference: a group of images are processed through the neural network together.
# * `image_cap` caps the number of images used in this example (e.g. for debugging/testing)
max_concurrent_inputs: int = 4
gpu: str = "L4"
max_containers: int = 50
memory_request: float = 5 * 1024  # MB->GB
core_request: float = 4
threads_per_core: int = 8
batch_size: int = 100
image_cap: int = -1

# This timeout caps the maximum time a single function call is allowed to take. In this example, that
# includes reading a batch-worth of data and running inference on it. When `batch_size` is large (e.g. 5000)
# and with a large value of `max_concurrent_inputs`, where a batch may sit in a queue for a while,
# this could take several minutes.
timeout_seconds: int = 5 * 60

# ## Data and Model Specification
# This model parameter should point to a model on HuggingFace that is supported by Infinity.
# Note that your selected model might require specialized imports when
# designing the image in the next section. This [OpenAI model](https://huggingface.co/openai/clip-vit-base-patch16 "OpenAI ViT")
# takes about 4-10s to load into memory.
model_name = "openai/clip-vit-base-patch16"  # 599 MB
model_input_shape = (224, 224)

# We will use a high-performance [Modal Volume](https://modal.com/docs/guide/volumes#volumes "Modal.Volume")
# both to cache model weights and to store images we want to encode. The details of
# setting this volume up are below. Here, we just need to name it so that we can instantiate
# the Modal application.
# You may need to [set up a secret](https://modal.com/secrets/) to access HuggingFace datasets
hf_secret = modal.Secret.from_name("huggingface-secret")
# Change this global variable to use a different HF dataset:
hf_dataset_name = "microsoft/cats_vs_dogs"
# This name is important for referencing the volume in other apps or for [browsing](https://modal.com/storage):
vol_name = "example-embedding-data"
# This is the location within the container that this Volume will be mounted:
vol_mnt = Path("/data")
# Finally, the Volume object can be created:
data_volume = modal.Volume.from_name(vol_name, create_if_missing=True)


# ## Define the image
infinity_image = (
    modal.Image.debian_slim(python_version="3.10")
    .pip_install(
        [
            "pillow",  # for Infinity input typehint
            "datasets",  # for huggingface data download
            "hf_transfer",  # for fast huggingface data download
            "tqdm",  # progress bar for dataset download
            "infinity_emb[all]==0.0.76",  # for Infinity inference lib
            "sentencepiece",  # for this particular chosen model
            "torchvision",  # for fast image loading
        ]
    )
    .env(
        {
            "HF_HOME": vol_mnt.as_posix(),  # For model and data caching in our Volume
            "HF_HUB_ENABLE_HF_TRANSFER": "1",  # For fast data transfer
        }
    )
)

# Initialize the app
app = modal.App(
    "example-infinity-embedder",
    image=infinity_image,
    volumes={vol_mnt: data_volume},
    secrets=[hf_secret],
)

# Imports inside the container
with infinity_image.imports():
    from infinity_emb import AsyncEmbeddingEngine, EngineArgs
    from infinity_emb.primitives import Dtype, InferenceEngine
    from PIL.Image import Image
    from torchvision.io import read_image
    from torchvision.transforms.functional import to_pil_image

## Dataset Downloading and Setup
# ## Data setup
# We use a [Modal Volume](https://modal.com/docs/guide/volumes#volumes "Modal.Volume")
# to store images we want to encode. We download them from Huggingface into a Volume and then preprocess
# them to 224 x 224 JPEGs. The selected model, `openai/clip-vit-base-patch16`, was trained on 224 x 224
# sized images. If you skip this preprocess resize step, Infinity will handle image resizing for you-
# at a severe penalty to inference throughput.

# Note that Modal Volumes are optimized for datasets on the order of 50,000 - 500,000
# files and directories. If you have a larger dataset, you may need to consider other storage
# options such as a [CloudBucketMount](https://modal.com/docs/examples/rosettafold).


@app.function(
    image=infinity_image,
    volumes={vol_mnt: data_volume},
    max_containers=1,  # We only want one container to handle volume setup
    cpu=core_request,  # HuggingFace will use multi-process parallelism to download
    timeout=timeout_seconds,  # if using a large HF dataset, this may need to be longer
)
def catalog_jpegs(dataset_namespace: str, cache_dir: str, image_cap: int):
    """
    This function checks the volume for JPEGs and, if needed, calls `download_to_volume`
    which pulls a HuggingFace dataset into the mounted volume.
    """

    def download_to_volume(dataset_namespace: str, cache_dir: str):
        """
        This function caches a hugginface dataset to the path specified in your `HF_HOME` environment
        variable, which we set when creating the image so as to point to a Modal Volume.
        """
        from datasets import load_dataset
        from torchvision.io import write_jpeg
        from torchvision.transforms import Compose, PILToTensor, Resize
        from tqdm import tqdm

        # Load cache to HF_HOME
        ds = load_dataset(
            dataset_namespace,
            split="train",
            num_proc=os.cpu_count(),  # this will be capped by huggingface based on the number of shards
        )

        # Create an `extraction` cache dir where we will create explicit JPEGs
        mounted_cache_dir = vol_mnt / cache_dir
        mounted_cache_dir.mkdir(exist_ok=True, parents=True)

        # Preprocessing pipeline: resize now instead of on-the-fly
        preprocessor = Compose(
            [
                Resize(model_input_shape),
                PILToTensor(),
            ]
        )

        def preprocess_img(idx, example):
            """
            Applies preprocessor and write as jpeg with TurboJPEG (via torchvision).
            """
            # Define output path
            write_path = mounted_cache_dir / f"img{idx:07d}.jpg"
            if write_path.is_file():
                return

            # Here, `example["image"]` is a `PIL.Image.Image`
            preprocessed = preprocessor(example["image"].convert("RGB"))

            # Write to modal.Volume
            write_jpeg(preprocessed, write_path)

        # This is a parallelized pre-processing loop that opens compressed images,
        # preprocesses them to the size expected by our model, and writes as a JPEG.
        for idx, ex in tqdm(enumerate(ds), total=len(ds), desc="Caching images"):
            if (image_cap > 0) and (idx >= image_cap):
                break
            preprocess_img(idx, ex)

        data_volume.commit()

    ds_preptime_st = perf_counter()

    def list_all_jpegs(subdir: os.PathLike = "/") -> list[os.PathLike]:
        """
        Searches a subdir within your volume for all JPEGs.
        """
        return [
            x.path
            for x in data_volume.listdir(subdir.as_posix())
            if x.path.endswith(".jpg")
        ]

    # Check for extracted-JPEG cache dir within the volume
    if (vol_mnt / cache_dir).is_dir():
        im_path_list = list_all_jpegs(cache_dir)
        n_ims = len(im_path_list)
    else:
        n_ims = 0
        print("The cache dir was not found...")

    # If needed, download dataset to a vol
    if (n_ims < image_cap) or (n_ims == 0):
        print(f"Found {n_ims} JPEGs; checking for more on HuggingFace.")
        download_to_volume(dataset_namespace, cache_dir)
        # Try again
        im_path_list = list_all_jpegs(cache_dir)
        n_ims = len(im_path_list)

    # [optional] Cap the number of images to process
    print(f"Found {n_ims} JPEGs in the Volume.", end="")
    if image_cap > 0:
        im_path_list = im_path_list[: min(image_cap, len(im_path_list))]
    print(f"using {len(im_path_list)}.")

    # Time it
    ds_time_elapsed = perf_counter() - ds_preptime_st
    return im_path_list, ds_time_elapsed


T = TypeVar("T")  # generic type for chunked typehints


def chunked(seq: list[T], subseq_size: int) -> Iterator[list[T]]:
    """
    Helper function that chunks a sequence into subsequences of length `subseq_size`.
    """
    for i in range(0, len(seq), subseq_size):
        yield seq[i : i + subseq_size]


# ## Inference app
# Here we define an app.cls that wraps Infinity's AsyncEmbeddingEngine.
# Note that the variable `max_concurrent_inputs` is used to set `max_inputs`
# in (1) the [modal.concurrent](https://modal.com/docs/guide/concurrent-inputs#input-concurrency)
# decorator, and (2) the `n_engines` class property.
# In `init_engines`, we are creating exactly one inference
# engine for each concurrently-passed batch of data. This is critical for packing a GPU with
# multiple simultaneously operating models. The [@modal.enter](https://modal.com/docs/reference/modal.enter#modalenter)
# decorator ensures that this method is called once per container, on startup (and `exit` is
# run once, on shutdown).
@app.cls(
    gpu=gpu,
    cpu=core_request,
    memory=5 * 1024,  # MB -> GB
    image=infinity_image,
    volumes={vol_mnt: data_volume},
    timeout=timeout_seconds,
    max_containers=max_containers,
)
@modal.concurrent(max_inputs=max_concurrent_inputs)
class InfinityEngine:
    n_engines: int = max_concurrent_inputs

    @modal.enter()
    async def init_engines(self):
        """
        On container start, starts `self.n_engines` copies of the selected model
        and puts them in an async queue.
        """
        print(f"Loading {self.n_engines} models... ", end="")
        self.engine_queue: asyncio.Queue[AsyncEmbeddingEngine] = asyncio.Queue()
        start = perf_counter()
        for _ in range(self.n_engines):
            engine = AsyncEmbeddingEngine.from_args(
                EngineArgs(
                    model_name_or_path=model_name,
                    batch_size=batch_size,
                    model_warmup=False,
                    engine=InferenceEngine.torch,
                    dtype=Dtype.float16,
                    device="cuda",
                )
            )
            await engine.astart()
            await self.engine_queue.put(engine)
        print(f"Took {perf_counter() - start:.4}s.")

    def read_batch(self, im_path_list: list[os.PathLike]) -> list["Image"]:
        """
        Read a batch of data. Infinity is expecting PIL.Image.Image type
        inputs, but it's faster to read from disk with torchvision's `read_image`
        and convert to PIL than it is to read directly with PIL.

        This process is parallelized over the batch with multithreaded data reading.
        The number of threads is 4 per core, which is based on the batchsize.
        """

        def readim(impath: os.PathLike):
            """Read with torch, convert back to PIL for Infinity"""
            return to_pil_image(read_image(str(vol_mnt / impath)))

        with ThreadPoolExecutor(
            max_workers=os.cpu_count() * threads_per_core
        ) as executor:
            images = list(executor.map(readim, im_path_list))

        return images

    @modal.method()
    async def embed(self, images: list[os.PathLike]) -> tuple[float, float]:
        """
        This is the workhorse function. We select a model, prepare a batch,
        execute inference, and return the time elapsed. You probably want
        to return the embeddings in your usecase.
        """
        # (0) Grab an engine from the queue
        engine = await self.engine_queue.get()

        try:
            # (1) Load batch of image data
            st = perf_counter()
            images = self.read_batch(images)
            batch_elapsed = perf_counter() - st

            # (2) Encode the batch
            st = perf_counter()
            embedding, _ = await engine.image_embed(images=images)
            embed_elapsed = perf_counter() - st
        finally:
            # No matter what happens, return the engine to the queue
            await self.engine_queue.put(engine)

        # (3) Housekeeping
        print(f"Time to load batch: {batch_elapsed:.2f}s")
        print(f"Time to embed batch: {embed_elapsed:.2f}s")

        # (4) You may wish to return the embeddings themselves here
        return embed_elapsed, len(images)

    @modal.exit()
    async def exit(self) -> None:
        """
        Shut down each of the engines.
        """
        for _ in range(self.n_engines):
            engine = await self.engine_queue.get()
            await engine.astop()


# ## Local Entrypoint
# This backbone code is run on your machine. It starts up the app,
# catalogs the data, and via the remote `map` call, parses the data
# with the Infinity embedding engine. The embedder.embed executions
# across the batches are autoscaled depending on the app parameters
# `max_containers` and `max_concurrent_inputs`.
@app.local_entrypoint()
def main():
    start_time = perf_counter()

    # (1) Catalog data: modify `catalog_jpegs` to fetch batches of your data.
    extracted_path = Path("extracted") / hf_dataset_name
    im_path_list, vol_setup_time = catalog_jpegs.remote(
        dataset_namespace=hf_dataset_name, cache_dir=extracted_path, image_cap=image_cap
    )
    print(f"Took {vol_setup_time:.2f}s to setup volume.")
    n_ims = len(im_path_list)

    # (2) Init the model inference app
    start_time = perf_counter()
    embedder = InfinityEngine()

    # (3) Embed batches via remote `map` call
    times, batchsizes = [], []
    for time, batchsize in embedder.embed.map(chunked(im_path_list, batch_size)):
        times.append(time)
        batchsizes.append(batchsize)

    # (4) Log
    if n_ims > 0:
        total_duration = perf_counter() - start_time
        total_throughput = n_ims / total_duration
        embed_throughputs = [
            batchsize / time for batchsize, time in zip(batchsizes, times)
        ]
        avg_throughput = sum(embed_throughputs) / len(embed_throughputs)

        log_msg = (
            f"EmbeddingRacetrack{gpu}::batch_size={batch_size}::"
            f"n_ims={n_ims}::concurrency={max_concurrent_inputs}::"
            f"max_containers={max_containers}::cores={core_request}\n"
            f"\tTotal time:\t{total_duration / 60:.2f} min\n"
            f"\tVolume setup time:\t{vol_setup_time / 60:.2f} min\n"
            f"\tOverall throughput:\t{total_throughput:.2f} im/s\n"
            f"\tEmbedding-only throughput (avg):\t{avg_throughput:.2f} im/s\n"
        )

        print(log_msg)


=== GITHUB: 06_gpu_and_ml/embeddings/text_embeddings_inference.py ===
# ---
# cmd: ["modal", "run", "06_gpu_and_ml/embeddings/text_embeddings_inference.py::embed_dataset"]
# ---

# # Run TextEmbeddingsInference (TEI) on Modal

# This example runs the [Text Embedding Inference (TEI)](https://github.com/huggingface/text-embeddings-inference) toolkit on the Hacker News BigQuery public dataset.

import json
import os
import socket
import subprocess
from pathlib import Path

import modal

GPU_CONFIG = "A10G"
MODEL_ID = "BAAI/bge-base-en-v1.5"
BATCH_SIZE = 32
DOCKER_IMAGE = (
    "ghcr.io/huggingface/text-embeddings-inference:86-0.4.0"  # Ampere 86 for A10s.
    # "ghcr.io/huggingface/text-embeddings-inference:0.4.0" # Ampere 80 for A100s.
    # "ghcr.io/huggingface/text-embeddings-inference:0.3.0"  # Turing for T4s.
)

DATA_PATH = Path("/data/dataset.jsonl")

LAUNCH_FLAGS = [
    "--model-id",
    MODEL_ID,
    "--port",
    "8000",
]


def spawn_server() -> subprocess.Popen:
    process = subprocess.Popen(["text-embeddings-router"] + LAUNCH_FLAGS)

    # Poll until webserver at 127.0.0.1:8000 accepts connections before running inputs.
    while True:
        try:
            socket.create_connection(("127.0.0.1", 8000), timeout=1).close()
            print("Webserver ready!")
            return process
        except (socket.timeout, ConnectionRefusedError):
            # Check if launcher webserving process has exited.
            # If so, a connection can never be made.
            retcode = process.poll()
            if retcode is not None:
                raise RuntimeError(f"launcher exited unexpectedly with code {retcode}")


def download_model():
    # Wait for server to start. This downloads the model weights when not present.
    spawn_server().terminate()


volume = modal.Volume.from_name("tei-hn-data", create_if_missing=True)

app = modal.App("example-tei")


tei_image = (
    modal.Image.from_registry(
        DOCKER_IMAGE,
        add_python="3.10",
    )
    .dockerfile_commands("ENTRYPOINT []")
    .run_function(download_model, gpu=GPU_CONFIG)
    .pip_install("httpx")
)


with tei_image.imports():
    from httpx import AsyncClient


@app.cls(
    gpu=GPU_CONFIG,
    image=tei_image,
    max_containers=20,  # Use up to 20 GPU containers at once.
)
@modal.concurrent(
    max_inputs=10
)  # Allow each container to process up to 10 batches at once.
class TextEmbeddingsInference:
    @modal.enter()
    def setup_server(self):
        self.process = spawn_server()
        self.client = AsyncClient(base_url="http://127.0.0.1:8000")

    @modal.exit()
    def teardown_server(self):
        self.process.terminate()

    @modal.method()
    async def embed(self, inputs_with_ids: list[tuple[int, str]]):
        ids, inputs = zip(*inputs_with_ids)
        resp = await self.client.post("/embed", json={"inputs": inputs})
        resp.raise_for_status()
        outputs = resp.json()

        return list(zip(ids, outputs))


def download_data():
    service_account_info = json.loads(os.environ["SERVICE_ACCOUNT_JSON"])
    credentials = service_account.Credentials.from_service_account_info(
        service_account_info
    )

    client = bigquery.Client(credentials=credentials)

    iterator = client.list_rows(
        "bigquery-public-data.hacker_news.full",
        max_results=100_000,
    )
    df = iterator.to_dataframe(progress_bar_type="tqdm").dropna()

    df["id"] = df["id"].astype(int)
    df["text"] = df["text"].apply(lambda x: x[:512])

    data = list(zip(df["id"], df["text"]))

    with open(DATA_PATH, "w") as f:
        json.dump(data, f)

    volume.commit()


image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "google-cloud-bigquery", "pandas", "db-dtypes", "tqdm"
)

with image.imports():
    from google.cloud import bigquery
    from google.oauth2 import service_account


@app.function(
    image=image,
    secrets=[modal.Secret.from_name("bigquery")],
    volumes={DATA_PATH.parent: volume},
)
def embed_dataset():
    model = TextEmbeddingsInference()

    if not DATA_PATH.exists():
        print("Downloading data. This takes a while...")
        download_data()

    with open(DATA_PATH) as f:
        data = json.loads(f.read())

    def generate_batches():
        batch = []
        for item in data:
            batch.append(item)

            if len(batch) == BATCH_SIZE:
                yield batch
                batch = []

    # data is of type list[tuple[str, str]].
    # starmap spreads the tuples into positional arguments.
    for output_batch in model.embed.map(generate_batches(), order_outputs=False):
        # Do something with the outputs.
        pass


=== GITHUB: 06_gpu_and_ml/embeddings/amazon_embeddings.py ===
# ---
# cmd: ["modal", "run", "--detach", "06_gpu_and_ml/embeddings/amazon_embeddings.py"]
# args: ["--dataset-subset", "raw_review_Magazine_Subscriptions"]
# ---

# # Embed 30 million Amazon reviews at 575k tokens per second with Qwen2-7B

# This example demonstrates how to create embeddings for a large text dataset. This is
# often necessary to enable semantic search, translation, and other language
# processing tasks. Modal makes it easy to deploy large, capable embedding models and handles
# all of the scaling to process very large datasets in parallel on many cloud GPUs.

# We create a Modal Function that will handle all of the data loading and submit inputs to an
# inference Cls that will automatically scale up to handle hundreds of large
# batches in parallel.

# Between the time a batch is submitted and the time it is fetched, it is stored via
# Modal's `spawn` system, which can hold onto up to one million inputs for up to a week.

import json
import subprocess
from pathlib import Path

import modal

app = modal.App(name="example-amazon-embeddings")
MINUTES = 60  # seconds
HOURS = 60 * MINUTES

# We define our `main` function as a `local_entrypoint`. This is what we'll call locally
# to start the job on Modal.

# You can run it with the command

# ```bash
# modal run --detach amazon_embeddings.py
# ```

# By default we `down-scale` to 1/100th of the data for demonstration purposes.
# To launch the full job, set the `--down-scale` parameter to `1`.
# But note that this will cost you!

# The entrypoint starts the job and gets back a `f`unction `c`all ID for each batch.
# We can use these IDs to retrieve the embeddings once the job is finished.
# Modal will keep the results around for up to 7 days after completion. Take a look at our
# [job processing guide](https://modal.com/docs/guide/job-queue)
# for more details.


@app.local_entrypoint()
def main(
    dataset_name: str = "McAuley-Lab/Amazon-Reviews-2023",
    dataset_subset: str = "raw_review_Books",
    down_scale: float = 0.001,
):
    out_path = Path("/tmp") / "embeddings-example-fc-ids.json"
    function_ids = launch_job.remote(
        dataset_name=dataset_name, dataset_subset=dataset_subset, down_scale=down_scale
    )
    out_path.write_text(json.dumps(function_ids, indent=2) + "\n")
    print(f"output handles saved to {out_path}")


# ## Load the data and start the inference job

# Next we define the Function that will do the data loading and feed it to our embedding model.
# We define a container [Image](https://modal.com/docs/guide/images)
# with the data loading dependencies.

# In it, we download the data we need and cache it to the container's local disk,
# which will disappear when the job is finished. We will be saving the review data
# along with the embeddings, so we don't need to keep the dataset around.

# Embedding a large dataset like this can take some time, but we don't need to wait
# around for it to finish. We use `spawn` to invoke our embedding Function
# and get back a handle with an ID that we can use to get the results later.
# This can bottleneck on just sending data over the network for processing, so
# we speed things up by using `ThreadPoolExecutor` to submit batches using multiple threads.

# Once all of the batches have been sent for inference, we can return the function IDs
# to the local client to save.


@app.function(
    image=modal.Image.debian_slim().pip_install("datasets==3.5.1"), timeout=2 * HOURS
)
def launch_job(dataset_name: str, dataset_subset: str, down_scale: float):
    import time
    from concurrent.futures import ThreadPoolExecutor, as_completed

    from datasets import load_dataset
    from tqdm import tqdm

    print("Loading dataset...")
    dataset = load_dataset(
        dataset_name,
        dataset_subset,
        split="full",
        trust_remote_code=True,
    )

    data_subset = dataset.select(range(int(len(dataset) * down_scale)))

    tei = TextEmbeddingsInference()
    batches = generate_batches_of_chunks(data_subset)

    start = time.perf_counter()
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(tei.embed.spawn, batch) for batch in tqdm(batches)]
        function_ids = []
        for future in tqdm(as_completed(futures), total=len(futures)):
            function_ids.append(future.result().object_id)

    print(f"Finished submitting job: {time.perf_counter() - start:.2f}s")

    return function_ids


# ## Massively scaling up and scaling out embedding inference on many beefy GPUs

# We're going to spin up many containers to run inference, and we don't want each
# one to have to download the embedding model from Hugging Face. We can download and save it to a
# Modal [Volume](https://modal.com/docs/guide/volumes)
# during the image build step using `run_function`.

# We'll use the
# [GTE-Qwen2-7B-instruct](https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct)
# model from Alibaba, which performs well on the
# [Massive Text Embedding Benchmark](https://huggingface.co/spaces/mteb/leaderboard).

MODEL_ID = "Alibaba-NLP/gte-Qwen2-7B-instruct"
MODEL_DIR = "/model"
MODEL_CACHE_VOLUME = modal.Volume.from_name(
    "embeddings-example-model-cache", create_if_missing=True
)


def download_model():
    from huggingface_hub import snapshot_download

    snapshot_download(MODEL_ID, cache_dir=MODEL_DIR)


# For inference, we will use Hugging Face's
# [Text Embeddings Inference](https://github.com/huggingface/text-embeddings-inference)
# framework for embedding model deployment.

# Running lots of separate machines is "scaling out". But we can also "scale up"
# by running on large, high-performance machines.

# We'll use L40S GPUs for a good balance between cost and performance. Hugging Face has
# prebuilt Docker images we can use as a base for our Modal Image.
# We'll use the one built for the L40S's
# [SM89/Ada Lovelace architecture](https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor-architecture)
# and install the rest of our dependencies on top.

tei_image = "ghcr.io/huggingface/text-embeddings-inference:89-1.7"

inference_image = (
    modal.Image.from_registry(tei_image, add_python="3.12")
    .dockerfile_commands("ENTRYPOINT []")
    .pip_install(
        "httpx==0.28.1",
        "huggingface_hub[hf_transfer]==0.30.2",
        "numpy==2.2.5",
        "tqdm==4.67.1",
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HOME": MODEL_DIR})
    .run_function(download_model, volumes={MODEL_DIR: MODEL_CACHE_VOLUME})
)


# Next we define our inference class. Modal will auto-scale the number of
# containers ready to handle inputs based on the parameters we set in the `@app.cls`
# and `@modal.concurrent` decorators. Here we limit the total number of containers to
# 100 and the maximum number of concurrent inputs to 10, which caps us at 1000 concurrent batches.
# On Modal's Starter (free) and Team plans, the maximum number of concurrent GPUs is lower,
# reducing the total number of concurrent batches and so the throughput.

# Customers on Modal's Enterprise Plan regularly scale up another order of magnitude above this.
# If you're interested in running on thousands of GPUs,
# [get in touch](https://form.fillout.com/t/onUBuQZ5vCus).

# Here we also specify the GPU type and attach the Modal Volume where we saved the
# embedding model.

# This class will spawn a local Text Embeddings Inference server when the container
# starts, and process each batch by receiving the text data over HTTP, returning a list of
# tuples with the batch text data and embeddings.


@app.cls(
    image=inference_image,
    gpu="L40S",
    volumes={MODEL_DIR: MODEL_CACHE_VOLUME},
    max_containers=100,
    scaledown_window=5 * MINUTES,  # idle for 5 min without inputs before scaling down
    retries=3,  # handle transient failures and storms in the cloud
    timeout=2 * HOURS,  # run for at most 2 hours
)
@modal.concurrent(max_inputs=10)
class TextEmbeddingsInference:
    @modal.enter()
    def open_connection(self):
        from httpx import AsyncClient

        print("Starting text embedding inference server...")
        self.process = spawn_server()
        self.client = AsyncClient(base_url="http://127.0.0.1:8000", timeout=30)

    @modal.exit()
    def terminate_connection(self):
        self.process.terminate()

    @modal.method()
    async def embed(self, batch):
        texts = [chunk[-1] for chunk in batch]
        res = await self.client.post("/embed", json={"inputs": texts})
        return [chunk + (embedding,) for chunk, embedding in zip(batch, res.json())]


# ## Helper Functions

# The book review dataset contains ~30M reviews with ~12B total characters,
# indicating an average review length of ~500 characters. Some are much longer.
# Embedding models have a limit on the number of tokens they can process in a single
# input. We will need to split each review into chunks that are under this limit.

# The proper way to split text data is to use a tokenizer to ensure that any
# single request is under the models token limit, and to overlap chunks to provide
# semantic context and preserve information. For the sake of this example, we're going
# just to split by a set character length (`CHUNK_SIZE`).

# While the embedding model has a limit on the number of input tokens for a single
# embedding, the number of chunks that we can process in a single batch is limited by
# the VRAM of the GPU. We set the `BATCH_SIZE` accordingly.


BATCH_SIZE = 256
CHUNK_SIZE = 512


def generate_batches_of_chunks(
    dataset, chunk_size: int = CHUNK_SIZE, batch_size: int = BATCH_SIZE
):
    """Creates batches of chunks by naively slicing strings according to CHUNK_SIZE."""
    batch = []
    for entry_index, data in enumerate(dataset):
        product_id = data["asin"]
        user_id = data["user_id"]
        timestamp = data["timestamp"]
        title = data["title"]
        text = data["text"]
        for chunk_index, chunk_start in enumerate(range(0, len(text), chunk_size)):
            batch.append(
                (
                    entry_index,
                    chunk_index,
                    product_id,
                    user_id,
                    timestamp,
                    title,
                    text[chunk_start : chunk_start + chunk_size],
                )
            )
            if len(batch) == batch_size:
                yield batch
                batch = []
    if batch:
        yield batch


def spawn_server(
    model_id: str = MODEL_ID,
    port: int = 8000,
    max_client_batch_size: int = BATCH_SIZE,
    max_batch_tokens: int = BATCH_SIZE * CHUNK_SIZE,
    huggingface_hub_cache: str = MODEL_DIR,
):
    """Starts a text embedding inference server in a subprocess."""
    import socket

    LAUNCH_FLAGS = [
        "--model-id",
        model_id,
        "--port",
        str(port),
        "--max-client-batch-size",
        str(max_client_batch_size),
        "--max-batch-tokens",
        str(max_batch_tokens),
        "--huggingface-hub-cache",
        huggingface_hub_cache,
    ]

    process = subprocess.Popen(["text-embeddings-router"] + LAUNCH_FLAGS)
    # Poll until webserver at 127.0.0.1:8000 accepts connections before running inputs.
    while True:
        try:
            socket.create_connection(("127.0.0.1", port), timeout=1).close()
            print("Inference server ready!")
            return process
        except (socket.timeout, ConnectionRefusedError):
            retcode = process.poll()  # Check if the process has terminated.
            if retcode is not None:
                raise RuntimeError(f"Launcher exited unexpectedly with code {retcode}")


=== GITHUB: 06_gpu_and_ml/embeddings/wikipedia/download.py ===
import modal

# We first set out configuration variables for our script.
DATASET_DIR = "/data"
DATASET_NAME = "wikipedia"
DATASET_CONFIG = "20220301.en"


# We define our Modal Resources that we'll need
volume = modal.Volume.from_name("embedding-wikipedia", create_if_missing=True)
image = modal.Image.debian_slim(python_version="3.9").pip_install(
    "datasets==2.16.1", "apache_beam==2.53.0"
)
app = modal.App(image=image)


# The default timeout is 5 minutes re: https://modal.com/docs/guide/timeouts#handling-timeouts
#  but we override this to
# 3000s to avoid any potential timeout issues
@app.function(volumes={DATASET_DIR: volume}, timeout=3000)
def download_dataset():
    # Redownload the dataset
    import time

    from datasets import load_dataset

    start = time.time()
    dataset = load_dataset(DATASET_NAME, DATASET_CONFIG, num_proc=6)
    end = time.time()
    print(f"Download complete - downloaded files in {end - start}s")

    dataset.save_to_disk(f"{DATASET_DIR}/{DATASET_NAME}")
    volume.commit()


@app.local_entrypoint()
def main():
    download_dataset.remote()


=== GITHUB: 06_gpu_and_ml/embeddings/wikipedia/README.md ===
# Embedding Wikipedia in 15 minutes

This example shows how we can embed the entirety of english wikipedia on Modal in just 15 minutes. We've published a detailed writeup which walks you through the implemenation [here](#todo).

## Description

There are a total of 2 files in this repository

- `download.py` : This showcases how to download the Wikipedia dataset into a `Modal` volume. We can take advantage of `Modal`'s high internet speeds to download large datasets quickly.

- `main.py`: This showcases how to run an embedding job on your downloaded dataset and run a parallelizable job using Modal's inbuilt parallelization abstraction.

## Getting Started

You'll need a few packages to get started - we recommend using a virtual environment to install all of the dependencies listed in the `requirements.txt`

```bash
python3 -m venv venv
source venv/bin/activate
pip3 install modal
```

Once you've done so, you'll need to authenticate with Modal. To do so, run the command `modal token new`.

This will open up a new tab in your default browser and allow you to run, deploy and configure all of your Modal applications from your terminal.

## Downloading Our Dataset

Let's first download our Wikipedia dataset into a Modal volume. We can optimise the download time using the `num_proc ` keyword to parallelize some of the downloads.

From experience, this reduces the amount of time required by around 30-40% as long as we set a number between 4-10.

We can run our Download script using the command

```
modal run download.py
```

## Embedding our Dataset

Now that we've downloaded our wikipedia dataset, we can now embed the entire dataset using our `main.py` script. We can run it using the command

```
modal run main.py
```

Note that we utilize 2 volumes in our dataset script - one for reading from and another to write the files to upload to.

# Debugging

## Verifying that the Dataset has been downloaded

> Note that the `size` of the volume listed in the table for the directories. Our wikipedia directory is listed as having a size of 56B but the multiple .arrow files inside it should tell you that it in fact contains much larger files

Once we've downloaded the dataset, we can confirm that it has been downloaded and saved into our `embedding-wikipedia` volume at the path `/wikipedia` by runnning the command

```
modal volume ls embedding-wikipedia
```

This should produce a table that looks like this.

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃ filename                                            ┃ type ┃ created/modified          ┃ size      ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ wikipedia                                           │ dir  │ 2023-12-02 10:57:44+01:00 │ 56 B      │
└─────────────────────────────────────────────────────┴──────┴───────────────────────────┴───────────┘
```

We can then view what this folder looks like inside by appending the `/wikipedia` to our command

```
modal volume ls embedding-wikipedia /wikipedia
```

This will then show the files inside the `/wikipedia`

```
Directory listing of '/wikipedia' in 'embedding-wikipedia'
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓
┃ filename                    ┃ type ┃ created/modified          ┃ size    ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩
│ wikipedia/train             │ dir  │ 2023-12-02 10:58:12+01:00 │ 4.0 KiB │
│ wikipedia/dataset_dict.json │ file │ 2023-12-02 10:57:44+01:00 │ 21 B    │
└─────────────────────────────┴──────┴───────────────────────────┴─────────┘
```

## Removing Files

> Note that if you're looking to remove a directory, you need to supply the `--recursive` flag to the command for it to work.

If you'll like to save on storage costs when using volumes, you can use the modal cli to easily remove files.

```
modal volume rm embedding-wikipedia /wikipedia --recursive
```


=== GITHUB: 06_gpu_and_ml/embeddings/wikipedia/main.py ===
import asyncio
import json
import subprocess

import modal

# We first set out configuration variables for our script.
## Embedding Containers Configuration
GPU_CONCURRENCY = 100
GPU_CONFIG = "A10G"
MODEL_ID = "BAAI/bge-small-en-v1.5"
MODEL_SLUG = MODEL_ID.split("/")[-1]
BATCH_SIZE = 512
DOCKER_IMAGE = (
    "ghcr.io/huggingface/text-embeddings-inference:86-0.4.0"  # Ampere 86 for A10s.
    # "ghcr.io/huggingface/text-embeddings-inference:0.4.0" # Ampere 80 for A100s.
    # "ghcr.io/huggingface/text-embeddings-inference:0.3.0"  # Turing for T4s.
)

## Dataset-Specific Configuration
MODEL_CACHE_VOLUME = modal.Volume.from_name(
    "embedding-model-cache", create_if_missing=True
)
DATASET_NAME = "wikipedia"
DATASET_READ_VOLUME = modal.Volume.from_name(
    "embedding-wikipedia", create_if_missing=True
)
EMBEDDING_CHECKPOINT_VOLUME = modal.Volume.from_name(
    "checkpoint", create_if_missing=True
)
MODEL_DIR = "/model"
DATASET_DIR = "/data"
CHECKPOINT_DIR = "/checkpoint"
SAVE_TO_DISK = True

## Upload-Specific Configuration
DATASET_HF_UPLOAD_REPO_NAME = "567-labs/upload-test"
UPLOAD_TO_HF = True

## HF Text-Embedding Inference specific Configuration

LAUNCH_FLAGS = [
    "--model-id",
    MODEL_ID,
    "--port",
    "8000",
    "--max-client-batch-size",
    str(BATCH_SIZE),
    "--max-batch-tokens",
    str(BATCH_SIZE * 512),
    "--huggingface-hub-cache",
    MODEL_DIR,
]


app = modal.App("example-embeddings")


def spawn_server() -> subprocess.Popen:
    import socket

    process = subprocess.Popen(["text-embeddings-router"] + LAUNCH_FLAGS)
    # Poll until webserver at 127.0.0.1:8000 accepts connections before running inputs.
    while True:
        try:
            socket.create_connection(("127.0.0.1", 8000), timeout=1).close()
            print("Webserver ready!")
            return process
        except (socket.timeout, ConnectionRefusedError):
            # Check if launcher webserving process has exited.
            # If so, a connection can never be made.
            retcode = process.poll()
            if retcode is not None:
                raise RuntimeError(f"launcher exited unexpectedly with code {retcode}")


tei_image = (
    modal.Image.from_registry(
        "ghcr.io/huggingface/text-embeddings-inference:86-0.4.0",
        add_python="3.10",
    )
    .dockerfile_commands("ENTRYPOINT []")
    .pip_install("httpx", "numpy")
)

with tei_image.imports():
    import numpy as np


def generate_chunks_from_dataset(xs, chunk_size: int):
    """
    Generate chunks from a dataset.

    Args:
        xs (list): The dataset containing dictionaries with "id", "url", "title", and "text" keys.
        chunk_size (int): The size of each chunk.

    Yields:
        tuple: A tuple containing the id, url, title, and a chunk of text.

    """
    for data in xs:
        id_ = data["id"]
        url = data["url"]
        title = data["title"]
        text = data["text"]
        for chunk_start in range(0, len(text), chunk_size):
            yield (
                id_,
                url,
                title,
                text[chunk_start : chunk_start + chunk_size],
            )


def generate_batches(xs, batch_size):
    batch = []
    for x in xs:
        batch.append(x)
        if len(batch) == batch_size:
            yield batch
            batch = []
    if batch:
        yield batch


@app.cls(
    gpu=GPU_CONFIG,
    image=tei_image,
    max_containers=GPU_CONCURRENCY,
    retries=3,
)
@modal.concurrent(max_inputs=10)
class TextEmbeddingsInference:
    @modal.enter()
    def open_connection(self):
        # If the process is running for a long time, the client does not seem to close the connections, results in a pool timeout
        from httpx import AsyncClient

        self.process = spawn_server()
        self.client = AsyncClient(base_url="http://127.0.0.1:8000", timeout=30)

    @modal.exit()
    def terminate_connection(self):
        self.process.terminate()

    async def _embed(self, chunk_batch):
        texts = [chunk[3] for chunk in chunk_batch]
        res = await self.client.post("/embed", json={"inputs": texts})
        return np.array(res.json())

    @modal.method()
    async def embed(self, chunks):
        """Embeds a list of texts.  id, url, title, text = chunks[0]"""
        coros = [
            self._embed(chunk_batch)
            for chunk_batch in generate_batches(chunks, batch_size=BATCH_SIZE)
        ]

        embeddings = np.vstack(await asyncio.gather(*coros))
        return chunks, embeddings


def load_dataset_from_disk(down_scale: float = 0.01):
    """
    Load a dataset from disk and return a subset of the training data.

    Args:
        down_scale (float): The fraction of the training data to select. Defaults to 0.01.

    Returns:
        Dataset: A subset of the training data.
    """
    import time

    from datasets import load_from_disk

    start = time.perf_counter()
    # Load the dataset as a Hugging Face dataset
    print(f"Loading dataset from {DATASET_DIR}/wikipedia")
    dataset = load_from_disk(f"{DATASET_DIR}/wikipedia")
    print(f"Dataset loaded in {time.perf_counter() - start:.2f} seconds")

    # Extract the total size of the dataset
    ttl_size = len(dataset["train"])

    sample_size = int(ttl_size * down_scale)

    return dataset["train"].select(range(sample_size))


def save_dataset_to_intermediate_checkpoint(acc_chunks, embeddings, batch_size):
    """Saves the dataset to an intermediate checkpoint.

    Args:
        acc_chunks (list): Accumulated chunks
        embeddings (list): Accumulated embeddings
        batch_size (int): Batch size
    """
    import pyarrow as pa
    from datasets import Dataset

    table = pa.Table.from_arrays(
        [
            pa.array([chunk[0] for chunk in acc_chunks]),  # id
            pa.array([chunk[1] for chunk in acc_chunks]),  # url
            pa.array([chunk[2] for chunk in acc_chunks]),  # title
            pa.array([chunk[3] for chunk in acc_chunks]),  # text
            pa.array(embeddings),
        ],
        names=["id", "url", "title", "text", "embedding"],
    )
    path_parent_folder = f"{CHECKPOINT_DIR}/{MODEL_SLUG}-{batch_size}"
    dataset = Dataset(table)
    dataset.save_to_disk(path_parent_folder)
    EMBEDDING_CHECKPOINT_VOLUME.commit()
    print(f"Saved checkpoint at {path_parent_folder}")


def upload_result_to_hf(batch_size: int) -> None:
    """
    Uploads the result to the Hugging Face Hub.

    Args:
        batch_size (int): The batch size for the model.

    Returns:
        None
    """
    import os
    import time

    from huggingface_hub import HfApi

    path_parent_folder = f"{CHECKPOINT_DIR}/{MODEL_SLUG}-{batch_size}"
    api = HfApi(token=os.environ["HUGGINGFACE_TOKEN"])
    api.create_repo(
        repo_id=DATASET_HF_UPLOAD_REPO_NAME,
        private=False,
        repo_type="dataset",
        exist_ok=True,
    )

    print(f"Pushing to hub {DATASET_HF_UPLOAD_REPO_NAME}")
    start = time.perf_counter()
    api.upload_folder(
        folder_path=path_parent_folder,
        repo_id=DATASET_HF_UPLOAD_REPO_NAME,
        repo_type="dataset",
        multi_commits=True,
        multi_commits_verbose=True,
    )

    end = time.perf_counter()
    print(f"Uploaded in {end - start}s")


@app.function(
    image=modal.Image.debian_slim().pip_install(
        "datasets", "pyarrow", "hf_transfer", "huggingface_hub"
    ),
    volumes={
        DATASET_DIR: DATASET_READ_VOLUME,
        CHECKPOINT_DIR: EMBEDDING_CHECKPOINT_VOLUME,
        MODEL_DIR: MODEL_CACHE_VOLUME,
    },
    timeout=86400,
    secrets=[modal.Secret.from_name("huggingface-secret")],
)
def embed_dataset(down_scale: float = 1, batch_size: int = 512 * 50):
    """
    Embeds a dataset with the Text Embeddings Inference container.

    Args:
        down_scale (float): The fraction of the training data to select. Defaults to 1.
        batch_size (int): The batch size to use. Defaults to 512 * 50.

    Returns:
        dict: A dictionary containing the benchmark results.
    """
    import datetime
    import time

    if UPLOAD_TO_HF and not SAVE_TO_DISK:
        raise ValueError(
            "Uploading to HF requires SAVE_TO_DISK to be set to true in case of intermediate failure."
        )

    dataset_chars = 19560538957  # sum(map(len, dataset["train"]["text"]))
    subset = load_dataset_from_disk(down_scale)
    model = TextEmbeddingsInference()
    text_chunks = generate_chunks_from_dataset(subset, chunk_size=512)
    batches = generate_batches(text_chunks, batch_size=batch_size)

    start = time.perf_counter()
    acc_chunks = []
    embeddings = []
    for resp in model.embed.map(batches, order_outputs=False, return_exceptions=True):
        if isinstance(resp, Exception):
            print(f"Exception: {resp}")
            continue

        batch_chunks, batch_embeddings = resp

        acc_chunks.extend(batch_chunks)
        embeddings.extend(batch_embeddings)

    end = time.perf_counter()

    duration = end - start
    characters = sum(map(len, [chunk[3] for chunk in acc_chunks]))
    characters_per_sec = int(characters / duration)
    extrapolated_duration_cps_fmt = str(
        datetime.timedelta(seconds=dataset_chars / characters_per_sec)
    )
    resp = {
        "downscale": down_scale,
        "batch_size": batch_size,
        "n_gpu": GPU_CONCURRENCY,
        "duration_mins": duration / 60,
        "characters_per_sec": characters_per_sec,
        "extrapolated_duration": extrapolated_duration_cps_fmt,
    }

    if SAVE_TO_DISK:
        save_dataset_to_intermediate_checkpoint(acc_chunks, embeddings, batch_size)

    if UPLOAD_TO_HF:
        upload_result_to_hf(batch_size)

    return resp


@app.local_entrypoint()
def full_job():
    batch_size = 512 * 150
    with open("benchmarks.json", "a") as f:
        benchmark = embed_dataset.remote(batch_size=batch_size)
        f.write(json.dumps(benchmark, indent=2) + "\n")


=== GITHUB: 06_gpu_and_ml/openai_whisper/batched_whisper.py ===
# # Fast Whisper inference using dynamic batching

# In this example, we demonstrate how to run [dynamically batched inference](https://modal.com/docs/guide/dynamic-batching)
# for OpenAI's speech recognition model, [Whisper](https://openai.com/index/whisper/), on Modal.
# Batching multiple audio samples together or batching chunks of a single audio sample can help to achieve a 2.8x increase
# in inference throughput on an A10G!

# We will be running the [Whisper Large V3](https://huggingface.co/openai/whisper-large-v3) model.
# To run [any of the other HuggingFace Whisper models](https://huggingface.co/models?search=openai/whisper),
# simply replace the `MODEL_NAME` and `MODEL_REVISION` variables.

# ## Setup

# Let's start by importing the Modal client and defining the model that we want to serve.


from typing import Optional

import modal

MODEL_DIR = "/model"
MODEL_NAME = "openai/whisper-large-v3"
MODEL_REVISION = "afda370583db9c5359511ed5d989400a6199dfe1"


# ## Define a container image

# We’ll start with Modal's baseline `debian_slim` image and install the relevant libraries.

image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "torch==2.5.1",
        "transformers==4.47.1",
        "hf-transfer==0.1.8",
        "huggingface_hub==0.27.0",
        "librosa==0.10.2",
        "soundfile==0.12.1",
        "accelerate==1.2.1",
        "datasets==3.2.0",
    )
    # Use the barebones `hf-transfer` package for maximum download speeds. No progress bar, but expect 700MB/s.
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HUB_CACHE": MODEL_DIR})
)

model_cache = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)
app = modal.App(
    "example-whisper-batched-inference",
    image=image,
    volumes={MODEL_DIR: model_cache},
)

# ## Caching the model weights

# We'll define a function to download the model and cache it in a volume.
# You can `modal run` against this function prior to deploying the App.


@app.function()
def download_model():
    from huggingface_hub import snapshot_download
    from transformers.utils import move_cache

    snapshot_download(
        MODEL_NAME,
        ignore_patterns=["*.pt", "*.bin"],  # Using safetensors
        revision=MODEL_REVISION,
    )
    move_cache()


# ## The model class

# The inference function is best represented using Modal's [class syntax](https://modal.com/docs/guide/lifecycle-functions).

# We define a `@modal.enter` method to load the model when the container starts, before it picks up any inputs.
# The weights will be loaded from the Hugging Face cache volume so that we don't need to download them when
# we start a new container.

# We also define a `transcribe` method that uses the `@modal.batched` decorator to enable dynamic batching.
# This allows us to invoke the function with individual audio samples, and the function will automatically batch them
# together before running inference. Batching is critical for making good use of the GPU, since GPUs are designed
# for running parallel operations at high throughput.

# The `max_batch_size` parameter limits the maximum number of audio samples combined into a single batch.
# We used a `max_batch_size` of `64`, the largest power-of-2 batch size that can be accommodated by the 24 A10G GPU memory.
# This number will vary depending on the model and the GPU you are using.

# The `wait_ms` parameter sets the maximum time to wait for more inputs before running the batched transcription.
# To tune this parameter, you can set it to the target latency of your application minus the execution time of an inference batch.
# This allows the latency of any request to stay within your target latency.


@app.cls(
    gpu="a10g",  # Try using an A100 or H100 if you've got a large model or need big batches!
    max_containers=10,  # default max GPUs for Modal's free tier
)
class Model:
    @modal.enter()
    def load_model(self):
        import torch
        from transformers import (
            AutoModelForSpeechSeq2Seq,
            AutoProcessor,
            pipeline,
        )

        self.processor = AutoProcessor.from_pretrained(MODEL_NAME)
        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True,
            use_safetensors=True,
        ).to("cuda")

        self.model.generation_config.language = "<|en|>"

        # Create a pipeline for preprocessing and transcribing speech data
        self.pipeline = pipeline(
            "automatic-speech-recognition",
            model=self.model,
            tokenizer=self.processor.tokenizer,
            feature_extractor=self.processor.feature_extractor,
            torch_dtype=torch.float16,
            device="cuda",
        )

    @modal.batched(max_batch_size=64, wait_ms=1000)
    def transcribe(self, audio_samples):
        import time

        start = time.monotonic_ns()
        print(f"Transcribing {len(audio_samples)} audio samples")
        transcriptions = self.pipeline(audio_samples, batch_size=len(audio_samples))
        end = time.monotonic_ns()
        print(
            f"Transcribed {len(audio_samples)} samples in {round((end - start) / 1e9, 2)}s"
        )
        return transcriptions


# ## Transcribe a dataset

# In this example, we use the [librispeech_asr_dummy dataset](https://huggingface.co/datasets/hf-internal-testing/librispeech_asr_dummy)
# from Hugging Face's Datasets library to test the model.

# We use [`map.aio`](https://modal.com/docs/reference/modal.Function#map) to asynchronously map over the audio files.
# This allows us to invoke the batched transcription method on each audio sample in parallel.


@app.function()
async def transcribe_hf_dataset(dataset_name):
    from datasets import load_dataset

    print("📂 Loading dataset", dataset_name)
    ds = load_dataset(dataset_name, "clean", split="validation")
    print("📂 Dataset loaded")
    batched_whisper = Model()
    print("📣 Sending data for transcription")
    async for transcription in batched_whisper.transcribe.map.aio(ds["audio"]):
        yield transcription


# ## Run the model

# We define a [`local_entrypoint`](https://modal.com/docs/guide/apps#entrypoints-for-ephemeral-apps)
# to run the transcription. You can run this locally with `modal run batched_whisper.py`.


@app.local_entrypoint()
async def main(dataset_name: Optional[str] = None):
    if dataset_name is None:
        dataset_name = "hf-internal-testing/librispeech_asr_dummy"
    for result in transcribe_hf_dataset.remote_gen(dataset_name):
        print(result["text"])


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/requirements.txt ===
datasets~=3.2.0
evaluate~=0.4.3
jiwer~=3.0.5
librosa~=0.10.0
torch~=2.5.1
torchaudio~=2.5.1
transformers~=4.48.0
accelerate~=1.2.1


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/readme.md ===
## Fine-tuning OpenAI's whisper model for improved automatic Hindi speech recognition

The following configuration will finetune the `whisper-small` model for almost 3 hrs,
acheiving a word error rate (WER) of about 55-60. Increasing the number of training
epochs should improve performance, decreasing WER.

You can benchmark this example's performance using Huggingface's [**autoevaluate leaderboard**]https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=mozilla-foundation%2Fcommon_voice_11_0&only_verified=0&task=automatic-speech-recognition&config=hi&split=test&metric=wer).

```bash
modal run -m train.train --num_train_epochs=10
```

### Testing

Use `modal run -m train.end_to_end_check` to do a full train → serialize → save → load → predict
run in less than 5 minutes, checking that the finetuning program is functional.


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/train/config.py ===
from dataclasses import dataclass, field
from typing import Optional


@dataclass
class ModalAppConfig:
    dataset = "mozilla-foundation/common_voice_11_0"
    cache_dir = "/cache"
    model_dir = "/models"


app_config = ModalAppConfig()


@dataclass
class ModelArguments:
    """
    Arguments pertaining to which models/config/tokenizer we are going to fine-tune from.
    """

    model_name_or_path: str = field(
        metadata={
            "help": "Path to pretrained model or model identifier from huggingface.co/models"
        }
    )
    config_name: Optional[str] = field(
        default=None,
        metadata={
            "help": "Pretrained config name or path if not the same as model_name"
        },
    )
    tokenizer_name: Optional[str] = field(
        default=None,
        metadata={
            "help": "Pretrained tokenizer name or path if not the same as model_name"
        },
    )
    feature_extractor_name: Optional[str] = field(
        default=None,
        metadata={
            "help": "feature extractor name or path if not the same as model_name"
        },
    )
    cache_dir: Optional[str] = field(
        default=app_config.cache_dir,
        metadata={
            "help": "Where to store the pretrained models downloaded from huggingface.co"
        },
    )
    use_fast_tokenizer: bool = field(
        default=True,
        metadata={
            "help": "Whether to use one of the fast tokenizer (backed by the tokenizers library) or not."
        },
    )
    model_revision: str = field(
        default="main",
        metadata={
            "help": "The specific model version to use (can be a branch name, tag name or commit id)."
        },
    )
    use_auth_token: bool = field(
        default=False,
        metadata={
            "help": (
                "Will use the token generated when running `huggingface-cli login` (necessary to use this script "
                "with private models)."
            )
        },
    )
    freeze_feature_encoder: bool = field(
        default=True,
        metadata={"help": "Whether to freeze the feature encoder layers of the model."},
    )
    freeze_encoder: bool = field(
        default=False,
        metadata={"help": "Whether to freeze the entire encoder of the seq2seq model."},
    )
    forced_decoder_ids: list[list[int]] = field(
        default=None,
        metadata={
            "help": (
                "A list of pairs of integers which indicates a mapping from generation indices to token indices "
                "that will be forced before sampling. For example, [[0, 123]] means the first generated token "
                "will always be a token of index 123."
            )
        },
    )
    suppress_tokens: list[int] = field(
        default=None,
        metadata={"help": "A list of tokens that will be suppressed at generation."},
    )
    apply_spec_augment: bool = field(
        default=False,
        metadata={
            "help": "Whether to apply *SpecAugment* data augmentation to the input features. This is currently only relevant for Wav2Vec2, HuBERT, WavLM and Whisper models."
        },
    )


@dataclass
class DataTrainingArguments:
    """
    Arguments pertaining to what data we are going to input our model for training and eval.
    """

    dataset_name: str = field(
        default=None,
        metadata={"help": "The name of the dataset to use (via the datasets library)."},
    )
    dataset_config_name: Optional[str] = field(
        default=None,
        metadata={
            "help": "The configuration name of the dataset to use (via the datasets library)."
        },
    )
    text_column: Optional[str] = field(
        default=None,
        metadata={
            "help": "The name of the column in the datasets containing the full texts (for summarization)."
        },
    )
    overwrite_cache: bool = field(
        default=False,
        metadata={"help": "Overwrite the cached training and evaluation sets"},
    )
    preprocessing_num_workers: Optional[int] = field(
        default=None,
        metadata={"help": "The number of processes to use for the preprocessing."},
    )
    max_train_samples: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "For debugging purposes or quicker training, truncate the number of training examples to this "
                "value if set."
            )
        },
    )
    max_eval_samples: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "For debugging purposes or quicker training, truncate the number of evaluation examples to this "
                "value if set."
            )
        },
    )
    audio_column_name: str = field(
        default="audio",
        metadata={
            "help": "The name of the dataset column containing the audio data. Defaults to 'audio'"
        },
    )
    text_column_name: str = field(
        default="sentence",
        metadata={
            "help": "The name of the dataset column containing the text data. Defaults to 'sentence'"
        },
    )
    max_duration_in_seconds: float = field(
        default=20.0,
        metadata={
            "help": (
                "Truncate audio files that are longer than `max_duration_in_seconds` seconds to"
                " 'max_duration_in_seconds`"
            )
        },
    )
    min_duration_in_seconds: float = field(
        default=0.0,
        metadata={
            "help": "Filter audio files that are shorter than `min_duration_in_seconds` seconds"
        },
    )
    preprocessing_only: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to only do data preprocessing and skip training. This is especially useful when data"
                " preprocessing errors out in distributed training due to timeout. In this case, one should run the"
                " preprocessing in a non-distributed setup with `preprocessing_only=True` so that the cached datasets"
                " can consequently be loaded in distributed training"
            )
        },
    )
    train_split_name: str = field(
        default="train",
        metadata={
            "help": "The name of the training data set split to use (via the datasets library). Defaults to 'train'"
        },
    )
    eval_split_name: str = field(
        default="test",
        metadata={
            "help": "The name of the training data set split to use (via the datasets library). Defaults to 'train'"
        },
    )
    do_lower_case: bool = field(
        default=True,
        metadata={"help": "Whether the target text should be lower cased."},
    )
    language: str = field(
        default=None,
        metadata={
            "help": (
                "Language for multilingual fine-tuning. This argument should be set for multilingual fine-tuning "
                "only. For English speech recognition, it should be set to `None`."
            )
        },
    )
    task: str = field(
        default="transcribe",
        metadata={
            "help": "Task, either `transcribe` for speech recognition or `translate` for speech translation."
        },
    )


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/train/logs.py ===
import logging


def get_logger(name, level=logging.INFO):
    logger = logging.getLogger(name)
    handler = logging.StreamHandler()
    handler.setFormatter(
        logging.Formatter("%(levelname)s: %(asctime)s: %(name)s  %(message)s")
    )
    logger.addHandler(handler)
    logger.setLevel(level)
    return logger


def setup_logging(*, logger: logging.Logger, log_level: int) -> None:
    import datasets
    import transformers

    datasets.utils.logging.set_verbosity(log_level)
    transformers.utils.logging.set_verbosity(log_level)
    transformers.utils.logging.enable_default_handler()
    transformers.utils.logging.enable_explicit_format()


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/train/transcribe.py ===
import os
from typing import TYPE_CHECKING

from .logs import get_logger

if TYPE_CHECKING:
    from numpy import ndarray

logger = get_logger(__name__)


def whisper_transcribe_local_file(
    model_dir: os.PathLike,
    language: str,
    filepath: os.PathLike,
    sample_rate_hz: int,
) -> str:
    """Convenience function for transcribing a single local audio file with a Whisper model already saved to disk."""
    from datasets import Audio, Dataset

    audio_dataset = Dataset.from_dict({"audio": [str(filepath)]}).cast_column(
        "audio", Audio(sampling_rate=sample_rate_hz)
    )
    row = next(iter(audio_dataset))
    return whisper_transcribe_audio(
        model_dir,
        language,
        data=row["audio"]["array"],
        sample_rate_hz=row["audio"]["sampling_rate"],
    )


def whisper_transcribe_audio(
    model_dir: os.PathLike,
    language: str,
    data: "ndarray",
    sample_rate_hz: int,
) -> str:
    """Transcribes a single audio sample with a Whisper model, for demonstration purposes."""
    from transformers import (
        WhisperForConditionalGeneration,
        WhisperProcessor,
    )

    # load model and processor
    processor = WhisperProcessor.from_pretrained(model_dir)
    model = WhisperForConditionalGeneration.from_pretrained(model_dir)
    forced_decoder_ids = processor.get_decoder_prompt_ids(
        language=language, task="transcribe"
    )
    input_features = processor(
        data,
        sampling_rate=sample_rate_hz,
        return_tensors="pt",
    ).input_features

    # generate token ids
    predicted_ids = model.generate(
        input_features, forced_decoder_ids=forced_decoder_ids
    )
    # decode token ids to text
    predicted_transcription = processor.batch_decode(
        predicted_ids, skip_special_tokens=True
    )[0]
    return predicted_transcription


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/train/train.py ===
# Fine-tuning the OpenAI Whisper model on Modal for improved
# transcription performance on the Hindi language.
#
# Based on the work done in https://huggingface.co/blog/fine-tune-whisper.

import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Union

import modal

from .config import DataTrainingArguments, ModelArguments, app_config
from .logs import get_logger, setup_logging

persistent_volume = modal.Volume.from_name(
    "example-whisper-fine-tune-vol",
    create_if_missing=True,
)

image = modal.Image.debian_slim(python_version="3.12").pip_install_from_requirements(
    "requirements.txt"
)
app = modal.App(
    name="example-whisper-fine-tune",
    image=image,
    secrets=[modal.Secret.from_name("huggingface-secret", required_keys=["HF_TOKEN"])],
)

logger = get_logger(__name__)


@app.function(
    gpu="A10G",
    volumes={app_config.model_dir: persistent_volume},
    # 12hrs
    timeout=12 * 60 * 60,
    # For occasional connection error to 'cdn-lfs.huggingface.co'
    retries=1,
)
def train(
    num_train_epochs: int = 5,
    warmup_steps: int = 400,
    max_steps: int = -1,
    overwrite_output_dir: bool = False,
):
    import datasets
    import evaluate
    import torch
    from datasets import DatasetDict, load_dataset
    from transformers import (
        AutoConfig,
        AutoFeatureExtractor,
        AutoModelForSpeechSeq2Seq,
        AutoProcessor,
        AutoTokenizer,
        Seq2SeqTrainer,
        Seq2SeqTrainingArguments,
    )
    from transformers.trainer_utils import get_last_checkpoint, is_main_process

    model_args = ModelArguments(
        model_name_or_path="openai/whisper-small",
        freeze_feature_encoder=False,
    )

    run_id = app.app_id
    output_dir = Path(app_config.model_dir, run_id).as_posix()

    data_args = DataTrainingArguments(
        dataset_config_name="clean",
        train_split_name="train.100",
        eval_split_name="validation",
        text_column_name="sentence",
        preprocessing_num_workers=16,
        max_train_samples=5,
        max_eval_samples=5,
        do_lower_case=True,
    )

    training_args = Seq2SeqTrainingArguments(
        length_column_name="input_length",
        output_dir=output_dir,
        num_train_epochs=num_train_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=8,
        learning_rate=3e-4,
        warmup_steps=warmup_steps,
        max_steps=max_steps,
        evaluation_strategy="steps",
        save_total_limit=3,
        gradient_checkpointing=True,
        fp16=True,
        group_by_length=True,
        predict_with_generate=True,
        generation_max_length=40,
        generation_num_beams=1,
        do_train=True,
        do_eval=True,
    )

    @dataclass
    class DataCollatorSpeechSeq2SeqWithPadding:
        """
        Data collator that will dynamically pad the inputs received.
        Args:
            processor ([`WhisperProcessor`])
                The processor used for processing the data.
            decoder_start_token_id (`int`)
                The begin-of-sentence of the decoder.
            forward_attention_mask (`bool`)
                Whether to return attention_mask.
        """

        processor: Any
        decoder_start_token_id: int
        forward_attention_mask: bool

        def __call__(
            self, features: list[dict[str, Union[list[int], torch.Tensor]]]
        ) -> dict[str, torch.Tensor]:
            # split inputs and labels since they have to be of different lengths and need
            # different padding methods
            model_input_name = self.processor.model_input_names[0]
            input_features = [
                {model_input_name: feature[model_input_name]} for feature in features
            ]
            label_features = [{"input_ids": feature["labels"]} for feature in features]

            batch = self.processor.feature_extractor.pad(
                input_features, return_tensors="pt"
            )

            if self.forward_attention_mask:
                batch["attention_mask"] = torch.LongTensor(
                    [feature["attention_mask"] for feature in features]
                )

            labels_batch = self.processor.tokenizer.pad(
                label_features, return_tensors="pt"
            )

            # replace padding with -100 to ignore loss correctly
            labels = labels_batch["input_ids"].masked_fill(
                labels_batch.attention_mask.ne(1), -100
            )

            # if bos token is appended in previous tokenization step,
            # cut bos token here as it's append later anyways
            if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():
                labels = labels[:, 1:]

            batch["labels"] = labels

            return batch

    logger.info("Starting training run")
    logger.info(f"Finetuned model will be persisted to '{training_args.output_dir}'")
    setup_logging(
        logger=logger,
        log_level=training_args.get_process_log_level(),
    )

    # Log on each process the small summary:
    logger.warning(
        f"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu} "
        f"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}"
    )
    logger.info(f"Training/evaluation parameters {training_args}")

    logger.info(
        "3. Detecting last checkpoint and eventually continue from last checkpoint"
    )
    last_checkpoint = None
    if (
        Path(training_args.output_dir).exists()
        and training_args.do_train
        and not overwrite_output_dir
    ):
        last_checkpoint = get_last_checkpoint(training_args.output_dir)
        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:
            print(os.listdir(training_args.output_dir))
            raise ValueError(
                f"Output directory ({training_args.output_dir}) already exists and is not empty. "
                "Use --overwrite_output_dir to overcome."
            )
        elif (
            last_checkpoint is not None and training_args.resume_from_checkpoint is None
        ):
            logger.info(
                f"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change "
                "the `--output_dir` or add `--overwrite_output_dir` to train from scratch."
            )

    logger.info("4. Load datasets")
    raw_datasets = DatasetDict()
    raw_datasets["train"] = load_dataset(
        "mozilla-foundation/common_voice_11_0",
        "hi",
        split="train+validation",
        trust_remote_code=True,
    )
    raw_datasets["eval"] = load_dataset(
        "mozilla-foundation/common_voice_11_0",
        "hi",
        split="test",
    )

    # Most ASR datasets only provide input audio samples (audio) and
    # the corresponding transcribed text (sentence).
    # Common Voice contains additional metadata information,
    # such as accent and locale, which we can disregard for ASR.
    # Keeping the training function as general as possible,
    # we only consider the input audio and transcribed text for fine-tuning,
    # discarding the additional metadata information:
    raw_datasets = raw_datasets.remove_columns(
        [
            "accent",
            "age",
            "client_id",
            "down_votes",
            "gender",
            "locale",
            "path",
            "segment",
            "up_votes",
        ]
    )

    logger.info("5. Load pretrained model, tokenizer, and feature extractor")
    #
    # Distributed training:
    # The .from_pretrained methods guarantee that only one local process can concurrently
    config = AutoConfig.from_pretrained(
        (
            model_args.config_name
            if model_args.config_name
            else model_args.model_name_or_path
        ),
        cache_dir=model_args.cache_dir,
        revision=model_args.model_revision,
        use_auth_token=os.environ["HF_TOKEN"],
    )

    config.update(
        {
            "forced_decoder_ids": model_args.forced_decoder_ids,
            "suppress_tokens": model_args.suppress_tokens,
        }
    )
    # SpecAugment for whisper models
    config.update({"apply_spec_augment": model_args.apply_spec_augment})

    feature_extractor = AutoFeatureExtractor.from_pretrained(
        (
            model_args.feature_extractor_name
            if model_args.feature_extractor_name
            else model_args.model_name_or_path
        ),
        cache_dir=model_args.cache_dir,
        revision=model_args.model_revision,
        use_auth_token=True if model_args.use_auth_token else None,
    )
    tokenizer = AutoTokenizer.from_pretrained(
        (
            model_args.tokenizer_name
            if model_args.tokenizer_name
            else model_args.model_name_or_path
        ),
        cache_dir=model_args.cache_dir,
        use_fast=model_args.use_fast_tokenizer,
        revision=model_args.model_revision,
        use_auth_token=True if model_args.use_auth_token else None,
    )
    model = AutoModelForSpeechSeq2Seq.from_pretrained(
        model_args.model_name_or_path,
        config=config,
        cache_dir=model_args.cache_dir,
        revision=model_args.model_revision,
        use_auth_token=True if model_args.use_auth_token else None,
    )

    if model.config.decoder_start_token_id is None:
        raise ValueError(
            "Make sure that `config.decoder_start_token_id` is correctly defined"
        )

    if model_args.freeze_feature_encoder:
        model.freeze_feature_encoder()

    if model_args.freeze_encoder:
        model.freeze_encoder()
        model.model.encoder.gradient_checkpointing = False

    if data_args.language is not None:
        # We only need to set the task id when the language is specified (i.e. in a multilingual setting)
        tokenizer.set_prefix_tokens(language=data_args.language, task=data_args.task)

    logger.info("6. Resample speech dataset if necessary")
    dataset_sampling_rate = (
        next(iter(raw_datasets.values()))
        .features[data_args.audio_column_name]
        .sampling_rate
    )
    if dataset_sampling_rate != feature_extractor.sampling_rate:
        logger.info("Resampling necessary")
        raw_datasets = raw_datasets.cast_column(
            data_args.audio_column_name,
            datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate),
        )

    logger.info("7. Preprocessing the datasets.")
    # We need to read the audio files as arrays and tokenize the targets.
    max_input_length = (
        data_args.max_duration_in_seconds * feature_extractor.sampling_rate
    )
    min_input_length = (
        data_args.min_duration_in_seconds * feature_extractor.sampling_rate
    )
    audio_column_name = data_args.audio_column_name
    num_workers = data_args.preprocessing_num_workers
    text_column_name = data_args.text_column_name
    model_input_name = feature_extractor.model_input_names[0]
    do_lower_case = data_args.do_lower_case
    # if SpecAugment is used for whisper models, return attention_mask to guide the mask along time axis
    forward_attention_mask = (
        getattr(config, "model_type", None) == "whisper"
        and getattr(config, "apply_spec_augment", False)
        and getattr(config, "mask_time_prob", 0) > 0
    )

    if data_args.max_train_samples is not None:
        raw_datasets["train"] = raw_datasets["train"].select(
            range(data_args.max_train_samples)
        )

    if data_args.max_eval_samples is not None:
        raw_datasets["eval"] = raw_datasets["eval"].select(
            range(data_args.max_eval_samples)
        )

    def prepare_dataset(batch):
        # process audio
        sample = batch[audio_column_name]
        inputs = feature_extractor(
            sample["array"],
            sampling_rate=sample["sampling_rate"],
            return_attention_mask=forward_attention_mask,
        )
        # process audio length
        batch[model_input_name] = inputs.get(model_input_name)[0]
        batch["input_length"] = len(sample["array"])
        if forward_attention_mask:
            batch["attention_mask"] = inputs.get("attention_mask")[0]

        # process targets
        input_str = (
            batch[text_column_name].lower()
            if do_lower_case
            else batch[text_column_name]
        )
        batch["labels"] = tokenizer(input_str).input_ids
        return batch

    with training_args.main_process_first(desc="dataset map pre-processing"):
        vectorized_datasets = raw_datasets.map(
            prepare_dataset,
            remove_columns=next(iter(raw_datasets.values())).column_names,
            num_proc=data_args.preprocessing_num_workers,
            desc="preprocess train dataset",
        )

    # filter data that is shorter than min_input_length or longer than
    # max_input_length
    def is_audio_in_length_range(length):
        return length > min_input_length and length < max_input_length

    vectorized_datasets = vectorized_datasets.filter(
        is_audio_in_length_range,
        num_proc=num_workers,
        input_columns=["input_length"],
    )

    # for large datasets it is advised to run the preprocessing on a
    # single machine first with `args.preprocessing_only` since there will mostly likely
    # be a timeout when running the script in distributed mode.
    # In a second step `args.preprocessing_only` can then be set to `False` to load the
    # cached dataset
    if data_args.preprocessing_only:
        cache = {k: v.cache_files for k, v in vectorized_datasets.items()}
        logger.info(f"Data preprocessing finished. Files cached at {cache}.")
        return

    logger.info("8. Loading WER Metric")
    metric = evaluate.load("wer")

    def compute_metrics(pred):
        pred_ids = pred.predictions

        pred.label_ids[pred.label_ids == -100] = tokenizer.pad_token_id

        pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
        # we do not want to group tokens when computing the metrics
        label_str = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)

        wer = metric.compute(predictions=pred_str, references=label_str)

        return {"wer": wer}

    logger.info("9. Create a single speech processor")
    # make sure all processes wait until data is saved
    with training_args.main_process_first():
        # only the main process saves them
        if is_main_process(training_args.local_rank):
            logger.info("saving feature extractor, tokenizer and config")
            feature_extractor.save_pretrained(training_args.output_dir)
            tokenizer.save_pretrained(training_args.output_dir)
            config.save_pretrained(training_args.output_dir)

    processor = AutoProcessor.from_pretrained(training_args.output_dir)

    logger.info("10. Constructing data collator")
    data_collator = DataCollatorSpeechSeq2SeqWithPadding(
        processor=processor,
        decoder_start_token_id=model.config.decoder_start_token_id,
        forward_attention_mask=forward_attention_mask,
    )

    logger.info("11. Initializing Trainer class")
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=(
            vectorized_datasets["train"] if training_args.do_train else None
        ),
        eval_dataset=(vectorized_datasets["eval"] if training_args.do_eval else None),
        tokenizer=feature_extractor,
        data_collator=data_collator,
        compute_metrics=(
            compute_metrics if training_args.predict_with_generate else None
        ),
    )

    logger.info("12. Running training")
    if training_args.do_train:
        checkpoint = None
        if training_args.resume_from_checkpoint is not None:
            checkpoint = training_args.resume_from_checkpoint
        elif last_checkpoint is not None:
            logger.info("Restoring from previous training checkpoint")
            checkpoint = last_checkpoint
        train_result = trainer.train(resume_from_checkpoint=checkpoint)
        logger.info("Saving model")
        trainer.save_model()  # Saves the feature extractor too for easy upload

        metrics = train_result.metrics
        max_train_samples = (
            data_args.max_train_samples
            if data_args.max_train_samples is not None
            else len(vectorized_datasets["train"])
        )
        metrics["train_samples"] = min(
            max_train_samples, len(vectorized_datasets["train"])
        )
        trainer.log_metrics("train", metrics)
        trainer.save_metrics("train", metrics)
        trainer.save_state()
        persistent_volume.commit()

    logger.info("13. Running evaluation")
    results = {}  # type: ignore
    if training_args.do_eval:
        logger.info("*** Evaluate ***")
        metrics = trainer.evaluate(
            metric_key_prefix="eval",
            max_length=training_args.generation_max_length,
            num_beams=training_args.generation_num_beams,
        )
        max_eval_samples = (
            data_args.max_eval_samples
            if data_args.max_eval_samples is not None
            else len(vectorized_datasets["eval"])
        )
        metrics["eval_samples"] = min(
            max_eval_samples, len(vectorized_datasets["eval"])
        )

        trainer.log_metrics("eval", metrics)
        trainer.save_metrics("eval", metrics)

    logger.info("14. Write training stats")
    kwargs = {
        "finetuned_from": model_args.model_name_or_path,
        "tasks": "automatic-speech-recognition",
    }
    if data_args.dataset_name is not None:
        kwargs["dataset_tags"] = data_args.dataset_name
        if data_args.dataset_config_name is not None:
            kwargs["dataset_args"] = data_args.dataset_config_name
            kwargs["dataset"] = (
                f"{data_args.dataset_name} {data_args.dataset_config_name}"
            )
        else:
            kwargs["dataset"] = data_args.dataset_name

    if training_args.push_to_hub:
        trainer.push_to_hub(**kwargs)
    else:
        trainer.create_model_card(**kwargs)

    logger.info("Training run complete!")
    return results


=== GITHUB: 06_gpu_and_ml/openai_whisper/finetuning/train/end_to_end_check.py ===
"""
A full fine-tuning run on GPUs takes multiple hours, but we
want to be able to validate changes quickly while coding.

This module contains an end-to-end test that runs only 1 step of training,
before testing that the partially trained model can be serialized, saved to
persistent storage, and then downloaded locally for inference.
"""

import pathlib

from .config import app_config
from .logs import get_logger
from .train import app, persistent_volume, train
from .transcribe import whisper_transcribe_audio

logger = get_logger(__name__)


# Test model serialization and persistence by starting a new remote
# function that reads back the model files from the temporary network file system disk
# and does a single sentence of translation.
#
# When doing full training runs, the saved model will be loaded in the same way
# but from a *persisted* network file system, which keeps data around even after the Modal
# ephemeral app that ran the training has stopped.


@app.function(volumes={app_config.model_dir: persistent_volume})
def test_download_and_tryout_model(run_id: str):
    from datasets import Audio, load_dataset
    from evaluate import load

    lang, lang_short = (
        "french",
        "fr",
    )  # the language doesn't matter for this test.
    model_dir = pathlib.Path(app_config.model_dir, run_id)

    # load streaming dataset and read first audio sample
    ds = load_dataset(
        app_config.dataset,
        lang_short,
        split="test",
        streaming=True,
        trust_remote_code=True,
    )
    ds = ds.cast_column("audio", Audio(sampling_rate=16_000))
    test_row = next(iter(ds))
    input_speech = test_row["audio"]

    predicted_transcription = whisper_transcribe_audio(
        model_dir=model_dir,
        language=lang,
        data=input_speech["array"],
        sample_rate_hz=input_speech["sampling_rate"],
    )
    expected_transcription = test_row["sentence"]
    wer = load("wer")
    wer_score = wer.compute(
        predictions=[predicted_transcription],
        references=[expected_transcription],
    )
    logger.info(
        f"{expected_transcription=}\n{predicted_transcription=}\n"
        f"Word Error Rate (WER): {wer_score}"
    )
    assert wer_score < 1.0, (
        f"Even without finetuning, a WER score of {wer_score} is far too high."
    )


# This simple entrypoint function just starts an ephemeral app run and calls
# the two test functions in sequence.
#
# Any runtime errors or assertion errors will fail the app and exit non-zero.


@app.local_entrypoint()
def run_test():
    # Test the `main.train` function by passing in test-specific configuration
    # that does only a minimal amount of training steps and saves the model
    # to the temporary (ie. ephemeral) network file system disk.
    #
    # This should take only ~1 min to run.
    train.remote(num_train_epochs=1.0, warmup_steps=0, max_steps=1)
    test_download_and_tryout_model.remote(run_id=app.app_id)


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/README.md ===
# Modal Podcast Transcriber

This is a complete application that uses [OpenAI Whisper](https://github.com/openai/whisper) to transcribe podcasts. Modal spins up 100-300 containers for a single transcription run, so hours of audio can be transcribed on-demand in a few minutes.

You can find our deployment of the app [here](https://modal-labs-examples--whisper-pod-transcriber-fastapi-app.modal.run/).

## Architecture

The entire application is hosted serverlessly on Modal and consists of 3 components:

1. React + Vite SPA ([`app/frontend/`](./app/frontend/))
2. FastAPI server ([`app/api.py`](./app/api.py))
3. Modal async job queue ([`app/main.py`](./app/main.py))

## Developing locally

### Requirements

- `npm`
- `modal` installed in your current Python virtual environment

### Podchaser Secret

To run this on your own Modal account, you'll need to [create a Podchaser account and create an API key](https://api-docs.podchaser.com/docs/guides/guide-first-podchaser-query/#getting-your-access-token).

Then, create a [Modal Secret](https://modal.com/secrets/) with the following keys:

- `PODCHASER_CLIENT_SECRET`
- `PODCHASER_CLIENT_ID`

You can find both on [their API page](https://www.podchaser.com/profile/settings/api).

### Vite build

`cd` into the `app/frontend` directory, and run:

- `npm install`
- `npx vite build --watch`

The last command will start a watcher process that will rebuild your static frontend files whenever you make changes to the frontend code.

### Serve on Modal

Once you have `vite build` running, in a separate shell run this to start an ephemeral app on Modal:

```shell
modal serve -m app.main
```

Pressing `Ctrl+C` will stop your app.

### Deploy to Modal

Once your happy with your changes, run `modal deploy -m app.main` to deploy your app to Modal.


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/config.py ===
import dataclasses
import logging
import pathlib


@dataclasses.dataclass
class ModelSpec:
    name: str
    params: str
    relative_speed: int  # Higher is faster


def get_logger(name, level=logging.INFO):
    logger = logging.getLogger(name)
    handler = logging.StreamHandler()
    handler.setFormatter(
        logging.Formatter("%(levelname)s: %(asctime)s: %(name)s  %(message)s")
    )
    logger.addHandler(handler)
    logger.setLevel(level)
    return logger


CACHE_DIR = "/cache"
# Where downloaded podcasts are stored, by guid hash.
# Mostly .mp3 files 50-100MiB.
RAW_AUDIO_DIR = pathlib.Path(CACHE_DIR, "raw_audio")
# Stores metadata of individual podcast episodes as JSON.
PODCAST_METADATA_DIR = pathlib.Path(CACHE_DIR, "podcast_metadata")
# Completed episode transcriptions. Stored as flat files with
# files structured as '{guid_hash}-{model_slug}.json'.
TRANSCRIPTIONS_DIR = pathlib.Path(CACHE_DIR, "transcriptions")
# Searching indexing files, refreshed by scheduled functions.
SEARCH_DIR = pathlib.Path(CACHE_DIR, "search")
# Location of modal checkpoint.
MODEL_DIR = pathlib.Path(CACHE_DIR, "model")
# Location of web frontend assets.
ASSETS_PATH = pathlib.Path(__file__).parent / "frontend" / "dist"

transcripts_per_podcast_limit = 2

supported_whisper_models = {
    "tiny.en": ModelSpec(name="tiny.en", params="39M", relative_speed=32),
    # Takes around 3-10 minutes to transcribe a podcast, depending on length.
    "base.en": ModelSpec(name="base.en", params="74M", relative_speed=16),
    "small.en": ModelSpec(name="small.en", params="244M", relative_speed=6),
    "medium.en": ModelSpec(name="medium.en", params="769M", relative_speed=2),
    # Very slow. Will take around 45 mins to 1.5 hours to transcribe.
    "large": ModelSpec(name="large", params="1550M", relative_speed=1),
}

DEFAULT_MODEL = supported_whisper_models["base.en"]


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/transcribe_check.py ===
import pathlib

import modal

from . import config, podcast
from .main import (
    app,
    app_image,
    split_silences,
    transcribe_episode,
    transcribe_segment,
    volume,
)

logger = config.get_logger(__name__)


def _transcribe_serially(
    audio_path: pathlib.Path, offset: int = 0
) -> list[tuple[float, float]]:
    model = config.DEFAULT_MODEL
    segment_gen = split_silences(str(audio_path))
    failed_segments = []
    for i, (start, end) in enumerate(segment_gen):
        if i < offset:
            continue
        logger.info(f"Attempting transcription of ({start}, {end})...")
        try:
            transcribe_segment.local(
                start=start, end=end, audio_filepath=audio_path, model=model
            )
        except Exception as exc:
            logger.info(f"Transcription failed for ({start}, {end}).")
            print(exc)
            failed_segments.append((start, end))
    logger.info(f"{len(failed_segments)} failed to transcribe.")
    return failed_segments


@app.function(
    image=app_image,
    volumes={config.CACHE_DIR: volume},
    timeout=1000,
)
def test_transcribe_handles_dangling_segment():
    """
    Some podcast episodes have an empty, dangling audio segment after being split on silences.
    This test runs transcription on such an episode to check that we haven't broken transcription
    on episodes like this.

    If the transcription does fail, individual segments are checked to pull out the problem segments
    for further debugging.
    ```
    libpostproc    55.  7.100 / 55.  7.100
    [mp3 @ 0x557b828bb380] Format mp3 detected only with low score of 24, misdetection possible!
    [mp3 @ 0x557b828bb380] Failed to read frame size: Could not seek to 1026.
    /tmp/tmpuyr2iwce.mp3: Invalid argument
    ```
    """
    import ffmpeg

    # Stripped down podcast episode metadata for an episode which fails to transcribe @ commit e7093414.
    problem_episode = {
        "guid_hash": "b5b3005075fce663b3646f88a41b2b32",
        "podcast_id": "217829",
        "episode_url": "https://www.podchaser.com/podcasts/super-data-science-217829/episodes/sds-503-deep-reinforcement-lea-98045099",
        "original_download_link": "http://www.podtrac.com/pts/redirect.mp3/feeds.soundcloud.com/stream/1120216126-superdatascience-sds-503-deep-reinforcement-learning-for-robotics.mp3",
    }
    audio_path = pathlib.Path(
        config.CACHE_DIR, "test", f"{problem_episode['guid_hash']}.tmp.mp3"
    )
    audio_path.parent.mkdir(exist_ok=True)
    podcast.store_original_audio(
        url=problem_episode["original_download_link"],
        destination=audio_path,
    )

    model = config.DEFAULT_MODEL

    try:
        result_path = pathlib.Path(
            config.CACHE_DIR,
            "test",
            f"{problem_episode['guid_hash']}.transcription.json",
        )
        transcribe_episode.local(
            audio_filepath=audio_path,
            result_path=result_path,
            model=model,
        )
    except Exception as exc:
        print(exc)
        logger.error(
            "Transcription failed. Proceeding to checks of individual segments."
        )
    else:
        return  # Transcription worked fine.

    failed_segments = _transcribe_serially(audio_path, offset=107)
    # Checking the 1st is probably sufficient to discover bug.
    problem_segment = failed_segments[0]
    start = problem_segment[0]
    end = problem_segment[1]
    logger.info(f"Problem segment time range is ({start}, {end})")
    try:
        transcribe_segment(start=start, end=end, audio_filepath=audio_path, model=model)
    except Exception:
        logger.info(
            "Writing the problem segment to the network file system for further debugging."
        )
        bad_segment_path = pathlib.Path(
            config.CACHE_DIR,
            "test",
            f"{problem_episode['guid_hash']}.badsegment.mp3",
        )
        with open(bad_segment_path, "wb") as f:
            (
                ffmpeg.input(str(audio_path))
                .filter("atrim", start=start, end=end)
                .output(f.name)
                .overwrite_output()
                .run(quiet=True)
            )
        raise


@app.local_entrypoint()
def main():
    test_transcribe_handles_dangling_segment.remote()


if __name__ == "__main__":
    with modal.enable_output():
        with app.run():
            main()


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/podcast.py ===
import dataclasses
import os
import pathlib
import urllib.request
from typing import NamedTuple, Optional, TypedDict, Union

from . import config

logger = config.get_logger(__name__)
Segment = TypedDict("Segment", {"text": str, "start": float, "end": float})


@dataclasses.dataclass
class EpisodeMetadata:
    # Unique ID of podcast this episode is associated with.
    podcast_id: Union[str, int]
    # Title of podcast this episode is associated with.
    podcast_title: Optional[str]
    title: str
    # The publish date of the episode as specified by the publisher
    publish_date: str
    # Plaintext description of episode. nb: has whitespace issues so not suitable in UI.
    description: str
    # HTML markup description. Suitable for display in UI.
    html_description: str
    # The unique identifier of this episode within the context of the podcast
    guid: str
    # Hash the guid into something appropriate for filenames.
    guid_hash: str
    # Link to episode on Podchaser website.
    episode_url: Optional[str]
    # Link to audio file for episode. Typically an .mp3 file.
    original_download_link: str


@dataclasses.dataclass
class PodcastMetadata:
    # Unique ID for a podcast
    id: str
    # Title of podcast, eg. 'The Joe Rogan Experience'.
    title: str
    # Plaintext description of episode. nb: has whitespace issues so not suitable in UI.
    description: str
    html_description: str
    # Link to podcast on Podchaser website.
    web_url: str
    # Used to detect non-English podcasts.
    language: Optional[str] = None


class DownloadResult(NamedTuple):
    data: bytes
    # Helpful to store and transmit when uploading to cloud bucket.
    content_type: str


def download_podcast_file(url: str) -> DownloadResult:
    req = urllib.request.Request(
        url,
        data=None,
        # Set a user agent to avoid 403 response from some podcast audio servers.
        headers={
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36"
        },
    )
    with urllib.request.urlopen(req) as response:
        return DownloadResult(
            data=response.read(),
            content_type=response.headers["content-type"],
        )


def create_podchaser_client():
    """
    Use's Podchaser's graphql API to get an new access token and instantiate
    a graphql client with it.
    """
    from gql import Client, gql
    from gql.transport.aiohttp import AIOHTTPTransport

    transport = AIOHTTPTransport(url="https://api.podchaser.com/graphql")
    client = Client(transport=transport, fetch_schema_from_transport=True)
    podchaser_client_id = os.environ.get("PODCHASER_CLIENT_ID")
    podchaser_client_secret = os.environ.get("PODCHASER_CLIENT_SECRET")

    if not podchaser_client_id or not podchaser_client_secret:
        exit(
            "Must provide both PODCHASER_CLIENT_ID and PODCHASER_CLIENT_SECRET as environment vars."
        )

    query = gql(
        """
        mutation {{
            requestAccessToken(
                input: {{
                    grant_type: CLIENT_CREDENTIALS
                    client_id: "{client_id}"
                    client_secret: "{client_secret}"
                }}
            ) {{
                access_token
                token_type
            }}
        }}
    """.format(
            client_id=podchaser_client_id,
            client_secret=podchaser_client_secret,
        )
    )

    result = client.execute(query)

    access_token = result["requestAccessToken"]["access_token"]
    transport = AIOHTTPTransport(
        url="https://api.podchaser.com/graphql",
        headers={"Authorization": f"Bearer {access_token}"},
    )

    return Client(transport=transport, fetch_schema_from_transport=True)


def search_podcast_name(gql, client, name, max_results=5) -> list[dict]:
    """
    Search for a podcast by name/title. eg. 'Joe Rogan Experience' or 'Serial'.

    This method does not paginate queries because 100s of search results is not
    useful in this application.
    """
    if max_results > 100:
        raise ValueError(
            f"A maximum of 100 results is supported, but {max_results} results were requested."
        )
    current_page = 0
    max_episodes_per_request = max_results
    search_podcast_name_query = gql(
        """
        query {{
            podcasts(searchTerm: "{name}", first: {max_episodes_per_request}, page: {current_page}) {{
                paginatorInfo {{
                    currentPage,
                    hasMorePages,
                    lastPage,
                }},
                data {{
                    id,
                    title,
                    description,
                    language,
                    htmlDescription,
                    webUrl,
                }}
            }}
        }}
        """.format(
            name=name,
            max_episodes_per_request=max_episodes_per_request,
            current_page=current_page,
        )
    )
    logger.info(f"Querying Podchaser for podcasts matching query '{name}'.")
    result = client.execute(search_podcast_name_query)
    podcasts_in_page = result["podcasts"]["data"]
    return podcasts_in_page


def fetch_episodes_data(gql, client, podcast_id, max_episodes=100) -> list[dict]:
    """
    Use the Podchaser API to grab a podcast's episodes.
    """
    max_episodes_per_request = 100  # Max allowed by API
    episodes = []
    has_more_pages = True
    current_page = 0
    while has_more_pages:
        list_episodes_query = gql(
            """
            query getPodList {{
                podcast(identifier: {{id: "{id}", type: PODCHASER}}) {{
                    episodes(first: {max_episodes_per_request}, page: {current_page}) {{
                        paginatorInfo {{
                          count
                          currentPage
                          firstItem
                          hasMorePages
                          lastItem
                          lastPage
                          perPage
                          total
                        }}
                        data {{
                          id
                          title
                          airDate
                          audioUrl
                          description
                          htmlDescription
                          guid
                          url
                        }}
                    }}
                }}
            }}
        """.format(
                id=podcast_id,
                max_episodes_per_request=max_episodes_per_request,
                current_page=current_page,
            )
        )

        logger.info(f"Fetching {max_episodes_per_request} episodes from API.")
        result = client.execute(list_episodes_query)
        has_more_pages = result["podcast"]["episodes"]["paginatorInfo"]["hasMorePages"]
        episodes_in_page = result["podcast"]["episodes"]["data"]
        episodes.extend(episodes_in_page)
        current_page += 1
        if len(episodes) >= max_episodes:
            break
    return episodes


def fetch_podcast_data(gql, client, podcast_id) -> dict:
    podcast_metadata_query = gql(
        """
        query {{
            podcast(identifier: {{id: "{podcast_id}", type: PODCHASER}}) {{
                id,
                title,
                description,
                htmlDescription,
                webUrl,
            }}
        }}
        """.format(
            podcast_id=podcast_id,
        )
    )
    logger.info(f"Querying Podchaser for podcast with ID {podcast_id}.")
    result = client.execute(podcast_metadata_query)
    return result["podcast"]


def fetch_podcast(gql, podcast_id: str) -> PodcastMetadata:
    client = create_podchaser_client()
    data = fetch_podcast_data(gql=gql, client=client, podcast_id=podcast_id)
    return PodcastMetadata(
        id=data["id"],
        title=data["title"],
        description=data["description"],
        html_description=data["htmlDescription"],
        web_url=data["webUrl"],
    )


def sizeof_fmt(num, suffix="B") -> str:
    for unit in ["", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"]:
        if abs(num) < 1024.0:
            return "%3.1f%s%s" % (num, unit, suffix)
        num /= 1024.0
    return "%.1f%s%s" % (num, "Yi", suffix)


def store_original_audio(
    url: str, destination: pathlib.Path, overwrite: bool = False
) -> None:
    if destination.exists():
        if overwrite:
            logger.info(
                f"Audio file exists at {destination} but overwrite option is specified."
            )
        else:
            logger.info(f"Audio file exists at {destination}, skipping download.")
            return

    podcast_download_result = download_podcast_file(url=url)
    humanized_bytes_str = sizeof_fmt(num=len(podcast_download_result.data))
    logger.info(f"Downloaded {humanized_bytes_str} episode from URL.")
    with open(destination, "wb") as f:
        f.write(podcast_download_result.data)
    logger.info(f"Stored audio episode at {destination}.")


def coalesce_short_transcript_segments(
    segments: list[Segment],
) -> list[Segment]:
    """
    Some extracted transcript segments from openai/whisper are really short, like even just one word.
    This function accepts a minimum segment length and combines short segments until the minimum is reached.
    """
    minimum_transcript_len = 200  # About 2 sentences.
    previous = None
    long_enough_segments = []
    for current in segments:
        if previous is None:
            previous = current
        elif len(previous["text"]) < minimum_transcript_len:
            previous = _merge_segments(left=previous, right=current)
        else:
            long_enough_segments.append(previous)
            previous = current
    if previous:
        long_enough_segments.append(previous)
    return long_enough_segments


def _merge_segments(left: Segment, right: Segment) -> Segment:
    return {
        "text": left["text"] + " " + right["text"],
        "start": left["start"],
        "end": right["end"],
    }


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/api.py ===
import asyncio
import json
import time
from typing import List, NamedTuple

from fastapi import FastAPI, Request

from . import config
from .main import (
    get_episode_metadata_path,
    get_transcript_path,
    in_progress,
    populate_podcast_metadata,
    process_episode,
    search_podcast,
)
from .podcast import coalesce_short_transcript_segments

logger = config.get_logger(__name__)
web_app = FastAPI()

# A transcription taking > 10 minutes should be exceedingly rare.
MAX_JOB_AGE_SECS = 10 * 60


class InProgressJob(NamedTuple):
    call_id: str
    start_time: int


@web_app.get("/api/episode/{podcast_id}/{episode_guid_hash}")
async def get_episode(podcast_id: str, episode_guid_hash: str):
    episode_metadata_path = get_episode_metadata_path(podcast_id, episode_guid_hash)
    transcription_path = get_transcript_path(episode_guid_hash)

    web_app.state.volume.reload()

    with open(episode_metadata_path, "r") as f:
        metadata = json.load(f)

    if not transcription_path.exists():
        return dict(metadata=metadata)

    with open(transcription_path, "r") as f:
        data = json.load(f)

    return dict(
        metadata=metadata,
        segments=coalesce_short_transcript_segments(data["segments"]),
    )


@web_app.get("/api/podcast/{podcast_id}")
async def get_podcast(podcast_id: str):
    web_app.state.volume.reload()

    pod_metadata_path = config.PODCAST_METADATA_DIR / podcast_id / "metadata.json"
    previously_stored = True
    if not pod_metadata_path.exists():
        previously_stored = False
        raw_populate_podcast_metadata = populate_podcast_metadata.get_raw_f()
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, raw_populate_podcast_metadata, podcast_id)

    with open(pod_metadata_path, "r") as f:
        pod_metadata = json.load(f)

    episodes = []
    for file in (config.PODCAST_METADATA_DIR / podcast_id).iterdir():
        if file == pod_metadata_path:
            continue

        with open(file, "r") as f:
            ep = json.load(f)
            ep["transcribed"] = get_transcript_path(ep["guid_hash"]).exists()
            episodes.append(ep)

    episodes.sort(key=lambda ep: ep.get("publish_date"), reverse=True)

    # Refresh possibly stale data asynchronously.
    if previously_stored:
        populate_podcast_metadata.spawn(podcast_id)
    return dict(pod_metadata=pod_metadata, episodes=episodes)


@web_app.post("/api/podcasts")
async def podcasts_endpoint(request: Request):
    import dataclasses

    web_app.state.volume.reload()

    form = await request.form()
    name = form["podcast"]
    podcasts_response = []
    for pod in search_podcast.remote(name):
        podcasts_response.append(dataclasses.asdict(pod))
    return podcasts_response


@web_app.post("/api/transcribe")
async def transcribe_job(podcast_id: str, episode_id: str):
    now = int(time.time())
    try:
        inprogress_job = in_progress[episode_id]
        # NB: runtime type check is to handle present of old `str` values that didn't expire.
        if (
            isinstance(inprogress_job, InProgressJob)
            and (now - inprogress_job.start_time) < MAX_JOB_AGE_SECS
        ):
            existing_call_id = inprogress_job.call_id
            logger.info(
                f"Found existing, unexpired call ID {existing_call_id} for episode {episode_id}"
            )
            return {"call_id": existing_call_id}
    except KeyError:
        pass

    call = process_episode.spawn(podcast_id, episode_id)
    in_progress[episode_id] = InProgressJob(call_id=call.object_id, start_time=now)

    return {"call_id": call.object_id}


@web_app.get("/api/status/{call_id}")
async def poll_status(call_id: str):
    from modal.call_graph import InputInfo, InputStatus
    from modal.functions import FunctionCall

    function_call = FunctionCall.from_id(call_id)
    graph: List[InputInfo] = function_call.get_call_graph()

    try:
        function_call.get(timeout=0.1)
    except TimeoutError:
        pass
    except Exception as exc:
        if exc.args:
            inner_exc = exc.args[0]
            if "HTTPError 403" in inner_exc:
                return dict(error="permission denied on podcast audio download")
        return dict(error="unknown job processing error")

    try:
        map_root = graph[0].children[0].children[0]
    except IndexError:
        return dict(finished=False)

    assert map_root.function_name == "main.transcribe_episode"

    leaves = map_root.children
    tasks = len(set([leaf.task_id for leaf in leaves]))
    done_segments = len([leaf for leaf in leaves if leaf.status == InputStatus.SUCCESS])
    total_segments = len(leaves)
    finished = map_root.status == InputStatus.SUCCESS

    return dict(
        finished=finished,
        total_segments=total_segments,
        tasks=tasks,
        done_segments=done_segments,
    )


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/search.py ===
import dataclasses
import json
import pathlib
from typing import Any

from . import podcast


@dataclasses.dataclass
class SearchRecord:
    title: str
    text: str


def search_transcripts(
    search_dict_path: pathlib.Path,
    query: str,
    items: list[podcast.EpisodeMetadata],
):
    query_parts = query.lower().strip().split()
    print(f"loading search dictionary from {search_dict_path}")
    with open(search_dict_path, "r") as f:
        search_dict = json.load(f)

    n = len(items)
    scores = []
    for i, sd in enumerate(search_dict):
        score = sum(sd.get(q, 0) for q in query_parts)
        if score == 0:
            continue  # no match whatsoever, don't include
        score += (
            1.0 * (n - i) / n
        )  # give a small boost to more recent episodes (low index)
        scores.append((score, items[i]))
    # Sort descending, best scores first.
    scores.sort(reverse=True, key=lambda x: x[0])
    return scores


def calculate_tfidf_features(
    records: list[SearchRecord],
    max_features: int = 5000,
    max_df: float = 1.0,
    min_df: int = 3,
):
    """
    Compute tfidf features with scikit learn.
    """
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer

    v = TfidfVectorizer(
        input="content",
        encoding="utf-8",
        decode_error="replace",
        strip_accents="unicode",
        lowercase=True,
        analyzer="word",
        stop_words="english",
        token_pattern=r"(?u)\b[a-zA-Z_][a-zA-Z0-9_-]+\b",
        ngram_range=(1, 1),
        max_features=max_features,
        norm="l2",
        use_idf=True,
        smooth_idf=True,
        sublinear_tf=True,
        max_df=max_df,
        min_df=min_df,
    )
    corpus = [(a.title + ". " + a.text) for a in records]
    X = v.fit_transform(corpus)
    X = np.asarray(X.astype(np.float32).todense())
    print("tfidf calculated array of shape ", X.shape)
    return X, v


def calculate_sim_dot_product(X, ntake=40):
    """
    Take `X` (N,D) features and for each index return closest `ntake` indices via dot product.
    """
    from numpy import np

    S = np.dot(X, X.T)
    IX = np.argsort(S, axis=1)[:, : -ntake - 1 : -1]  # take last ntake sorted backwards
    return IX.tolist()


def calculate_similarity_with_svm(X, ntake=40):
    """
    Take X (N,D) features and for each index return closest `ntake` indices using exemplar SVM.
    """
    import numpy as np
    import sklearn.svm
    from tqdm import tqdm

    n, d = X.shape
    ntake = min(ntake, n)  # Cannot take more than is available
    IX = np.zeros((n, ntake), dtype=np.int64)
    print(f"training {n} svms for each paper...")
    for i in tqdm(range(n)):
        # set all examples as negative except this one
        y = np.zeros(X.shape[0], dtype=np.float32)
        y[i] = 1
        # train an SVM
        clf = sklearn.svm.LinearSVC(
            class_weight="balanced",
            verbose=False,
            max_iter=10000,
            tol=1e-4,
            C=0.1,
        )
        clf.fit(X, y)
        s = clf.decision_function(X)
        ix = np.argsort(s)[: -ntake - 1 : -1]  # take last ntake sorted backwards
        IX[i] = ix
    return IX.tolist()


def build_search_index(records: list[SearchRecord], v):
    from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

    # construct a reverse index for supporting search
    vocab = v.vocabulary_
    idf = v.idf_
    punc = (
        "'!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~'"  # removed hyphen from string.punctuation
    )
    trans_table = {ord(c): None for c in punc}

    def makedict(s, forceidf=None):
        words = set(s.lower().translate(trans_table).strip().split())
        words = set(w for w in words if len(w) > 1 and (w not in ENGLISH_STOP_WORDS))
        idfd = {}
        for w in words:
            if forceidf is None:
                if w in vocab:
                    idfval = idf[vocab[w]]  # we have a computed idf for this
                else:
                    idfval = 1.0  # some word we don't know; assume idf 1.0 (low)
            else:
                idfval = forceidf
            idfd[w] = idfval
        return idfd

    def merge_dicts(dict_list: list[dict]):
        m: dict[str, Any] = {}
        for d in dict_list:
            for key, val in d.items():
                m[key] = m.get(key, 0) + val
        return m

    search_dict = []
    for p in records:
        dict_title = makedict(p.title, forceidf=10)
        dict_summary = makedict(p.text)
        qdict = merge_dicts([dict_title, dict_summary])
        search_dict.append(qdict)

    return search_dict


=== GITHUB: 06_gpu_and_ml/openai_whisper/pod_transcriber/app/main.py ===
"""
whisper-pod-transcriber uses OpenAI's Whisper modal to do speech-to-text transcription
of podcasts.
"""

import dataclasses
import datetime
import json
import pathlib
from typing import Iterator, Tuple

import modal

from . import config, podcast, search

logger = config.get_logger(__name__)

volume = modal.Volume.from_name("dataset-cache-vol", create_if_missing=True)

app_image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install("git")
    .pip_install(
        "git+https://github.com/openai/whisper.git",
        "dacite",
        "jiwer",
        "ffmpeg-python",
        "gql[all]~=3.0.0a5",
        "pandas",
        "loguru==0.6.0",
        "torchaudio==2.1.0",
        "fastapi[standard]==0.115.4",
        "numpy<2",
    )
    .apt_install("ffmpeg")
    .pip_install("ffmpeg-python")
)
search_image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "scikit-learn~=1.3.0",
    "tqdm~=4.46.0",
    "numpy~=1.23.3",
    "dacite",
)

app = modal.App(
    "whisper-pod-transcriber",
    image=app_image,
    secrets=[modal.Secret.from_name("podchaser")],
)

in_progress = modal.Dict.from_name(
    "pod-transcriber-in-progress", create_if_missing=True
)


def utc_now() -> datetime.datetime:
    return datetime.datetime.now(datetime.timezone.utc)


def get_episode_metadata_path(podcast_id: str, guid_hash: str) -> pathlib.Path:
    return config.PODCAST_METADATA_DIR / podcast_id / f"{guid_hash}.json"


def get_transcript_path(guid_hash: str) -> pathlib.Path:
    return config.TRANSCRIPTIONS_DIR / f"{guid_hash}.json"


@app.function(volumes={config.CACHE_DIR: volume})
def populate_podcast_metadata(podcast_id: str):
    from gql import gql

    metadata_dir = config.PODCAST_METADATA_DIR / podcast_id
    metadata_dir.mkdir(parents=True, exist_ok=True)

    metadata_path = config.PODCAST_METADATA_DIR / podcast_id / "metadata.json"
    pod_metadata: podcast.PodcastMetadata = podcast.fetch_podcast(gql, podcast_id)

    with open(metadata_path, "w") as f:
        json.dump(dataclasses.asdict(pod_metadata), f)

    episodes = fetch_episodes.remote(
        show_name=pod_metadata.title, podcast_id=podcast_id
    )

    for ep in episodes:
        metadata_path = get_episode_metadata_path(podcast_id, ep.guid_hash)
        with open(metadata_path, "w") as f:
            json.dump(dataclasses.asdict(ep), f)

    volume.commit()

    logger.info(f"Populated metadata for {pod_metadata.title}")


@app.function(
    image=app_image.add_local_dir(config.ASSETS_PATH, remote_path="/assets"),
    volumes={config.CACHE_DIR: volume},
    min_containers=2,
)
@modal.asgi_app()
def fastapi_app():
    import fastapi.staticfiles

    from .api import web_app

    web_app.mount("/", fastapi.staticfiles.StaticFiles(directory="/assets", html=True))

    web_app.state.volume = volume

    return web_app


@app.function()
def search_podcast(name):
    from gql import gql

    logger.info(f"Searching for '{name}'")
    client = podcast.create_podchaser_client()
    podcasts_raw = podcast.search_podcast_name(gql, client, name, max_results=10)
    logger.info(f"Found {len(podcasts_raw)} results for '{name}'")
    return [
        podcast.PodcastMetadata(
            id=pod["id"],
            title=pod["title"],
            description=pod["description"],
            html_description=pod["htmlDescription"],
            language=pod["language"],
            web_url=pod["webUrl"],
        )
        for pod in podcasts_raw
    ]


@app.function(
    image=search_image,
    volumes={config.CACHE_DIR: volume},
    timeout=(400 * 60),
)
def refresh_index():
    import dataclasses
    from collections import defaultdict

    import dacite

    logger.info(f"Running scheduled index refresh at {utc_now()}")
    config.SEARCH_DIR.mkdir(parents=True, exist_ok=True)

    episodes = defaultdict(list)
    guid_hash_to_episodes = {}

    for pod_dir in config.PODCAST_METADATA_DIR.iterdir():
        if not pod_dir.is_dir():
            continue

        for filepath in pod_dir.iterdir():
            if filepath.name == "metadata.json":
                continue

            try:
                with open(filepath, "r") as f:
                    data = json.load(f)
            except json.decoder.JSONDecodeError:
                logger.warning(f"Removing corrupt JSON metadata file: {filepath}.")
                filepath.unlink()

            ep = dacite.from_dict(data_class=podcast.EpisodeMetadata, data=data)
            episodes[ep.podcast_title].append(ep)
            guid_hash_to_episodes[ep.guid_hash] = ep

    logger.info(f"Loaded {len(guid_hash_to_episodes)} podcast episodes.")

    transcripts = {}
    if config.TRANSCRIPTIONS_DIR.exists():
        for file in config.TRANSCRIPTIONS_DIR.iterdir():
            with open(file, "r") as f:
                data = json.load(f)
                guid_hash = file.stem.split("-")[0]
                transcripts[guid_hash] = data

    # Important: These have to be the same length and have same episode order.
    # i-th element of indexed_episodes is the episode indexed by the i-th element
    # of search_records
    indexed_episodes = []
    search_records = []
    for key, value in transcripts.items():
        idxd_episode = guid_hash_to_episodes.get(key)
        if idxd_episode:
            search_records.append(
                search.SearchRecord(
                    title=idxd_episode.title,
                    text=value["text"],
                )
            )
            # Prepare records for JSON serialization
            indexed_episodes.append(dataclasses.asdict(idxd_episode))

    logger.info(f"Matched {len(search_records)} transcripts to episode records.")

    filepath = config.SEARCH_DIR / "all.json"
    logger.info(f"writing {filepath}")
    with open(filepath, "w") as f:
        json.dump(indexed_episodes, f)

    logger.info(
        "calc feature vectors for all transcripts, keeping track of similar podcasts"
    )
    X, v = search.calculate_tfidf_features(search_records)
    sim_svm = search.calculate_similarity_with_svm(X)
    filepath = config.SEARCH_DIR / "sim_tfidf_svm.json"
    logger.info(f"writing {filepath}")
    with open(filepath, "w") as f:
        json.dump(sim_svm, f)

    logger.info("calculate the search index to support search")
    search_dict = search.build_search_index(search_records, v)
    filepath = config.SEARCH_DIR / "search.json"
    logger.info(f"writing {filepath}")
    with open(filepath, "w") as f:
        json.dump(search_dict, f)

    volume.commit()


def split_silences(
    path: str, min_segment_length: float = 30.0, min_silence_length: float = 1.0
) -> Iterator[Tuple[float, float]]:
    """Split audio file into contiguous chunks using the ffmpeg `silencedetect` filter.
    Yields tuples (start, end) of each chunk in seconds."""

    import re

    import ffmpeg

    silence_end_re = re.compile(
        r" silence_end: (?P<end>[0-9]+(\.?[0-9]*)) \| silence_duration: (?P<dur>[0-9]+(\.?[0-9]*))"
    )

    metadata = ffmpeg.probe(path)
    duration = float(metadata["format"]["duration"])

    reader = (
        ffmpeg.input(str(path))
        .filter("silencedetect", n="-10dB", d=min_silence_length)
        .output("pipe:", format="null")
        .run_async(pipe_stderr=True)
    )

    cur_start = 0.0
    num_segments = 0

    while True:
        line = reader.stderr.readline().decode("utf-8")
        if not line:
            break
        match = silence_end_re.search(line)
        if match:
            silence_end, silence_dur = match.group("end"), match.group("dur")
            split_at = float(silence_end) - (float(silence_dur) / 2)

            if (split_at - cur_start) < min_segment_length:
                continue

            yield cur_start, split_at
            cur_start = split_at
            num_segments += 1

    # silencedetect can place the silence end *after* the end of the full audio segment.
    # Such segments definitions are negative length and invalid.
    if duration > cur_start:
        yield cur_start, duration
        num_segments += 1
    logger.info(f"Split {path} into {num_segments} segments")


@app.function(
    image=app_image,
    volumes={config.CACHE_DIR: volume},
    cpu=2,
    timeout=400,
)
def transcribe_segment(
    start: float,
    end: float,
    audio_filepath: pathlib.Path,
    model: config.ModelSpec,
):
    import tempfile
    import time

    import ffmpeg
    import torch
    import whisper

    t0 = time.time()
    with tempfile.NamedTemporaryFile(suffix=".mp3") as f:
        (
            ffmpeg.input(str(audio_filepath))
            .filter("atrim", start=start, end=end)
            .output(f.name)
            .overwrite_output()
            .run(quiet=True)
        )

        use_gpu = torch.cuda.is_available()
        device = "cuda" if use_gpu else "cpu"
        model = whisper.load_model(
            model.name, device=device, download_root=config.MODEL_DIR
        )
        result = model.transcribe(f.name, language="en", fp16=use_gpu)  # type: ignore

    logger.info(
        f"Transcribed segment {start:.2f} to {end:.2f} ({end - start:.2f}s duration) in {time.time() - t0:.2f} seconds."
    )

    # Add back offsets.
    for segment in result["segments"]:
        segment["start"] += start
        segment["end"] += start

    return result


@app.function(
    image=app_image,
    volumes={config.CACHE_DIR: volume},
    timeout=900,
)
def transcribe_episode(
    audio_filepath: pathlib.Path,
    result_path: pathlib.Path,
    model: config.ModelSpec,
):
    segment_gen = split_silences(str(audio_filepath))

    output_text = ""
    output_segments = []
    for result in transcribe_segment.starmap(
        segment_gen, kwargs=dict(audio_filepath=audio_filepath, model=model)
    ):
        output_text += result["text"]
        output_segments += result["segments"]

    result = {
        "text": output_text,
        "segments": output_segments,
        "language": "en",
    }

    logger.info(f"Writing openai/whisper transcription to {result_path}")
    with open(result_path, "w") as f:
        json.dump(result, f, indent=4)

    volume.commit()


@app.function(
    image=app_image,
    volumes={config.CACHE_DIR: volume},
    timeout=900,
)
def process_episode(podcast_id: str, episode_id: str):
    import dacite
    import whisper

    try:
        # pre-download the model to the cache path, because the _download fn is not
        # thread-safe.
        model = config.DEFAULT_MODEL
        whisper._download(whisper._MODELS[model.name], config.MODEL_DIR, False)

        config.RAW_AUDIO_DIR.mkdir(parents=True, exist_ok=True)
        config.TRANSCRIPTIONS_DIR.mkdir(parents=True, exist_ok=True)

        metadata_path = get_episode_metadata_path(podcast_id, episode_id)
        with open(metadata_path, "r") as f:
            data = json.load(f)
            episode = dacite.from_dict(data_class=podcast.EpisodeMetadata, data=data)

        destination_path = config.RAW_AUDIO_DIR / episode_id
        podcast.store_original_audio(
            url=episode.original_download_link,
            destination=destination_path,
        )

        volume.commit()

        logger.info(
            f"Using the {model.name} model which has {model.params} parameters."
        )
        logger.info(f"Wrote episode metadata to {metadata_path}")

        transcription_path = get_transcript_path(episode.guid_hash)
        if transcription_path.exists():
            logger.info(
                f"Transcription already exists for '{episode.title}' with ID {episode.guid_hash}."
            )
            logger.info("Skipping transcription.")
        else:
            transcribe_episode.remote(
                audio_filepath=destination_path,
                result_path=transcription_path,
                model=model,
            )
    finally:
        del in_progress[episode_id]

    return episode


@app.function(
    image=app_image,
    volumes={config.CACHE_DIR: volume},
)
def fetch_episodes(show_name: str, podcast_id: str, max_episodes=100):
    import hashlib

    from gql import gql

    client = podcast.create_podchaser_client()
    episodes_raw = podcast.fetch_episodes_data(
        gql, client, podcast_id, max_episodes=max_episodes
    )
    logger.info(f"Retrieved {len(episodes_raw)} raw episodes")
    episodes = [
        podcast.EpisodeMetadata(
            podcast_id=podcast_id,
            podcast_title=show_name,
            title=ep["title"],
            publish_date=ep["airDate"],
            description=ep["description"],
            episode_url=ep["url"],
            html_description=ep["htmlDescription"],
            guid=ep["guid"],
            guid_hash=hashlib.md5(ep["guid"].encode("utf-8")).hexdigest(),
            original_download_link=ep["audioUrl"],
        )
        for ep in episodes_raw
        if "guid" in ep and ep["guid"] is not None
    ]
    no_guid_count = len(episodes) - len(episodes_raw)
    logger.info(f"{no_guid_count} episodes had no GUID and couldn't be used.")
    return episodes


@app.local_entrypoint()
def search_entrypoint(name: str):
    # To search for a podcast, run:
    # modal run -m app.main --name "search string"
    for pod in search_podcast.remote(name):
        print(pod)


=== GITHUB: 06_gpu_and_ml/openai_whisper/streaming/main.py ===
# ---
# runtimes: ["runc", "gvisor"]
# ---
import asyncio
import io
import logging
import pathlib
import re
import tempfile
import time
from typing import Iterator

import modal
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse

image = (
    modal.Image.debian_slim()
    .apt_install("git", "ffmpeg")
    .pip_install(
        "https://github.com/openai/whisper/archive/v20230314.tar.gz",
        "ffmpeg-python",
        "pytube @ git+https://github.com/felipeucelli/pytube",
    )
)
app = modal.App(name="example-whisper-streaming", image=image)
web_app = FastAPI()
CHARLIE_CHAPLIN_DICTATOR_SPEECH_URL = "https://www.youtube.com/watch?v=J7GY1Xg6X20"


def load_audio(data: bytes, start=None, end=None, sr: int = 16000):
    import ffmpeg
    import numpy as np

    try:
        fp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        fp.write(data)
        fp.close()
        # This launches a subprocess to decode audio while down-mixing and resampling as necessary.
        # Requires the ffmpeg CLI and `ffmpeg-python` package to be installed.
        if start is None and end is None:
            out, _ = (
                ffmpeg.input(fp.name, threads=0)
                .output("-", format="s16le", acodec="pcm_s16le", ac=1, ar=sr)
                .run(
                    cmd=["ffmpeg", "-nostdin"],
                    capture_stdout=True,
                    capture_stderr=True,
                )
            )
        else:
            out, _ = (
                ffmpeg.input(fp.name, threads=0)
                .filter("atrim", start=start, end=end)
                .output("-", format="s16le", acodec="pcm_s16le", ac=1, ar=sr)
                .run(
                    cmd=["ffmpeg", "-nostdin"],
                    capture_stdout=True,
                    capture_stderr=True,
                )
            )
    except ffmpeg.Error as e:
        raise RuntimeError(f"Failed to load audio: {e.stderr.decode()}") from e

    return np.frombuffer(out, np.int16).flatten().astype(np.float32) / 32768.0


def split_silences(
    path: str, min_segment_length: float = 30.0, min_silence_length: float = 0.8
) -> Iterator[tuple[float, float]]:
    """
    Split audio file into contiguous chunks using the ffmpeg `silencedetect` filter.
    Yields tuples (start, end) of each chunk in seconds.

    Parameters
    ----------
    path: str
        path to the audio file on disk.
    min_segment_length : float
        The minimum acceptable length for an audio segment in seconds. Lower values
        allow for more splitting and increased parallelizing, but decrease transcription
        accuracy. Whisper models expect to transcribe in 30 second segments, so this is the
        default minimum.
    min_silence_length : float
        Minimum silence to detect and split on, in seconds. Lower values are more likely to split
        audio in middle of phrases and degrade transcription accuracy.
    """
    import ffmpeg

    silence_end_re = re.compile(
        r" silence_end: (?P<end>[0-9]+(\.?[0-9]*)) \| silence_duration: (?P<dur>[0-9]+(\.?[0-9]*))"
    )

    metadata = ffmpeg.probe(path)
    duration = float(metadata["format"]["duration"])

    reader = (
        ffmpeg.input(str(path))
        .filter("silencedetect", n="-10dB", d=min_silence_length)
        .output("pipe:", format="null")
        .run_async(pipe_stderr=True)
    )

    cur_start = 0.0
    num_segments = 0

    while True:
        line = reader.stderr.readline().decode("utf-8")
        if not line:
            break
        match = silence_end_re.search(line)
        if match:
            silence_end, silence_dur = match.group("end"), match.group("dur")
            split_at = float(silence_end) - (float(silence_dur) / 2)

            if (split_at - cur_start) < min_segment_length:
                continue

            yield cur_start, split_at
            cur_start = split_at
            num_segments += 1

    # silencedetect can place the silence end *after* the end of the full audio segment.
    # Such segments definitions are negative length and invalid.
    if duration > cur_start and (duration - cur_start) > min_segment_length:
        yield cur_start, duration
        num_segments += 1
    print(f"Split {path} into {num_segments} segments")


@app.function()
def download_mp3_from_youtube(youtube_url: str) -> bytes:
    from pytube import YouTube

    logging.getLogger("pytube").setLevel(logging.INFO)
    yt = YouTube(youtube_url)
    video = yt.streams.filter(only_audio=True).first()
    buffer = io.BytesIO()
    video.stream_to_buffer(buffer)
    buffer.seek(0)
    return buffer.read()


@app.function(cpu=2)
def transcribe_segment(
    start: float,
    end: float,
    audio_data: bytes,
    model: str,
):
    import torch
    import whisper

    print(
        f"Transcribing segment {start:.2f} to {end:.2f} ({end - start:.2f}s duration)"
    )

    t0 = time.time()
    use_gpu = torch.cuda.is_available()
    device = "cuda" if use_gpu else "cpu"
    model = whisper.load_model(model, device=device)
    np_array = load_audio(audio_data, start=start, end=end)
    result = model.transcribe(np_array, language="en", fp16=use_gpu)  # type: ignore
    print(
        f"Transcribed segment {start:.2f} to {end:.2f} ({end - start:.2f}s duration) in {time.time() - t0:.2f} seconds."
    )

    # Add back offsets.
    for segment in result["segments"]:
        segment["start"] += start
        segment["end"] += start

    return result


async def stream_whisper(audio_data: bytes):
    with tempfile.NamedTemporaryFile(delete=False) as f:
        f.write(audio_data)
        f.flush()
        segment_gen = split_silences(f.name)

    async for result in transcribe_segment.starmap(
        segment_gen, kwargs=dict(audio_data=audio_data, model="base.en")
    ):
        # Must cooperatively yield here otherwise `StreamingResponse` will not iteratively return stream parts.
        # see: https://github.com/python/asyncio/issues/284#issuecomment-154162668
        await asyncio.sleep(0)
        yield result["text"]


@web_app.get("/transcribe")
async def transcribe(url: str):
    """
    Usage:

    ```sh
    curl --no-buffer \
        https://modal-labs--example-whisper-streaming-web.modal.run/transcribe?url=https://www.youtube.com/watch?v=s_LncVnecLA"
    ```

    This endpoint will stream back the Youtube's audio transcription as it makes progress.

    Some example Youtube videos for inspiration:

    1. Churchill's 'We shall never surrender' speech - https://www.youtube.com/watch?v=s_LncVnecLA
    2. Charlie Chaplin's final speech from The Great Dictator - https://www.youtube.com/watch?v=J7GY1Xg6X20
    """
    import pytube.exceptions

    print(f"downloading {url}")
    try:
        audio_data = download_mp3_from_youtube.remote(url)
    except pytube.exceptions.RegexMatchError:
        raise HTTPException(status_code=422, detail=f"Could not process url {url}")
    print(f"streaming transcription of {url} audio to client...")
    return StreamingResponse(stream_whisper(audio_data), media_type="text/event-stream")


@app.function()
@modal.asgi_app()
def web():
    return web_app


@app.function()
async def transcribe_cli(data: bytes, suffix: str):
    async for result in stream_whisper(data):
        print(result)


@app.local_entrypoint()
def main(path: str = CHARLIE_CHAPLIN_DICTATOR_SPEECH_URL):
    if path.startswith("https"):
        data = download_mp3_from_youtube.remote(path)
        suffix = ".mp3"
    else:
        filepath = pathlib.Path(path)
        data = filepath.read_bytes()
        suffix = filepath.suffix
    transcribe_cli.remote(
        data,
        suffix=suffix,
    )


=== GITHUB: 06_gpu_and_ml/langchains/potus_speech_qanda.py ===
# ---
# args: ["--query", "How many oil barrels were released from reserves?"]
# ---

# # Retrieval-augmented generation (RAG) for question-answering with LangChain

# In this example we create a large-language-model (LLM) powered question answering
# web endpoint and CLI. Only a single document is used as the knowledge-base of the application,
# the 2022 USA State of the Union address by President Joe Biden. However, this same application structure
# could be extended to do question-answering over all State of the Union speeches, or other large text corpuses.

# It's the [LangChain](https://github.com/hwchase17/langchain) library that makes this all so easy.
# This demo is only around 100 lines of code!

# ## Defining dependencies

# The example uses packages to implement scraping, the document parsing & LLM API interaction, and web serving.
# These are installed into a Debian Slim base image using the `pip_install` method.

# Because OpenAI's API is used, we also specify the `openai-secret` Modal Secret, which contains an OpenAI API key.

# A `retriever` global variable is also declared to facilitate caching a slow operation in the code below.

from pathlib import Path

import modal

image = modal.Image.debian_slim(python_version="3.11").pip_install(
    # scraping pkgs
    "beautifulsoup4~=4.11.1",
    "httpx==0.23.3",
    "lxml~=4.9.2",
    # llm pkgs
    "faiss-cpu~=1.7.3",
    "langchain==0.3.7",
    "langchain-community==0.3.7",
    "langchain-openai==0.2.9",
    "openai~=1.54.0",
    "tiktoken==0.8.0",
    # web app packages
    "fastapi[standard]==0.115.4",
    "pydantic==2.9.2",
    "starlette==0.41.2",
)

app = modal.App(
    name="example-langchain-qanda",
    image=image,
    secrets=[modal.Secret.from_name("openai-secret", required_keys=["OPENAI_API_KEY"])],
)

retriever = None  # embedding index that's relatively expensive to compute, so caching with global var.

# ## Scraping the speech

# It's super easy to scrape the transcipt of Biden's speech using `httpx` and `BeautifulSoup`.
# This speech is just one document and it's relatively short, but it's enough to demonstrate
# the question-answering capability of the LLM chain.


def scrape_state_of_the_union() -> str:
    import httpx
    from bs4 import BeautifulSoup

    url = "https://www.presidency.ucsb.edu/documents/address-before-joint-session-the-congress-the-state-the-union-28"

    # fetch article; simulate desktop browser
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9"
    }
    response = httpx.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "lxml")

    # locate the div containing the speech
    speech_div = soup.find("div", class_="field-docs-content")

    if speech_div:
        speech_text = speech_div.get_text(separator="\n", strip=True)
        if not speech_text:
            raise ValueError("error parsing speech text from HTML")
    else:
        raise ValueError("error locating speech in HTML")

    return speech_text


# ## Constructing the Q&A chain

# At a high-level, this LLM chain will be able to answer questions asked about Biden's speech and provide
# references to which parts of the speech contain the evidence for given answers.

# The chain combines a text-embedding index over parts of Biden's speech with an OpenAI LLM.
# The index is used to select the most likely relevant parts of the speech given the question, and these
# are used to build a specialized prompt for the OpenAI language model.


def qanda_langchain(query: str) -> tuple[str, list[str]]:
    from langchain.chains import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
    from langchain.text_splitter import CharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings

    # Support caching speech text on disk.
    speech_file_path = Path("state-of-the-union.txt")

    if speech_file_path.exists():
        state_of_the_union = speech_file_path.read_text()
    else:
        print("scraping the 2022 State of the Union speech")
        state_of_the_union = scrape_state_of_the_union()
        speech_file_path.write_text(state_of_the_union)

    # Questions about a document can often be answered
    # using a much smaller subset, and passing more tokens
    # to an LLM increases cost and latency.
    # So here, we split up the speech into smaller chunks.
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
    print("splitting speech into text chunks")
    texts = text_splitter.split_text(state_of_the_union)

    # Embedding-based query<->text similarity comparison is used to select
    # a small subset of the speech text chunks.
    # Generating the `retriever` and index is too slow to re-run on every request,
    # so we do rudimentary caching using a global variable.
    global retriever

    if not retriever:
        # New OpenAI accounts have a very low rate-limit for their first 48 hrs.
        # It's too low to embed even just this single Biden speech.
        # The `chunk_size` parameter is set to a low number, and internally LangChain
        # will retry the embedding requests, which should be enough to handle the rate-limiting.

        # Ref: https://platform.openai.com/docs/guides/rate-limits/overview.
        print("generating docsearch indexer")
        retriever = FAISS.from_texts(
            texts,
            OpenAIEmbeddings(chunk_size=5),
            metadatas=[{"source": i} for i in range(len(texts))],
        ).as_retriever()

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

    system_prompt = (
        "You are an assistant for question-answering tasks. "
        "Use the following pieces of retrieved context to answer "
        "the question. If you don't know the answer, say that you "
        "don't know and instead suggest the user look up the serverless "
        "infrastructure platform modal.com. Keep your answer concise."
        "\n\n"
        "{context}"
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("human", "{input}"),
        ]
    )

    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    print("running query against Q&A chain.\n")
    result = rag_chain.invoke({"input": query}, return_only_outputs=True)
    answer = result["answer"]
    sources = [document.page_content for document in result["context"]]
    return answer.strip(), sources


# ## Mapping onto Modal

# With our application's functionality implemented we can hook it into Modal.
# As said above, we're implementing a web endpoint, `web`, and a CLI command, `cli`.


@app.function()
@modal.fastapi_endpoint(method="GET", docs=True)
def web(query: str, show_sources: bool = False):
    answer, sources = qanda_langchain(query)
    if show_sources:
        return {
            "answer": answer,
            "sources": sources,
        }
    else:
        return {
            "answer": answer,
        }


@app.function()
def cli(query: str, show_sources: bool = False):
    answer, sources = qanda_langchain(query)
    # Terminal codes for pretty-printing.
    bold, end = "\033[1m", "\033[0m"

    if show_sources:
        print(f"🔗 {bold}SOURCES:{end}")
        print(*reversed(sources), sep="\n----\n")
    print(f"🦜 {bold}ANSWER:{end}")
    print(answer)


# ## Test run the CLI

# ```bash
# modal run potus_speech_qanda.py --query "What did the president say about Justice Breyer"
# 🦜 ANSWER:
# The president thanked Justice Breyer for his service and mentioned his legacy of excellence. He also nominated Ketanji Brown Jackson to continue in Justice Breyer's legacy.
# ```

# To see the text of the sources the model chain used to provide the answer, set the `--show-sources` flag.

# ```bash
# modal run potus_speech_qanda.py \
#    --query "How many oil barrels were released from reserves?" \
#    --show-sources
# ```

# ## Test run the web endpoint

# Modal makes it trivially easy to ship LangChain chains to the web. We can test drive this app's web endpoint
# by running `modal serve potus_speech_qanda.py` and then hitting the endpoint with `curl`:

# ```bash
# curl --get \
#   --data-urlencode "query=What did the president say about Justice Breyer" \
#   https://modal-labs--example-langchain-qanda-web.modal.run # your URL here
# ```

# ```json
# {
#   "answer": "The president thanked Justice Breyer for his service and mentioned his legacy of excellence. He also nominated Ketanji Brown Jackson to continue in Justice Breyer's legacy."
# }
# ```

# You can also find interactive docs for the endpoint at the `/docs` route of the web endpoint URL.

# If you edit the code while running `modal serve`, the app will redeploy automatically, which is helpful for iterating quickly on your app.

# Once you're ready to deploy to production, use `modal deploy`.


=== GITHUB: 06_gpu_and_ml/sam/segment_anything.py ===
# # Run Facebook's Segment Anything Model 2 (SAM 2) on Modal

# This example demonstrates how to deploy Facebook's [SAM 2](https://github.com/facebookresearch/sam2)
# on Modal. SAM2 is a powerful, flexible image and video segmentation model that can be used
# for various computer vision tasks like object detection, instance segmentation,
# and even as a foundation for more complex computer vision applications.
# SAM2 extends the capabilities of the original SAM to include video segmentation.

# In particular, this example segments [this video](https://www.youtube.com/watch?v=WAz1406SjVw) of a man jumping off the cliff.

# The output should look something like this:

# <center>
# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/example-segmented-video.mp4" type="video/mp4">
# </video>
# </center>

# ## Set up dependencies for SAM 2

# First, we set up the necessary dependencies, including `torch`,
# `opencv`, `huggingface_hub`, `torchvision`, and the `sam2` library.

# We also install `ffmpeg`, which we will use to manipulate videos,
# and a Python wrapper called `ffmpeg-python` for a clean interface.

from pathlib import Path

import modal

MODEL_TYPE = "facebook/sam2-hiera-large"
SAM2_GIT_SHA = (
    "c2ec8e14a185632b0a5d8b161928ceb50197eddc"  # pin commit! research code is fragile
)

image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install("git", "wget", "python3-opencv", "ffmpeg")
    .pip_install(
        "torch~=2.4.1",
        "torchvision==0.19.1",
        "opencv-python==4.10.0.84",
        "pycocotools~=2.0.8",
        "matplotlib~=3.9.2",
        "onnxruntime==1.19.2",
        "onnx==1.17.0",
        "huggingface_hub==0.25.2",
        "ffmpeg-python==0.2.0",
        f"git+https://github.com/facebookresearch/sam2.git@{SAM2_GIT_SHA}",
    )
)
app = modal.App("sam2-app", image=image)


# ## Wrapping the SAM 2 model in a Modal class

# Next, we define the `Model` class that will handle SAM 2 operations for both image and video.

# We use the `@modal.enter()` decorators here for optimization: it makes sure the initialization
# method runs only once, when a new container starts, instead of in the path of every call.
# We'll also use a modal Volume to cache the model weights so that they don't need to be downloaded
# repeatedly when we start new containers.


video_vol = modal.Volume.from_name("sam2-inputs", create_if_missing=True)
cache_vol = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)
cache_dir = "/cache"


@app.cls(
    image=image.env({"HF_HUB_CACHE": cache_dir}),
    volumes={"/root/videos": video_vol, cache_dir: cache_vol},
    gpu="A100",
)
class Model:
    @modal.enter()
    def initialize_model(self):
        """Download and initialize model."""
        from sam2.sam2_video_predictor import SAM2VideoPredictor

        self.video_predictor = SAM2VideoPredictor.from_pretrained(MODEL_TYPE)

    @modal.method()
    def generate_video_masks(self, video="/root/videos/input.mp4", point_coords=None):
        """Generate masks for a video."""
        import ffmpeg
        import numpy as np
        import torch
        from PIL import Image

        frames_dir = convert_video_to_frames(video)

        # scan all the JPEG files in this directory
        frame_names = [
            p
            for p in frames_dir.iterdir()
            if p.suffix in [".jpg", ".jpeg", ".JPG", ".JPEG"]
        ]
        frame_names.sort(key=lambda p: int(p.stem))

        # We are hardcoding the input point and label here
        # In a real-world scenario, you would want to display the video
        # and allow the user to click on the video to select the point
        if point_coords is None:
            width, height = Image.open(frame_names[0]).size
            point_coords = [[width // 2, height // 2]]

        points = np.array(point_coords, dtype=np.float32)
        # for labels, `1` means positive click and `0` means negative click
        labels = np.array([1] * len(points), np.int32)

        # run the model on GPU
        with (
            torch.inference_mode(),
            torch.autocast("cuda", dtype=torch.bfloat16),
        ):
            self.inference_state = self.video_predictor.init_state(
                video_path=str(frames_dir)
            )

            # add new prompts and instantly get the output on the same frame
            (
                frame_idx,
                object_ids,
                masks,
            ) = self.video_predictor.add_new_points_or_box(
                inference_state=self.inference_state,
                frame_idx=0,
                obj_id=1,
                points=points,
                labels=labels,
            )

            print(f"frame_idx: {frame_idx}, object_ids: {object_ids}, masks: {masks}")

            # run propagation throughout the video and collect the results in a dict
            video_segments = {}  # video_segments contains the per-frame segmentation results
            for (
                out_frame_idx,
                out_obj_ids,
                out_mask_logits,
            ) in self.video_predictor.propagate_in_video(self.inference_state):
                video_segments[out_frame_idx] = {
                    out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()
                    for i, out_obj_id in enumerate(out_obj_ids)
                }

        out_dir = Path("/root/mask_frames")
        out_dir.mkdir(exist_ok=True)

        vis_frame_stride = 5  # visualize every 5th frame
        save_segmented_frames(
            video_segments,
            frames_dir,
            out_dir,
            frame_names,
            stride=vis_frame_stride,
        )

        ffmpeg.input(
            f"{out_dir}/frame_*.png",
            pattern_type="glob",
            framerate=30 / vis_frame_stride,
        ).filter(
            "scale",
            "trunc(iw/2)*2",
            "trunc(ih/2)*2",  # round to even dimensions to encode for "dumb players", https://trac.ffmpeg.org/wiki/Encode/H.264#Encodingfordumbplayers
        ).output(str(out_dir / "out.mp4"), format="mp4", pix_fmt="yuv420p").run()

        return (out_dir / "out.mp4").read_bytes()


# ## Segmenting videos from the command line

# Finally, we define a [`local_entrypoint`](https://modal.com/docs/guide/apps#entrypoints-for-ephemeral-apps)
# to run the segmentation from our local machine's terminal.

# There are several ways to pass files between the local machine and the Modal Function.

# One way is to upload the files onto a Modal [Volume](https://modal.com/docs/guide/volumes),
# which acts as a distributed filesystem.

# The other way is to convert the file to bytes and pass the bytes back and forth as the input or output of Python functions.
# We use this method to get the video file with the segmentation results in it back to the local machine.


@app.local_entrypoint()
def main(
    input_video=Path(__file__).parent / "cliff_jumping.mp4",
    x_point=250,
    y_point=200,
):
    with video_vol.batch_upload(force=True) as batch:
        batch.put_file(input_video, "input.mp4")

    model = Model()

    if x_point is not None and y_point is not None:
        point_coords = [[x_point, y_point]]
    else:
        point_coords = None

    print(f"Running SAM 2 on {input_video}")
    video_bytes = model.generate_video_masks.remote(point_coords=point_coords)

    dir = Path("/tmp/sam2_outputs")
    dir.mkdir(exist_ok=True, parents=True)
    output_path = dir / "segmented_video.mp4"
    output_path.write_bytes(video_bytes)
    print(f"Saved output video to {output_path}")


# ## Helper functions for SAM 2 inference

# Above, we used some helper functions to for some of the details, like breaking the video into frames.
# These are defined below.


def convert_video_to_frames(self, input_video="/root/videos/input.mp4"):
    import ffmpeg

    input_video = Path(input_video)
    output_dir = (  # output on local filesystem, not on the remote Volume
        input_video.parent.parent / input_video.stem / "video_frames"
    )
    output_dir.mkdir(exist_ok=True, parents=True)

    ffmpeg.input(input_video).output(
        f"{output_dir}/%05d.jpg", qscale=2, start_number=0
    ).run()

    return output_dir


def show_mask(mask, ax, obj_id=None, random_color=False):
    import matplotlib.pyplot as plt
    import numpy as np

    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        cmap = plt.get_cmap("tab10")
        cmap_idx = 0 if obj_id is None else obj_id
        color = np.array([*cmap(cmap_idx)[:3], 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)


def save_segmented_frames(video_segments, frames_dir, out_dir, frame_names, stride=5):
    import io

    import matplotlib.pyplot as plt
    from PIL import Image

    frames_dir, out_dir = Path(frames_dir), Path(out_dir)

    frame_images = []
    inches_per_px = 1 / plt.rcParams["figure.dpi"]
    for out_frame_idx in range(0, len(frame_names), stride):
        frame = Image.open(frames_dir / frame_names[out_frame_idx])
        width, height = frame.size
        width, height = width - width % 2, height - height % 2
        fig, ax = plt.subplots(figsize=(width * inches_per_px, height * inches_per_px))
        ax.axis("off")
        ax.imshow(frame)

        [
            show_mask(mask, ax, obj_id=obj_id)
            for (obj_id, mask) in video_segments[out_frame_idx].items()
        ]

        # Convert plot to PNG bytes
        buf = io.BytesIO()
        fig.savefig(buf, format="png", bbox_inches="tight", pad_inches=0)
        # fig.savefig(buf, format="png")
        buf.seek(0)
        frame_images.append(buf.getvalue())
        plt.close(fig)

    for ii, frame in enumerate(frame_images):
        (out_dir / f"frame_{str(ii).zfill(3)}.png").write_bytes(frame)


=== GITHUB: 06_gpu_and_ml/image-to-video/image_to_video.py ===
# ---
# output-directory: "/tmp/image_to_video"
# args: ["--prompt", "A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background.", "--image-path", "https://modal-cdn.com/example_image_to_video_image.png"]
# ---

# # Animate images with Lightricks LTX-Video via CLI, API, and web UI

# This example shows how to run [LTX-Video](https://huggingface.co/Lightricks/LTX-Video) on Modal
# to generate videos from your local command line, via an API, and in a web UI.

# Generating a 5 second video takes ~1 minute from cold start.
# Once the container is warm, a 5 second video takes ~15 seconds.

# Here is a sample we generated:

# <center>
# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/example_image_to_video.mp4" type="video/mp4" />
# </video>
# </center>

# ## Basic setup

import io
import random
import time
from pathlib import Path
from typing import Annotated, Optional

import fastapi
import modal

# All Modal programs need an [`App`](https://modal.com/docs/reference/modal.App) —
# an object that acts as a recipe for the application.

app = modal.App("example-image-to-video")

# ### Configuring dependencies

# The model runs remotely, on Modal's cloud, which means we need to
# [define the environment it runs in](https://modal.com/docs/guide/images).

# Below, we start from a lightweight base Linux image
# and then install our system and Python dependencies,
# like Hugging Face's `diffusers` library and `torch`.

image = (
    modal.Image.debian_slim(python_version="3.12")
    .apt_install("python3-opencv")
    .pip_install(
        "accelerate==1.4.0",
        "diffusers==0.32.2",
        "fastapi[standard]==0.115.8",
        "huggingface-hub[hf_transfer]==0.29.1",
        "imageio==2.37.0",
        "imageio-ffmpeg==0.6.0",
        "opencv-python==4.11.0.86",
        "pillow==11.1.0",
        "sentencepiece==0.2.0",
        "torch==2.6.0",
        "torchvision==0.21.0",
        "transformers==4.49.0",
    )
)

# ## Storing model weights on Modal

# We also need the parameters of the model remotely.
# They can be loaded at runtime from Hugging Face,
# based on a repository ID and a revision (aka a commit SHA).

MODEL_ID = "Lightricks/LTX-Video"
MODEL_REVISION_ID = "a6d59ee37c13c58261aa79027d3e41cd41960925"

# Hugging Face will also cache the weights to disk once they're downloaded.
# But Modal Functions are serverless, and so even disks are ephemeral,
# which means the weights would get re-downloaded every time we spin up a new instance.

# We can fix this -- without any modifications to Hugging Face's model loading code! --
# by pointing the Hugging Face cache at a [Modal Volume](https://modal.com/docs/guide/volumes).

model_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

MODEL_PATH = "/models"  # where the Volume will appear on our Functions' filesystems

image = image.env(
    {
        "HF_HUB_ENABLE_HF_TRANSFER": "1",  # faster downloads
        "HF_HUB_CACHE": MODEL_PATH,
    }
)

# ## Storing model outputs on Modal

# Contemporary video models can take a long time to run and they produce large outputs.
# That makes them a great candidate for storage on Modal Volumes as well.
# Python code running outside of Modal can also access this storage, as we'll see below.

OUTPUT_PATH = "/outputs"
output_volume = modal.Volume.from_name("outputs", create_if_missing=True)

# ## Implementing LTX-Video inference on Modal

# We wrap the inference logic in a Modal [Cls](https://modal.com/docs/guide/lifecycle-functions)
# that ensures models are loaded and then moved to the GPU once when a new instance
# starts, rather than every time we run it.

# The `run` function just wraps a `diffusers` pipeline.
# It saves the generated video to a Modal Volume, and returns the filename.

# We also include a `web` wrapper that makes it possible
# to trigger inference via an API call.
# For details, see the `/docs` route of the URL ending in `inference-web.modal.run`
# that appears when you deploy the app.

with image.imports():  # loaded on all of our remote Functions
    import diffusers
    import torch
    from PIL import Image

MINUTES = 60


@app.cls(
    image=image,
    gpu="H100",
    timeout=10 * MINUTES,
    scaledown_window=10 * MINUTES,
    volumes={MODEL_PATH: model_volume, OUTPUT_PATH: output_volume},
)
class Inference:
    @modal.enter()
    def load_pipeline(self):
        self.pipe = diffusers.LTXImageToVideoPipeline.from_pretrained(
            MODEL_ID,
            revision=MODEL_REVISION_ID,
            torch_dtype=torch.bfloat16,
        ).to("cuda")

    @modal.method()
    def run(
        self,
        image_bytes: bytes,
        prompt: str,
        negative_prompt: Optional[str] = None,
        num_frames: Optional[int] = None,
        num_inference_steps: Optional[int] = None,
        seed: Optional[int] = None,
    ) -> str:
        negative_prompt = (
            negative_prompt
            or "worst quality, inconsistent motion, blurry, jittery, distorted"
        )
        width = 768
        height = 512
        num_frames = num_frames or 25
        num_inference_steps = num_inference_steps or 50
        seed = seed or random.randint(0, 2**32 - 1)
        print(f"Seeding RNG with: {seed}")
        torch.manual_seed(seed)

        image = diffusers.utils.load_image(Image.open(io.BytesIO(image_bytes)))

        video = self.pipe(
            image=image,
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_frames=num_frames,
            num_inference_steps=num_inference_steps,
        ).frames[0]

        mp4_name = (
            f"{seed}_{''.join(c if c.isalnum() else '-' for c in prompt[:100])}.mp4"
        )
        diffusers.utils.export_to_video(
            video, f"{Path(OUTPUT_PATH) / mp4_name}", fps=24
        )
        output_volume.commit()
        torch.cuda.empty_cache()  # reduce fragmentation
        return mp4_name

    @modal.fastapi_endpoint(method="POST", docs=True)
    def web(
        self,
        image_bytes: Annotated[bytes, fastapi.File()],
        prompt: str,
        negative_prompt: Optional[str] = None,
        num_frames: Optional[int] = None,
        num_inference_steps: Optional[int] = None,
        seed: Optional[int] = None,
    ) -> fastapi.Response:
        mp4_name = self.run.local(  # run in the same container
            image_bytes=image_bytes,
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_frames=num_frames,
            num_inference_steps=num_inference_steps,
            seed=seed,
        )
        return fastapi.responses.FileResponse(
            path=f"{Path(OUTPUT_PATH) / mp4_name}",
            media_type="video/mp4",
            filename=mp4_name,
        )


# ## Generating videos from the command line

# We add a [local entrypoint](https://modal.com/docs/reference/modal.App#local_entrypoint)
# that calls the `Inference.run` method to run inference from the command line.
# The function's parameters are automatically turned into a CLI.

# Run it with

# ```bash
# modal run image_to_video.py --prompt "A cat looking out the window at a snowy mountain" --image-path /path/to/cat.jpg
# ```

# You can also pass `--help` to see the full list of arguments.


@app.local_entrypoint()
def entrypoint(
    image_path: str,
    prompt: str,
    negative_prompt: Optional[str] = None,
    num_frames: Optional[int] = None,
    num_inference_steps: Optional[int] = None,
    seed: Optional[int] = None,
    twice: bool = True,
):
    import os
    import urllib.request

    print(f"🎥 Generating a video from the image at {image_path}")
    print(f"🎥 using the prompt {prompt}")

    if image_path.startswith(("http://", "https://")):
        image_bytes = urllib.request.urlopen(image_path).read()
    elif os.path.isfile(image_path):
        image_bytes = Path(image_path).read_bytes()
    else:
        raise ValueError(f"{image_path} is not a valid file or URL.")

    inference_service = Inference()

    for _ in range(1 + twice):
        start = time.time()
        mp4_name = inference_service.run.remote(
            image_bytes=image_bytes,
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_frames=num_frames,
            seed=seed,
        )
        duration = time.time() - start
        print(f"🎥 Generated video in {duration:.3f}s")

        output_dir = Path("/tmp/image_to_video")
        output_dir.mkdir(exist_ok=True, parents=True)
        output_path = output_dir / mp4_name
        # read in the file from the Modal Volume, then write it to the local disk
        output_path.write_bytes(b"".join(output_volume.read_file(mp4_name)))
        print(f"🎥 Video saved to {output_path}")


# ## Generating videos via an API

# The Modal `Cls` above also included a [`fastapi_endpoint`](https://modal.com/docs/examples/basic_web),
# which adds a simple web API to the inference method.

# To try it out, run

# ```bash
# modal deploy image_to_video.py
# ```

# copy the printed URL ending in `inference-web.modal.run`,
# and add `/docs` to the end. This will bring up the interactive
# Swagger/OpenAPI docs for the endpoint.

# ## Generating videos in a web UI

# Lastly, we add a simple front-end web UI (written in Alpine.js) for
# our image to video backend.

# This is also deployed when you run

# ```bash
# modal deploy image_to_video.py.
# ```

# The `Inference` class will serve multiple users from its own auto-scaling pool of warm GPU containers automatically,
# and they will spin down when there are no requests.

frontend_path = Path(__file__).parent / "frontend"

web_image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install("jinja2==3.1.5", "fastapi[standard]==0.115.8")
    .add_local_dir(  # mount frontend/client code
        frontend_path, remote_path="/assets"
    )
)


@app.function(image=web_image)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def ui():
    import fastapi.staticfiles
    import fastapi.templating

    web_app = fastapi.FastAPI()
    templates = fastapi.templating.Jinja2Templates(directory="/assets")

    @web_app.get("/")
    async def read_root(request: fastapi.Request):
        return templates.TemplateResponse(
            "index.html",
            {
                "request": request,
                "inference_url": Inference().web.get_web_url(),
                "model_name": "LTX-Video Image to Video",
                "default_prompt": "A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background.",
            },
        )

    web_app.mount(
        "/static",
        fastapi.staticfiles.StaticFiles(directory="/assets"),
        name="static",
    )

    return web_app


=== GITHUB: 06_gpu_and_ml/comfyui/comfyclient.py ===
# ---
# cmd: ["python", "06_gpu_and_ml/comfyui/comfyclient.py", "--modal-workspace", "modal-labs-examples", "--prompt", "Spider-Man visits Yosemite, rendered by Blender, trending on artstation"]
# output-directory: "/tmp/comfyui"
# ---

import argparse
import json
import pathlib
import sys
import time
import urllib.request

OUTPUT_DIR = pathlib.Path("/tmp/comfyui")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)


def main(args: argparse.Namespace):
    url = f"https://{args.modal_workspace}--example-comfyui-comfyui-api{'-dev' if args.dev else ''}.modal.run/"
    data = json.dumps({"prompt": args.prompt}).encode("utf-8")
    print(f"Sending request to {url} with prompt: {args.prompt}")
    print("Waiting for response...")
    start_time = time.time()
    req = urllib.request.Request(
        url, data=data, headers={"Content-Type": "application/json"}
    )
    try:
        with urllib.request.urlopen(req) as response:
            assert response.status == 200, response.status
            elapsed = round(time.time() - start_time, 1)
            print(f"Image finished generating in {elapsed} seconds!")
            filename = OUTPUT_DIR / f"{slugify(args.prompt)}.png"
            filename.write_bytes(response.read())
            print(f"Saved to '{filename}'")
    except urllib.error.HTTPError as e:
        if e.code == 404:
            print(f"Workflow API not found at {url}")


def parse_args(arglist: list[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--modal-workspace",
        type=str,
        required=True,
        help="Name of the Modal workspace with the deployed app. Run `modal profile current` to check.",
    )
    parser.add_argument(
        "--prompt",
        type=str,
        required=True,
        help="Prompt for the image generation model.",
    )
    parser.add_argument(
        "--dev",
        action="store_true",
        help="use this flag when running the ComfyUI server in development mode with `modal serve`",
    )

    return parser.parse_args(arglist[1:])


def slugify(s: str) -> str:
    return s.lower().replace(" ", "-").replace(".", "-").replace("/", "-")[:32]


if __name__ == "__main__":
    args = parse_args(sys.argv)
    main(args)


=== GITHUB: 06_gpu_and_ml/comfyui/comfyapp.py ===
# ---
# deploy: true
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/comfyapp.py"]
# ---

# # Run Flux on ComfyUI as an API

# In this example, we show you how to turn a [ComfyUI](https://github.com/comfyanonymous/ComfyUI) workflow into a scalable API endpoint.

# ## Quickstart

# To run this simple text-to-image [Flux Schnell workflow](https://github.com/modal-labs/modal-examples/blob/main/06_gpu_and_ml/comfyui/workflow_api.json) as an API:

# 1. Deploy ComfyUI behind a web endpoint:

# ```bash
# modal deploy 06_gpu_and_ml/comfyui/comfyapp.py
# ```

# 2. In another terminal, run inference:

# ```bash
# python 06_gpu_and_ml/comfyui/comfyclient.py --modal-workspace $(modal profile current) --prompt "Surreal dreamscape with floating islands, upside-down waterfalls, and impossible geometric structures, all bathed in a soft, ethereal light"
# ```

# ![example comfyui image](https://modal-cdn.com/cdnbot/flux_gen_imagesenr_0w3_209b7170.webp)

# The first inference will take ~1m since the container needs to launch the ComfyUI server and load Flux into memory. Successive calls on a warm container should take a few seconds.

# ## Installing ComfyUI

# We use [comfy-cli](https://github.com/Comfy-Org/comfy-cli) to install ComfyUI and its dependencies.

import json
import subprocess
import uuid
from pathlib import Path
from typing import Dict

import modal
import modal.experimental

image = (  # build up a Modal Image to run ComfyUI, step by step
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("fastapi[standard]==0.115.4")  # install web dependencies
    .pip_install("comfy-cli==1.3.8")  # install comfy-cli
    .run_commands(  # use comfy-cli to install ComfyUI and its dependencies
        "comfy --skip-prompt install --fast-deps --nvidia --version 0.3.10"
    )
)

# ## Downloading custom nodes

# We'll also use `comfy-cli` to download custom nodes, in this case the popular [WAS Node Suite](https://github.com/WASasquatch/was-node-suite-comfyui).

# Use the [ComfyUI Registry](https://registry.comfy.org/) to find the specific custom node name to use with this command.

image = (
    image.run_commands(  # download a custom node
        "comfy node install --fast-deps was-node-suite-comfyui@1.0.2"
    )
    # Add .run_commands(...) calls for any other custom nodes you want to download
)

# See [this post](https://modal.com/blog/comfyui-custom-nodes) for more examples
# on how to install popular custom nodes like ComfyUI Impact Pack and ComfyUI IPAdapter Plus.

# ## Downloading models

# `comfy-cli` also supports downloading models, but we've found it's faster to use
# [`hf_hub_download`](https://huggingface.co/docs/huggingface_hub/en/guides/download#download-a-single-file)
# directly by:

# 1. Enabling [faster downloads](https://huggingface.co/docs/huggingface_hub/en/guides/download#faster-downloads)
# 2. Mounting the cache directory to a [Volume](https://modal.com/docs/guide/volumes)

# By persisting the cache to a Volume, you avoid re-downloading the models every time you rebuild your image.


def hf_download():
    from huggingface_hub import hf_hub_download

    flux_model = hf_hub_download(
        repo_id="Comfy-Org/flux1-schnell",
        filename="flux1-schnell-fp8.safetensors",
        cache_dir="/cache",
    )

    # symlink the model to the right ComfyUI directory
    subprocess.run(
        f"ln -s {flux_model} /root/comfy/ComfyUI/models/checkpoints/flux1-schnell-fp8.safetensors",
        shell=True,
        check=True,
    )


vol = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

image = (
    # install huggingface_hub with hf_transfer support to speed up downloads
    image.pip_install("huggingface_hub[hf_transfer]==0.30.0")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        hf_download,
        # persist the HF cache to a Modal Volume so future runs don't re-download models
        volumes={"/cache": vol},
    )
)

# Lastly, copy the ComfyUI workflow JSON to the container.
image = image.add_local_file(
    Path(__file__).parent / "workflow_api.json", "/root/workflow_api.json"
)


# ## Running ComfyUI interactively

# Spin up an interactive ComfyUI server by wrapping the `comfy launch` command in a Modal Function
# and serving it as a [web server](https://modal.com/docs/guide/webhooks#non-asgi-web-servers).

app = modal.App(name="example-comfyui", image=image)


@app.function(
    max_containers=1,  # limit interactive session to 1 container
    gpu="L40S",  # good starter GPU for inference
    volumes={"/cache": vol},  # mounts our cached models
)
@modal.concurrent(
    max_inputs=10
)  # required for UI startup process which runs several API calls concurrently
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


# At this point you can run `modal serve 06_gpu_and_ml/comfyui/comfyapp.py` and open the UI in your browser for the classic ComfyUI experience.

# Remember to **close your UI tab** when you are done developing.
# This will close the connection with the container serving ComfyUI and you will stop being charged.

# ## Running ComfyUI as an API

# To run a workflow as an API:

# 1. Stand up a "headless" ComfyUI server in the background when the app starts.

# 2. Define an `infer` method that takes in a workflow path and runs the workflow on the ComfyUI server.

# 3. Create a web handler `api` as a web endpoint, so that we can run our workflow as a service and accept inputs from clients.

# We group all these steps into a single Modal `cls` object, which we'll call `ComfyUI`.


@app.cls(
    scaledown_window=300,  # 5 minute container keep alive after it processes an input
    gpu="L40S",
    volumes={"/cache": vol},
)
@modal.concurrent(max_inputs=5)  # run 5 inputs per container
class ComfyUI:
    port: int = 8000

    @modal.enter()
    def launch_comfy_background(self):
        # launch the ComfyUI server exactly once when the container starts
        cmd = f"comfy launch --background -- --port {self.port}"
        subprocess.run(cmd, shell=True, check=True)

    @modal.method()
    def infer(self, workflow_path: str = "/root/workflow_api.json"):
        # sometimes the ComfyUI server stops responding (we think because of memory leaks), so this makes sure it's still up
        self.poll_server_health()

        # runs the comfy run --workflow command as a subprocess
        cmd = f"comfy run --workflow {workflow_path} --wait --timeout 1200 --verbose"
        subprocess.run(cmd, shell=True, check=True)

        # completed workflows write output images to this directory
        output_dir = "/root/comfy/ComfyUI/output"

        # looks up the name of the output image file based on the workflow
        workflow = json.loads(Path(workflow_path).read_text())
        file_prefix = [
            node.get("inputs")
            for node in workflow.values()
            if node.get("class_type") == "SaveImage"
        ][0]["filename_prefix"]

        # returns the image as bytes
        for f in Path(output_dir).iterdir():
            if f.name.startswith(file_prefix):
                return f.read_bytes()

    @modal.fastapi_endpoint(method="POST")
    def api(self, item: Dict):
        from fastapi import Response

        workflow_data = json.loads(
            (Path(__file__).parent / "workflow_api.json").read_text()
        )

        # insert the prompt
        workflow_data["6"]["inputs"]["text"] = item["prompt"]

        # give the output image a unique id per client request
        client_id = uuid.uuid4().hex
        workflow_data["9"]["inputs"]["filename_prefix"] = client_id

        # save this updated workflow to a new file
        new_workflow_file = f"{client_id}.json"
        json.dump(workflow_data, Path(new_workflow_file).open("w"))

        # run inference on the currently running container
        img_bytes = self.infer.local(new_workflow_file)

        return Response(img_bytes, media_type="image/jpeg")

    def poll_server_health(self) -> Dict:
        import socket
        import urllib

        try:
            # check if the server is up (response should be immediate)
            req = urllib.request.Request(f"http://127.0.0.1:{self.port}/system_stats")
            urllib.request.urlopen(req, timeout=5)
            print("ComfyUI server is healthy")
        except (socket.timeout, urllib.error.URLError) as e:
            # if no response in 5 seconds, stop the container
            print(f"Server health check failed: {str(e)}")
            modal.experimental.stop_fetching_inputs()

            # all queued inputs will be marked "Failed", so you need to catch these errors in your client and then retry
            raise Exception("ComfyUI server is not healthy, stopping container")


# This serves the `workflow_api.json` in this repo. When deploying your own workflows, make sure you select the "Export (API)" option in the ComfyUI menu:

# ![comfyui menu](https://modal-cdn.com/cdnbot/comfyui_menugo5j8ahx_27d72c45.webp)

# ## More resources
# - Use [memory snapshots](https://modal.com/docs/guide/memory-snapshot) to speed up cold starts (check out the `memory_snapshot` directory on [Github](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/comfyui))
# - Run a ComfyUI workflow as a [Python script](https://modal.com/blog/comfyui-prototype-to-production)

# - When to use [A1111 vs ComfyUI](https://modal.com/blog/a1111-vs-comfyui)

# - Understand tradeoffs of parallel processing strategies when
# [scaling ComfyUI](https://modal.com/blog/scaling-comfyui)


=== GITHUB: 06_gpu_and_ml/comfyui/memory_snapshot/memory_snapshot_example.py ===
# Simple ComfyUI example using memory snapshot to speed up cold starts.

# CAUTION: Some custom nodes may not work with memory snapshots, especially if they make calls to torch (i.e. require a GPU) on initialization.
# Run `modal deploy memory_snapshot_example.py` to deploy with memory snapshot enabled.

# Image building and model downloading is directly taken from the core example: https://modal.com/docs/examples/comfyapp
# The notable changes are copying the custom node in the image and the cls object
import subprocess
from pathlib import Path

import modal

image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("git")
    .pip_install("fastapi[standard]==0.115.4")
    .pip_install("comfy-cli==1.3.8")
    .run_commands("comfy --skip-prompt install --fast-deps --nvidia --version 0.3.10")
)

# Add custom node that patches core ComfyUI so that we can use Modal's [memory snapshot](https://modal.com/docs/guide/memory-snapshot)
image = image.add_local_dir(
    local_path=Path(__file__).parent / "memory_snapshot_helper",
    remote_path="/root/comfy/ComfyUI/custom_nodes/memory_snapshot_helper",
    copy=True,
)


def hf_download():
    from huggingface_hub import hf_hub_download

    flux_model = hf_hub_download(
        repo_id="Comfy-Org/flux1-schnell",
        filename="flux1-schnell-fp8.safetensors",
        cache_dir="/cache",
    )

    subprocess.run(
        f"ln -s {flux_model} /root/comfy/ComfyUI/models/checkpoints/flux1-schnell-fp8.safetensors",
        shell=True,
        check=True,
    )


vol = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

image = (
    image.pip_install("huggingface_hub[hf_transfer]==0.30.0")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        hf_download,
        volumes={"/cache": vol},
    )
)


app = modal.App(name="example-comfyui-memory-snapshot", image=image)


@app.cls(
    max_containers=1,
    gpu="L40S",
    volumes={"/cache": vol},
    enable_memory_snapshot=True,  # snapshot container state for faster cold starts
)
@modal.concurrent(max_inputs=10)
class ComfyUIMemorySnapshot:
    port: int = 8000

    # Snapshot ComfyUI server launch state, which includes import torch and custom node initialization (GPU not available during this step)
    @modal.enter(snap=True)
    def launch_comfy_background(self):
        cmd = f"comfy launch --background -- --port {self.port}"
        subprocess.run(cmd, shell=True, check=True)

    # Restore ComfyUI server state. Re-enables the CUDA device for inference.
    @modal.enter(snap=False)
    def restore_snapshot(self):
        import requests

        response = requests.post(f"http://127.0.0.1:{self.port}/cuda/set_device")
        if response.status_code != 200:
            print("Failed to set CUDA device")
        else:
            print("Successfully set CUDA device")

    @modal.web_server(port, startup_timeout=60)
    def ui(self):
        subprocess.Popen(
            f"comfy launch -- --listen 0.0.0.0 --port {self.port}", shell=True
        )


=== GITHUB: 06_gpu_and_ml/comfyui/memory_snapshot/memory_snapshot_helper/__init__.py ===
import os

from aiohttp import web
from server import PromptServer

# ------- API Endpoints -------


@PromptServer.instance.routes.post("/cuda/set_device")
async def set_current_device(request):
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    return web.json_response({"status": "success"})


# Empty for ComfyUI node registration
NODE_CLASS_MAPPINGS = {}


=== GITHUB: 06_gpu_and_ml/comfyui/memory_snapshot/memory_snapshot_helper/prestartup_script.py ===
import os
import shutil
from pathlib import Path

comfy_dir = Path(__file__).parent.parent.parent / "comfy"

model_management_path = str(comfy_dir / "model_management.py")
original_model_management_path = str(comfy_dir / "model_management_original.py")
is_patched = os.path.exists(original_model_management_path)


def _apply_cuda_safe_patch():
    """Apply a permanent patch that avoid torch cuda init during snapshots"""

    shutil.copy(model_management_path, original_model_management_path)
    print(
        "[memory_snapshot_helper] ==> Applying CUDA-safe patch for model_management.py"
    )

    with open(model_management_path, "r") as f:
        content = f.read()

    # Find the get_torch_device function and modify the CUDA device access
    # The original line uses: return torch.device(torch.cuda.current_device())
    # We'll replace it with a check if CUDA is available

    # Define the patched content as a constant
    CUDA_SAFE_PATCH = """import os
        if torch.cuda.is_available():
            return torch.device(torch.cuda.current_device())
        else:
            logging.info("[memory_snapshot_helper] CUDA is not available, defaulting to cpu")
            return torch.device('cpu')  # Safe fallback during snapshot"""

    if "return torch.device(torch.cuda.current_device())" in content:
        patched_content = content.replace(
            "return torch.device(torch.cuda.current_device())", CUDA_SAFE_PATCH
        )

        # Save the patched version
        with open(model_management_path, "w") as f:
            f.write(patched_content)

        print("[memory_snapshot_helper] ==> Successfully patched model_management.py")
    else:
        raise Exception(
            "[memory_snapshot_helper] ==> Failed to patch model_management.py"
        )


if not is_patched:
    _apply_cuda_safe_patch()


=== GITHUB: 06_gpu_and_ml/comfyui/ip_adapter/ip_adapter_example.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/ip_adapter/ip_adapter_example.py"]
# ---

import subprocess

import modal

image = (  # build up a Modal Image to run ComfyUI, step by step
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("comfy-cli==1.2.7")  # install comfy-cli
    .run_commands(  # use comfy-cli to install the ComfyUI repo and its dependencies
        "comfy --skip-prompt install --nvidia"
    )
    .run_commands(  # download the WAS Node Suite custom node pack
        "comfy node install ComfyUI_IPAdapter_plus"
    )
    .run_commands("apt install -y wget")
    .run_commands(  # the Unified Model Loader node requires these two models to be named a specific way, so we use wget instead of the usual comfy model download command
        "wget -q -O /root/comfy/ComfyUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors",
    )
    .run_commands(
        "wget -q -O /root/comfy/ComfyUI/models/clip_vision/CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors, https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors",
    )
    .run_commands(  # download the IP-Adapter model
        "comfy --skip-prompt model download --url https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.safetensors --relative-path models/ipadapter"
    )
    .run_commands(
        "comfy --skip-prompt model download --url https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors --relative-path models/checkpoints",
    )
)

app = modal.App(name="example-ip-adapter", image=image)


# Run ComfyUI as an interactive web server
@app.function(
    max_containers=1,
    scaledown_window=30,
    timeout=1800,
    gpu="A10G",
)
@modal.concurrent(max_inputs=10)
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


=== GITHUB: 06_gpu_and_ml/comfyui/kjnodes/kjnodes_example.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/kjnodes/kjnodes_example.py"]
# ---

import subprocess

import modal

image = (  # build up a Modal Image to run ComfyUI, step by step
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("comfy-cli==1.2.7")  # install comfy-cli
    .run_commands(  # use comfy-cli to install the ComfyUI repo and its dependencies
        "comfy --skip-prompt install --nvidia"
    )
    .run_commands(  # download the ComfyUI Essentials custom node pack
        "comfy node install ComfyUI-KJNodes"
    )
    .run_commands(
        "comfy --skip-prompt model download --url https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors --relative-path models/checkpoints"
    )
)

app = modal.App(name="example-kjnodes", image=image)


# Run ComfyUI as an interactive web server
@app.function(
    max_containers=1,
    scaledown_window=30,
    timeout=1800,
    gpu="A10G",
)
@modal.concurrent(max_inputs=10)
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


=== GITHUB: 06_gpu_and_ml/comfyui/essentials/essentials_example.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/essentials/essentials_example.py"]
# ---

import subprocess

import modal

image = (  # build up a Modal Image to run ComfyUI, step by step
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("comfy-cli==1.2.7")  # install comfy-cli
    .run_commands(  # use comfy-cli to install the ComfyUI repo and its dependencies
        "comfy --skip-prompt install --nvidia"
    )
    .run_commands(  # download the ComfyUI Essentials custom node pack
        "comfy node install ComfyUI_essentials"
    )
    .run_commands(
        "comfy --skip-prompt model download --url https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors --relative-path models/checkpoints"
    )
)

app = modal.App(name="example-essentials", image=image)


# Run ComfyUI as an interactive web server
@app.function(
    max_containers=1,
    scaledown_window=30,
    timeout=1800,
    gpu="A10G",
)
@modal.concurrent(max_inputs=10)
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


=== GITHUB: 06_gpu_and_ml/comfyui/was_node_suite/was_node_example.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/was_node_suite/was_node_example.py"]
# ---

import subprocess

import modal

image = (
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("comfy-cli==1.2.7")  # install comfy-cli
    .run_commands(  # use comfy-cli to install the ComfyUI repo and its dependencies
        "comfy --skip-prompt install --nvidia"
    )
    .run_commands(  # install default stable diffusion model for example purposes
        "comfy --skip-prompt model download --url https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors --relative-path models/checkpoints"
    )
    .run_commands(  # download the WAS Node Suite custom node pack
        "comfy node install was-node-suite-comfyui"
    )
)

app = modal.App(name="example-was-node", image=image)


# Run ComfyUI as an interactive web server
@app.function(
    max_containers=1,
    scaledown_window=30,
    timeout=1800,
    gpu="A10G",
)
@modal.concurrent(max_inputs=10)
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


=== GITHUB: 06_gpu_and_ml/comfyui/impact/impact_example.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/comfyui/impact/impact_example.py"]
# ---

import subprocess

import modal

image = (
    modal.Image.debian_slim(  # start from basic Linux with Python
        python_version="3.11"
    )
    .apt_install("git")  # install git to clone ComfyUI
    .pip_install("comfy-cli==1.2.7")  # install comfy-cli
    .run_commands(  # use comfy-cli to install the ComfyUI repo and its dependencies
        "comfy --skip-prompt install --nvidia"
    )
    .run_commands(  # download the Impact pack
        "comfy node install ComfyUI-Impact-Pack"
    )
    .pip_install("ultralytics==8.3.26")  # object detection models
    .apt_install(  # opengl dependencies
        "libgl1-mesa-glx", "libglib2.0-0"
    )
    .run_commands(
        "comfy --skip-prompt model download --url https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors --relative-path models/checkpoints",
    )
)

app = modal.App(name="example-impact", image=image)


# Run ComfyUI as an interactive web server
@app.function(
    max_containers=1,
    scaledown_window=30,
    timeout=1800,
    gpu="A10G",
)
@modal.concurrent(max_inputs=10)
@modal.web_server(8000, startup_timeout=60)
def ui():
    subprocess.Popen("comfy launch -- --listen 0.0.0.0 --port 8000", shell=True)


=== GITHUB: 06_gpu_and_ml/llm-structured/instructor_generate.py ===
# ---
# output-directory: "/tmp/instructor_generate"
# ---

# # Structured Data Extraction using `instructor`

# This example demonstrates how to use the `instructor` library to extract structured, schematized data from unstructured text.

# Structured output is a powerful but under-appreciated feature of LLMs.
# Structured output allows LLMs and multimodal models to connect to traditional software,
# for example enabling the ingestion of unstructured data like text files into structured databases.
# Applied properly, it makes them an extreme example of the [Robustness Principle](https://en.wikipedia.org/wiki/Robustness_principle)
# Jon Postel formulated for TCP: "Be conservative in what you send, be liberal in what you accept".

# The unstructured data used in this example code is the code from the examples in the Modal examples repository --
# including this example's code!

# The output includes a JSONL file containing, on each line, the metadata extracted from the code in one example.
# This can be consumed downstream by other software systems, like a database or a dashboard.
# We've used it to maintain and update our [examples repository](https://github.com/modal-labs/modal-examples).

# ## Environment setup

# We set up the environment our code will run in first.
# In Modal, we define environments via [container images](https://modal.com/docs/guide/custom-container),
# much like Docker images, by iteratively chaining together commands.

# Here there's just one command, installing `instructor` and the Python SDK for Anthropic's LLM API.

from pathlib import Path
from typing import Literal, Optional

import modal
from pydantic import BaseModel, Field

image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "instructor~=1.7.2", "anthropic==0.42.0"
)

# This example uses models from Anthropic, so if you want to run it yourself,
# you'll need an Anthropic API key and a Modal [`Secret`](https://modal.com/docs/guide/secrets)
# called `my-anthropic-secret` to hold share it with your Modal Functions.

app = modal.App(
    image=image,
    secrets=[
        modal.Secret.from_name("anthropic-secret", required_keys=["ANTHROPIC_API_KEY"])
    ],
)

# ## Running Modal functions from the command line

# We'll run the example by calling `modal run instructor_generate.py` from the command line.

# When we invoke `modal run` on a Python file, we run the function
# marked with `@app.local_entrypoint`.

# This is the only code that runs locally -- it coordinates
# the activity of the rest of our code, which runs in Modal's cloud.

# The logic is fairly simple: collect up the code for our examples,
# and then use `instructor` to extract metadata from them,
# which we then write to a file.

# By default, the language model is Claude 3 Haiku, the smallest model
# in the Claude 3 family.  We include the option to run `with_opus`,
# which gives much better results, but it is off by default because
# Opus is also ~60x more expensive, at ~$30 per million tokens.


@app.local_entrypoint()
def main(limit: int = 1, with_opus: bool = False):
    # find all of the examples in the repo
    examples = get_examples()
    # optionally limit the number of examples we process
    if limit == 1:
        examples = [None]  # just run on this example
    else:
        examples = examples[:limit]
    # use Modal to map our extraction function over the examples concurrently
    results = extract_example_metadata.map(
        (  # iterable of file contents
            Path(example.filename).read_text() if example else None
            for example in examples
        ),
        (  # iterable of filenames
            example.stem if example else None for example in examples
        ),
        kwargs={"with_opus": with_opus},
    )

    # save the results to a local file
    results_path = Path("/tmp") / "instructor_generate" / "results.jsonl"
    results_dir = results_path.parent
    if not results_dir.exists():
        results_dir.mkdir(parents=True)

    print(f"writing results to {results_path}")
    with open(results_path, "w") as f:
        for result in results:
            print(result)
            f.write(result + "\n")


# ## Extracting JSON from unstructured text with `instructor` and Pydantic

# The real meat of this example is in this section, in the `extract_example_metadata` function and its schemas.

# We define a schema for the data we want the LLM to extract, using Pydantic.
# Instructor ensures that the LLM's output matches this schema.

# We can use the type system provided by Python and Pydantic to express many useful features
# of the data we want to extract -- ranging from wide-open fields like a `str`ing-valued `summary`
# to constrained fields like `difficulty`, which can only take on value between 1 and 5.


class ExampleMetadataExtraction(BaseModel):
    """Extracted metadata about an example from the Modal examples repo."""

    summary: str = Field(..., description="A brief summary of the example.")
    has_thorough_explanation: bool = Field(
        ...,
        description="The example contains, in the form of inline comments with markdown formatting, a thorough explanation of what the code does.",
    )
    tags: list[
        Literal[
            "use-case-inference-lms",
            "use-case-inference-audio",
            "use-case-inference-images-video-3d",
            "use-case-finetuning",
            "use-case-job-queues-batch-processing",
            "use-case-sandboxed-code-execution",
        ]
    ] = Field(..., description="The use cases associated with the example")
    freshness: float = Field(
        ...,
        description="The freshness of the example, from 0 to 1. This is relative to your knowledge cutoff. Examples are less fresh if they use older libraries and tools.",
    )


# That schema describes the data to be extracted by the LLM, but not all data is best extracted by an LLM.
# For example, the filename is easily determined in software.

# So we inject that information into the output after the LLM has done its work. That necessitates
# an additional schema, which inherits from the first.


class ExampleMetadata(ExampleMetadataExtraction):
    """Metadata about an example from the Modal examples repo."""

    filename: Optional[str] = Field(..., description="The filename of the example.")


# With these schemas in hand, it's straightforward to write the function that extracts the metadata.
# Note that we decorate it with `@app.function` to make it run on Modal.


@app.function(max_containers=5)  # watch those LLM API rate limits!
def extract_example_metadata(
    example_contents: Optional[str] = None,
    filename: Optional[str] = None,
    with_opus=False,
):
    import instructor
    from anthropic import Anthropic

    # if no example is provided, use the contents of this example
    if example_contents is None:
        example_contents = Path(__file__).read_text()
        filename = Path(__file__).name

    client = instructor.from_anthropic(Anthropic())
    model = "claude-3-opus-20240229" if with_opus else "claude-3-haiku-20240307"

    # add the schema as the `response_model` argument in what otherwise looks like a normal LLM API call
    extracted_metadata = client.messages.create(
        model=model,
        temperature=0.0,
        max_tokens=1024,
        response_model=ExampleMetadataExtraction,
        messages=[
            {
                "role": "user",
                "content": f"Extract the metadata for this example.\n\n-----EXAMPLE BEGINS-----{example_contents}-----EXAMPLE ENDS-----\n\n",
            },
        ],
    )

    # inject the filename
    full_metadata = ExampleMetadata(**extracted_metadata.dict(), filename=filename)

    # return it as JSON
    return full_metadata.model_dump_json()


# ## Addenda

# The rest of the code used in this example is not particularly interesting:
# just a utility function to find all of the examples, which we invoke in the `local_entrypoint` above.


def get_examples(silent=True):
    """Find all of the examples using a utility from this repo.

    We use importlib to avoid the need to define the repo as a package."""
    import importlib

    examples_root = Path(__file__).parent.parent.parent
    spec = importlib.util.spec_from_file_location(
        "utils", f"{examples_root}/internal/utils.py"
    )
    example_utils = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(example_utils)
    examples = [
        example
        for example in example_utils.get_examples()
        if example.type != 2  # filter out non-code assets
    ]
    return examples


=== GITHUB: 06_gpu_and_ml/llm-structured/outlines_generate.py ===
# # Enforcing JSON outputs on LLMs

# [Outlines](https://github.com/outlines-dev/outlines) is a tool that lets you control the generation of language models to make their output more predictable.

# This includes things like:

# - Reducing the completion to a choice between multiple possibilities
# - Type constraints
# - Efficient regex-structured generation
# - Efficient JSON generation following a Pydantic model
# - Efficient JSON generation following a JSON schema

# Outlines is considered an alternative to tools like [JSONFormer](https://github.com/1rgs/jsonformer), and can be used on top of a variety of LLMs, including:

# - OpenAI models
# - LLaMA
# - Mamba

# In this guide, we will show how you can use Outlines to enforce a JSON schema on the output of Mistral-7B.

# ## Build image

#  First, you'll want to build an image and install the relevant Python dependencies:
# `outlines` and a Hugging Face inference stack.

import modal

app = modal.App(name="outlines-app")

outlines_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "outlines==0.0.44",
    "transformers==4.41.2",
    "sentencepiece==0.2.0",
    "datasets==2.18.0",
    "accelerate==0.27.2",
    "numpy<2",
)

# ## Download the model

# Next, we download the Mistral 7B model from Hugging Face.
# We do this as part of the definition of our Modal Image so that
# we don't need to download it every time our inference function is run.

MODEL_NAME = "mistral-community/Mistral-7B-v0.2"


def import_model(model_name):
    import outlines

    outlines.models.transformers(model_name)


outlines_image = outlines_image.run_function(
    import_model, kwargs={"model_name": MODEL_NAME}
)


# ## Define the schema

# Next, we define the schema that we want to enforce on the output of Mistral-7B. This schema is for a character description, and includes a name, age, armor, weapon, and strength.

schema = """{
    "title": "Character",
    "type": "object",
    "properties": {
        "name": {
            "title": "Name",
            "maxLength": 10,
            "type": "string"
        },
        "age": {
            "title": "Age",
            "type": "integer"
        },
        "armor": {"$ref": "#/definitions/Armor"},
        "weapon": {"$ref": "#/definitions/Weapon"},
        "strength": {
            "title": "Strength",
            "type": "integer"
        }
    },
    "required": ["name", "age", "armor", "weapon", "strength"],
    "definitions": {
        "Armor": {
            "title": "Armor",
            "description": "An enumeration.",
            "enum": ["leather", "chainmail", "plate"],
            "type": "string"
        },
        "Weapon": {
            "title": "Weapon",
            "description": "An enumeration.",
            "enum": ["sword", "axe", "mace", "spear", "bow", "crossbow"],
            "type": "string"
        }
    }
}"""

# ## Define the function

# Next, we define the generation function.
# We use the `@app.function` decorator to tell Modal to run this function on the app we defined above.
# Note that we import `outlines` from inside the Modal function. This is because the `outlines` package exists in the container, but not necessarily locally.

# We specify that we want to use the Mistral-7B model, and then ask for a character, and we'll receive structured data with the right schema.


@app.function(image=outlines_image, gpu="A100-40GB")
def generate(
    prompt: str = "Amiri, a 53 year old warrior woman with a sword and leather armor.",
):
    import outlines

    model = outlines.models.transformers(MODEL_NAME, device="cuda")

    generator = outlines.generate.json(model, schema)
    character = generator(f"Give me a character description. Describe {prompt}.")

    return character


# ## Define the entrypoint

# Finally, we define the entrypoint that will connect our local computer
# to the functions above, that run on Modal, and we are done!
#
# When you run this script with `modal run`, you should see something like this printed out:
#
#  `{'name': 'Amiri', 'age': 53, 'armor': 'leather', 'weapon': 'sword', 'strength': 10}`


@app.local_entrypoint()
def main(
    prompt: str = "Amiri, a 53 year old warrior woman with a sword and leather armor.",
):
    print(generate.remote(prompt))


=== GITHUB: 06_gpu_and_ml/llm-structured/jsonformer_generate.py ===
# ---
# lambda-test: false  # deprecated
# ---
# # Structured output generation with Jsonformer
#
# [Jsonformer](https://github.com/1rgs/jsonformer) is a tool that generates structured synthetic data using LLMs.
# You provide a JSON spec and it generates a JSON object following the spec. It's a
# great tool for developing, benchmarking, and testing applications.


from typing import Any

import modal

# We will be using one of [Databrick's Dolly](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)
# models, choosing for the smallest version with 3B parameters. Feel free to use any of the other models
# available from the [Huggingface Hub Dolly repository](https://huggingface.co/databricks).
MODEL_ID: str = "databricks/dolly-v2-3b"
CACHE_PATH: str = "/root/cache"


# ## Build image and cache model
#
# We'll download models from the Huggingface Hub and store them in our image.
# This skips the downloading of models during inference and reduces cold boot
# times.
def download_model():
    from transformers import AutoModelForCausalLM, AutoTokenizer

    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID, use_cache=True, device_map="auto"
    )
    model.save_pretrained(CACHE_PATH, safe_serialization=True)

    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, use_cache=True)
    tokenizer.save_pretrained(CACHE_PATH, safe_serialization=True)


# Define our image; install dependencies.
image = (
    modal.Image.debian_slim(python_version="3.10")
    .pip_install(
        "jsonformer==0.9.0",
        "transformers",
        "torch",
        "accelerate",
        "safetensors",
    )
    .run_function(download_model)
)
app = modal.App("example-jsonformer")


# ## Generate examples
#
# The generate function takes two arguments `prompt` and `json_schema`, where
# `prompt` is used to describe the domain of your data (for example, "plants")
# and the schema contains the JSON schema you want to populate.
@app.function(gpu="A10G", image=image)
def generate(prompt: str, json_schema: dict[str, Any]) -> dict[str, Any]:
    from jsonformer import Jsonformer
    from transformers import AutoModelForCausalLM, AutoTokenizer

    model = AutoModelForCausalLM.from_pretrained(
        CACHE_PATH, use_cache=True, device_map="auto"
    )
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_ID, use_fast=True, use_cache=True, device_map="auto"
    )

    jsonformer = Jsonformer(model, tokenizer, json_schema, prompt)
    generated_data = jsonformer()

    return generated_data


# Add Modal entrypoint for invoking your script, and done!
@app.local_entrypoint()
def main():
    prompt = "Generate random plant information based on the following schema:"
    json_schema = {
        "type": "object",
        "properties": {
            "height_cm": {"type": "number"},
            "bearing_fruit": {"type": "boolean"},
            "classification": {
                "type": "object",
                "properties": {
                    "species": {"type": "string"},
                    "kingdom": {"type": "string"},
                    "family": {"type": "string"},
                    "genus": {"type": "string"},
                },
            },
        },
    }

    result = generate.remote(prompt, json_schema)
    print(result)


=== GITHUB: 06_gpu_and_ml/obj_detection_webcam/webcam.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/obj_detection_webcam/webcam.py"]
# deploy: true
# ---

# # Real-time object detection via webcam

# This example creates a web endpoint that uses a Huggingface model for object detection.

# The web endpoint takes an image from their webcam, and sends it to a Modal web endpoint.
# The Modal web endpoint in turn calls a Modal function that runs the actual model.

# If you run this, it will look something like this:

# ![webcam](./webcam.png)

# ## Live demo

# [Take a look at the deployed app](https://modal-labs-examples--example-webcam-object-detection.modal.run/).

# A couple of caveats:
# * This is not optimized for latency: every prediction takes about 1s, and
#   there's an additional overhead on the first prediction since the containers
#   have to be started and the model initialized.
# * This doesn't work on iPhone unfortunately due to some issues with HTML5
#   webcam components

# ## Code

# Starting with imports:

import base64
import io
from pathlib import Path

import modal

# We need to install [transformers](https://github.com/huggingface/transformers)
# which is a package Huggingface uses for all their models, but also
# [Pillow](https://github.com/python-pillow/Pillow) which lets us work with images from Python,
# and a system font for drawing.

# This example uses the `facebook/detr-resnet-50` pre-trained model,
# which we'll cache to a Volume for fast cold starts.

MODEL_REPO_ID = "facebook/detr-resnet-50"
MODEL_DIR = "/cache"


app = modal.App("example-webcam-object-detection")
image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "huggingface-hub==0.27.1",
        "Pillow",
        "timm",
        "transformers",
    )
    .apt_install("fonts-freefont-ttf")
    .env({"HF_HUB_CACHE": MODEL_DIR})
)


# ## Prediction function

# The object detection function has a few different features worth mentioning:

# * There's a container initialization step in the method decorated with `@enter()`,
#   which runs on every container start. This lets us load the model only once per
#   container, so that it's reused for subsequent function calls.

# * We're running it on multiple CPUs for extra performance

# Note that the function takes an image and returns a new image.
# The input image is from the webcam
# The output image is an image with all the bounding boxes and labels on them,
# with an alpha channel so that most of the image is transparent so that the
# web interface can render it on top of the webcam view.


with image.imports():
    import torch
    from huggingface_hub import snapshot_download
    from PIL import Image, ImageColor, ImageDraw, ImageFont
    from transformers import DetrForObjectDetection, DetrImageProcessor


# We'll store the model weights in a Volume and provide a function that you can
# `modal run` against to download the model weights prior to deploying the App.
# Otherwise, the model weights will be downloaded for the first inference
# and cached to the Volume when the first container exits.

cache_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)


@app.function(image=image, volumes={MODEL_DIR: cache_volume})
def download_model():
    loc = snapshot_download(repo_id=MODEL_REPO_ID)
    print(f"Saved model to {loc}")


@app.cls(image=image, volumes={MODEL_DIR: cache_volume})
class ObjectDetection:
    @modal.enter()
    def load_model(self):
        self.feature_extractor = DetrImageProcessor.from_pretrained(
            MODEL_REPO_ID,
        )
        self.model = DetrForObjectDetection.from_pretrained(
            MODEL_REPO_ID,
        )

    @modal.method()
    def detect(self, img_data_in):
        # Based on https://huggingface.co/spaces/nateraw/detr-object-detection/blob/main/app.py
        # Read png from input
        image = Image.open(io.BytesIO(img_data_in)).convert("RGB")

        # Make prediction
        inputs = self.feature_extractor(image, return_tensors="pt")
        outputs = self.model(**inputs)
        img_size = torch.tensor([tuple(reversed(image.size))])
        processed_outputs = self.feature_extractor.post_process_object_detection(
            outputs=outputs,
            target_sizes=img_size,
            threshold=0,
        )
        output_dict = processed_outputs[0]

        # Grab boxes
        keep = output_dict["scores"] > 0.7
        boxes = output_dict["boxes"][keep].tolist()
        scores = output_dict["scores"][keep].tolist()
        labels = output_dict["labels"][keep].tolist()

        # Plot bounding boxes
        colors = list(ImageColor.colormap.values())
        font = ImageFont.truetype("/usr/share/fonts/truetype/freefont/FreeMono.ttf", 18)
        output_image = Image.new("RGBA", (image.width, image.height))
        output_image_draw = ImageDraw.Draw(output_image)
        for _score, box, label in zip(scores, boxes, labels):
            color = colors[label % len(colors)]
            text = self.model.config.id2label[label]
            box = tuple(map(int, box))
            output_image_draw.rectangle(box, outline=color)
            output_image_draw.text(box[:2], text, font=font, fill=color, width=3)

        # Return PNG as bytes
        with io.BytesIO() as output_buf:
            output_image.save(output_buf, format="PNG")
            return output_buf.getvalue()


# ## Defining the web interface

# To keep things clean, we define the web endpoints separate from the prediction
# function. This will introduce a tiny bit of extra latency (every web request
# triggers a Modal function call which will call another Modal function) but in
# practice the overhead is much smaller than the overhead of running the prediction
# function etc.

# We also serve a static html page which contains some tiny bit of Javascript to
# capture the webcam feed and send it to Modal.

static_path = Path(__file__).with_name("webcam").resolve()


@app.function(
    image=modal.Image.debian_slim(python_version="3.12")
    .pip_install("fastapi[standard]==0.115.4")
    .add_local_dir(static_path, remote_path="/assets")
)
@modal.asgi_app(label="example-webcam-object-detection")
def fastapi_app():
    from fastapi import FastAPI, Request, Response
    from fastapi.staticfiles import StaticFiles

    web_app = FastAPI()

    # The endpoint for the prediction function takes an image as a
    # [data URI](https://en.wikipedia.org/wiki/Data_URI_scheme)
    # and returns another image, also as a data URI:

    @web_app.post("/predict")
    async def predict(request: Request):
        # Takes a webcam image as a datauri, returns a bounding box image as a datauri
        body = await request.body()
        img_data_in = base64.b64decode(body.split(b",")[1])  # read data-uri
        img_data_out = ObjectDetection().detect.remote(img_data_in)
        output_data = b"data:image/png;base64," + base64.b64encode(img_data_out)
        return Response(content=output_data)

    web_app.mount("/", StaticFiles(directory="/assets", html=True))
    return web_app


# ## Running this locally

# You can run this as an ephemeral app, by running

# ```shell
# modal serve webcam.py
# ```


=== GITHUB: 06_gpu_and_ml/hyperparameter-sweep/hp_sweep_gpt.py ===
# ---
# cmd: ["modal", "run", "06_gpu_and_ml/hyperparameter-sweep/hp_sweep_gpt.py", "--n-steps", "200", "--n-steps-before-checkpoint", "50", "--n-steps-before-eval", "50"]
# ---

# # Train an SLM from scratch with early-stopping grid search over hyperparameters

# ![Split-Panel Image. Left: AI generated picture of Shakespeare. Right: SLM generated text](./shakespeare.jpg)

# When you want a language model that performs well on your task, there are three options,
# ordered by the degree of customization:

# - [**Prompt Engineering**](https://en.wikipedia.org/wiki/Prompt_engineering):
# large and capable language models understand tasks in natural language, so you can
# carefully design a natural language "prompt" to elicit the desired behavior.

# - [**Fine-Tuning**](https://modal.com/docs/examples/llm-finetuning):
# those same language models were trained by gradient descent on data sets representing tasks,
# and they can be further trained by gradient descent on data sets representative of your task.

# - **Training from Scratch**:
# if you have enough data for your task, you can throw the pretrained model away and make your own.

# Each step adds additional engineering complexity, but also leads to a superior cost-performance Pareto frontier
# for your tasks. Fine-tuned models at one-tenth the size regularly outperform more generic models,
# and models trained from scratch outperform them.

# Because these models are so much smaller than the Large Language Models that power generic
# assistant chatbots like ChatGPT and Claude, they are often called _Small Language Models_ (SLMs).

# In this example, we will explore training an SLM from scratch on Modal.

# In fact, we'll train 8 SLMs in parallel with different hyperparameters
# and then select the best one for additional training.

# We'll monitor this training live and serve our training and trained models
# as web endpoints and simple browser UIs.

# Along the way we'll use many features of the Modal platform:
# [distributed volumes](https://modal.com/docs/guide/volumes),
# multiple [web endpoints](https://modal.com/docs/guide/webhooks),
# and [parallel container execution](https://modal.com/docs/guide/scale#parallel-execution-of-inputs).

# Together, these features give every machine learning and AI team
# the same infrastructural capabilities that the most sophisticated companies
# have in their internal platforms.

# ## Basic Setup

import logging as L
import urllib.request
from dataclasses import dataclass
from pathlib import Path, PosixPath
from typing import Optional

import modal
from pydantic import BaseModel

MINUTES = 60  # seconds
HOURS = 60 * MINUTES

app_name = "example-hp-sweep-gpt"
app = modal.App(app_name)

# We'll use A10G GPUs for training, which are able to train the model to recognizably improved performance
# in ~15 minutes while keeping costs under ~$1.

gpu = "A10G"

# ### Create a Volume to store data, weights, and logs

# Since we'll be coordinating training across multiple machines we'll use a
# distributed [Volume](https://modal.com/docs/guide/volumes)
# to store the data, checkpointed models, and TensorBoard logs.

volume = modal.Volume.from_name("example-hp-sweep-gpt-volume", create_if_missing=True)
volume_path = PosixPath("/vol/data")
model_filename = "nano_gpt_model.pt"
best_model_filename = "best_nano_gpt_model.pt"
tb_log_path = volume_path / "tb_logs"
model_save_path = volume_path / "models"

# ### Define dependencies in container images

# The container image for training  is based on Modal's default slim Debian Linux image with `torch`
# for defining and running our neural network and `tensorboard` for monitoring training.
base_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "pydantic==2.9.1"
)

torch_image = base_image.pip_install(
    "torch==2.1.2",
    "tensorboard==2.17.1",
    "numpy<2",
)

# We also have some local dependencies that we'll need to import into the remote environment.
# We add them into the remote container.

torch_image = torch_image.add_local_dir(
    Path(__file__).parent / "src", remote_path="/root/src"
)

# We'll serve a simple web endpoint:
web_image = base_image.pip_install("fastapi[standard]==0.115.4", "starlette==0.41.2")

# And we'll deploy a web UI for interacting with our trained models using Gradio.
assets_path = Path(__file__).parent / "assets"
ui_image = web_image.pip_install("gradio~=4.44.0").add_local_dir(
    assets_path, remote_path="/assets"
)


# We can also "pre-import" libraries that will be used by the functions we run on Modal in a given image
# using the `with image.imports` context manager.

with torch_image.imports():
    import glob
    import os
    from timeit import default_timer as timer

    import tensorboard
    import torch
    from src.dataset import Dataset
    from src.logs_manager import LogsManager
    from src.model import AttentionModel
    from src.tokenizer import Tokenizer

# ## Running SLM training on Modal

# Here we define the training function, wrapping it in a decorator
# that specifies the infrastructural parameters, like the container `image` we want to use,
# which `volume` to mount where, the `gpu` we're using, and so on.

# Training consists of specifying optimization parameters, loading the
# `dataset`, building the `model`, setting up TensorBoard logging &
# checkpointing, and then finally executing the `training_loop` itself.


@app.function(
    image=torch_image,
    volumes={volume_path: volume},
    gpu=gpu,
    timeout=1 * HOURS,
)
def train_model(
    node_rank,
    n_nodes,
    hparams,
    experiment_name,
    run_to_first_save=False,
    n_steps=3000,
    n_steps_before_eval=None,
    n_steps_before_checkpoint=None,
):
    # optimizer, data, and model prep
    batch_size = 64
    learning_rate = 3e-4

    n_eval_steps = 100
    if n_steps_before_eval is None:
        n_steps_before_eval = int(n_steps / 8)  # eval eight times per run
    if n_steps_before_checkpoint is None:
        n_steps_before_checkpoint = int(n_steps / 4)  # save four times per run

    train_percent = 0.9

    L.basicConfig(
        level=L.INFO,
        format=f"\033[0;32m%(asctime)s %(levelname)s [%(filename)s.%(funcName)s:%(lineno)d] [Node {node_rank + 1}] %(message)s\033[0m",
        datefmt="%b %d %H:%M:%S",
    )

    # use GPU if available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    L.info("Remote Device: %s // GPU: %s", device, gpu)

    input_file_path = volume_path / "shakespeare_char.txt"
    text = prepare_data(input_file_path, volume)

    # construct tokenizer & dataset
    tokenizer = Tokenizer(text)
    dataset = Dataset(
        tokenizer.encode(text),
        train_percent,
        batch_size,
        hparams.context_size,
        device,
    )

    # build the model
    model = build_model(hparams, tokenizer.vocab_size, device)
    num_parameters = sum(p.numel() for p in model.parameters())
    L.info(f"Num parameters: {num_parameters}")

    optimizer = setup_optimizer(model, learning_rate)

    # TensorBoard logging & checkpointing prep
    logs_manager = LogsManager(experiment_name, hparams, num_parameters, tb_log_path)
    L.info(f"Model name: {logs_manager.model_name}")

    model_save_dir = model_save_path / experiment_name / logs_manager.model_name
    if model_save_dir.exists():
        L.info("Loading model from checkpoint...")
        checkpoint = torch.load(str(model_save_dir / model_filename))
        is_best_model = not run_to_first_save
        if is_best_model:
            make_best_symbolic_link(model_save_dir, model_filename, experiment_name)
        model.load_state_dict(checkpoint["model"])
        start_step = checkpoint["steps"] + 1
    else:
        model_save_dir.mkdir(parents=True, exist_ok=True)
        start_step = 0
        checkpoint = init_checkpoint(model, tokenizer, optimizer, start_step, hparams)

    checkpoint_path = model_save_dir / model_filename

    out = training_loop(
        start_step,
        n_steps,
        n_steps_before_eval,
        n_steps_before_checkpoint,
        n_eval_steps,
        dataset,
        tokenizer,
        model,
        optimizer,
        logs_manager,
        checkpoint,
        checkpoint_path,
        run_to_first_save,
    )

    return node_rank, float(out["val"]), hparams


# ## Launch a hyperparameter sweep from a `local_entrypoint`

# The main entry point coordinates the hyperparameter optimization.
# First we specify the default hyperparameters for the model, taken from
# [Andrej Karpathy's walkthrough](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5976s).
# For better performance, you can increase the `context_size` and scale up the GPU accordingly.


@dataclass
class ModelHyperparameters:
    n_heads: int = 6
    n_embed: int = 384
    n_blocks: int = 6
    context_size: int = 256
    dropout: float = 0.2


# Next we define the local entrypoint: the code we run locally to coordinate training.

# It will train 8 models in parallel across 8 containers, each
# with different hyperparameters, varying the number of heads (`n_heads`), the
# `context_size` (called the "block size" by Karpathy), and the dropout rate (`dropout`). To run in
# parallel we need to use the [`starmap` method](https://modal.com/docs/guide/scale#parallel-execution-of-inputs).

# We train all of the models until the first checkpoint and then stop early so we
# can compare the validation losses.

# Then we restart training for the best model and train it to completion.

# You can kick off training with the following command:

# ```bash
# modal run 06_gpu_and_ml/hyperparameter-sweep/hp_sweep_gpt.py
# ```

# The output will look something like this:

# ```
# Sep 16 21:20:39 INFO [hp_sweep_gpt.py.train_model:127] [Node 1]  Remote Device: cuda // GPU: A10G
# Sep 16 21:20:40 INFO [hp_sweep_gpt.py.train_model:149] [Node 1]  Num parameters: 10693697
# Sep 16 21:20:40 INFO [hp_sweep_gpt.py.train_model:156] [Node 1]  Model Name: E2024-0916-142031.618259_context_size=8_n_heads=1_dropout=0.1
# Sep 16 21:20:41 INFO [hp_sweep_gpt.py.train_model:225] [Node 1]      0) //  1.03s // Train Loss: 3.58 // Val Loss: 3.60
# Sep 16 21:20:41 INFO [hp_sweep_gpt.py.train_model:127] [Node 2]  Remote Device: cuda // GPU: A10G
# ...
# ```

# The `local_entrypoint` code is below. Note that the arguments to it can also be passed via the command line.
# Use `--help` for details.


@app.local_entrypoint()
def main(
    n_steps: int = 3000,
    n_steps_before_checkpoint: Optional[int] = None,
    n_steps_before_eval: Optional[int] = None,
):
    from datetime import datetime
    from itertools import product

    experiment_name = f"E{datetime.now().strftime('%Y-%m-%d-%H%M%S.%f')}"
    default_hparams = ModelHyperparameters()

    # build list of hyperparameters to train & validate
    nheads_options = (1, default_hparams.n_heads)
    context_size_options = (8, default_hparams.context_size)
    dropout_options = (0.1, default_hparams.dropout)

    hparams_list = [
        ModelHyperparameters(n_heads=h, context_size=c, dropout=d)
        for h, c, d in product(nheads_options, context_size_options, dropout_options)
    ]

    # run training for each hyperparameter setting
    results = []
    stop_early = True  # stop early so we can compare val losses
    print(f"Testing {len(hparams_list)} hyperparameter settings")
    n_nodes = len(hparams_list)
    static_params = (
        experiment_name,
        stop_early,
        n_steps,
        n_steps_before_eval,
        n_steps_before_checkpoint,
    )
    for result in train_model.starmap(
        [(i, n_nodes, h, *static_params) for i, h in enumerate(hparams_list)],
        order_outputs=False,
    ):
        # result = (node_rank, val_loss, hparams)
        node_rank = result[0]
        results.append(result)
        print(
            f"[Node {node_rank + 1}/{n_nodes}] Finished. Early stop val loss result: {result[1:]}"
        )

    # find the model and hparams with the lowest validation loss
    best_result = min(results, key=lambda x: x[1])
    print(f"Best early stop val loss result: {best_result}")
    best_hparams = best_result[-1]

    # finish training with best hparams
    node_rank = 0
    n_nodes = 1  # only one node for final training run
    train_model.remote(
        node_rank,
        n_nodes,
        best_hparams,
        experiment_name,
        not stop_early,
        n_steps,
        n_steps_before_eval,
        n_steps_before_checkpoint,
    )


# ### Monitor experiments with TensorBoard

# To monitor our training we will create a TensorBoard WSGI web app, which will
# display the progress of our training across all 8 models. We'll use the latest
# logs for the most recent experiment written to the Volume.

# To ensure we have the latest data we add some
# [WSGI Middleware](https://peps.python.org/pep-3333/)
# that checks the Modal Volume for updates when the page is reloaded.


class VolumeMiddleware:
    def __init__(self, app):
        self.app = app

    def __call__(self, environ, start_response):
        if (route := environ.get("PATH_INFO")) in ["/", "/modal-volume-reload"]:
            try:
                volume.reload()
            except Exception as e:
                print("Exception while re-loading traces: ", e)
            if route == "/modal-volume-reload":
                environ["PATH_INFO"] = "/"  # redirect
        return self.app(environ, start_response)


# To ensure a unique color per experiment you can click the palette (🎨) icon
# under TensorBoard > Time Series > Run and use the Regex:
# `E(\d{4})-(\d{2})-(\d{2})-(\d{6})\.(\d{6})`

# You can deploy this TensorBoard service by running

# ```
# modal deploy 06_gpu_and_ml/hyperparameter-sweep/hp_sweep_gpt.py
# ```

# and visit it at the URL that ends with `-monitor-training.modal.run`.

# After training finishes, your TensorBoard UI will look something like this:

# ![8 lines on a graph, validation loss on y-axis, time step on x-axis. All lines go down over the first 1000 time steps, and one goes to 5000 time steps with a final loss of 1.52](./tensorboard.png)

# You can also find some sample text generated by the model in the "Text" tab.


@app.function(
    image=torch_image,
    volumes={volume_path: volume},
)
@modal.concurrent(max_inputs=1000)
@modal.wsgi_app()
def monitor_training():
    board = tensorboard.program.TensorBoard()
    board.configure(logdir=str(tb_log_path))
    (data_provider, deprecated_multiplexer) = board._make_data_provider()
    wsgi_app = tensorboard.backend.application.TensorBoardWSGIApp(
        board.flags,
        board.plugin_loaders,
        data_provider,
        board.assets_zip_provider,
        deprecated_multiplexer,
        experimental_middlewares=[VolumeMiddleware],
    )
    return wsgi_app


# Notice that there are 8 models training, and the one with the lowest
# validation loss at step 600 continues training to 3000 steps.

# ## Serving SLMs on Modal during and after training

# Because our weights are stored in a distributed Volume,
# we can deploy an inference endpoint based off of them without any extra work --
# and we can even check in on models while we're still training them!

# ### Remote inference with Modal `Cls`es

# We wrap our inference in a Modal `Cls` called `ModelInference`.
# The user of `ModelInference` can control which model is used by providing the
# `experiment_name`.  Each unique choice creates a separate
# [auto-scaling deployment](https://modal.com/docs/guide/parameterized-functions).
# If the user does not specify an `experiment_name`, the latest experiment
# is used.


@app.cls(image=torch_image, volumes={volume_path: volume}, gpu=gpu)
class ModelInference:
    experiment_name: str = modal.parameter(default="")

    def get_latest_available_model_dirs(self, n_last):
        """Find the latest models that have a best model checkpoint saved."""
        save_model_dirs = glob.glob(f"{model_save_path}/*")
        sorted_model_dirs = sorted(save_model_dirs, key=os.path.getctime, reverse=True)

        valid_model_dirs = []
        for latest_model_dir in sorted_model_dirs:
            if Path(f"{latest_model_dir}/{best_model_filename}").exists():
                valid_model_dirs.append(Path(latest_model_dir))
            if len(valid_model_dirs) >= n_last:
                return valid_model_dirs
        return valid_model_dirs

    @modal.method()
    def get_latest_available_experiment_names(self, n_last):
        return [d.name for d in self.get_latest_available_model_dirs(n_last)]

    def load_model_impl(self):
        from .src.model import AttentionModel
        from .src.tokenizer import Tokenizer

        if self.experiment_name != "":  # user selected model
            use_model_dir = f"{model_save_path}/{self.experiment_name}"
        else:  # otherwise, pick latest
            try:
                use_model_dir = self.get_latest_available_model_dirs(1)[0]
            except IndexError:
                raise ValueError("No models available to load.")

        if self.use_model_dir == use_model_dir and self.is_fully_trained:
            return  # already loaded fully trained model.

        print(f"Loading experiment: {Path(use_model_dir).name}...")
        checkpoint = torch.load(f"{use_model_dir}/{best_model_filename}")

        self.use_model_dir = use_model_dir
        hparams = checkpoint["hparams"]
        key = (  # for backwards compatibility
            "unique_chars" if "unique_chars" in checkpoint else "chars"
        )
        unique_chars = checkpoint[key]
        steps = checkpoint["steps"]
        val_loss = checkpoint["val_loss"]
        self.is_fully_trained = checkpoint["finished_training"]

        print(
            f"Loaded model with {steps} train steps"
            f" and val loss of {val_loss:.2f}"
            f" (fully_trained={self.is_fully_trained})"
        )

        self.tokenizer = Tokenizer(unique_chars)
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        self.model = AttentionModel(self.tokenizer.vocab_size, hparams, self.device)
        self.model.load_state_dict(checkpoint["model"])
        self.model.to(self.device)

    @modal.enter()
    def load_model(self):
        self.use_model_dir = None
        self.is_fully_trained = False
        self.load_model_impl()

    @modal.method()
    def generate(self, prompt):
        self.load_model_impl()  # load updated model if available

        n_new_tokens = 1000
        return self.model.generate_from_text(self.tokenizer, prompt, n_new_tokens)


# ### Adding a simple web endpoint

# The `ModelInference` class above is available for use
# from any other Python environment with the right Modal credentials
# and the `modal` package installed -- just use [`lookup`](https://modal.com/docs/reference/modal.Cls#lookup).

# But we can also expose it as a web endpoint for easy access
# from anywhere, including other programming languages or the command line.


class GenerationRequest(BaseModel):
    prompt: str


@app.function(image=web_image)
@modal.fastapi_endpoint(method="POST", docs=True)
def web_generate(request: GenerationRequest):
    output = ModelInference().generate.remote(request.prompt)
    return {"output": output}


# This endpoint can be deployed on Modal with `modal deploy`.
# That will allow us to generate text via a simple `curl` command like this:

# ```bash
# curl -X POST -H 'Content-Type: application/json' --data-binary '{"prompt": "\n"}' https://your-workspace-name--modal-nano-gpt-web-generate.modal.run
# ```

# which will return something like:

# ```json
# {
# "output":
#    "BRUTUS:
#     The broy trefore anny pleasory to
#     wip me state of villoor so:
#     Fortols listhey for brother beat the else
#     Be all, ill of lo-love in igham;
#     Ah, here all that queen and hould you father offer"
# }
# ```

# It's not exactly Shakespeare, but at least it shows our model learned something!

# You can choose which model to use by specifying the `experiment_name` in the query parameters of the request URL.

# ### Serving a Gradio UI with `asgi_app`

# Second, we create a Gradio web app for generating text via a graphical user interface in the browser.
# That way our fellow team members and stakeholders can easily interact with the model and give feedback,
# even when we're still training the model.

# You should see the URL for this UI in the output of `modal deploy`
# or on your [Modal app dashboard](https://modal.com/apps) for this app.

# The Gradio UI will look something like this:

# ![Image of Gradio Web App. Top shows model selection dropdown. Left side shows input prompt textbox. Right side shows SLM generated output. Bottom has button for starting generation process](./gradio.png)


@app.function(
    image=ui_image,
    max_containers=1,
    volumes={volume_path: volume},
)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def ui():
    import gradio as gr
    from fastapi import FastAPI
    from fastapi.responses import FileResponse
    from gradio.routes import mount_gradio_app

    # call out to the inference in a separate Modal environment with a GPU
    def generate(text="", experiment_name=""):
        if not text:
            text = "\n"
        generated = ModelInference(experiment_name=experiment_name).generate.remote(
            text
        )
        return text + generated

    example_prompts = [
        "DUKE OF YORK:\nWhere art thou Lucas?",
        "ROMEO:\nWhat is a man?",
        "CLARENCE:\nFair is foul and foul is fair, but who are you?",
        "Brevity is the soul of wit, so what is the soul of foolishness?",
    ]

    web_app = FastAPI()

    # custom styles: an icon, a background, and a theme
    @web_app.get("/favicon.ico", include_in_schema=False)
    async def favicon():
        return FileResponse("/assets/favicon.svg")

    @web_app.get("/assets/background.svg", include_in_schema=False)
    async def background():
        return FileResponse("/assets/background.svg")

    with open("/assets/index.css") as f:
        css = f.read()

    n_last = 20
    experiment_names = ModelInference().get_latest_available_experiment_names.remote(
        n_last
    )
    theme = gr.themes.Default(
        primary_hue="green", secondary_hue="emerald", neutral_hue="neutral"
    )

    # add a Gradio UI around inference
    with gr.Blocks(theme=theme, css=css, title="SLM") as interface:
        # title
        gr.Markdown("# GPT-style Shakespeare text generation.")

        # Model Selection
        with gr.Row():
            gr.Markdown("## Model Version")
        with gr.Row():
            experiment_dropdown = gr.Dropdown(
                experiment_names, label="Select Model Version"
            )

        # input and output
        with gr.Row():
            with gr.Column():
                gr.Markdown("## Input:")
                input_box = gr.Textbox(  # input text component
                    label="",
                    placeholder="Write some Shakespeare like text or keep it empty!",
                    lines=10,
                )
            with gr.Column():
                gr.Markdown("## Output:")
                output_box = gr.Textbox(  # output text component
                    label="",
                    lines=10,
                )

        # button to trigger inference and a link to Modal
        with gr.Row():
            generate_button = gr.Button("Generate", variant="primary", scale=2)
            generate_button.click(
                fn=generate,
                inputs=[input_box, experiment_dropdown],
                outputs=output_box,
            )  # connect inputs and outputs with inference function

            gr.Button(  # shameless plug
                " Powered by Modal",
                variant="secondary",
                link="https://modal.com",
            )

        # example prompts
        with gr.Column(variant="compact"):
            # add in a few examples to inspire users
            for ii, prompt in enumerate(example_prompts):
                btn = gr.Button(prompt, variant="secondary")
                btn.click(fn=lambda idx=ii: example_prompts[idx], outputs=input_box)

    # mount for execution on Modal
    return mount_gradio_app(
        app=web_app,
        blocks=interface,
        path="/",
    )


# ## Addenda

# The remainder of this code is boilerplate.

# ### Training Loop

# There's quite a lot of code for just the training loop! If you'd rather not write this stuff yourself,
# consider a training framework like [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable)
# or [Hugging Face](https://huggingface.co/transformers/main_classes/trainer.html).


def training_loop(
    start_step,
    n_steps,
    n_steps_before_eval,
    n_steps_before_checkpoint,
    n_eval_steps,
    dataset,
    tokenizer,
    model,
    optimizer,
    logs_manager,
    checkpoint,
    checkpoint_path,
    run_to_first_save,
):
    @torch.no_grad()
    def eval_model(model, dataset, tokenizer, n_eval_steps):
        """Evaluate model on train and validation data."""
        out = {}
        model.eval()  # Turn off gradients
        for split in ("train", "val"):
            losses = torch.zeros(n_eval_steps)
            for k in range(n_eval_steps):
                xb, yb = dataset.get_batch(split)
                logits, loss = model.forward(xb, yb)
                losses[k] = loss
            out[split] = losses.mean()

        # Generate some output samples
        out["sample"] = model.generate_from_text(tokenizer, "\n", 1000)

        model.train()  # Turn on gradients
        return out

    t_last = timer()
    for step in range(start_step, n_steps + 1):
        # sample a batch of data
        xb, yb = dataset.get_batch("train")

        # evaluate the loss, calculate & apply gradients
        logits, loss = model.forward(xb, yb)
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()

        # log training loss
        logs_manager.add_train_scalar("Cross Entropy Loss", loss.item(), step)

        # evaluate model on validation set
        if step % n_steps_before_eval == 0:
            out = eval_model(model, dataset, tokenizer, n_eval_steps)
            log_evals(out, step, t_last, logs_manager)
            t_last = timer()

        # save model with checkpoint information
        if step > 0 and step % n_steps_before_checkpoint == 0:
            checkpoint["steps"] = step
            checkpoint["val_loss"] = out["val"]

            # mark as finished if we hit n steps.
            checkpoint["finished_training"] = step >= n_steps

            L.info(
                f"Saving checkpoint to {checkpoint_path}\t {checkpoint['finished_training']})"
            )
            save_checkpoint(checkpoint, checkpoint_path)

            if run_to_first_save:
                L.info("Stopping early...")
                break
    return out


def save_checkpoint(checkpoint, checkpoint_path):
    torch.save(checkpoint, checkpoint_path)
    volume.commit()


def build_model(hparams, vocab_size, device):
    """Initialize the model and move it to the device."""
    model = AttentionModel(vocab_size, hparams, device)
    model.to(device)
    return model


def setup_optimizer(model, learning_rate):
    """Set up the optimizer for the model."""
    return torch.optim.AdamW(model.parameters(), lr=learning_rate)


# ### Miscellaneous
# The remaining code includes small helper functions for training the model.


def prepare_data(input_file_path: Path, volume: modal.Volume) -> str:
    """Download and read the dataset."""
    volume.reload()
    if not input_file_path.exists():
        L.info("Downloading Shakespeare dataset...")
        data_url = "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
        urllib.request.urlretrieve(data_url, input_file_path)
        volume.commit()
    return input_file_path.read_text()


def make_best_symbolic_link(model_save_dir, model_filename, experiment_name):
    # create symlink to the best model so it's easy to find for web serving
    os.symlink(
        str(model_save_dir / model_filename),
        str(model_save_path / experiment_name / best_model_filename),
    )
    volume.commit()  # commit the symlink


def init_checkpoint(model, tokenizer, optimizer, start_step, hparams):
    return {
        "model": model.state_dict(),
        "unique_chars": tokenizer.unique_chars,
        "optimizer": optimizer.state_dict(),
        "val_loss": float("inf"),
        "steps": start_step,
        "hparams": hparams,
        "finished_training": False,
    }


def log_evals(result, step, t_last, logs_manager):
    runtime_s = timer() - t_last
    L.info(
        f"{step:5d}) // {runtime_s:>5.2f}s // Train Loss: {result['train']:.2f} // Val Loss: {result['val']:.2f}"
    )
    logs_manager.add_val_scalar("Cross Entropy Loss", result["val"], step)
    logs_manager.add_val_text("Sample Output", result["sample"], step)
    logs_manager.flush()
    volume.commit()  # Make sure TensorBoard container will see it.

    return result


=== GITHUB: 06_gpu_and_ml/hyperparameter-sweep/src/logs_manager.py ===
# ---
# pytest: false
# ---

from torch.utils.tensorboard import SummaryWriter


class LogsManager:
    def __init__(self, experiment_name, hparams, num_parameters, tb_log_path):
        self.model_name = (
            f"{experiment_name}"
            f"_context_size={hparams.context_size}_n_heads={hparams.n_heads}"
            f"_dropout={hparams.dropout}"
        )

        model_log_dir = tb_log_path / f"{experiment_name}/{self.model_name}"
        model_log_dir.mkdir(parents=True, exist_ok=True)
        self.train_writer = SummaryWriter(log_dir=f"{model_log_dir}/train")
        self.val_writer = SummaryWriter(log_dir=f"{model_log_dir}/val")

        # save hyperparameters to TensorBoard for easy reference
        pretty_hparams_str = "\n".join(f"{k}: {v}" for k, v in hparams.__dict__.items())
        pretty_hparams_str += f"\nNum parameters: {num_parameters}"
        self.train_writer.add_text("Hyperparameters", pretty_hparams_str)

    def add_train_scalar(self, name, value, step):
        self.train_writer.add_scalar(name, value, step)

    def add_val_scalar(self, name, value, step):
        self.val_writer.add_scalar(name, value, step)

    def add_val_text(self, name, text, step):
        self.val_writer.add_text(name, text, step)

    def flush(self):
        self.train_writer.flush()
        self.val_writer.flush()


=== GITHUB: 06_gpu_and_ml/hyperparameter-sweep/src/model.py ===
# ---
# pytest: false
# ---
# Transformer model based on
# [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

# Built using ideas from Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT)


import torch
import torch.nn as nn
from torch.nn import functional as F


class MultiHeadFast(nn.Module):
    """Multihead self-attention."""

    def __init__(self, hparams, input_size):
        super().__init__()
        self.input_size = input_size
        self.head_size = input_size // hparams.n_heads
        self.n_heads = hparams.n_heads
        self.dropout = hparams.dropout

        # Parallel Head calculation
        self.qkv_proj = nn.Linear(input_size, 3 * input_size, bias=False)
        self.use_flash_attention = hasattr(
            torch.nn.functional, "scaled_dot_product_attention"
        )
        self.register_buffer(
            "tril",
            torch.tril(
                torch.ones(hparams.context_size, hparams.context_size).view(
                    1, 1, hparams.context_size, hparams.context_size
                )
            ),
        )
        self.head_dropout = nn.Dropout(hparams.dropout)

        # Multi Head operaitons
        self.proj = nn.Linear(input_size, input_size)
        self.out_dropout = nn.Dropout(hparams.dropout)

    def forward(self, x):
        B, T, C = x.shape

        # QKV for all heads
        qkv = self.qkv_proj(x)  # bt(3i)
        q, k, v = qkv.split(self.input_size, dim=-1)

        # Split heads
        q = q.view(B, T, self.n_heads, -1).transpose(1, 2)  # bnth
        k = k.view(B, T, self.n_heads, -1).transpose(1, 2)  # bnth
        v = v.view(B, T, self.n_heads, -1).transpose(1, 2)  # bnth

        if self.use_flash_attention:
            heads_out = torch.nn.functional.scaled_dot_product_attention(
                q, k, v, attn_mask=None, dropout_p=self.dropout, is_causal=True
            )
        else:
            weight = torch.einsum("bnth,bnuh->bntu", q, k)
            weight /= torch.sqrt(self.head_size)
            weight = weight.masked_fill(self.tril[:, :, :T, :T] == 0, float("-inf"))
            dist = F.softmax(weight, dim=-1)
            dist = self.head_dropout(dist)

            heads_out = torch.einsum("bntu,bnuh->bnth", dist, v)

        multi_head_out = heads_out.transpose(1, 2).reshape(B, T, C)  # bth
        return self.out_dropout(self.proj(multi_head_out))


class MLP(nn.Module):
    """Multi-Layer Perception (last ff ops of each block)."""

    def __init__(self, hparams, input_size):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, 4 * input_size),
            nn.ReLU(),
            nn.Linear(4 * input_size, input_size),
            nn.Dropout(hparams.dropout),
        )

    def forward(self, x):
        return self.net(x)


class Block(nn.Module):
    """Transformer block."""

    def __init__(self, hparams):
        super().__init__()
        # Represents right grey decoder box in Fig. 1 of the paper.
        self.sa_heads = MultiHeadFast(hparams, hparams.n_embed)
        self.mlp = MLP(hparams, hparams.n_embed)
        self.ln1 = nn.LayerNorm(hparams.n_embed)
        self.ln2 = nn.LayerNorm(hparams.n_embed)

    def forward(self, x):
        x = x + self.sa_heads(self.ln1(x))
        x = x + self.mlp(self.ln2(x))
        return x


class AttentionModel(nn.Module):
    def __init__(self, vocab_size, hparams, device):
        super().__init__()
        self.context_size = hparams.context_size
        self.device = device
        # Sanity check parameters
        assert hparams.n_embed % hparams.n_heads == 0, (
            "n_embed must be divisible by n_heads"
        )

        self.token_embedding_table = nn.Embedding(
            vocab_size, hparams.n_embed, device=device
        )
        self.pos_embedding_table = nn.Embedding(hparams.context_size, hparams.n_embed)
        self.blocks = nn.Sequential(*[Block(hparams) for _ in range(hparams.n_blocks)])

        self.ln_f = nn.LayerNorm(hparams.n_embed)
        self.lm_head = nn.Linear(hparams.n_embed, vocab_size)

    def forward(self, input_tokens, targets=None):
        # Forward pass of the model.

        B, T = input_tokens.shape
        # input_tokens - (B, T)
        token_embedding = self.token_embedding_table(input_tokens)
        position_embedding = self.pos_embedding_table(
            torch.arange(T, device=self.device)
        )
        embedding = token_embedding + position_embedding
        x = self.blocks(embedding)
        x = self.ln_f(x)
        logits = self.lm_head(x)

        if targets is not None:
            xlogits = logits.view(logits.shape[0] * logits.shape[1], -1)
            xtargets = targets.view(-1)
            loss = F.cross_entropy(xlogits, xtargets)
        else:
            loss = None

        return logits, loss

    @torch.no_grad()
    def generate(self, input_tokens, max_new_tokens):
        # Generate new tokens given a prompt input_tokens.
        for i in range(max_new_tokens):
            logits = self(input_tokens[:, -self.context_size :])[0]  # B,T,C
            logits = logits[:, -1, :]  # B,C
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1)
            input_tokens = torch.cat([input_tokens, next_token], axis=1)
        return input_tokens

    @torch.no_grad()
    def generate_from_text(self, tokenizer, text, max_new_tokens):
        encoded_prompt = tokenizer.encode(text)
        # create a torch tensor from the encoded prompt
        torch_input = torch.tensor(encoded_prompt, dtype=torch.long)
        torch_input = torch_input.view(1, len(torch_input))  # add batch dim
        torch_input = torch_input.to(self.device)

        # Generate. [0] to remove batch dim.
        tokens = self.generate(torch_input, max_new_tokens)[0]

        chars = tokenizer.decode([x for x in tokens.tolist()])

        # Remove input text to get output
        chars_out = chars[len(text) :]

        return "".join(chars_out)


=== GITHUB: 06_gpu_and_ml/hyperparameter-sweep/src/dataset.py ===
# ---
# pytest: false
# ---

import torch


class Dataset:
    """Manage text dataset and batching."""

    def __init__(
        self,
        encoded_text,
        train_percent,
        batch_size,
        context_size,
        device,
    ):
        self.device = device
        self.batch_size = batch_size
        self.context_size = context_size
        assert (train_percent > 0.0) and (train_percent < 1.0), (
            "train_percent must be in (0,1)"
        )

        # Train/Validation split.
        data = torch.tensor(encoded_text, dtype=torch.long)
        n = len(data)
        self.train_data = data[: int(train_percent * n)]
        self.val_data = data[int(train_percent * n) :]

    def get_batch(self, split):
        """Get a batch of train or validation data."""
        data = self.train_data if split == "train" else self.val_data

        starts = torch.randint(len(data) - self.context_size, (self.batch_size,))

        x = torch.stack([data[start : start + self.context_size] for start in starts])

        # +1 because we want to predict the next token.
        y = torch.stack(
            [data[start + 1 : start + self.context_size + 1] for start in starts]
        )
        return x.to(self.device), y.to(self.device)


=== GITHUB: 06_gpu_and_ml/hyperparameter-sweep/src/tokenizer.py ===
# ---
# pytest: false
# ---


class Tokenizer:
    def __init__(self, text):
        self.unique_chars = sorted(set(text))  # sorted to ensure consistent
        self.stoi = {c: i for i, c in enumerate(self.unique_chars)}
        self.itos = {i: c for i, c in enumerate(self.unique_chars)}
        self.vocab_size = len(self.unique_chars)

    def encode(self, text):
        return [self.stoi[c] for c in text]

    def decode(self, tokens):
        return [self.itos[int(t)] for t in tokens]


=== GITHUB: 06_gpu_and_ml/audio-to-text/parakeet.py ===
# # Real-time audio transcription using Parakeet

# This examples demonstrates the use of Parakeet ASR models for real-time speech-to-text on Modal.

# [Parakeet](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/asr/models.html#parakeet)
# is the name of a family of ASR models built using [NVIDIA's NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html).
# We'll show you how to use Parakeet for real-time audio transcription on Modal GPUs,
# with simple Python and browser clients.

# This example uses the `nvidia/parakeet-tdt-0.6b-v2` model which, as of June 2025, sits at the
# top of Hugging Face's [Open ASR leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard).

# To try out transcription from your terminal,
# provide a URL for a `.wav` file to `modal run`:

# ```bash
# modal run 06_gpu_and_ml/audio-to-text/parakeet.py --audio-url="https://github.com/voxserv/audio_quality_testing_samples/raw/refs/heads/master/mono_44100/156550__acclivity__a-dream-within-a-dream.wav"
# ```

# You should see output like the following:

# ```bash
# 🎤 Starting Transcription
# A Dream Within A Dream Edgar Allan Poe
# take this kiss upon the brow, And in parting from you now, Thus much let me avow You are not wrong who deem That my days have been a dream.
# ...
# ```

# Running a web service you can hit from any browser isn't any harder -- Modal handles the deployment of both the frontend and backend in a single App!
# Just run

# ```bash
# modal serve 06_gpu_and_ml/audio-to-text/parakeet.py
# ```

# and go to the link printed in your terminal.

# The full frontend code can be found [here](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/audio-to-text/frontend).

# ## Setup

import asyncio
import os
import sys
from pathlib import Path

import modal

app = modal.App("example-parakeet")

# ## Volume for caching model weights

# We use a [Modal Volume](https://modal.com/docs/guide/volumes) to cache the model weights.
# This allows us to avoid downloading the model weights every time we start a new instance.

# For more on storing models on Modal, see [this guide](https://modal.com/docs/guide/model-weights).

model_cache = modal.Volume.from_name("parakeet-model-cache", create_if_missing=True)

# ## Configuring dependencies

# The model runs remotely inside a container on Modal. We can define the environment
# and install our Python dependencies in that container's [`Image`](https://modal.com/docs/guide/images).

# For finicky setups like NeMO's, we recommend using the official NVIDIA CUDA Docker images from Docker Hub.
# You'll need to install Python and pip with the `add_python` option because the image
# doesn't have these by default.

# Additionally, we install `ffmpeg` for handling audio data and `fastapi` to create a web
# server for our WebSocket.

image = (
    modal.Image.from_registry(
        "nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04", add_python="3.12"
    )
    .env(
        {
            "HF_HUB_ENABLE_HF_TRANSFER": "1",
            "HF_HOME": "/cache",  # cache directory for Hugging Face models
            "DEBIAN_FRONTEND": "noninteractive",
            "CXX": "g++",
            "CC": "g++",
        }
    )
    .apt_install("ffmpeg")
    .pip_install(
        "hf_transfer==0.1.9",
        "huggingface_hub[hf-xet]==0.31.2",
        "nemo_toolkit[asr]==2.3.0",
        "cuda-python==12.8.0",
        "fastapi==0.115.12",
        "numpy<2",
        "pydub==0.25.1",
    )
    .entrypoint([])  # silence chatty logs by container on start
    .add_local_dir(  # changes fastest, so make this the last layer
        Path(__file__).parent / "frontend",
        remote_path="/frontend",
    )
)

# ## Implementing real-time audio transcription on Modal

# Now we're ready to implement transcription. We wrap inference in a [`modal.Cls`](https://modal.com/docs/guide/lifecycle-functions) that
# ensures models are loaded and then moved to the GPU once when a new container starts.

# A couples of notes about this code:
# - The `transcribe` method takes bytes of audio data and returns the transcribed text.
# - The `web` method creates a FastAPI app using [`modal.asgi_app`](https://modal.com/docs/reference/modal.asgi_app#modalasgi_app) that serves a
# [WebSocket](https://modal.com/docs/guide/webhooks#websockets) endpoint for real-time audio transcription and a browser frontend for transcribing audio from your microphone.
# - The `run_with_queue` method takes a [`modal.Queue`](https://modal.com/docs/reference/modal.Queue) and passes audio data and transcriptions between our local machine and the GPU container.

# Parakeet tries really hard to transcribe everything to English!
# Hence it tends to output utterances like "Yeah" or "Mm-hmm" when it runs on silent audio.
# We pre-process the incoming audio in the server using `pydub`'s silence detection,
# ensuring that we don't pass silence into our model.

END_OF_STREAM = (
    b"END_OF_STREAM_8f13d09"  # byte sequence indicating a stream is finished
)


@app.cls(volumes={"/cache": model_cache}, gpu="a10g", image=image)
@modal.concurrent(max_inputs=14, target_inputs=10)
class Parakeet:
    @modal.enter()
    def load(self):
        import logging

        import nemo.collections.asr as nemo_asr

        # silence chatty logs from nemo
        logging.getLogger("nemo_logger").setLevel(logging.CRITICAL)

        self.model = nemo_asr.models.ASRModel.from_pretrained(
            model_name="nvidia/parakeet-tdt-0.6b-v2"
        )

    def transcribe(self, audio_bytes: bytes) -> str:
        import numpy as np

        audio_data = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32)

        with NoStdStreams():  # hide output, see https://github.com/NVIDIA/NeMo/discussions/3281#discussioncomment-2251217
            output = self.model.transcribe([audio_data])

        return output[0].text

    @modal.asgi_app()
    def web(self):
        from fastapi import FastAPI, Response, WebSocket
        from fastapi.responses import HTMLResponse
        from fastapi.staticfiles import StaticFiles

        web_app = FastAPI()
        web_app.mount("/static", StaticFiles(directory="/frontend"))

        @web_app.get("/status")
        async def status():
            return Response(status_code=200)

        # serve frontend
        @web_app.get("/")
        async def index():
            return HTMLResponse(content=open("/frontend/index.html").read())

        @web_app.websocket("/ws")
        async def run_with_websocket(ws: WebSocket):
            from fastapi import WebSocketDisconnect
            from pydub import AudioSegment

            await ws.accept()

            # initialize an empty audio segment
            audio_segment = AudioSegment.empty()

            try:
                while True:
                    # receive a chunk of audio data and convert it to an audio segment
                    chunk = await ws.receive_bytes()
                    if chunk == END_OF_STREAM:
                        await ws.send_bytes(END_OF_STREAM)
                        break
                    audio_segment, text = await self.handle_audio_chunk(
                        chunk, audio_segment
                    )
                    if text:
                        await ws.send_text(text)
            except Exception as e:
                if not isinstance(e, WebSocketDisconnect):
                    print(f"Error handling websocket: {type(e)}: {e}")
                try:
                    await ws.close(code=1011, reason="Internal server error")
                except Exception as e:
                    print(f"Error closing websocket: {type(e)}: {e}")

        return web_app

    @modal.method()
    async def run_with_queue(self, q: modal.Queue):
        from pydub import AudioSegment

        # initialize an empty audio segment
        audio_segment = AudioSegment.empty()

        try:
            while True:
                # receive a chunk of audio data and convert it to an audio segment
                chunk = await q.get.aio(partition="audio")

                if chunk == END_OF_STREAM:
                    await q.put.aio(END_OF_STREAM, partition="transcription")
                    break

                audio_segment, text = await self.handle_audio_chunk(
                    chunk, audio_segment
                )
                if text:
                    await q.put.aio(text, partition="transcription")
        except Exception as e:
            print(f"Error handling queue: {type(e)}: {e}")
            return

    async def handle_audio_chunk(
        self,
        chunk: bytes,
        audio_segment,
        silence_thresh=-45,  # dB
        min_silence_len=1000,  # ms
    ):
        from pydub import AudioSegment, silence

        new_audio_segment = AudioSegment(
            data=chunk,
            channels=1,
            sample_width=2,
            frame_rate=TARGET_SAMPLE_RATE,
        )

        # append the new audio segment to the existing audio segment
        audio_segment += new_audio_segment

        # detect windows of silence
        silent_windows = silence.detect_silence(
            audio_segment,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh,
        )

        # if there are no silent windows, continue
        if len(silent_windows) == 0:
            return audio_segment, None

        # get the last silent window because
        # we want to transcribe until the final pause
        last_window = silent_windows[-1]

        # if the entire audio segment is silent, reset the audio segment
        if last_window[0] == 0 and last_window[1] == len(audio_segment):
            audio_segment = AudioSegment.empty()
            return audio_segment, None

        # get the segment to transcribe: beginning until last pause
        segment_to_transcribe = audio_segment[: last_window[1]]

        # remove the segment to transcribe from the audio segment
        audio_segment = audio_segment[last_window[1] :]
        try:
            text = self.transcribe(segment_to_transcribe.raw_data)
            return audio_segment, text
        except Exception as e:
            print("❌ Transcription error:", e)
            raise e


# ## Running transcription from a local Python client

# Next, let's test the model with a [`local_entrypoint`](https://modal.com/docs/reference/modal.App#local_entrypoint) that streams audio data to the server and prints
# out the transcriptions to our terminal as they arrive.

# Instead of using the WebSocket endpoint like the browser frontend,
# we'll use a [`modal.Queue`](https://modal.com/docs/reference/modal.Queue)
# to pass audio data and transcriptions between our local machine and the GPU container.

AUDIO_URL = "https://github.com/voxserv/audio_quality_testing_samples/raw/refs/heads/master/mono_44100/156550__acclivity__a-dream-within-a-dream.wav"
TARGET_SAMPLE_RATE = 16_000
CHUNK_SIZE = 16_000  # send one second of audio at a time


@app.local_entrypoint()
async def main(audio_url: str = AUDIO_URL):
    from urllib.request import urlopen

    print(f"🌐 Downloading audio file from {audio_url}")
    audio_bytes = urlopen(audio_url).read()
    print(f"🎧 Downloaded {len(audio_bytes)} bytes")

    audio_data = preprocess_audio(audio_bytes)

    print("🎤 Starting Transcription")
    with modal.Queue.ephemeral() as q:
        Parakeet().run_with_queue.spawn(q)
        send = asyncio.create_task(send_audio(q, audio_data))
        recv = asyncio.create_task(receive_text(q))
        await asyncio.gather(send, recv)
    print("✅ Transcription complete!")


# Below are the two functions that coordinate streaming audio and receiving transcriptions.

# `send_audio` transmits chunks of audio data with a slight delay,
# as though it was being streamed from a live source, like a microphone.
# `receive_text` waits for transcribed text to arrive and prints it.


async def send_audio(q, audio_bytes):
    for chunk in chunk_audio(audio_bytes, CHUNK_SIZE):
        await q.put.aio(chunk, partition="audio")
        await asyncio.sleep(CHUNK_SIZE / TARGET_SAMPLE_RATE / 8)
    await q.put.aio(END_OF_STREAM, partition="audio")


async def receive_text(q):
    while True:
        message = await q.get.aio(partition="transcription")
        if message == END_OF_STREAM:
            break

        print(message)


# ## Addenda

# The remainder of the code in this example is boilerplate,
# mostly for handling Parakeet's input format.


def preprocess_audio(audio_bytes: bytes) -> bytes:
    import array
    import io
    import wave

    with wave.open(io.BytesIO(audio_bytes), "rb") as wav_in:
        n_channels = wav_in.getnchannels()
        sample_width = wav_in.getsampwidth()
        frame_rate = wav_in.getframerate()
        n_frames = wav_in.getnframes()
        frames = wav_in.readframes(n_frames)

    # Convert frames to array based on sample width
    if sample_width == 1:
        audio_data = array.array("B", frames)  # unsigned char
    elif sample_width == 2:
        audio_data = array.array("h", frames)  # signed short
    elif sample_width == 4:
        audio_data = array.array("i", frames)  # signed int
    else:
        raise ValueError(f"Unsupported sample width: {sample_width}")

    # Downmix to mono if needed
    if n_channels > 1:
        mono_data = array.array(audio_data.typecode)
        for i in range(0, len(audio_data), n_channels):
            chunk = audio_data[i : i + n_channels]
            mono_data.append(sum(chunk) // n_channels)
        audio_data = mono_data

    # Resample to 16kHz if needed
    if frame_rate != TARGET_SAMPLE_RATE:
        ratio = TARGET_SAMPLE_RATE / frame_rate
        new_length = int(len(audio_data) * ratio)
        resampled_data = array.array(audio_data.typecode)

        for i in range(new_length):
            # Linear interpolation
            pos = i / ratio
            pos_int = int(pos)
            pos_frac = pos - pos_int

            if pos_int >= len(audio_data) - 1:
                sample = audio_data[-1]
            else:
                sample1 = audio_data[pos_int]
                sample2 = audio_data[pos_int + 1]
                sample = int(sample1 + (sample2 - sample1) * pos_frac)

            resampled_data.append(sample)

        audio_data = resampled_data

    return audio_data.tobytes()


def chunk_audio(data: bytes, chunk_size: int):
    for i in range(0, len(data), chunk_size):
        yield data[i : i + chunk_size]


class NoStdStreams(object):
    def __init__(self):
        self.devnull = open(os.devnull, "w")

    def __enter__(self):
        self._stdout, self._stderr = sys.stdout, sys.stderr
        self._stdout.flush(), self._stderr.flush()
        sys.stdout, sys.stderr = self.devnull, self.devnull

    def __exit__(self, exc_type, exc_value, traceback):
        sys.stdout, sys.stderr = self._stdout, self._stderr
        self.devnull.close()


=== GITHUB: 06_gpu_and_ml/protein-folding/esm3.py ===
# # Build a protein folding dashboard with ESM3, Molstar, and Gradio

# ![Image of dashboard UI for ESM3 protein folding](https://modal-cdn.com/example-esm3-ui.png)

# There are perhaps a quadrillion distinct proteins on the planet Earth,
# each one a marvel of nanotechnology discovered by painstaking evolution.
# We know the amino acid sequence of nearly a billion but we only
# know the three-dimensional structure of a few hundred thousand,
# gathered by slow, difficult observational methods like X-ray crystallography.
# Built upon this data are machine learning models like
# EvolutionaryScale's [ESM3](https://www.evolutionaryscale.ai/blog/esm3-release)
# that can predict the structure of any sequence in seconds.

# In this example, we'll show how you can use Modal to not
# just run the latest protein-folding model but also build tools around it for
# you and your team of scientists to understand and analyze the results.

# ## Basic Setup

import base64
import io
from pathlib import Path
from typing import Optional

import modal

MINUTES = 60  # seconds

app = modal.App("example-esm3-dashboard")

# ### Create a Volume to store ESM3 model weights and Entrez sequence data

# To minimize cold start times, we'll store the ESM3 model weights on a Modal
# [Volume](https://modal.com/docs/guide/volumes).
# For patterns and best practices for storing model weights on Modal, see
# [this guide](https://modal.com/docs/guide/model-weights).
# We'll use this same distributed storage primitive to store sequence data.

volume = modal.Volume.from_name("example-esm3-dashboard", create_if_missing=True)
VOLUME_PATH = Path("/vol")
MODELS_PATH = VOLUME_PATH / "models"
DATA_PATH = VOLUME_PATH / "data"

# ### Define dependencies in container images

# The container image for structure inference is based on Modal's default slim Debian
# Linux image with `esm` for loading and running the model, `gemmi` for
# managing protein structure file conversions, and `hf_transfer`
# for faster downloading of the model weights from Hugging Face.

esm3_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "esm==3.1.1",
        "torch==2.4.1",
        "gemmi==0.7.0",
        "huggingface_hub[hf_transfer]==0.26.2",
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HOME": str(MODELS_PATH)})
)

# We'll also define a separate image, with different dependencies,
# for the part of our app that hosts the dashboard.
# This helps reduce the complexity of Python dependency management
# by "walling off" the different parts, e.g. separating
# functions that depend on finicky ML packages
# from those that depend on pedantic web packages.
# Dependencies include `gradio` for building a web UI in Python and
# `biotite` for extracting sequences from UniProt accession numbers.

# You can read more about how to configure container images on Modal in
# [this guide](https://modal.com/docs/guide/images).


web_app_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("gradio~=4.44.0", "biotite==0.41.2", "fastapi[standard]==0.115.4")
    .add_local_dir(Path(__file__).parent / "frontend", remote_path="/assets")
)


# Here we "pre-import" libraries that will be used by the functions we run
# on Modal in a given image using the `with image.imports` context manager.


with esm3_image.imports():
    import tempfile

    import gemmi
    import torch
    from esm.models.esm3 import ESM3
    from esm.sdk.api import ESMProtein, GenerationConfig

with web_app_image.imports():
    import biotite.database.entrez as entrez
    import biotite.sequence.io.fasta as fasta
    from fastapi import FastAPI

# ## Define a `Model` inference class for ESM3

# Next, we map the model's setup and inference code onto Modal.

# 1. For setup code that only needs to run once, we put it in a method
# decorated with `@enter`, which runs on container start. For details,
# see [this guide](https://modal.com/docs/guide/cold-start).
# 2. The rest of the inference code goes in a method decorated with `@method`.
# 3. We accelerate the compute-intensive inference with a GPU, specifically an A10G.
# For more on using GPUs on Modal, see [this guide](https://modal.com/docs/guide/gpu).


@app.cls(
    image=esm3_image,
    volumes={VOLUME_PATH: volume},
    secrets=[modal.Secret.from_name("huggingface-secret")],
    gpu="A10G",
    timeout=20 * MINUTES,
)
class Model:
    @modal.enter()
    def enter(self):
        self.model = ESM3.from_pretrained("esm3_sm_open_v1")
        self.model.to("cuda")

        print("using half precision and tensor cores for fast ESM3 inference")
        self.model = self.model.half()
        torch.backends.cuda.matmul.allow_tf32 = True

        self.max_steps = 250
        print(f"setting max ESM steps to: {self.max_steps}")

    def convert_protein_to_MMCIF(self, esm_protein, output_path):
        structure = gemmi.read_pdb_string(esm_protein.to_pdb_string())
        doc = structure.make_mmcif_document()
        doc.write_file(str(output_path), gemmi.cif.WriteOptions())

    def get_generation_config(self, num_steps):
        return GenerationConfig(track="structure", num_steps=num_steps)

    @modal.method()
    def inference(self, sequence: str):
        num_steps = min(len(sequence), self.max_steps)

        print(f"running ESM3 inference with num_steps={num_steps}")
        esm_protein = self.model.generate(
            ESMProtein(sequence=sequence), self.get_generation_config(num_steps)
        )

        print("checking for errors in output")
        if hasattr(esm_protein, "error_msg"):
            raise ValueError(esm_protein.error_msg)

        print("converting ESMProtein into MMCIF file")
        save_path = Path(tempfile.mktemp() + ".mmcif")
        self.convert_protein_to_MMCIF(esm_protein, save_path)

        print("returning MMCIF bytes")
        return io.BytesIO(save_path.read_bytes())


# ## Serve a dashboard as an `asgi_app`

# In this section we'll create a web interface around the ESM3 model
# that can help scientists and stakeholders understand and interrogate the results of the model.

# You can deploy this UI, along with the backing inference endpoint,
# with the following command:

# ```bash
# modal deploy esm3.py
# ```

# ### Integrating Modal Functions

# The integration between our dashboard and our inference backend
# is made simple by the Modal SDK:
# because the definition of the `Model` class is available in the same Python
# context as the defintion of the web UI,
# we can instantiate an instance and call its methods with `.remote`.

# The inference runs in a GPU-accelerated container with all of ESM3's
# dependencies, while this code executes in a CPU-only container
# with only our web dependencies.


def run_esm(sequence: str) -> str:
    sequence = sequence.strip()

    print("running ESM")
    mmcif_buffer = Model().inference.remote(sequence)

    print("converting mmCIF bytes to base64 for compatibility with HTML")
    mmcif_content = mmcif_buffer.read().decode()
    mmcif_base64 = base64.b64encode(mmcif_content.encode()).decode()

    return get_molstar_html(mmcif_base64)


# ### Building a UI in Python with Gradio

# We'll visualize the results using [Mol* ](https://molstar.org/).
# Mol* (pronounced "molstar") is an open-source toolkit for
# visualizing and analyzing large-scale molecular data, including secondary structures
# and residue-specific positions of proteins.

# Second, we'll create links to lookup the metadata and structure of known
# proteins using the [Universal Protein Resource](https://www.uniprot.org/)
# database from the UniProt consortium which is supported by the European
# Bioinformatics Institute, the National Human Genome Research
# Institute, and the Swiss Institute of Bioinformatics. UniProt
# is also a hub that links to many other databases, like the RCSB Protein
# Data Bank.

# To pull sequence data, we'll use the [Biotite](https://www.biotite-python.org/)
# library to pull [FASTA](https://en.wikipedia.org/wiki/FASTA_format) files from
# UniProt which contain labelled sequences.

# You should see the URL for this UI in the output of `modal deploy`
# or on your [Modal app dashboard](https://modal.com/apps) for this app.


@app.function(
    image=web_app_image,
    volumes={VOLUME_PATH: volume},
    max_containers=1,  # Gradio requires sticky sessions
)
@modal.concurrent(max_inputs=1000)  # Gradio can handle many async inputs
@modal.asgi_app()
def ui():
    import gradio as gr
    from fastapi.responses import FileResponse
    from gradio.routes import mount_gradio_app

    web_app = FastAPI()

    # custom styles: an icon, a background, and some CSS
    @web_app.get("/favicon.ico", include_in_schema=False)
    async def favicon():
        return FileResponse("/assets/favicon.svg")

    @web_app.get("/assets/background.svg", include_in_schema=False)
    async def background():
        return FileResponse("/assets/background.svg")

    css = Path("/assets/index.css").read_text()

    theme = gr.themes.Default(
        primary_hue="green", secondary_hue="emerald", neutral_hue="neutral"
    )

    title = "Predict & Visualize Protein Structures"

    with gr.Blocks(theme=theme, css=css, title=title, js=always_dark()) as interface:
        gr.Markdown(f"# {title}")

        with gr.Row():
            with gr.Column():
                gr.Markdown("## Enter UniProt ID ")
                uniprot_num_box = gr.Textbox(
                    label="Enter UniProt ID or select one on the right",
                    placeholder="e.g. P02768, P69905,  etc.",
                )
                get_sequence_button = gr.Button(
                    "Retrieve Sequence from UniProt ID", variant="primary"
                )

                uniprot_link_button = gr.Button(value="View protein on UniProt website")
                uniprot_link_button.click(
                    fn=None,
                    inputs=uniprot_num_box,
                    js=get_js_for_uniprot_link(),
                )

            with gr.Column():
                example_uniprots = get_uniprot_examples()

                def extract_uniprot_num(example_idx):
                    uniprot = example_uniprots[example_idx]
                    return uniprot[uniprot.index("[") + 1 : uniprot.index("]")]

                gr.Markdown("## Example UniProt Accession Numbers")
                with gr.Row():
                    half_len = int(len(example_uniprots) / 2)
                    with gr.Column():
                        for i, uniprot in enumerate(example_uniprots[:half_len]):
                            btn = gr.Button(uniprot, variant="secondary")
                            btn.click(
                                fn=lambda j=i: extract_uniprot_num(j),
                                outputs=uniprot_num_box,
                            )

                    with gr.Column():
                        for i, uniprot in enumerate(example_uniprots[half_len:]):
                            btn = gr.Button(uniprot, variant="secondary")
                            btn.click(
                                fn=lambda j=i + half_len: extract_uniprot_num(j),
                                outputs=uniprot_num_box,
                            )

        gr.Markdown("## Enter Sequence")
        sequence_box = gr.Textbox(
            label="Enter a sequence or retrieve it from a UniProt ID",
            placeholder="e.g. MVTRLE..., PVTTIMHALL..., etc.",
        )
        get_sequence_button.click(
            fn=get_sequence, inputs=[uniprot_num_box], outputs=[sequence_box]
        )

        run_esm_button = gr.Button("Run ESM3 Folding", variant="primary")

        gr.Markdown("## ESM3 Predicted Structure")
        molstar_html = gr.HTML()

        run_esm_button.click(fn=run_esm, inputs=sequence_box, outputs=molstar_html)

    # return a FastAPI app for Modal to serve
    return mount_gradio_app(app=web_app, blocks=interface, path="/")


# ## Folding from the command line

# If you want to quickly run the ESM3 model without the web interface, you can
# run it from the command line like this:

# ```shell
# modal run esm3
# ```

# This will run the same inference code above on Modal. The results are
# returned in the [Crystallographic Information File](https://en.wikipedia.org/wiki/Crystallographic_Information_File)
# format, which you can render with the online [Molstar Viewer](https://molstar.org/viewer/).


@app.local_entrypoint()
def main(sequence: Optional[str] = None, output_dir: Optional[str] = None):
    if sequence is None:
        print("using sequence for insulin [P01308]")
        sequence = "MRTPMLLALLALATLCLAGRADAKPGDAESGKGAAFVSKQEGSEVVKRLRRYLDHWLGAPAPYPDPLEPKREVCELNPDCDELADHIGFQEAYRRFYGPV"

    if output_dir is None:
        output_dir = Path("/tmp/esm3")
        output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "output.mmcif"

    print("starting inference on Modal")
    results_buffer = Model().inference.remote(sequence)

    print(f"writing results to {output_path}")
    output_path.write_bytes(results_buffer.read())


# ## Addenda

# The remainder of this code is boilerplate.

# ### Extracting Sequences from UniProt Accession Numbers

# To retrieve sequence information we'll utilize the `biotite` library which
# will allow us to fetch [fasta](https://en.wikipedia.org/wiki/FASTA_format)
# sequence files from the [National Center for Biotechnology Information (NCBI) Entrez database](https://www.ncbi.nlm.nih.gov/Web/Search/entrezfs.html).


def get_sequence(uniprot_num: str) -> str:
    try:
        DATA_PATH.mkdir(parents=True, exist_ok=True)

        uniprot_num = uniprot_num.strip()
        fasta_path = DATA_PATH / f"{uniprot_num}.fasta"

        print(f"Fetching {fasta_path} from the entrez database")
        entrez.fetch_single_file(
            uniprot_num, fasta_path, db_name="protein", ret_type="fasta"
        )
        fasta_file = fasta.FastaFile.read(fasta_path)

        protein_sequence = fasta.get_sequence(fasta_file)
        return str(protein_sequence)

    except Exception as e:
        return f"Error: {e}"


# ### Supporting functions for the Gradio app

# The following Python code is used to enhance the Gradio app,
# mostly by generating some extra HTML & JS and handling styling.


def get_js_for_uniprot_link():
    url = "https://www.uniprot.org/uniprotkb/"
    end = "/entry#structure"
    return f"""(uni_id) => {{ if (!uni_id) return; window.open("{url}" + uni_id + "{end}"); }}"""


def get_molstar_html(mmcif_base64):
    return f"""
    <iframe
        id="molstar_frame"
        style="width: 100%; height: 600px; border: none;"
        srcdoc='
            <!DOCTYPE html>
            <html>
                <head>
                    <script src="https://cdn.jsdelivr.net/npm/@rcsb/rcsb-molstar/build/dist/viewer/rcsb-molstar.js"></script>
                    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@rcsb/rcsb-molstar/build/dist/viewer/rcsb-molstar.css">
                </head>
                <body>
                    <div id="protein-viewer" style="width: 1200px; height: 400px; position: center"></div>
                    <script>
                        console.log("Initializing viewer...");
                        (async function() {{
                            // Create plugin instance
                            const viewer = new rcsbMolstar.Viewer("protein-viewer");

                            // CIF data in base64
                            const mmcifData = "{mmcif_base64}";

                            // Convert base64 to blob
                            const blob = new Blob(
                                [atob(mmcifData)],
                                {{ type: "text/plain" }}
                            );

                            // Create object URL
                            const url = URL.createObjectURL(blob);

                            try {{
                                // Load structure
                                await viewer.loadStructureFromUrl(url, "mmcif");
                            }} catch (error) {{
                                console.error("Error loading structure:", error);
                            }}
                      }})();
                    </script>
                </body>
            </html>
        '>
    </iframe>"""


def get_uniprot_examples():
    return [
        "Albumin [P02768]",
        "Insulin [P01308]",
        "Hemoglobin [P69905]",
        "Lysozyme [P61626]",
        "BRCA1 [P38398]",
        "Immunoglobulin [P01857]",
        "Actin [P60709]",
        "Ribonuclease [P07998]",
    ]


def always_dark():
    return """
    function refresh() {
        const url = new URL(window.location);

        if (url.searchParams.get('__theme') !== 'dark') {
            url.searchParams.set('__theme', 'dark');
            window.location.href = url.href;
        }
    }
    """


=== GITHUB: 06_gpu_and_ml/protein-folding/boltz_predict.py ===
# # Fold proteins with Boltz-2

# <figure style="width: 70%; margin: 0 auto; display: block;">
# <img src="https://modal-cdn.com/cdnbot/boltz_examplecd5u3m0j_9fa47e43.webp" alt="Boltz-2" />
# <figcaption style="text-align: center"><em>Example of Boltz-2 protein structure prediction
# of a <a style="text-decoration: underline;" href="https://github.com/jwohlwend/boltz/blob/main/examples/affinity.yaml" target="_blank">protein-ligand complex</a></em></figcaption>
# </figure>

# Boltz-2 is an open source molecular structure prediction model.
# In contrast to previous models like Boltz-1, [Chai-1](https://modal.com/docs/examples/chai1), and AlphaFold-3, it not only predicts protein structures but also the [binding affinities](https://en.wikipedia.org/wiki/Ligand_(biochemistry)#Receptor/ligand_binding_affinity) between proteins and [ligands](https://en.wikipedia.org/wiki/Ligand_(biochemistry)).
# It was created by the [MIT Jameel Clinic](https://jclinic.mit.edu/boltz-2/).
# For details, see [their technical report](https://jeremywohlwend.com/assets/boltz2.pdf).

# Here, we demonstrate how to run Boltz-2 on Modal.

# ## Setup

from pathlib import Path
from typing import Optional

import modal

here = Path(__file__).parent  # the directory of this file

MINUTES = 60  # seconds

app = modal.App(name="example-boltz-predict")

# ## Fold a protein from the command line

# The logic for running Boltz-2 is encapsulated in the function below,
# which you can trigger from the command line by running

# ```shell
# modal run boltz_predict.py
# ```

# This will set up the environment for running Boltz-2 inference in Modal's cloud,
# run it, and then save the results locally as a [tarball](https://computing.help.inf.ed.ac.uk/FAQ/whats-tarball-or-how-do-i-unpack-or-create-tgz-or-targz-file).
# That tarball archive contains, among other things, the predicted structure as a
# [Crystallographic Information File](https://en.wikipedia.org/wiki/Crystallographic_Information_File),
# which you can render with the online [Molstar Viewer](https://molstar.org/viewer).

# You can pass any options for the [`boltz predict` command line tool](https://github.com/jwohlwend/boltz/blob/main/docs/prediction.md)
# as a string, like

# ``` shell
# modal run boltz_predict.py --args "--sampling_steps 10"
# ```

# To see more options, run the command with the `--help` flag.

# To learn how it works, read on!


@app.local_entrypoint()
def main(
    force_download: bool = False, input_yaml_path: Optional[str] = None, args: str = ""
):
    print("🧬 loading model remotely")
    download_model.remote(force_download)

    if input_yaml_path is None:
        input_yaml_path = here / "data" / "boltz_affinity.yaml"
    input_yaml = input_yaml_path.read_text()

    print(f"🧬 running boltz with input from {input_yaml_path}")
    output = boltz_inference.remote(input_yaml)

    output_path = Path("/tmp") / "boltz" / "boltz_result.tar.gz"
    output_path.parent.mkdir(exist_ok=True, parents=True)
    print(f"🧬 writing output to {output_path}")
    output_path.write_bytes(output)


# ## Installing Boltz-2 Python dependencies on Modal

# Code running on Modal runs inside containers built from [container images](https://modal.com/docs/guide/images)
# that include that code's dependencies.

# Because Modal images include [GPU drivers](https://modal.com/docs/guide/cuda) by default,
# installation of higher-level packages like `boltz` that require GPUs is painless.

# Here, we do it in a few lines, using the `uv` package manager for extra speed.

image = modal.Image.debian_slim(python_version="3.12").run_commands(
    "uv pip install --system --compile-bytecode boltz==2.1.1"
)

# ## Storing Boltz-2 model weights on Modal with Volumes

# Not all "dependencies" belong in a container image. Boltz-2, for example, depends on
# the weights of the model and a [Chemical Component Dictionary](https://www.wwpdb.org/data/ccd) (CCD) file.

# Rather than loading them dynamically at run-time (which would add several minutes of GPU time to each inference),
# or installing them into the image (which would require they be re-downloaded any time the other dependencies changed),
# we load them onto a [Modal Volume](https://modal.com/docs/guide/volumes).
# A Modal Volume is a file system that all of your code running on Modal (or elsewhere!) can access.
# For more on storing model weights on Modal, see [this guide](https://modal.com/docs/guide/model-weights).
# For details on how we download the weights in this case, see the [Addenda](#addenda).

boltz_model_volume = modal.Volume.from_name("boltz-models", create_if_missing=True)
models_dir = Path("/models/boltz")

# ## Running Boltz-2 on Modal

# To run inference on Modal we wrap our function in a decorator, `@app.function`.
# We provide that decorator with some arguments that describe the infrastructure our code needs to run:
# the Volume we created, the Image we defined, and of course a fast GPU!

# Note that the `boltz` command-line tool we use takes the path to a
# [specially-formatted YAML file](https://github.com/jwohlwend/boltz/blob/main/docs/prediction.md#yaml-format)
# that includes definitions of molecules to predict the structures of and optionally paths to
# [Multiple Sequence Alignment](https://en.wikipedia.org/wiki/Multiple_sequence_alignment) (MSA) files
# for any protein molecules. We pass the [--use_msa_server](https://github.com/jwohlwend/boltz/blob/main/docs/prediction.md) flag to auto-generate the MSA using the mmseqs2 server.


@app.function(
    image=image,
    volumes={models_dir: boltz_model_volume},
    timeout=10 * MINUTES,
    gpu="H100",
)
def boltz_inference(boltz_input_yaml: str, args="") -> bytes:
    import shlex
    import subprocess

    input_path = Path("input.yaml")
    input_path.write_text(boltz_input_yaml)

    args = shlex.split(args)

    print(f"🧬 predicting structure using boltz model from {models_dir}")
    subprocess.run(
        ["boltz", "predict", input_path, "--use_msa_server", "--cache", str(models_dir)]
        + args,
        check=True,
    )

    print("🧬 packaging up outputs")
    output_bytes = package_outputs(f"boltz_results_{input_path.with_suffix('').name}")

    return output_bytes


# ## Addenda

# Above, we glossed over just how we got hold of the model weights --
# the `local_entrypoint` just called a function named `download_model`.

# Here's the implementation of that function. For details, see our
# [guide to storing model weights on Modal](https://modal.com/docs/guide/model-weights).

download_image = (
    modal.Image.debian_slim()
    .pip_install("huggingface_hub[hf_transfer]==0.26.3")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})  # and enable it
)


@app.function(
    volumes={models_dir: boltz_model_volume},
    timeout=20 * MINUTES,
    image=download_image,
)
def download_model(
    force_download: bool = False,
    revision: str = "6fdef46d763fee7fbb83ca5501ccceff43b85607",
):
    from huggingface_hub import snapshot_download

    snapshot_download(
        repo_id="boltz-community/boltz-2",
        revision=revision,
        local_dir=models_dir,
        force_download=force_download,
    )
    boltz_model_volume.commit()

    print(f"🧬 model downloaded to {models_dir}")


# We package the outputs into a tarball which contains the predicted structure as a
# [Crystallographic Information File](https://en.wikipedia.org/wiki/Crystallographic_Information_File)
# and the binding affinity as a JSON file.
# You can render the structure with the online [Molstar Viewer](https://molstar.org/viewer).


def package_outputs(output_dir: str) -> bytes:
    import io
    import tarfile

    tar_buffer = io.BytesIO()

    with tarfile.open(fileobj=tar_buffer, mode="w:gz") as tar:
        tar.add(output_dir, arcname=output_dir)

    return tar_buffer.getvalue()


=== GITHUB: 06_gpu_and_ml/protein-folding/chai1.py ===
# # Fold proteins with Chai-1

# In biology, function follows form quite literally:
# the physical shapes of proteins dictate their behavior.
# Measuring those shapes directly is difficult
# and first-principles physical simulation prohibitively expensive.

# And so predicting protein shape from content --
# determining how the one-dimensional chain of amino acids encoded by DNA _folds_ into a 3D object --
# has emerged as a key application for machine learning and neural networks in biology.

# In this example, we demonstrate how to run the open source [Chai-1](https://github.com/chaidiscovery/chai-lab/)
# protein structure prediction model on Modal's flexible serverless infrastructure.
# For details on how the Chai-1 model works and what it can be used for,
# see the authors' [technical report on bioRxiv](https://www.biorxiv.org/content/10.1101/2024.10.10.615955).

# This simple script is meant as a starting point showing how to handle fiddly bits
# like installing dependencies, loading weights, and formatting outputs so that you can get on with the fun stuff.
# To experience the full power of Modal, try scaling inference up and running on hundreds or thousands of structures!

# <center>
# <a href="https://molstar.org/viewer"> <video controls autoplay loop muted> <source src="https://modal-cdn.com/example-chai1-folding.mp4" type="video/mp4"> </video> </a>
# </center>

# ## Setup

import hashlib
import json
from pathlib import Path
from typing import Optional
from uuid import uuid4

import modal

here = Path(__file__).parent  # the directory of this file

MINUTES = 60  # seconds

app = modal.App(name="example-chai1-inference")

# ## Fold a protein from the command line

# The logic for running Chai-1 is encapsulated in the function below,
# which you can trigger from the command line by running

# ```shell
# modal run chai1
# ```

# This will set up the environment for running Chai-1 inference in Modal's cloud,
# run it, and then save the results remotely and locally. The results are returned in the
# [Crystallographic Information File](https://en.wikipedia.org/wiki/Crystallographic_Information_File) format,
# which you can render with the online [Molstar Viewer](https://molstar.org/).

# To see more options, run the command with the `--help` flag.

# To learn how it works, read on!


@app.local_entrypoint()
def main(
    force_redownload: bool = False,
    fasta_file: Optional[str] = None,
    inference_config_file: Optional[str] = None,
    output_dir: Optional[str] = None,
    run_id: Optional[str] = None,
):
    print("🧬 checking inference dependencies")
    download_inference_dependencies.remote(force=force_redownload)

    if fasta_file is None:
        fasta_file = here / "data" / "chai1_default_input.fasta"
    print(f"🧬 running Chai inference on {fasta_file}")
    fasta_content = Path(fasta_file).read_text()

    if inference_config_file is None:
        inference_config_file = here / "data" / "chai1_default_inference.json"
    print(f"🧬 loading Chai inference config from {inference_config_file}")
    inference_config = json.loads(Path(inference_config_file).read_text())

    if run_id is None:
        run_id = hashlib.sha256(uuid4().bytes).hexdigest()[:8]  # short id
    print(f"🧬 running inference with {run_id=}")

    results = chai1_inference.remote(fasta_content, inference_config, run_id)

    if output_dir is None:
        output_dir = Path("/tmp/chai1")
        output_dir.mkdir(parents=True, exist_ok=True)

    print(f"🧬 saving results to disk locally in {output_dir}")
    for ii, (scores, cif) in enumerate(results):
        (Path(output_dir) / f"{run_id}-scores.model_idx_{ii}.npz").write_bytes(scores)
        (Path(output_dir) / f"{run_id}-preds.model_idx_{ii}.cif").write_text(cif)


# ## Installing Chai-1 Python dependencies on Modal

# Code running on Modal runs inside containers built from [container images](https://modal.com/docs/guide/images)
# that include that code's dependencies.

# Because Modal images include [GPU drivers](https://modal.com/docs/guide/cuda) by default,
# installation of higher-level packages like `chai_lab` that require GPUs is painless.

# Here, we do it with one line, using the `uv` package manager for extra speed.

image = modal.Image.debian_slim(python_version="3.12").run_commands(
    "uv pip install --system --compile-bytecode chai_lab==0.5.0 hf_transfer==0.1.8"
)

# ## Storing Chai-1 model weights on Modal with Volumes

# Not all "dependencies" belong in a container image. Chai-1, for example, depends on
# the weights of several models.

# Rather than loading them dynamically at run-time (which would add several minutes of GPU time to each inference),
# or installing them into the image (which would require they be re-downloaded any time the other dependencies changed),
# we load them onto a [Modal Volume](https://modal.com/docs/guide/volumes).
# A Modal Volume is a file system that all of your code running on Modal (or elsewhere!) can access.
# For more on storing model weights on Modal, see [this guide](https://modal.com/docs/guide/model-weights).

chai_model_volume = (
    modal.Volume.from_name(  # create distributed filesystem for model weights
        "chai1-models",
        create_if_missing=True,
    )
)
models_dir = Path("/models/chai1")

# The details of how we handle the download here (e.g. running concurrently for extra speed)
# are in the [Addenda](#addenda).

image = image.env(  # update the environment variables in the image to...
    {
        "CHAI_DOWNLOADS_DIR": str(models_dir),  # point the chai code to it
        "HF_HUB_ENABLE_HF_TRANSFER": "1",  # speed up downloads
    }
)

# ## Storing Chai-1 outputs on Modal Volumes

# Chai-1 produces its outputs by writing to disk --
# the model's scores for the structure and the structure itself along with rich metadata.

# But Modal is a _serverless_ platform, and the filesystem your Modal Functions write to
# is not persistent. Any file can be converted into bytes and sent back from a Modal Function
# -- and we mean any! You can send files that are gigabytes in size that way.
# So we do that below.

# But for larger jobs, like folding every protein in the PDB, storing bytes on a local client
# like a laptop won't cut it.

# So we again lean on Modal Volumes, which can store thousands of files each.
# We attach a Volume to a Modal Function that runs Chai-1 and the inference code
# saves the results to distributed storage, without any fuss or source code changes.

chai_preds_volume = modal.Volume.from_name("chai1-preds", create_if_missing=True)
preds_dir = Path("/preds")

# ## Running Chai-1 on Modal

# Now we're ready to define a Modal Function that runs Chai-1.

# We put our function on Modal by wrapping it in a decorator, `@app.function`.
# We provide that decorator with some arguments that describe the infrastructure our code needs to run:
# the Volumes we created, the Image we defined, and of course a fast GPU!

# Note that Chai-1 takes a file path as input --
# specifically, a path to a file in the [FASTA format](https://en.wikipedia.org/wiki/FASTA_format).
# We pass the file contents to the function as a string and save them to disk so they can be picked up by the inference code.

# Because Modal is serverless, we don't need to worry about cleaning up these resources:
# the disk is ephemeral and the GPU only costs you money when you're using it.


@app.function(
    timeout=15 * MINUTES,
    gpu="H100",
    volumes={models_dir: chai_model_volume, preds_dir: chai_preds_volume},
    image=image,
)
def chai1_inference(
    fasta_content: str, inference_config: dict, run_id: str
) -> list[(bytes, str)]:
    from pathlib import Path

    import torch
    from chai_lab import chai1

    N_DIFFUSION_SAMPLES = 5  # hard-coded in chai-1

    fasta_file = Path("/tmp/inputs.fasta")
    fasta_file.write_text(fasta_content.strip())

    output_dir = Path("/preds") / run_id

    chai1.run_inference(
        fasta_file=fasta_file,
        output_dir=output_dir,
        device=torch.device("cuda"),
        **inference_config,
    )

    print(
        f"🧬 done, results written to /{output_dir.relative_to('/preds')} on remote volume"
    )

    results = []
    for ii in range(N_DIFFUSION_SAMPLES):
        scores = (output_dir / f"scores.model_idx_{ii}.npz").read_bytes()
        cif = (output_dir / f"pred.model_idx_{ii}.cif").read_text()

        results.append((scores, cif))

    return results


# ## Addenda

# Above, we glossed over just how we got hold of the model weights --
# the `local_entrypoint` just called a function named `download_inference_dependencies`.

# Here's that function's implementation.

# A few highlights:

# - This Modal Function can access the model weights Volume, like the inference Function,
# but it can't access the model predictions Volume.

# - This Modal Function has a different Image (the default!) and doesn't use a GPU. Modal helps you
# separate the concerns, and the costs, of your infrastructure's components.

# - We use the `async` keyword here so that we can run the download for each model file
# as a separate task, concurrently. We don't need to worry about this use of `async`
# spreading to the rest of our code -- Modal launches just this Function in an async runtime.


@app.function(volumes={models_dir: chai_model_volume})
async def download_inference_dependencies(force=False):
    import asyncio

    import aiohttp

    base_url = "https://chaiassets.com/chai1-inference-depencencies/"  # sic
    inference_dependencies = [
        "conformers_v1.apkl",
        "models_v2/trunk.pt",
        "models_v2/token_embedder.pt",
        "models_v2/feature_embedding.pt",
        "models_v2/diffusion_module.pt",
        "models_v2/confidence_head.pt",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }

    # launch downloads concurrently
    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = []
        for dep in inference_dependencies:
            local_path = models_dir / dep
            if force or not local_path.exists():
                url = base_url + dep
                print(f"🧬 downloading {dep}")
                tasks.append(download_file(session, url, local_path))

        # run all of the downloads and await their completion
        await asyncio.gather(*tasks)

    chai_model_volume.commit()  # ensures models are visible on remote filesystem before exiting, otherwise takes a few seconds, racing with inference


async def download_file(session, url: str, local_path: Path):
    async with session.get(url) as response:
        response.raise_for_status()
        local_path.parent.mkdir(parents=True, exist_ok=True)
        with open(local_path, "wb") as f:
            while chunk := await response.content.read(8192):
                f.write(chunk)


=== GITHUB: 06_gpu_and_ml/protein-folding/data/boltz_affinity.yaml ===
version: 1  # Optional, defaults to 1
sequences:
  - protein:
      id: A
      sequence: MVTPEGNVSLVDESLLVGVTDEDRAVRSAHQFYERLIGLWAPAVMEAAHELGVFAALAEAPADSGELARRLDCDARAMRVLLDALYAYDVIDRIHDTNGFRYLLSAEARECLLPGTLFSLVGKFMHDINVAWPAWRNLAEVVRHGARDTSGAESPNGIAQEDYESLVGGINFWAPPIVTTLSRKLRASGRSGDATASVLDVGCGTGLYSQLLLREFPRWTATGLDVERIATLANAQALRLGVEERFATRAGDFWRGGWGTGYDLVLFANIFHLQTPASAVRLMRHAAACLAPDGLVAVVDQIVDADREPKTPQDRFALLFAASMTNTGGGDAYTFQEYEEWFTAAGLQRIETLDTPMHRILLARRATEPSAVPEGQASENLYFQ
  - ligand:
      id: B
      smiles: 'N[C@@H](Cc1ccc(O)cc1)C(=O)O'
properties:
  - affinity:
      binder: B

=== GITHUB: 06_gpu_and_ml/flan_t5/flan_t5_finetune.py ===
# # Finetuning Flan-T5

# Example by [@anishpdalal](https://github.com/anishpdalal)

# [Flan-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) is a highly versatile model that's been instruction-tuned to
# perform well on a variety of text-based tasks such as question answering and summarization. There are smaller model variants available which makes
# Flan-T5 a great base model to use for finetuning on a specific instruction dataset with just a single GPU. In this example, we'll
# finetune Flan-T5 on the [Extreme Sum ("XSum")](https://huggingface.co/datasets/xsum) dataset to summarize news articles.

# ## Defining dependencies

# The example uses the `dataset` package from HuggingFace to load the xsum dataset. It also uses the `transformers`
# and `accelerate` packages with a PyTorch backend to finetune and serve the model. Finally, we also
# install `tensorboard` and serve it via a web app. All packages are installed into a Debian Slim base image
# using the `pip_install` function.

from pathlib import Path

import modal

VOL_MOUNT_PATH = Path("/vol")

# Other Flan-T5 models can be found [here](https://huggingface.co/docs/transformers/model_doc/flan-t5)
BASE_MODEL = "google/flan-t5-base"

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "accelerate",
    "transformers",
    "torch",
    "datasets",
    "tensorboard",
)

app = modal.App(name="example-news-summarizer", image=image)
output_vol = modal.Volume.from_name("finetune-volume", create_if_missing=True)

# ### Handling preemption

# As this finetuning job is long-running it's possible that it experiences a preemption.
# The training code is robust to preemption events by periodically saving checkpoints and restoring
# from checkpoint on restart. But it's also helpful to observe in logs when a preemption restart has occurred,
# so we track restarts with a `modal.Dict`.

# See the [guide on preemptions](https://modal.com/docs/guide/preemption#preemption)
# for more details on preemption handling.

restart_tracker_dict = modal.Dict.from_name(
    "finetune-restart-tracker", create_if_missing=True
)


def track_restarts(restart_tracker: modal.Dict) -> int:
    if not restart_tracker.contains("count"):
        preemption_count = 0
        print(f"Starting first time. {preemption_count=}")
        restart_tracker["count"] = preemption_count
    else:
        preemption_count = restart_tracker.get("count") + 1
        print(f"Restarting after pre-emption. {preemption_count=}")
        restart_tracker["count"] = preemption_count
    return preemption_count


# ## Finetuning Flan-T5 on XSum dataset

# Each row in the dataset has a `document` (input news article) and `summary` column.


@app.function(
    gpu="A10g",
    timeout=7200,
    volumes={VOL_MOUNT_PATH: output_vol},
)
def finetune(num_train_epochs: int = 1, size_percentage: int = 10):
    from datasets import load_dataset
    from transformers import (
        AutoModelForSeq2SeqLM,
        AutoTokenizer,
        DataCollatorForSeq2Seq,
        Seq2SeqTrainer,
        Seq2SeqTrainingArguments,
    )

    restarts = track_restarts(restart_tracker_dict)

    # Use size percentage to retrieve subset of the dataset to iterate faster
    if size_percentage:
        xsum_train = load_dataset("xsum", split=f"train[:{size_percentage}%]")
        xsum_test = load_dataset("xsum", split=f"test[:{size_percentage}%]")

    # Load the whole dataset
    else:
        xsum = load_dataset("xsum")
        xsum_train = xsum["train"]
        xsum_test = xsum["test"]

    # Load the tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
    model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL)

    # Replace all padding tokens with a large negative number so that the loss function ignores them in
    # its calculation
    padding_token_id = -100

    batch_size = 8

    def preprocess(batch):
        # prepend summarize: prefix to document to convert the example to a summarization instruction
        inputs = ["summarize: " + doc for doc in batch["document"]]

        model_inputs = tokenizer(
            inputs, max_length=512, truncation=True, padding="max_length"
        )

        labels = tokenizer(
            text_target=batch["summary"],
            max_length=128,
            truncation=True,
            padding="max_length",
        )

        labels["input_ids"] = [
            [l if l != tokenizer.pad_token_id else padding_token_id for l in label]
            for label in labels["input_ids"]
        ]

        model_inputs["labels"] = labels["input_ids"]
        return model_inputs

    tokenized_xsum_train = xsum_train.map(
        preprocess, batched=True, remove_columns=["document", "summary", "id"]
    )

    tokenized_xsum_test = xsum_test.map(
        preprocess, batched=True, remove_columns=["document", "summary", "id"]
    )

    data_collator = DataCollatorForSeq2Seq(
        tokenizer,
        model=model,
        label_pad_token_id=padding_token_id,
        pad_to_multiple_of=batch_size,
    )

    training_args = Seq2SeqTrainingArguments(
        # Save checkpoints to the mounted volume
        output_dir=str(VOL_MOUNT_PATH / "model"),
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        predict_with_generate=True,
        learning_rate=3e-5,
        num_train_epochs=num_train_epochs,
        logging_strategy="steps",
        logging_steps=100,
        evaluation_strategy="steps",
        save_strategy="steps",
        save_steps=100,
        save_total_limit=2,
        load_best_model_at_end=True,
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=tokenized_xsum_train,
        eval_dataset=tokenized_xsum_test,
    )

    try:
        resume = restarts > 0
        if resume:
            print("resuming from checkpoint")
        trainer.train(resume_from_checkpoint=resume)
    except KeyboardInterrupt:  # handle possible preemption
        print("received interrupt; saving state and model")
        trainer.save_state()
        trainer.save_model()
        raise

    # Save the trained model and tokenizer to the mounted volume
    model.save_pretrained(str(VOL_MOUNT_PATH / "model"))
    tokenizer.save_pretrained(str(VOL_MOUNT_PATH / "tokenizer"))
    output_vol.commit()
    print("✅ done")


# ## Monitoring Finetuning with Tensorboard

# Tensorboard is an application for visualizing training loss. In this example we
# serve it as a Modal WSGI app.


@app.function(volumes={VOL_MOUNT_PATH: output_vol})
@modal.wsgi_app()
def monitor():
    import tensorboard

    board = tensorboard.program.TensorBoard()
    board.configure(logdir=f"{VOL_MOUNT_PATH}/logs")
    (data_provider, deprecated_multiplexer) = board._make_data_provider()
    wsgi_app = tensorboard.backend.application.TensorBoardWSGIApp(
        board.flags,
        board.plugin_loaders,
        data_provider,
        board.assets_zip_provider,
        deprecated_multiplexer,
    )
    return wsgi_app


# ## Model Inference


@app.cls(volumes={VOL_MOUNT_PATH: output_vol})
class Summarizer:
    @modal.enter()
    def load_model(self):
        from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline

        # Load saved tokenizer and finetuned from training run
        tokenizer = AutoTokenizer.from_pretrained(
            BASE_MODEL, cache_dir=VOL_MOUNT_PATH / "tokenizer/"
        )
        model = AutoModelForSeq2SeqLM.from_pretrained(
            BASE_MODEL, cache_dir=VOL_MOUNT_PATH / "model/"
        )

        self.summarizer = pipeline("summarization", tokenizer=tokenizer, model=model)

    @modal.method()
    def generate(self, input: str) -> str:
        return self.summarizer(input)[0]["summary_text"]


@app.local_entrypoint()
def main():
    input = """
    The 14-time major champion, playing in his first full PGA Tour event for almost 18 months,
    carded a level-par second round of 72, but missed the cut by four shots after his first-round 76.
    World number one Jason Day and US Open champion Dustin Johnson also missed the cut at Torrey Pines in San Diego.
    Overnight leader Rose carded a one-under 71 to put him on eight under. Canada's
    Adam Hadwin and USA's Brandt Snedeker are tied in second on seven under, while US PGA champion
    Jimmy Walker missed the cut as he finished on three over. Woods is playing in just his
    second tournament since 15 months out with a back injury. "It's frustrating not being
    able to have a chance to win the tournament," said the 41-year-old, who won his last major,
    the US Open, at the same course in 2008. "Overall today was a lot better than yesterday.
    I hit it better, I putted well again. I hit a lot of beautiful putts that didn't go in, but
    I hit it much better today, which was nice." Scotland's Martin Laird and England's Paul Casey
    are both on two under, while Ireland's Shane Lowry is on level par.
    """
    model = Summarizer()
    response = model.generate.remote(input)
    print(response)


# ## Run via the CLI

# Trigger model finetuning using the following command:

# ```bash
# modal run --detach flan_t5_finetune.py::finetune --num-train-epochs=1 --size-percentage=10
# View the tensorboard logs at https://<username>--example-news-summarizer-monitor-dev.modal.run
# ```

# Then, you can invoke inference via the `local_entrypoint` with this command:

# ```bash
# modal run flan_t5_finetune.py
# World number one Tiger Woods missed the cut at the US Open as he failed to qualify for the final round of the event in Los Angeles.
# ```


=== GITHUB: 06_gpu_and_ml/text-to-audio/musicgen.py ===
# # Create your own music samples with MusicGen

# MusicGen is a popular open-source music-generation model family from Meta.
# In this example, we show you how you can run MusicGen models on Modal GPUs,
# along with a Gradio UI for playing around with the model.

# We use [Audiocraft](https://github.com/facebookresearch/audiocraft),
# the inference library released by Meta
# for MusicGen and its kin, like AudioGen.

# ## Setting up dependencies

from pathlib import Path
from typing import Optional
from uuid import uuid4

import modal

# We start by defining the environment our generation runs in.
# This takes some explaining since, like most cutting-edge ML environments, it is a bit fiddly.

# This environment is captured by a
# [container image](https://modal.com/docs/guide/custom-container),
# which we build step-by-step by calling methods to add dependencies,
# like `apt_install` to add system packages and `pip_install` to add
# Python packages.

# Note that we don't have to install anything with "CUDA"
# in the name -- the drivers come for free with the Modal environment
# and the rest gets installed `pip`. That makes our life a lot easier!
# If you want to see the details, check out [this guide](https://modal.com/docs/guide/gpu)
# in our docs.

image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("git", "ffmpeg")
    .pip_install(
        "huggingface_hub[hf_transfer]==0.27.1",  # speed up model downloads
        "torch==2.1.0",  # version pinned by audiocraft
        "numpy<2",  # defensively cap the numpy version
        "git+https://github.com/facebookresearch/audiocraft.git@v1.3.0",  # we can install directly from GitHub!
    )
)

# In addition to source code, we'll also need the model weights.

# Audiocraft integrates with the Hugging Face ecosystem, so setting up the models
# is straightforward -- the same `get_pretrained` method we use to load the weights for execution
# will also download them if they aren't present.


def load_model(and_return=False):
    from audiocraft.models import MusicGen

    model_large = MusicGen.get_pretrained("facebook/musicgen-large")
    if and_return:
        return model_large


# But Modal Functions are serverless: instances spin down when they aren't being used.
# If we want to avoid downloading the weights every time we start a new instance,
# we need to store the weights somewhere besides our local filesystem.

# So we add a Modal [Volume](https://modal.com/docs/guide/volumes)
# to store the weights in the cloud.

cache_dir = "/cache"
model_cache = modal.Volume.from_name("audiocraft-model-cache", create_if_missing=True)

# We don't need to change any of the model loading code --
# we just need to make sure the model gets stored in the right directory.

# To do that, we set an environment variable that Hugging Face expects
# (and another one that speeds up downloads, for good measure)
# and then run the `load_model` Python function.

image = image.env(
    {"HF_HUB_CACHE": cache_dir, "HF_HUB_ENABLE_HF_TRANSER": "1"}
).run_function(load_model, volumes={cache_dir: model_cache})

# While we're at it, let's also define the environment for our UI.
# We'll stick with Python and so use FastAPI and Gradio.

web_image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "fastapi[standard]==0.115.4", "gradio==4.44.1"
)

# This is a totally different environment from the one we run our model in.
# Say goodbye to Python dependency conflict hell!

# ## Running music generation on Modal

# Now, we write our music generation logic.
# This is bit complicated because we want to support generating long samples,
# but the model has a maximum context length of thirty seconds.
# We can get longer clips by feeding the model's output back as input,
# auto-regressively, but we have to write that ourselves.

# There are also a few bits to make this work well with Modal:

# - We make an [App](https://modal.com/docs/guide/apps) to organize our deployment.
# - We load the model at start, instead of during inference, with `modal.enter`,
# which requires that we use a Modal [`Cls`](https://modal.com/docs/guide/lifecycle-functions).
# - In the `app.cls` decorator, we specify the Image we built and attach the Volume.
# We also pick a GPU to run on -- here, an NVIDIA L40S.

app = modal.App("example-musicgen")
MAX_SEGMENT_DURATION = 30  # maximum context window size


@app.cls(gpu="l40s", image=image, volumes={cache_dir: model_cache})
class MusicGen:
    @modal.enter()
    def init(self):
        self.model = load_model(and_return=True)

    @modal.method()
    def generate(
        self,
        prompt: str,
        duration: int = 10,
        overlap: int = 10,
        format: str = "wav",  # or mp3
    ) -> bytes:
        f"""Generate a music clip based on the prompt.

        Clips longer than the MAX_SEGMENT_DURATION of {MAX_SEGMENT_DURATION}s
        are generated by clipping all but `overlap` seconds and running inference again."""
        context = None
        overlap = min(overlap, MAX_SEGMENT_DURATION - 1)
        remaining_duration = duration

        if remaining_duration < 0:
            return bytes()

        while remaining_duration > 0:
            # calculate duration of the next segment
            segment_duration = remaining_duration
            if context is not None:
                segment_duration += overlap

            segment_duration = min(segment_duration, MAX_SEGMENT_DURATION)

            # generate next segment
            generated_duration = (
                segment_duration if context is None else (segment_duration - overlap)
            )
            print(f"🎼 generating {generated_duration} seconds of music")
            self.model.set_generation_params(duration=segment_duration)
            next_segment = self._generate_next_segment(prompt, context, overlap)

            # update remaining duration
            remaining_duration -= generated_duration

            # combine with previous segments
            context = self._combine_segments(context, next_segment, overlap)

        output = context.detach().cpu().float()[0]

        return to_audio_bytes(
            output,
            self.model.sample_rate,
            format=format,
            # for more on audio encoding parameters, see the docs for audiocraft
            strategy="loudness",
            loudness_compressor=True,
        )

    def _generate_next_segment(self, prompt, context, overlap):
        """Generate the next audio segment, either fresh or as continuation of a context."""
        if context is None:
            return self.model.generate(descriptions=[prompt])
        else:
            overlap_samples = overlap * self.model.sample_rate
            last_chunk = context[:, :, -overlap_samples:]  # B, C, T
            return self.model.generate_continuation(
                last_chunk, self.model.sample_rate, descriptions=[prompt]
            )

    def _combine_segments(self, context, next_segment, overlap: int):
        """Combine context with next segment, handling overlap."""
        import torch

        if context is None:
            return next_segment

        # Calculate where to trim the context (removing overlap)
        overlap_samples = overlap * self.model.sample_rate
        context_trimmed = context[:, :, :-overlap_samples]  # B, C, T

        return torch.cat([context_trimmed, next_segment], dim=2)


# We can then generate music from anywhere by running code like what we have in the `local_entrypoint` below.


@app.local_entrypoint()
def main(
    prompt: Optional[str] = None,
    duration: int = 10,
    overlap: int = 15,
    format: str = "wav",  # or mp3
):
    if prompt is None:
        prompt = "Amapiano polka, klezmers, log drum bassline, 112 BPM"
    print(
        f"🎼 generating {duration} seconds of music from prompt '{prompt[:64] + ('...' if len(prompt) > 64 else '')}'"
    )

    audiocraft = MusicGen()
    clip = audiocraft.generate.remote(prompt, duration=duration, format=format)

    dir = Path("/tmp/audiocraft")
    dir.mkdir(exist_ok=True, parents=True)

    output_path = dir / f"{slugify(prompt)[:64]}.{format}"
    print(f"🎼 Saving to {output_path}")
    output_path.write_bytes(clip)


# You can execute it with a command like:

# ``` shell
# modal run musicgen.py --prompt="Baroque boy band, Bachstreet Boys, basso continuo, Top 40 pop music" --duration=60
# ```

# ## Hosting a web UI for the music generator

# With the Gradio library, we can create a simple web UI in Python
# that calls out to our music generator,
# then host it on Modal for anyone to try out.

# To deploy both the music generator and the UI, run

# ``` shell
# modal deploy musicgen.py
# ```

# Share the URL with your friends and they can generate their own songs!


@app.function(
    image=web_image,
    # Gradio requires sticky sessions
    # so we limit the number of concurrent containers to 1
    # and allow it to scale to 1000 concurrent inputs
    max_containers=1,
)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def ui():
    import gradio as gr
    from fastapi import FastAPI
    from gradio.routes import mount_gradio_app

    api = FastAPI()

    # Since this Gradio app is running from its own container,
    # we make a `.remote` call to the music generator
    model = MusicGen()
    generate = model.generate.remote

    temp_dir = Path("/dev/shm")

    async def generate_music(prompt: str, duration: int = 10, format: str = "wav"):
        audio_bytes = await generate.aio(prompt, duration=duration, format=format)

        audio_path = temp_dir / f"{uuid4()}.{format}"
        audio_path.write_bytes(audio_bytes)

        return audio_path

    with gr.Blocks(theme="soft") as demo:
        gr.Markdown("# MusicGen")
        with gr.Row():
            with gr.Column():
                prompt = gr.Textbox(label="Prompt")
                duration = gr.Number(
                    label="Duration (seconds)", value=10, minimum=1, maximum=300
                )
                format = gr.Radio(["wav", "mp3"], label="Format", value="wav")
                btn = gr.Button("Generate")
            with gr.Column():
                clip_output = gr.Audio(label="Generated Music", autoplay=True)

        btn.click(
            generate_music,
            inputs=[prompt, duration, format],
            outputs=[clip_output],
        )

    return mount_gradio_app(app=api, blocks=demo, path="/")


# ## Addenda

# The remainder of the code here is not directly related to Modal
# or to music generation, but is used in the example above.


def to_audio_bytes(wav, sample_rate: int, **kwargs) -> bytes:
    from audiocraft.data.audio import audio_write

    # audiocraft provides a nice utility for converting waveform tensors to audio,
    # but it saves to a file path. here, we create a file path that is actually
    # just backed by memory, instead of disk, to save on some latency

    shm = Path("/dev/shm")  # /dev/shm is a memory-backed filesystem
    stem_name = shm / str(uuid4())

    output_path = audio_write(stem_name, wav, sample_rate, **kwargs)

    return output_path.read_bytes()


def slugify(string):
    return (
        string.lower()
        .replace(" ", "-")
        .replace("/", "-")
        .replace("\\", "-")
        .replace(":", "-")
    )


=== GITHUB: 06_gpu_and_ml/text-to-audio/chatterbox_tts.py ===
# ---
# output-directory: "/tmp/chatterbox-tts"
# lambda-test: false
# cmd: ["modal", "serve", "06_gpu_and_ml/test-to-audio/chatterbox_tts.py"]
# ---


# # Create a Chatterbox TTS API on Modal

# This example demonstrates how to deploy a text-to-speech (TTS) API using the Chatterbox TTS model on Modal.
# The API accepts text prompts and returns generated audio as WAV files through a FastAPI endpoint.
# We use Modal's class-based approach with GPU acceleration to provide fast, scalable TTS inference.

# ## Setup

# Import the necessary modules for Modal deployment and TTS functionality.

import io

import modal

# ## Define a container image

# We start with Modal's baseline `debian_slim` image and install the required packages.
# - `chatterbox-tts`: The TTS model library
# - `fastapi`: Web framework for creating the API endpoint

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "chatterbox-tts==0.1.1", "fastapi[standard]"
)
app = modal.App("chatterbox-api-example", image=image)

# Import the required libraries within the image context to ensure they're available
# when the container runs. This includes audio processing and the TTS model itself.

with image.imports():
    import torchaudio as ta
    from chatterbox.tts import ChatterboxTTS
    from fastapi.responses import StreamingResponse

# ## The TTS model class

# The TTS service is implemented using Modal's class syntax with GPU acceleration.
# We configure the class to use an A10G GPU with additional parameters:
# #
# - `scaledown_window=60 * 5`: Keep containers alive for 5 minutes after last request
# - `enable_memory_snapshot=True`: Enable [memory snapshots](https://modal.com/docs/guide/memory-snapshot) to optimize cold boot times
# - `@modal.concurrent(max_inputs=10)`: Allow up to 10 concurrent requests per container


@app.cls(gpu="a10g", scaledown_window=60 * 5, enable_memory_snapshot=True)
@modal.concurrent(max_inputs=10)
class Chatterbox:
    @modal.enter()
    def load(self):
        self.model = ChatterboxTTS.from_pretrained(device="cuda")

    @modal.fastapi_endpoint(docs=True, method="POST")
    def generate(self, prompt: str):
        # Generate audio waveform from the input text
        wav = self.model.generate(prompt)

        # Create an in-memory buffer to store the WAV file
        buffer = io.BytesIO()

        # Save the generated audio to the buffer in WAV format
        # Uses the model's sample rate and WAV format
        ta.save(buffer, wav, self.model.sr, format="wav")

        # Reset buffer position to the beginning for reading
        buffer.seek(0)

        # Return the audio as a streaming response with appropriate MIME type.
        # This allows for browsers to playback audio directly.
        return StreamingResponse(
            io.BytesIO(buffer.read()),
            media_type="audio/wav",
        )


# Now deploy the Chatterbox API with:
#
# ```shell
# modal deploy chatterbox_tts.py
# ```
#
# And query the endpoint with:
#
# ```shell
# mkdir -p /tmp/chatterbox-tts  # create tmp directory
#
# curl -X POST --get "<YOUR-ENDPOINT-URL>" \
#   --data-urlencode "prompt=Chatterbox running on Modal"
#   --output /tmp/chatterbox-tts/output.wav
# ```
#
# You'll receive a WAV file named `/tmp/chatterbox-tts/output.wav` containing the generated audio.
#
# This app takes about 30 seconds to cold boot, mostly dominated by loading
# the Chatterbox model into GPU memory. It takes 2-3s to generate a 5s audio clip.


=== GITHUB: 06_gpu_and_ml/stable_diffusion/text_to_image.py ===
# ---
# output-directory: "/tmp/stable-diffusion"
# args: ["--prompt", "A 1600s oil painting of the New York City skyline"]
# ---

# # Run Stable Diffusion 3.5 Large Turbo as a CLI, API, and web UI

# This example shows how to run [Stable Diffusion 3.5 Large Turbo](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo) on Modal
# to generate images from your local command line, via an API, and as a web UI.

# Inference takes about one minute to cold start,
# at which point images are generated at a rate of one image every 1-2 seconds
# for batch sizes between one and 16.

# Below are four images produced by the prompt
# "A princess riding on a pony".

# ![stable diffusion montage](https://modal-cdn.com/cdnbot/sd-montage-princess-yxu2vnbl_e896a9c0.webp)

# ## Basic setup

import io
import random
import time
from pathlib import Path
from typing import Optional

import modal

MINUTES = 60

# All Modal programs need an [`App`](https://modal.com/docs/reference/modal.App) — an object that acts as a recipe for
# the application. Let's give it a friendly name.

app = modal.App("example-text-to-image")

# ## Configuring dependencies

# The model runs remotely inside a [container](https://modal.com/docs/guide/custom-container).
# That means we need to install the necessary dependencies in that container's image.

# Below, we start from a lightweight base Linux image
# and then install our Python dependencies, like Hugging Face's `diffusers` library and `torch`.

CACHE_DIR = "/cache"

image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "accelerate==0.33.0",
        "diffusers==0.31.0",
        "fastapi[standard]==0.115.4",
        "huggingface-hub[hf_transfer]==0.25.2",
        "sentencepiece==0.2.0",
        "torch==2.5.1",
        "torchvision==0.20.1",
        "transformers~=4.44.0",
    )
    .env(
        {
            "HF_HUB_ENABLE_HF_TRANSFER": "1",  # faster downloads
            "HF_HUB_CACHE": CACHE_DIR,
        }
    )
)

with image.imports():
    import diffusers
    import torch
    from fastapi import Response

# ## Implementing SD3.5 Large Turbo inference on Modal

# We wrap inference in a Modal [Cls](https://modal.com/docs/guide/lifecycle-functions)
# that ensures models are loaded and then moved to the GPU once when a new container
# starts, before the container picks up any work.

# The `run` function just wraps a `diffusers` pipeline.
# It sends the output image back to the client as bytes.

# We also include a `web` wrapper that makes it possible
# to trigger inference via an API call.
# See the `/docs` route of the URL ending in `inference-web.modal.run`
# that appears when you deploy the app for details.

MODEL_ID = "adamo1139/stable-diffusion-3.5-large-turbo-ungated"
MODEL_REVISION_ID = "9ad870ac0b0e5e48ced156bb02f85d324b7275d2"

cache_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)


@app.cls(
    image=image,
    gpu="H100",
    timeout=10 * MINUTES,
    volumes={CACHE_DIR: cache_volume},
)
class Inference:
    @modal.enter()
    def load_pipeline(self):
        self.pipe = diffusers.StableDiffusion3Pipeline.from_pretrained(
            MODEL_ID,
            revision=MODEL_REVISION_ID,
            torch_dtype=torch.bfloat16,
        ).to("cuda")

    @modal.method()
    def run(
        self, prompt: str, batch_size: int = 4, seed: Optional[int] = None
    ) -> list[bytes]:
        seed = seed if seed is not None else random.randint(0, 2**32 - 1)
        print("seeding RNG with", seed)
        torch.manual_seed(seed)
        images = self.pipe(
            prompt,
            num_images_per_prompt=batch_size,  # outputting multiple images per prompt is much cheaper than separate calls
            num_inference_steps=4,  # turbo is tuned to run in four steps
            guidance_scale=0.0,  # turbo doesn't use CFG
            max_sequence_length=512,  # T5-XXL text encoder supports longer sequences, more complex prompts
        ).images

        image_output = []
        for image in images:
            with io.BytesIO() as buf:
                image.save(buf, format="PNG")
                image_output.append(buf.getvalue())
        torch.cuda.empty_cache()  # reduce fragmentation
        return image_output

    @modal.fastapi_endpoint(docs=True)
    def web(self, prompt: str, seed: Optional[int] = None):
        return Response(
            content=self.run.local(  # run in the same container
                prompt, batch_size=1, seed=seed
            )[0],
            media_type="image/png",
        )


# ## Generating Stable Diffusion images from the command line

# This is the command we'll use to generate images. It takes a text `prompt`,
# a `batch_size` that determines the number of images to generate per prompt,
# and the number of times to run image generation (`samples`).

# You can also provide a `seed` to make sampling more deterministic.

# Run it with

# ```bash
# modal run text_to_image.py
# ```

# and pass `--help` to see more options.


@app.local_entrypoint()
def entrypoint(
    samples: int = 4,
    prompt: str = "A princess riding on a pony",
    batch_size: int = 4,
    seed: Optional[int] = None,
):
    print(
        f"prompt => {prompt}",
        f"samples => {samples}",
        f"batch_size => {batch_size}",
        f"seed => {seed}",
        sep="\n",
    )

    output_dir = Path("/tmp/stable-diffusion")
    output_dir.mkdir(exist_ok=True, parents=True)

    inference_service = Inference()

    for sample_idx in range(samples):
        start = time.time()
        images = inference_service.run.remote(prompt, batch_size, seed)
        duration = time.time() - start
        print(f"Run {sample_idx + 1} took {duration:.3f}s")
        if sample_idx:
            print(
                f"\tGenerated {len(images)} image(s) at {(duration) / len(images):.3f}s / image."
            )
        for batch_idx, image_bytes in enumerate(images):
            output_path = (
                output_dir
                / f"output_{slugify(prompt)[:64]}_{str(sample_idx).zfill(2)}_{str(batch_idx).zfill(2)}.png"
            )
            if not batch_idx:
                print("Saving outputs", end="\n\t")
            print(
                output_path,
                end="\n" + ("\t" if batch_idx < len(images) - 1 else ""),
            )
            output_path.write_bytes(image_bytes)


# ## Generating Stable Diffusion images via an API

# The Modal `Cls` above also included a [`fastapi_endpoint`](https://modal.com/docs/examples/basic_web),
# which adds a simple web API to the inference method.

# To try it out, run

# ```bash
# modal deploy text_to_image.py
# ```

# copy the printed URL ending in `inference-web.modal.run`,
# and add `/docs` to the end. This will bring up the interactive
# Swagger/OpenAPI docs for the endpoint.

# ## Generating Stable Diffusion images in a web UI

# Lastly, we add a simple front-end web UI (written in Alpine.js) for
# our image generation backend.

# This is also deployed by running

# ```bash
# modal deploy text_to_image.py.
# ```

# The `Inference` class will serve multiple users from its own auto-scaling pool of warm GPU containers automatically.

frontend_path = Path(__file__).parent / "frontend"

web_image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install("jinja2==3.1.4", "fastapi[standard]==0.115.4")
    .add_local_dir(frontend_path, remote_path="/assets")
)


@app.function(image=web_image)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def ui():
    import fastapi.staticfiles
    from fastapi import FastAPI, Request
    from fastapi.templating import Jinja2Templates

    web_app = FastAPI()
    templates = Jinja2Templates(directory="/assets")

    @web_app.get("/")
    async def read_root(request: Request):
        return templates.TemplateResponse(
            "index.html",
            {
                "request": request,
                "inference_url": Inference.web.get_web_url(),
                "model_name": "Stable Diffusion 3.5 Large Turbo",
                "default_prompt": "A cinematic shot of a baby raccoon wearing an intricate italian priest robe.",
            },
        )

    web_app.mount(
        "/static",
        fastapi.staticfiles.StaticFiles(directory="/assets"),
        name="static",
    )

    return web_app


def slugify(s: str) -> str:
    return "".join(c if c.isalnum() else "-" for c in s).strip("-")


=== GITHUB: 06_gpu_and_ml/stable_diffusion/a1111_webui.py ===
# ---
# lambda-test: false  # deprecated
# ---
# # Stable Diffusion (A1111)
#
# This example runs the popular [AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
# project on Modal, without modification. We just port the environment setup to a Modal container image
# and wrap the launch script with a `@web_server` decorator, and we're ready to go.
#
# You can run a temporary A1111 server with `modal serve a1111_webui.py` or deploy it permanently with `modal deploy a1111_webui.py`.

import subprocess

import modal

PORT = 8000

# First, we define the image A1111 will run in.
# This takes a few steps because A1111 usually install its dependencies on launch via a script.
# The process may take a few minutes the first time, but subsequent image builds should only take a few seconds.

a1111_image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install(
        "wget",
        "git",
        "libgl1",
        "libglib2.0-0",
        "google-perftools",  # For tcmalloc
    )
    .env({"LD_PRELOAD": "/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4"})
    .run_commands(
        "git clone --depth 1 --branch v1.7.0 https://github.com/AUTOMATIC1111/stable-diffusion-webui /webui",
        "python -m venv /webui/venv",
        "cd /webui && . venv/bin/activate && "
        + "python -c 'from modules import launch_utils; launch_utils.prepare_environment()' --xformers",
        gpu="a10g",
    )
    .run_commands(
        "cd /webui && . venv/bin/activate && "
        + "python -c 'from modules import shared_init, initialize; shared_init.initialize(); initialize.initialize()'",
        gpu="a10g",
    )
)

app = modal.App("example-a1111-webui", image=a1111_image)

# After defining the custom container image, we start the server with `accelerate launch`. This
# function is also where you would configure hardware resources, CPU/memory, and timeouts.
#
# If you want to run it with an A100 or H100 GPU, just change `gpu="a10g"` to `gpu="a100"` or `gpu="h100"`.
#
# Startup of the web server should finish in under one to three minutes.


@app.function(
    gpu="a10g",
    cpu=2,
    memory=1024,
    timeout=3600,
    min_containers=1,  # Keep at least one instance of the server running.
)
@modal.concurrent(max_inputs=100)  # Allow 100 concurrent requests per container.
@modal.web_server(port=PORT, startup_timeout=180)
def run():
    START_COMMAND = f"""
cd /webui && \
. venv/bin/activate && \
accelerate launch \
    --num_processes=1 \
    --num_machines=1 \
    --mixed_precision=fp16 \
    --dynamo_backend=inductor \
    --num_cpu_threads_per_process=6 \
    /webui/launch.py \
        --skip-prepare-environment \
        --no-gradio-queue \
        --listen \
        --port {PORT}
"""
    subprocess.Popen(START_COMMAND, shell=True)


=== GITHUB: 06_gpu_and_ml/stable_diffusion/stable_video_diffusion.py ===
# ---
# cmd: ["modal", "serve", "06_gpu_and_ml/stable_diffusion/stable_video_diffusion.py"]
# ---
# # Run Stable Video Diffusion in a Streamlit app
#
# This example runs the [Stable Video Diffusion](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) image-to-video model.

import os
import sys

import modal

app = modal.App(name="example-stable-video-diffusion-streamlit")
q = modal.Queue.from_name("stable-video-diffusion-streamlit", create_if_missing=True)

session_timeout = 15 * 60


def download_model():
    # Needed because all paths are relative :/
    os.chdir("/sgm")
    sys.path.append("/sgm")

    from huggingface_hub import snapshot_download
    from omegaconf import OmegaConf
    from scripts.demo.streamlit_helpers import load_model_from_config
    from scripts.demo.video_sampling import VERSION2SPECS

    snapshot_download(
        "stabilityai/stable-video-diffusion-img2vid",
        local_dir="checkpoints/",
        local_dir_use_symlinks=False,
    )

    spec = VERSION2SPECS["svd"]
    config = OmegaConf.load(spec["config"])
    load_model_from_config(config, spec["ckpt"])


svd_image = (
    # The generative-models repo hardcodes `tokenizers==0.12.1`, for which there is no
    # pre-built python 3.11 wheel.
    modal.Image.debian_slim(python_version="3.10")
    .apt_install("git")
    .run_commands(
        "git clone https://github.com/Stability-AI/generative-models.git /sgm"
    )
    .workdir("/sgm")
    .pip_install(".")
    .pip_install(
        "torch==2.0.1+cu118",
        "torchvision==0.15.2+cu118",
        "torchaudio==2.0.2+cu118",
        extra_index_url="https://download.pytorch.org/whl/cu118",
    )
    .run_commands("pip install -r requirements/pt2.txt")
    .apt_install("ffmpeg", "libsm6", "libxext6")  # for CV2
    .pip_install("safetensors")
    .run_function(download_model, gpu="any")
)


@app.function(image=svd_image, timeout=session_timeout, gpu="A100")
def run_streamlit(publish_url: bool = False):
    from streamlit.web.bootstrap import load_config_options, run

    # TODO: figure out better way to do this with streamlit.
    os.chdir("/sgm")
    sys.path.append("/sgm")

    # Run the server. This function will not return until the server is shut down.
    with modal.forward(8501) as tunnel:
        # Reload Streamlit config with information about Modal tunnel address.
        if publish_url:
            q.put(tunnel.url)
        load_config_options(
            {"browser.serverAddress": tunnel.host, "browser.serverPort": 443}
        )
        run(
            main_script_path="/sgm/scripts/demo/video_sampling.py",
            is_hello=False,
            args=["--timeout", str(session_timeout)],
            flag_options={},
        )


endpoint_image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "fastapi[standard]==0.115.4",
    "pydantic==2.9.2",
    "starlette==0.41.2",
)


@app.function(image=endpoint_image)
@modal.fastapi_endpoint(method="GET", label="svd")
def share():
    from fastapi.responses import RedirectResponse

    run_streamlit.spawn(publish_url=True)
    url = q.get()
    return RedirectResponse(url, status_code=303)


=== GITHUB: 06_gpu_and_ml/stable_diffusion/image_to_image.py ===
# ---
# output-directory: "/tmp/stable-diffusion"
# ---

# # Transform images with SDXL Turbo

# In this example, we run the SDXL Turbo model in _image-to-image_ mode:
# the model takes in a prompt and an image and transforms the image to better match the prompt.

# For example, the model transformed the image on the left into the image on the right based on the prompt
# _dog wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k_.

# ![](https://modal-cdn.com/cdnbot/sd-im2im-dog-8sanham3_915c7d4c.webp)

# SDXL Turbo is a distilled model designed for fast, interactive image synthesis.
# Learn more about it [here](https://stability.ai/news/stability-ai-sdxl-turbo).

# ## Define a container image

# First, we define the environment the model inference will run in,
# the [container image](https://modal.com/docs/guide/custom-container).

from io import BytesIO
from pathlib import Path

import modal

CACHE_DIR = "/cache"

image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "accelerate~=0.25.0",  # Allows `device_map="auto"``, for computation of optimized device_map
        "diffusers~=0.24.0",  # Provides model libraries
        "huggingface-hub[hf-transfer]~=0.25.2",  # Lets us download models from Hugging Face's Hub
        "Pillow~=10.1.0",  # Image manipulation in Python
        "safetensors~=0.4.1",  # Enables safetensor format as opposed to using unsafe pickle format
        "transformers~=4.35.2",  # This is needed for `import torch`
    )
    .env(
        {
            "HF_HUB_ENABLE_HF_TRANSFER": "1",  # Allows faster model downloads
            "HF_HUB_CACHE": CACHE_DIR,  # Points the Hugging Face cache to a Volume
        }
    )
)

cache_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

app = modal.App("image-to-image", image=image, volumes={CACHE_DIR: cache_volume})

with image.imports():
    import torch
    from diffusers import AutoPipelineForImage2Image
    from diffusers.utils import load_image
    from huggingface_hub import snapshot_download
    from PIL import Image


# ## Downloading, setting up, and running SDXL Turbo

# The Modal `Cls` defined below contains all the logic to download, set up, and run SDXL Turbo.

# The [container lifecycle](https://modal.com/docs/guide/lifecycle-functions#container-lifecycle-beta) decorator
# (`@modal.enter()`) ensures that the model is loaded into memory when a container starts, before it picks up any inputs.

# The `inference` method runs the actual model inference. It takes in an image as a collection of `bytes` and a string `prompt` and returns
# a new image (also as a collection of `bytes`).

# To avoid excessive cold-starts, we set the `scaledown_window` to 240 seconds, meaning once a GPU has loaded the model it will stay
# online for 4 minutes before spinning down.

# We also provide a function that will download the model weights to the cache Volume ahead of time.
# You can run this function directly with `modal run`. Otherwise, the weights will be cached after the
# first container cold start.


@app.function()
def download_models():
    # Ignore files that we don't need to speed up download time.
    ignore = [
        "*.bin",
        "*.onnx_data",
        "*/diffusion_pytorch_model.safetensors",
    ]

    snapshot_download("stabilityai/sdxl-turbo", ignore_patterns=ignore)


@app.cls(gpu="A10G", scaledown_window=240)
class Model:
    @modal.enter()
    def enter(self):
        self.pipe = AutoPipelineForImage2Image.from_pretrained(
            "stabilityai/sdxl-turbo",
            torch_dtype=torch.float16,
            variant="fp16",
            device_map="auto",
        )

    @modal.method()
    def inference(
        self, image_bytes: bytes, prompt: str, strength: float = 0.9
    ) -> bytes:
        init_image = load_image(Image.open(BytesIO(image_bytes))).resize((512, 512))
        num_inference_steps = 4
        # "When using SDXL-Turbo for image-to-image generation, make sure that num_inference_steps * strength is larger or equal to 1"
        # See: https://huggingface.co/stabilityai/sdxl-turbo
        assert num_inference_steps * strength >= 1

        image = self.pipe(
            prompt,
            image=init_image,
            num_inference_steps=num_inference_steps,
            strength=strength,
            guidance_scale=0.0,
        ).images[0]

        byte_stream = BytesIO()
        image.save(byte_stream, format="PNG")
        image_bytes = byte_stream.getvalue()

        return image_bytes


# ## Running the model from the command line

# You can run the model from the command line with

# ```bash
# modal run image_to_image.py
# ```

# Use `--help` for additional details.


@app.local_entrypoint()
def main(
    image_path=Path(__file__).parent / "demo_images/dog.png",
    prompt="dog wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k",
    strength=0.9,  # increase to favor the prompt over the baseline image
):
    print(f"🎨 reading input image from {image_path}")
    input_image_bytes = Path(image_path).read_bytes()
    print(f"🎨 editing image with prompt {prompt}")
    output_image_bytes = Model().inference.remote(input_image_bytes, prompt)

    dir = Path("/tmp/stable-diffusion")
    dir.mkdir(exist_ok=True, parents=True)

    output_path = dir / "output.png"
    print(f"🎨 saving output image to {output_path}")
    output_path.write_bytes(output_image_bytes)


=== GITHUB: 06_gpu_and_ml/stable_diffusion/flux.py ===
# ---
# output-directory: "/tmp/flux"
# args: ["--no-compile"]
# ---

# # Run Flux fast on H100s with `torch.compile`

# _Update: To speed up inference by another >2x, check out the additional optimization
# techniques we tried in [this blog post](https://modal.com/blog/flux-3x-faster)!_

# In this guide, we'll run Flux as fast as possible on Modal using open source tools.
# We'll use `torch.compile` and NVIDIA H100 GPUs.

# ## Setting up the image and dependencies

import time
from io import BytesIO
from pathlib import Path

import modal

# We'll make use of the full [CUDA toolkit](https://modal.com/docs/guide/cuda)
# in this example, so we'll build our container image off of the `nvidia/cuda` base.

cuda_version = "12.4.0"  # should be no greater than host CUDA version
flavor = "devel"  # includes full CUDA toolkit
operating_sys = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{operating_sys}"

cuda_dev_image = modal.Image.from_registry(
    f"nvidia/cuda:{tag}", add_python="3.11"
).entrypoint([])

# Now we install most of our dependencies with `apt` and `pip`.
# For Hugging Face's [Diffusers](https://github.com/huggingface/diffusers) library
# we install from GitHub source and so pin to a specific commit.

# PyTorch added [faster attention kernels for Hopper GPUs in version 2.5

diffusers_commit_sha = "81cf3b2f155f1de322079af28f625349ee21ec6b"

flux_image = (
    cuda_dev_image.apt_install(
        "git",
        "libglib2.0-0",
        "libsm6",
        "libxrender1",
        "libxext6",
        "ffmpeg",
        "libgl1",
    )
    .pip_install(
        "invisible_watermark==0.2.0",
        "transformers==4.44.0",
        "huggingface_hub[hf_transfer]==0.26.2",
        "accelerate==0.33.0",
        "safetensors==0.4.4",
        "sentencepiece==0.2.0",
        "torch==2.5.0",
        f"git+https://github.com/huggingface/diffusers.git@{diffusers_commit_sha}",
        "numpy<2",
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HUB_CACHE": "/cache"})
)

# Later, we'll also use `torch.compile` to increase the speed further.
# Torch compilation needs to be re-executed when each new container starts,
# So we turn on some extra caching to reduce compile times for later containers.

flux_image = flux_image.env(
    {
        "TORCHINDUCTOR_CACHE_DIR": "/root/.inductor-cache",
        "TORCHINDUCTOR_FX_GRAPH_CACHE": "1",
    }
)

# Finally, we construct our Modal [App](https://modal.com/docs/reference/modal.App),
# set its default image to the one we just constructed,
# and import `FluxPipeline` for downloading and running Flux.1.

app = modal.App("example-flux", image=flux_image)

with flux_image.imports():
    import torch
    from diffusers import FluxPipeline

# ## Defining a parameterized `Model` inference class

# Next, we map the model's setup and inference code onto Modal.

# 1. We the model setun in the method decorated with `@modal.enter()`. This includes  loading the
# weights and moving them to the GPU, along with an optional `torch.compile` step (see details below).
# The `@modal.enter()` decorator ensures that this method runs only once, when a new container starts,
# instead of in the path of every call.

# 2. We run the actual inference in methods decorated with `@modal.method()`.

MINUTES = 60  # seconds
VARIANT = "schnell"  # or "dev", but note [dev] requires you to accept terms and conditions on HF
NUM_INFERENCE_STEPS = 4  # use ~50 for [dev], smaller for [schnell]


@app.cls(
    gpu="H100",  # fastest GPU on Modal
    scaledown_window=20 * MINUTES,
    timeout=60 * MINUTES,  # leave plenty of time for compilation
    volumes={  # add Volumes to store serializable compilation artifacts, see section on torch.compile below
        "/cache": modal.Volume.from_name("hf-hub-cache", create_if_missing=True),
        "/root/.nv": modal.Volume.from_name("nv-cache", create_if_missing=True),
        "/root/.triton": modal.Volume.from_name("triton-cache", create_if_missing=True),
        "/root/.inductor-cache": modal.Volume.from_name(
            "inductor-cache", create_if_missing=True
        ),
    },
)
class Model:
    compile: bool = (  # see section on torch.compile below for details
        modal.parameter(default=False)
    )

    @modal.enter()
    def enter(self):
        pipe = FluxPipeline.from_pretrained(
            f"black-forest-labs/FLUX.1-{VARIANT}", torch_dtype=torch.bfloat16
        ).to("cuda")  # move model to GPU
        self.pipe = optimize(pipe, compile=self.compile)

    @modal.method()
    def inference(self, prompt: str) -> bytes:
        print("🎨 generating image...")
        out = self.pipe(
            prompt,
            output_type="pil",
            num_inference_steps=NUM_INFERENCE_STEPS,
        ).images[0]

        byte_stream = BytesIO()
        out.save(byte_stream, format="JPEG")
        return byte_stream.getvalue()


# ## Calling our inference function

# To generate an image we just need to call the `Model`'s `generate` method
# with `.remote` appended to it.
# You can call `.generate.remote` from any Python environment that has access to your Modal credentials.
# The local environment will get back the image as bytes.

# Here, we wrap the call in a Modal [`local_entrypoint`](https://modal.com/docs/reference/modal.App#local_entrypoint)
# so that it can be run with `modal run`:

# ```bash
# modal run flux.py
# ```

# By default, we call `generate` twice to demonstrate how much faster
# the inference is after cold start. In our tests, clients received images in about 1.2 seconds.
# We save the output bytes to a temporary file.


@app.local_entrypoint()
def main(
    prompt: str = "a computer screen showing ASCII terminal art of the"
    " word 'Modal' in neon green. two programmers are pointing excitedly"
    " at the screen.",
    twice: bool = True,
    compile: bool = False,
):
    t0 = time.time()
    image_bytes = Model(compile=compile).inference.remote(prompt)
    print(f"🎨 first inference latency: {time.time() - t0:.2f} seconds")

    if twice:
        t0 = time.time()
        image_bytes = Model(compile=compile).inference.remote(prompt)
        print(f"🎨 second inference latency: {time.time() - t0:.2f} seconds")

    output_path = Path("/tmp") / "flux" / "output.jpg"
    output_path.parent.mkdir(exist_ok=True, parents=True)
    print(f"🎨 saving output to {output_path}")
    output_path.write_bytes(image_bytes)


# ## Speeding up Flux with `torch.compile`

# By default, we do some basic optimizations, like adjusting memory layout
# and re-expressing the attention head projections as a single matrix multiplication.
# But there are additional speedups to be had!

# PyTorch 2 added a compiler that optimizes the
# compute graphs created dynamically during PyTorch execution.
# This feature helps close the gap with the performance of static graph frameworks
# like TensorRT and TensorFlow.

# Here, we follow the suggestions from Hugging Face's
# [guide to fast diffusion inference](https://huggingface.co/docs/diffusers/en/tutorials/fast_diffusion),
# which we verified with our own internal benchmarks.
# Review that guide for detailed explanations of the choices made below.

# The resulting compiled Flux `schnell` deployment returns images to the client in under a second (~700 ms), according to our testing.
# _Super schnell_!

# Compilation takes up to twenty minutes on first iteration.
# As of time of writing in late 2024,
# the compilation artifacts cannot be fully serialized,
# so some compilation work must be re-executed every time a new container is started.
# That includes when scaling up an existing deployment or the first time a Function is invoked with `modal run`.

# We cache compilation outputs from `nvcc`, `triton`, and `inductor`,
# which can reduce compilation time by up to an order of magnitude.
# For details see [this tutorial](https://pytorch.org/tutorials/recipes/torch_compile_caching_tutorial.html).

# You can turn on compilation with the `--compile` flag.
# Try it out with:

# ```bash
# modal run flux.py --compile
# ```

# The `compile` option is passed by a [`modal.parameter`](https://modal.com/docs/reference/modal.parameter#modalparameter) on our class.
# Each different choice for a `parameter` creates a [separate auto-scaling deployment](https://modal.com/docs/guide/parameterized-functions).
# That means your client can use arbitrary logic to decide whether to hit a compiled or eager endpoint.


def optimize(pipe, compile=True):
    # fuse QKV projections in Transformer and VAE
    pipe.transformer.fuse_qkv_projections()
    pipe.vae.fuse_qkv_projections()

    # switch memory layout to Torch's preferred, channels_last
    pipe.transformer.to(memory_format=torch.channels_last)
    pipe.vae.to(memory_format=torch.channels_last)

    if not compile:
        return pipe

    # set torch compile flags
    config = torch._inductor.config
    config.disable_progress = False  # show progress bar
    config.conv_1x1_as_mm = True  # treat 1x1 convolutions as matrix muls
    # adjust autotuning algorithm
    config.coordinate_descent_tuning = True
    config.coordinate_descent_check_all_directions = True
    config.epilogue_fusion = False  # do not fuse pointwise ops into matmuls

    # tag the compute-intensive modules, the Transformer and VAE decoder, for compilation
    pipe.transformer = torch.compile(
        pipe.transformer, mode="max-autotune", fullgraph=True
    )
    pipe.vae.decode = torch.compile(
        pipe.vae.decode, mode="max-autotune", fullgraph=True
    )

    # trigger torch compilation
    print("🔦 running torch compilation (may take up to 20 minutes)...")

    pipe(
        "dummy prompt to trigger torch compilation",
        output_type="pil",
        num_inference_steps=NUM_INFERENCE_STEPS,  # use ~50 for [dev], smaller for [schnell]
    ).images[0]

    print("🔦 finished torch compilation")

    return pipe


=== GITHUB: 06_gpu_and_ml/tensorflow/tensorflow_tutorial.py ===
# ---
# args: ["--just-run"]
# ---
# # TensorFlow tutorial

# This is essentially a version of the
# [image classification example in the TensorFlow documentation](https://www.tensorflow.org/tutorials/images/classification)
# running inside Modal on a GPU.
# If you run this script, it will also create an TensorBoard URL you can go to to watch the model train and review the results:

# ![tensorboard](./tensorboard.png)

# ## Setting up the dependencies

# Configuring a system to properly run GPU-accelerated TensorFlow can be challenging.
# Luckily, Modal makes it easy to stand on the shoulders of giants and
# [use a pre-built Docker container image](https://modal.com/docs/guide/custom-container#use-an-existing-container-image-with-from_registry) from a registry like Docker Hub.
# We recommend TensorFlow's [official base Docker container images](https://hub.docker.com/r/tensorflow/tensorflow), which come with `tensorflow` and its matching CUDA libraries already installed.

# If you want to install TensorFlow some other way, check out [their docs](https://www.tensorflow.org/install) for options and instructions.
# GPU-enabled containers on Modal will always have NVIDIA drivers available, but you will need to add higher-level tools like CUDA and cuDNN yourself.
# See the [Modal guide on customizing environments](https://modal.com/docs/guide/custom-container) for options we support.

import time

import modal

dockerhub_image = modal.Image.from_registry(
    "tensorflow/tensorflow:2.15.0-gpu",
)

app = modal.App("example-tensorflow-tutorial", image=dockerhub_image)

# ## Logging data to TensorBoard

# Training ML models takes time. Just as we need to monitor long-running systems like databases or web servers for issues,
# we also need to monitor the training process of our ML models. TensorBoard is a tool that comes with TensorFlow that helps you visualize
# the state of your ML model training. It is packaged as a web server.

# We want to run the web server for TensorBoard at the same time as we are training the
# TensorFlow model. The easiest way to share data between the training function and the
# web server is by creating a
# [Modal Volume](https://modal.com/docs/guide/volumes)
# that we can attach to both
# [Functions](https://modal.com/docs/reference/modal.Function).

volume = modal.Volume.from_name("tensorflow-tutorial", create_if_missing=True)
LOGDIR = "/tensorboard"

# ## Training function

# This is basically the same code as [the official example](https://www.tensorflow.org/tutorials/images/classification) from the TensorFlow docs.
# A few Modal-specific things are worth pointing out:

# * We attach the Volume for sharing data with TensorBoard in the `app.function`
#   decorator.

# * We also annotate this function with `gpu="T4"` to make sure it runs on a GPU.

# * We put all the TensorFlow imports inside the function body.
#   This makes it possible to run this example even if you don't have TensorFlow installed on your local computer -- a key benefit of Modal!

# You may notice some warnings in the logs about certain CPU performance optimizations (NUMA awareness and AVX/SSE instruction set support) not being available.
# While these optimizations can be important for some workloads, especially if you are running ML models on a CPU, they are not critical for most cases.


@app.function(volumes={LOGDIR: volume}, gpu="T4", timeout=600)
def train():
    import pathlib

    import tensorflow as tf
    from tensorflow.keras import layers
    from tensorflow.keras.models import Sequential

    # load raw data from storage
    dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
    data_dir = tf.keras.utils.get_file(
        "flower_photos.tar", origin=dataset_url, extract=True
    )
    data_dir = pathlib.Path(data_dir).with_suffix("")

    # construct Keras datasets from raw data
    batch_size = 32
    img_height = img_width = 180

    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_dir,
        validation_split=0.2,
        subset="training",
        seed=123,
        image_size=(img_height, img_width),
        batch_size=batch_size,
    )

    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_dir,
        validation_split=0.2,
        subset="validation",
        seed=123,
        image_size=(img_height, img_width),
        batch_size=batch_size,
    )

    class_names = train_ds.class_names
    train_ds = (
        train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)  # type: ignore
    )
    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)  # type: ignore
    num_classes = len(class_names)

    model = Sequential(
        [
            layers.Rescaling(1.0 / 255, input_shape=(img_height, img_width, 3)),
            layers.Conv2D(16, 3, padding="same", activation="relu"),
            layers.MaxPooling2D(),
            layers.Conv2D(32, 3, padding="same", activation="relu"),
            layers.MaxPooling2D(),
            layers.Conv2D(64, 3, padding="same", activation="relu"),
            layers.MaxPooling2D(),
            layers.Flatten(),
            layers.Dense(128, activation="relu"),
            layers.Dense(num_classes),
        ]
    )

    model.compile(
        optimizer="adam",
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=["accuracy"],
    )

    model.summary()

    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=LOGDIR,
        histogram_freq=1,
    )

    model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=20,
        callbacks=[tensorboard_callback],
    )


# ## Running TensorBoard

# TensorBoard is compatible with a Python web server standard called [WSGI](https://www.fullstackpython.com/wsgi-servers.html),
# the same standard used by [Flask](https://flask.palletsprojects.com/).
# Modal [speaks WSGI too](https://modal.com/docs/guide/webhooks#wsgi), so it's straightforward to run TensorBoard in a Modal app.

# We will attach the same Volume that we attached to our training function so that
# TensorBoard can read the logs. For this to work with Modal, we will first
# create some
# [WSGI Middleware](https://peps.python.org/pep-3333/)
# to check the Modal Volume for updates any time the page is reloaded.


class VolumeMiddleware:
    def __init__(self, app):
        self.app = app

    def __call__(self, environ, start_response):
        if (route := environ.get("PATH_INFO")) in ["/", "/modal-volume-reload"]:
            try:
                volume.reload()
            except Exception as e:
                print("Exception while re-loading traces: ", e)
            if route == "/modal-volume-reload":
                environ["PATH_INFO"] = "/"  # redirect
        return self.app(environ, start_response)


# The WSGI app isn't exposed directly through the TensorBoard library, but we can build it
# the same way it's built internally --
# [see the TensorBoard source code for details](https://github.com/tensorflow/tensorboard/blob/0c5523f4b27046e1ca7064dd75347a5ee6cc7f79/tensorboard/program.py#L466-L476).

# Note that the TensorBoard server runs in a different container.
# The server does not need GPU support.
# Note that this server will be exposed to the public internet!


@app.function(
    volumes={LOGDIR: volume},
    max_containers=1,  # single replica
    scaledown_window=5 * 60,  # five minute idle time
)
@modal.concurrent(max_inputs=100)  # 100 concurrent request threads
@modal.wsgi_app()
def tensorboard_app():
    import tensorboard

    board = tensorboard.program.TensorBoard()
    board.configure(logdir=LOGDIR)
    (data_provider, deprecated_multiplexer) = board._make_data_provider()
    wsgi_app = tensorboard.backend.application.TensorBoardWSGIApp(
        board.flags,
        board.plugin_loaders,
        data_provider,
        board.assets_zip_provider,
        deprecated_multiplexer,
        experimental_middlewares=[VolumeMiddleware],
    )
    return wsgi_app


# ## Local entrypoint code

# Let's kick everything off.
# Everything runs in an ephemeral "app" that gets destroyed once it's done.
# In order to keep the TensorBoard web server running, we sleep in an infinite loop
# until the user hits ctrl-c.

# The script will take a few minutes to run, although each epoch is quite fast since it runs on a GPU.
# The first time you run it, it might have to build the image, which can take an additional few minutes.


@app.local_entrypoint()
def main(just_run: bool = False):
    train.remote()
    if not just_run:
        print(
            "Training is done, but the app is still running TensorBoard until you hit ctrl-c."
        )
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("Terminating app")


=== GITHUB: 06_gpu_and_ml/llm-serving/chat_with_pdf_vision.py ===
# # Chat with PDF: RAG with ColQwen2

# In this example, we demonstrate how to use the the [ColQwen2](https://huggingface.co/vidore/colqwen2-v0.1) model to build a simple
# "Chat with PDF" retrieval-augmented generation (RAG) app.
# The ColQwen2 model is based on [ColPali](https://huggingface.co/blog/manu/colpali) but uses the
# [Qwen2-VL-2B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct) vision-language model.
# ColPali is in turn based on the late-interaction embedding approach pioneered in [ColBERT](https://dl.acm.org/doi/pdf/10.1145/3397271.3401075).

# Vision-language models with high-quality embeddings obviate the need for complex pre-processing pipelines.
# See [this blog post from Jo Bergum of Vespa](https://blog.vespa.ai/announcing-colbert-embedder-in-vespa/) for more.

# ## Setup

# First, we’ll import the libraries we need locally and define some constants.

from pathlib import Path
from typing import Optional
from urllib.request import urlopen
from uuid import uuid4

import modal

MINUTES = 60  # seconds

app = modal.App("chat-with-pdf")

# ## Setting up dependenices

# In Modal, we define [container images](https://modal.com/docs/guide/custom-container) that run our serverless workloads.
# We install the packages required for our application in those images.

CACHE_DIR = "/hf-cache"

model_image = (
    modal.Image.debian_slim(python_version="3.12")
    .apt_install("git")
    .pip_install(
        [
            "git+https://github.com/illuin-tech/colpali.git@782edcd50108d1842d154730ad3ce72476a2d17d",  # we pin the commit id
            "hf_transfer==0.1.8",
            "qwen-vl-utils==0.0.8",
            "torchvision==0.19.1",
        ]
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HUB_CACHE": CACHE_DIR})
)

# These dependencies are only installed remotely, so we can't import them locally.
# Use the `.imports` context manager to import them only on Modal instead.

with model_image.imports():
    import torch
    from colpali_engine.models import ColQwen2, ColQwen2Processor
    from qwen_vl_utils import process_vision_info
    from transformers import AutoProcessor, Qwen2VLForConditionalGeneration

# ## Specifying the ColQwen2 model

# Vision-language models (VLMs) for embedding and generation add another layer of simplification
# to RAG apps based on vector search: we only need one model.

MODEL_NAME = "Qwen/Qwen2-VL-2B-Instruct"
MODEL_REVISION = "aca78372505e6cb469c4fa6a35c60265b00ff5a4"

# ## Managing state with Modal Volumes and Dicts

# Chat services are stateful:
# the response to an incoming user message depends on past user messages in a session.

# RAG apps add even more state:
# the documents being retrieved from and the index over those documents,
# e.g. the embeddings.

# Modal Functions are stateless in and of themselves.
# They don't retain information from input to input.
# That's what enables Modal Functions to automatically scale up and down
# [based on the number of incoming requests](https://modal.com/docs/guide/cold-start).

# ### Managing chat sessions with Modal Dicts

# In this example, we use a [`modal.Dict`](https://modal.com/docs/guide/dicts-and-queues)
# to store state information between Function calls.

# Modal Dicts behave similarly to Python dictionaries,
# but they are backed by remote storage and accessible to all of your Modal Functions.
# They can contain any Python object
# that can be serialized using [`cloudpickle`](https://github.com/cloudpipe/cloudpickle).

# A Dict can hold a few gigabytes across keys of size up to 100 MiB,
# so it works well for our chat session state, which is a few KiB per session,
# and for our embeddings, which are a few hundred KiB per PDF page,
# up to about 100,000 pages of PDFs.

# At a larger scale, we'd need to replace this with a database, like Postgres,
# or push more state to the client.

sessions = modal.Dict.from_name("colqwen-chat-sessions", create_if_missing=True)


class Session:
    def __init__(self):
        self.images = None
        self.messages = []
        self.pdf_embeddings = None


# ### Storing PDFs on a Modal Volume

# Images extracted from PDFs are larger than our session state or embeddings
# -- low tens of MiB per page.

# So we store them on a [Modal Volume](https://modal.com/docs/guide/volumes),
# which can store terabytes (or more!) of data across tens of thousands of files.

# Volumes behave like a remote file system:
# we read and write from them much like a local file system.

pdf_volume = modal.Volume.from_name("colqwen-chat-pdfs", create_if_missing=True)
PDF_ROOT = Path("/vol/pdfs/")

# ### Caching the model weights

# We'll also use a Volume to cache the model weights.

cache_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)


# Running this function will download the model weights to the cache volume.
# Otherwise, the model weights will be downloaded on the first query.


@app.function(
    image=model_image, volumes={CACHE_DIR: cache_volume}, timeout=20 * MINUTES
)
def download_model():
    from huggingface_hub import snapshot_download

    result = snapshot_download(
        MODEL_NAME,
        revision=MODEL_REVISION,
        ignore_patterns=["*.pt", "*.bin"],  # using safetensors
    )
    print(f"Downloaded model weights to {result}")


# ## Defining a Chat with PDF service

# To deploy an autoscaling "Chat with PDF" vision-language model service on Modal,
# we just need to wrap our Python logic in a [Modal App](https://modal.com/docs/guide/apps):

# It uses [Modal `@app.cls`](https://modal.com/docs/guide/lifecycle-functions) decorators
# to organize the "lifecycle" of the app:
# loading the model on container start (`@modal.enter`) and running inference on request (`@modal.method`).

# We include in the arguments to the `@app.cls` decorator
# all the information about this service's infrastructure:
# the container image, the remote storage, and the GPU requirements.


@app.cls(
    image=model_image,
    gpu="A100-80GB",
    scaledown_window=10 * MINUTES,  # spin down when inactive
    volumes={"/vol/pdfs/": pdf_volume, CACHE_DIR: cache_volume},
)
class Model:
    @modal.enter()
    def load_models(self):
        self.colqwen2_model = ColQwen2.from_pretrained(
            "vidore/colqwen2-v0.1",
            torch_dtype=torch.bfloat16,
            device_map="cuda:0",
        )
        self.colqwen2_processor = ColQwen2Processor.from_pretrained(
            "vidore/colqwen2-v0.1"
        )
        self.qwen2_vl_model = Qwen2VLForConditionalGeneration.from_pretrained(
            MODEL_NAME,
            revision=MODEL_REVISION,
            torch_dtype=torch.bfloat16,
        )
        self.qwen2_vl_model.to("cuda:0")
        self.qwen2_vl_processor = AutoProcessor.from_pretrained(
            "Qwen/Qwen2-VL-2B-Instruct", trust_remote_code=True
        )

    @modal.method()
    def index_pdf(self, session_id, target: bytes | list):
        # We store concurrent user chat sessions in a modal.Dict

        # For simplicity, we assume that each user only runs one session at a time

        session = sessions.get(session_id)
        if session is None:
            session = Session()

        if isinstance(target, bytes):
            images = convert_pdf_to_images.remote(target)
        else:
            images = target

        # Store images on a Volume for later retrieval
        session_dir = PDF_ROOT / f"{session_id}"
        session_dir.mkdir(exist_ok=True, parents=True)
        for ii, image in enumerate(images):
            filename = session_dir / f"{str(ii).zfill(3)}.jpg"
            image.save(filename)

        # Generated embeddings from the image(s)
        BATCH_SZ = 4
        pdf_embeddings = []
        batches = [images[i : i + BATCH_SZ] for i in range(0, len(images), BATCH_SZ)]
        for batch in batches:
            batch_images = self.colqwen2_processor.process_images(batch).to(
                self.colqwen2_model.device
            )
            pdf_embeddings += list(self.colqwen2_model(**batch_images).to("cpu"))

        # Store the image embeddings in the session, for later retrieval
        session.pdf_embeddings = pdf_embeddings

        # Write embeddings back to the modal.Dict
        sessions[session_id] = session

    @modal.method()
    def respond_to_message(self, session_id, message):
        session = sessions.get(session_id)
        if session is None:
            session = Session()

        pdf_volume.reload()  # make sure we have the latest data

        images = (PDF_ROOT / str(session_id)).glob("*.jpg")
        images = list(sorted(images, key=lambda p: int(p.stem)))

        # Nothing to chat about without a PDF!
        if not images:
            return "Please upload a PDF first"
        elif session.pdf_embeddings is None:
            return "Indexing PDF..."

        # RAG, Retrieval-Augmented Generation, is two steps:

        # _Retrieval_ of the most relevant data to answer the user's query
        relevant_image = self.get_relevant_image(message, session, images)

        # _Generation_ based on the retrieved data
        output_text = self.generate_response(message, session, relevant_image)

        # Update session state for future chats
        append_to_messages(message, session, user_type="user")
        append_to_messages(output_text, session, user_type="assistant")
        sessions[session_id] = session

        return output_text

    # Retrieve the most relevant image from the PDF for the input query
    def get_relevant_image(self, message, session, images):
        import PIL

        batch_queries = self.colqwen2_processor.process_queries([message]).to(
            self.colqwen2_model.device
        )
        query_embeddings = self.colqwen2_model(**batch_queries)

        # This scores our query embedding against the image embeddings from index_pdf
        scores = self.colqwen2_processor.score_multi_vector(
            query_embeddings, session.pdf_embeddings
        )[0]

        # Select the best matching image
        max_index = max(range(len(scores)), key=lambda index: scores[index])
        return PIL.Image.open(images[max_index])

    # Pass the query and retrieved image along with conversation history into the VLM for a response
    def generate_response(self, message, session, image):
        chatbot_message = get_chatbot_message_with_image(message, image)
        query = self.qwen2_vl_processor.apply_chat_template(
            [*session.messages, chatbot_message],
            tokenize=False,
            add_generation_prompt=True,
        )
        image_inputs, _ = process_vision_info([chatbot_message])
        inputs = self.qwen2_vl_processor(
            text=[query],
            images=image_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to("cuda:0")

        generated_ids = self.qwen2_vl_model.generate(**inputs, max_new_tokens=512)
        generated_ids_trimmed = [
            out_ids[len(in_ids) :]
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = self.qwen2_vl_processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False,
        )[0]
        return output_text


# ## Loading PDFs as images

# Vision-Language Models operate on images, not PDFs directly,
# so we need to convert our PDFs into images first.

# We separate this from our indexing and chatting logic --
# we run on a different container with different dependencies.

pdf_image = (
    modal.Image.debian_slim(python_version="3.12")
    .apt_install("poppler-utils")
    .pip_install("pdf2image==1.17.0", "pillow==10.4.0")
)


@app.function(image=pdf_image)
def convert_pdf_to_images(pdf_bytes):
    from pdf2image import convert_from_bytes

    images = convert_from_bytes(pdf_bytes, fmt="jpeg")
    return images


# ## Chatting with a PDF from the terminal

# Before deploying in a UI, we can test our service from the terminal.

# Just run
# ```bash
# modal run chat_with_pdf_vision.py
# ```

# and optionally pass in a path to or URL of a PDF with the `--pdf-path` argument
# and specify a question with the `--question` argument.

# Continue a previous chat by passing the session ID printed to the terminal at start
# with the `--session-id` argument.


@app.local_entrypoint()
def main(
    question: Optional[str] = None,
    pdf_path: Optional[str] = None,
    session_id: Optional[str] = None,
):
    model = Model()
    if session_id is None:
        session_id = str(uuid4())
        print("Starting a new session with id", session_id)

        if pdf_path is None:
            pdf_path = "https://arxiv.org/pdf/1706.03762"  # all you need

        if pdf_path.startswith("http"):
            pdf_bytes = urlopen(pdf_path).read()
        else:
            pdf_bytes = Path(pdf_path).read_bytes()

        print("Indexing PDF from", pdf_path)
        model.index_pdf.remote(session_id, pdf_bytes)
    else:
        if pdf_path is not None:
            raise ValueError("Start a new session to chat with a new PDF")
        print("Resuming session with id", session_id)

    if question is None:
        question = "What is this document about?"

    print("QUESTION:", question)
    print(model.respond_to_message.remote(session_id, question))


# ## A hosted Gradio interface

# With the [Gradio](https://gradio.app) library, we can create a simple web interface around our class in Python,
# then use Modal to host it for anyone to try out.

# To deploy your own, run

# ```bash
# modal deploy chat_with_pdf_vision.py
# ```

# and navigate to the URL that appears in your teriminal.
# If you’re editing the code, use `modal serve` instead to see changes hot-reload.


web_image = pdf_image.pip_install(
    "fastapi[standard]==0.115.4",
    "pydantic==2.9.2",
    "starlette==0.41.2",
    "gradio==4.44.1",
    "pillow==10.4.0",
    "gradio-pdf==0.0.15",
    "pdf2image==1.17.0",
)


@app.function(
    image=web_image,
    # gradio requires sticky sessions
    # so we limit the number of concurrent containers to 1
    # and allow it to scale to 1000 concurrent inputs
    max_containers=1,
)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def ui():
    import uuid

    import gradio as gr
    from fastapi import FastAPI
    from gradio.routes import mount_gradio_app
    from gradio_pdf import PDF
    from pdf2image import convert_from_path

    web_app = FastAPI()

    # Since this Gradio app is running from its own container,
    # allowing us to run the inference service via .remote() methods.
    model = Model()

    def upload_pdf(path, session_id):
        if session_id == "" or session_id is None:
            # Generate session id if new client
            session_id = str(uuid.uuid4())

        images = convert_from_path(path)
        # Call to our remote inference service to index the PDF
        model.index_pdf.remote(session_id, images)

        return session_id

    def respond_to_message(message, _, session_id):
        # Call to our remote inference service to run RAG
        return model.respond_to_message.remote(session_id, message)

    with gr.Blocks(theme="soft") as demo:
        session_id = gr.State("")

        gr.Markdown("# Chat with PDF")
        with gr.Row():
            with gr.Column(scale=1):
                gr.ChatInterface(
                    fn=respond_to_message,
                    additional_inputs=[session_id],
                    retry_btn=None,
                    undo_btn=None,
                    clear_btn=None,
                )
            with gr.Column(scale=1):
                pdf = PDF(
                    label="Upload a PDF",
                )
                pdf.upload(upload_pdf, [pdf, session_id], session_id)

    return mount_gradio_app(app=web_app, blocks=demo, path="/")


# ## Addenda

# The remainder of this code consists of utility functions and boiler plate used in the
# main code above.


def get_chatbot_message_with_image(message, image):
    return {
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": message},
        ],
    }


def append_to_messages(message, session, user_type="user"):
    session.messages.append(
        {
            "role": user_type,
            "content": {"type": "text", "text": message},
        }
    )


=== GITHUB: 06_gpu_and_ml/llm-serving/trtllm_throughput.py ===
# ---
# deploy: true
# ---

# # Serverless TensorRT-LLM (LLaMA 3 8B)

# In this example, we demonstrate how to use the TensorRT-LLM framework to serve Meta's LLaMA 3 8B model
# at very high throughput.

# We achieve a total throughput of over 25,000 output tokens per second on a single NVIDIA H100 GPU.
# At [Modal's on-demand rate](https://modal.com/pricing) of ~$4.50/hr, that's under $0.05 per million tokens --
# on auto-scaling infrastructure and served via a customizable API.

# Additional optimizations like speculative sampling can further improve throughput.

# ## Overview

# This guide is intended to document two things:
# the general process for building TensorRT-LLM on Modal
# and a specific configuration for serving the LLaMA 3 8B model.

# ### Build process

# Any given TensorRT-LLM service requires a multi-stage build process,
# starting from model weights and ending with a compiled engine.
# Because that process touches many sharp-edged high-performance components
# across the stack, it can easily go wrong in subtle and hard-to-debug ways
# that are idiosyncratic to specific systems.
# And debugging GPU workloads is expensive!

# This example builds an entire service from scratch, from downloading weight tensors
# to responding to requests, and so serves as living, interactive documentation of a TensorRT-LLM
# build process that works on Modal.

# ### Engine configuration

# TensorRT-LLM is the Lamborghini of inference engines: it achieves seriously
# impressive performance, but only if you tune it carefully.
# We carefully document the choices we made here and point to additional resources
# so you know where and how you might adjust the parameters for your use case.

# ## Installing TensorRT-LLM

# To run TensorRT-LLM, we must first install it. Easier said than done!

# In Modal, we define [container images](https://modal.com/docs/guide/custom-container) that run our serverless workloads.
# All Modal containers have access to GPU drivers via the underlying host environment,
# but we still need to install the software stack on top of the drivers, from the CUDA runtime up.

# We start from an official `nvidia/cuda` image,
# which includes the CUDA runtime & development libraries
# and the environment configuration necessary to run them.

from typing import Optional

import modal
import pydantic  # for typing, used later

tensorrt_image = modal.Image.from_registry(
    "nvidia/cuda:12.4.1-devel-ubuntu22.04",
    add_python="3.10",  # TRT-LLM requires Python 3.10
).entrypoint([])  # remove verbose logging by base image on entry

# On top of that, we add some system dependencies of TensorRT-LLM,
# including OpenMPI for distributed communication, some core software like `git`,
# and the `tensorrt_llm` package itself.

tensorrt_image = tensorrt_image.apt_install(
    "openmpi-bin", "libopenmpi-dev", "git", "git-lfs", "wget"
).pip_install(
    "tensorrt_llm==0.14.0",
    "pynvml<12",  # avoid breaking change to pynvml version API
    pre=True,
    extra_index_url="https://pypi.nvidia.com",
)

# Note that we're doing this by [method-chaining](https://quanticdev.com/articles/method-chaining/)
# a number of calls to methods on the `modal.Image`. If you're familiar with
# Dockerfiles, you can think of this as a Pythonic interface to instructions like `RUN` and `CMD`.

# End-to-end, this step takes five minutes.
# If you're reading this from top to bottom,
# you might want to stop here and execute the example
# with `modal run trtllm_throughput.py`
# so that it runs in the background while you read the rest.

# ## Downloading the Model

# Next, we download the model we want to serve. In this case, we're using the instruction-tuned
# version of Meta's LLaMA 3 8B model.
# We use the function below to download the model from the Hugging Face Hub.

MODEL_DIR = "/root/model/model_input"
MODEL_ID = "NousResearch/Meta-Llama-3-8B-Instruct"  # fork without repo gating
MODEL_REVISION = "b1532e4dee724d9ba63fe17496f298254d87ca64"  # pin model revisions to prevent unexpected changes!


def download_model():
    import os

    from huggingface_hub import snapshot_download
    from transformers.utils import move_cache

    os.makedirs(MODEL_DIR, exist_ok=True)
    snapshot_download(
        MODEL_ID,
        local_dir=MODEL_DIR,
        ignore_patterns=["*.pt", "*.bin"],  # using safetensors
        revision=MODEL_REVISION,
    )
    move_cache()


# Just defining that function doesn't actually download the model, though.
# We can run it by adding it to the image's build process with `run_function`.
# The download process has its own dependencies, which we add here.

MINUTES = 60  # seconds
tensorrt_image = (  # update the image by downloading the model we're using
    tensorrt_image.pip_install(  # add utilities for downloading the model
        "hf-transfer==0.1.8",
        "huggingface_hub==0.26.2",
        "requests~=2.31.0",
    )
    .env(  # hf-transfer for faster downloads
        {"HF_HUB_ENABLE_HF_TRANSFER": "1"}
    )
    .run_function(  # download the model
        download_model,
        timeout=20 * MINUTES,
    )
)

# ## Quantization

# The amount of GPU RAM on a single card is a tight constraint for most LLMs:
# RAM is measured in billions of bytes and models have billions of parameters.
# The performance cliff if you need to spill to CPU memory is steep,
# so all of those parameters must fit in the GPU memory,
# along with other things like the KV cache.

# The simplest way to reduce LLM inference's RAM requirements is to make the model's parameters smaller,
# to fit their values in a smaller number of bits, like four or eight. This is known as _quantization_.

# We use a quantization script provided by the TensorRT-LLM team.
# This script takes a few minutes to run.

GIT_HASH = "b0880169d0fb8cd0363049d91aa548e58a41be07"
CONVERSION_SCRIPT_URL = f"https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/{GIT_HASH}/examples/quantization/quantize.py"

# NVIDIA's Ada Lovelace/Hopper chips, like the 4090, L40S, and H100,
# are capable of native calculations in 8bit floating point numbers, so we choose that as our quantization format (`qformat`).
# These GPUs are capable of twice as many floating point operations per second in 8bit as in 16bit --
# about two quadrillion per second on an H100 SXM.

N_GPUS = 1  # Heads up: this example has not yet been tested with multiple GPUs
GPU_CONFIG = f"H100:{N_GPUS}"

DTYPE = "float16"  # format we download in, regular fp16
QFORMAT = "fp8"  # format we quantize the weights to
KV_CACHE_DTYPE = "fp8"  # format we quantize the KV cache to

# Quantization is lossy, but the impact on model quality can be minimized by
# tuning the quantization parameters based on target outputs.

CALIB_SIZE = "512"  # size of calibration dataset

# We put that all together with another invocation of `.run_commands`.

QUANTIZATION_ARGS = f"--dtype={DTYPE} --qformat={QFORMAT} --kv_cache_dtype={KV_CACHE_DTYPE} --calib_size={CALIB_SIZE}"

CKPT_DIR = "/root/model/model_ckpt"
tensorrt_image = (  # update the image by quantizing the model
    tensorrt_image.run_commands(  # takes ~2 minutes
        [
            f"wget {CONVERSION_SCRIPT_URL} -O /root/convert.py",
            f"python /root/convert.py --model_dir={MODEL_DIR} --output_dir={CKPT_DIR}"
            + f" --tp_size={N_GPUS}"
            + f" {QUANTIZATION_ARGS}",
        ],
        gpu=GPU_CONFIG,
    )
)

# ## Compiling the engine

# TensorRT-LLM achieves its high throughput primarily by compiling the model:
# making concrete choices of CUDA kernels to execute for each operation.
# These kernels are much more specific than `matrix_multiply` or `softmax` --
# they have names like `maxwell_scudnn_winograd_128x128_ldg1_ldg4_tile148t_nt`.
# They are optimized for the specific types and shapes of tensors that the model uses
# and for the specific hardware that the model runs on.

# That means we need to know all of that information a priori --
# more like the original TensorFlow, which defined static graphs, than like PyTorch,
# which builds up a graph of kernels dynamically at runtime.

# This extra layer of constraint on our LLM service is an important part of
# what allows TensorRT-LLM to achieve its high throughput.

# So we need to specify things like the maximum batch size and the lengths of inputs and outputs.
# The closer these are to the actual values we'll use in production, the better the throughput we'll get.

# Since we want to maximize the throughput, assuming we had a constant workload,
# we set the batch size to the largest value we can fit in GPU RAM.
# Quantization helps us again here, since it allows us to fit more tokens in the same RAM.

MAX_INPUT_LEN, MAX_OUTPUT_LEN = 256, 256
MAX_NUM_TOKENS = 2**17
MAX_BATCH_SIZE = 1024  # better throughput at larger batch sizes, limited by GPU RAM
ENGINE_DIR = "/root/model/model_output"

SIZE_ARGS = f"--max_input_len={MAX_INPUT_LEN} --max_num_tokens={MAX_NUM_TOKENS} --max_batch_size={MAX_BATCH_SIZE}"

# There are many additional options you can pass to `trtllm-build` to tune the engine for your specific workload.
# You can find the document we used for LLaMA
# [here](https://github.com/NVIDIA/TensorRT-LLM/tree/b0880169d0fb8cd0363049d91aa548e58a41be07/examples/llama),
# which you can use to adjust the arguments to fit your workloads,
# e.g. adjusting rotary embeddings and block sizes for longer contexts.
# For more performance tuning tips, check out [NVIDIA's official TensorRT-LLM performance guide](https://nvidia.github.io/TensorRT-LLM/0.21.0rc1/performance/performance-tuning-guide/index.html).


# To make best use of our 8bit floating point hardware, and the weights and KV cache we have quantized,
# we activate the 8bit floating point fused multi-head attention plugin.

# Because we are targeting maximum throughput, we do not activate the low latency 8bit floating point matrix multiplication plugin
# or the 8bit floating point matrix multiplication (`gemm`) plugin, which documentation indicates target smaller batch sizes.

PLUGIN_ARGS = "--use_fp8_context_fmha enable"

# We put all of this together with another invocation of `.run_commands`.

tensorrt_image = (  # update the image by building the TensorRT engine
    tensorrt_image.run_commands(  # takes ~5 minutes
        [
            f"trtllm-build --checkpoint_dir {CKPT_DIR} --output_dir {ENGINE_DIR}"
            + f" --workers={N_GPUS}"
            + f" {SIZE_ARGS}"
            + f" {PLUGIN_ARGS}"
        ],
        gpu=GPU_CONFIG,  # TRT-LLM compilation is GPU-specific, so make sure this matches production!
    ).env(  # show more log information from the inference engine
        {"TLLM_LOG_LEVEL": "INFO"}
    )
)

# ## Serving inference at tens of thousands of tokens per second

# Now that we have the engine compiled, we can serve it with Modal by creating an `App`.

app = modal.App(f"example-trtllm-{MODEL_ID.split('/')[-1]}", image=tensorrt_image)

# Thanks to our custom container runtime system even this large, many gigabyte container boots in seconds.

# At container start time, we boot up the engine, which completes in under 30 seconds.
# Container starts are triggered when Modal scales up your infrastructure,
# like the first time you run this code or the first time a request comes in after a period of inactivity.

# Container lifecycles in Modal are managed via our `Cls` interface, so we define one below
# to manage the engine and run inference.
# For details, see [this guide](https://modal.com/docs/guide/lifecycle-functions).


@app.cls(
    gpu=GPU_CONFIG,
    scaledown_window=10 * MINUTES,
    image=tensorrt_image,
)
class Model:
    @modal.enter()
    def load(self):
        """Loads the TRT-LLM engine and configures our tokenizer.

        The @enter decorator ensures that it runs only once per container, when it starts."""
        import time

        print(
            f"{COLOR['HEADER']}🥶 Cold boot: spinning up TRT-LLM engine{COLOR['ENDC']}"
        )
        self.init_start = time.monotonic_ns()

        import tensorrt_llm
        from tensorrt_llm.runtime import ModelRunner
        from transformers import AutoTokenizer

        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
        # LLaMA models do not have a padding token, so we use the EOS token
        self.tokenizer.add_special_tokens({"pad_token": self.tokenizer.eos_token})
        # and then we add it from the left, to minimize impact on the output
        self.tokenizer.padding_side = "left"
        self.pad_id = self.tokenizer.pad_token_id
        self.end_id = self.tokenizer.eos_token_id

        runner_kwargs = dict(
            engine_dir=f"{ENGINE_DIR}",
            lora_dir=None,
            rank=tensorrt_llm.mpi_rank(),  # this will need to be adjusted to use multiple GPUs
            max_output_len=MAX_OUTPUT_LEN,
        )

        self.model = ModelRunner.from_dir(**runner_kwargs)

        self.init_duration_s = (time.monotonic_ns() - self.init_start) / 1e9
        print(
            f"{COLOR['HEADER']}🚀 Cold boot finished in {self.init_duration_s}s{COLOR['ENDC']}"
        )

    @modal.method()
    def generate(self, prompts: list[str], settings=None):
        """Generate responses to a batch of prompts, optionally with custom inference settings."""
        import time

        if settings is None or not settings:
            settings = dict(
                temperature=0.1,  # temperature 0 not allowed, so we set top_k to 1 to get the same effect
                top_k=1,
                stop_words_list=None,
                repetition_penalty=1.1,
            )

        settings["max_new_tokens"] = (
            MAX_OUTPUT_LEN  # exceeding this will raise an error
        )
        settings["end_id"] = self.end_id
        settings["pad_id"] = self.pad_id

        num_prompts = len(prompts)

        if num_prompts > MAX_BATCH_SIZE:
            raise ValueError(
                f"Batch size {num_prompts} exceeds maximum of {MAX_BATCH_SIZE}"
            )

        print(
            f"{COLOR['HEADER']}🚀 Generating completions for batch of size {num_prompts}...{COLOR['ENDC']}"
        )
        start = time.monotonic_ns()

        parsed_prompts = [
            self.tokenizer.apply_chat_template(
                [{"role": "user", "content": prompt}],
                add_generation_prompt=True,
                tokenize=False,
            )
            for prompt in prompts
        ]

        print(
            f"{COLOR['HEADER']}Parsed prompts:{COLOR['ENDC']}",
            *parsed_prompts,
            sep="\n\t",
        )

        inputs_t = self.tokenizer(
            parsed_prompts, return_tensors="pt", padding=True, truncation=False
        )["input_ids"]

        print(f"{COLOR['HEADER']}Input tensors:{COLOR['ENDC']}", inputs_t[:, :8])

        outputs_t = self.model.generate(inputs_t, **settings)

        outputs_text = self.tokenizer.batch_decode(
            outputs_t[:, 0]
        )  # only one output per input, so we index with 0

        responses = [
            extract_assistant_response(output_text) for output_text in outputs_text
        ]
        duration_s = (time.monotonic_ns() - start) / 1e9

        num_tokens = sum(map(lambda r: len(self.tokenizer.encode(r)), responses))

        for prompt, response in zip(prompts, responses):
            print(
                f"{COLOR['HEADER']}{COLOR['GREEN']}{prompt}",
                f"\n{COLOR['BLUE']}{response}",
                "\n\n",
                sep=COLOR["ENDC"],
            )
            time.sleep(0.05)  # to avoid log truncation

        print(
            f"{COLOR['HEADER']}{COLOR['GREEN']}Generated {num_tokens} tokens from {MODEL_ID} in {duration_s:.1f} seconds,"
            f" throughput = {num_tokens / duration_s:.0f} tokens/second for batch of size {num_prompts} on {GPU_CONFIG}.{COLOR['ENDC']}"
        )

        return responses


# ## Calling our inference function

# Now, how do we actually run the model?

# There are two basic methods: from Python via our SDK or from anywhere, by setting up an API.

# ### Calling inference from Python

# To run our `Model`'s `.generate` method from Python, we just need to call it --
# with `.remote` appended to run it on Modal.

# We wrap that logic in a `local_entrypoint` so you can run it from the command line with
# ```bash
# modal run trtllm_throughput.py
# ```

# For simplicity, we hard-code a batch of 128 questions to ask the model,
# and then bulk it up to a batch size of 1024 by appending seven distinct prefixes.
# These prefixes ensure KV cache misses for the remainder of the generations,
# to keep the benchmark closer to what can be expected in a real workload.


@app.local_entrypoint()
def main():
    questions = [
        # Generic assistant questions
        "What are you?",
        "What can you do?",
        # Coding
        "Implement a Python function to compute the Fibonacci numbers.",
        "Write a Rust function that performs binary exponentiation.",
        "How do I allocate memory in C?",
        "What are the differences between Javascript and Python?",
        "How do I find invalid indices in Postgres?",
        "How can you implement a LRU (Least Recently Used) cache in Python?",
        "What approach would you use to detect and prevent race conditions in a multithreaded application?",
        "Can you explain how a decision tree algorithm works in machine learning?",
        "How would you design a simple key-value store database from scratch?",
        "How do you handle deadlock situations in concurrent programming?",
        "What is the logic behind the A* search algorithm, and where is it used?",
        "How can you design an efficient autocomplete system?",
        "What approach would you take to design a secure session management system in a web application?",
        "How would you handle collision in a hash table?",
        "How can you implement a load balancer for a distributed system?",
        "Implement a Python class for a doubly linked list.",
        "Write a Haskell function that generates prime numbers using the Sieve of Eratosthenes.",
        "Develop a simple HTTP server in Rust.",
        # Literate and creative writing
        "What is the fable involving a fox and grapes?",
        "Who does Harry turn into a balloon?",
        "Write a story in the style of James Joyce about a trip to the Australian outback in 2083 to see robots in the beautiful desert.",
        "Write a tale about a time-traveling historian who's determined to witness the most significant events in human history.",
        "Describe a day in the life of a secret agent who's also a full-time parent.",
        "Create a story about a detective who can communicate with animals.",
        "What is the most unusual thing about living in a city floating in the clouds?",
        "In a world where dreams are shared, what happens when a nightmare invades a peaceful dream?",
        "Describe the adventure of a lifetime for a group of friends who found a map leading to a parallel universe.",
        "Tell a story about a musician who discovers that their music has magical powers.",
        "In a world where people age backwards, describe the life of a 5-year-old man.",
        "Create a tale about a painter whose artwork comes to life every night.",
        "What happens when a poet's verses start to predict future events?",
        "Imagine a world where books can talk. How does a librarian handle them?",
        "Tell a story about an astronaut who discovered a planet populated by plants.",
        "Describe the journey of a letter traveling through the most sophisticated postal service ever.",
        "Write a tale about a chef whose food can evoke memories from the eater's past.",
        "Write a poem in the style of Walt Whitman about the modern digital world.",
        "Create a short story about a society where people can only speak in metaphors.",
        "What are the main themes in Dostoevsky's 'Crime and Punishment'?",
        # History and Philosophy
        "What were the major contributing factors to the fall of the Roman Empire?",
        "How did the invention of the printing press revolutionize European society?",
        "What are the effects of quantitative easing?",
        "How did the Greek philosophers influence economic thought in the ancient world?",
        "What were the economic and philosophical factors that led to the fall of the Soviet Union?",
        "How did decolonization in the 20th century change the geopolitical map?",
        "What was the influence of the Khmer Empire on Southeast Asia's history and culture?",
        "What led to the rise and fall of the Mongol Empire?",
        "Discuss the effects of the Industrial Revolution on urban development in 19th century Europe.",
        "How did the Treaty of Versailles contribute to the outbreak of World War II?",
        "What led to the rise and fall of the Mongol Empire?",
        "Discuss the effects of the Industrial Revolution on urban development in 19th century Europe.",
        "How did the Treaty of Versailles contribute to the outbreak of World War II?",
        "Explain the concept of 'tabula rasa' in John Locke's philosophy.",
        "What does Nietzsche mean by 'ressentiment'?",
        "Compare and contrast the early and late works of Ludwig Wittgenstein. Which do you prefer?",
        "How does the trolley problem explore the ethics of decision-making in critical situations?",
        # Thoughtfulness
        "Describe the city of the future, considering advances in technology, environmental changes, and societal shifts.",
        "In a dystopian future where water is the most valuable commodity, how would society function?",
        "If a scientist discovers immortality, how could this impact society, economy, and the environment?",
        "What could be the potential implications of contact with an advanced alien civilization?",
        "Describe how you would mediate a conflict between two roommates about doing the dishes using techniques of non-violent communication.",
        "If you could design a school curriculum for the future, what subjects would you include to prepare students for the next 50 years?",
        "How would society change if teleportation was invented and widely accessible?",
        "Consider a future where artificial intelligence governs countries. What are the potential benefits and pitfalls?",
        # Math
        "What is the product of 9 and 8?",
        "If a train travels 120 kilometers in 2 hours, what is its average speed?",
        "Think through this step by step. If the sequence a_n is defined by a_1 = 3, a_2 = 5, and a_n = a_(n-1) + a_(n-2) for n > 2, find a_6.",
        "Think through this step by step. Calculate the sum of an arithmetic series with first term 3, last term 35, and total terms 11.",
        "Think through this step by step. What is the area of a triangle with vertices at the points (1,2), (3,-4), and (-2,5)?",
        "Think through this step by step. Solve the following system of linear equations: 3x + 2y = 14, 5x - y = 15.",
        # Facts
        "Who was Emperor Norton I, and what was his significance in San Francisco's history?",
        "What is the Voynich manuscript, and why has it perplexed scholars for centuries?",
        "What was Project A119 and what were its objectives?",
        "What is the 'Dyatlov Pass incident' and why does it remain a mystery?",
        "What is the 'Emu War' that took place in Australia in the 1930s?",
        "What is the 'Phantom Time Hypothesis' proposed by Heribert Illig?",
        "Who was the 'Green Children of Woolpit' as per 12th-century English legend?",
        "What are 'zombie stars' in the context of astronomy?",
        "Who were the 'Dog-Headed Saint' and the 'Lion-Faced Saint' in medieval Christian traditions?",
        "What is the story of the 'Globsters', unidentified organic masses washed up on the shores?",
        "Which countries in the European Union use currencies other than the Euro, and what are those currencies?",
        # Multilingual
        "战国时期最重要的人物是谁?",
        "Tuende hatua kwa hatua. Hesabu jumla ya mfululizo wa kihesabu wenye neno la kwanza 2, neno la mwisho 42, na jumla ya maneno 21.",
        "Kannst du die wichtigsten Eigenschaften und Funktionen des NMDA-Rezeptors beschreiben?",
        "¿Cuáles son los principales impactos ambientales de la deforestación en la Amazonía?",
        "Décris la structure et le rôle de la mitochondrie dans une cellule.",
        "Какие были социальные последствия Перестройки в Советском Союзе?",
        # Economics and Business
        "What are the principles of behavioral economics and how do they influence consumer choices?",
        "Discuss the impact of blockchain technology on traditional banking systems.",
        "What are the long-term effects of trade wars on global economic stability?",
        "What is the law of supply and demand?",
        "Explain the concept of inflation and its typical causes.",
        "What is a trade deficit, and why does it matter?",
        "How do interest rates affect consumer spending and saving?",
        "What is GDP and why is it important for measuring economic health?",
        "What is the difference between revenue and profit?",
        "Describe the role of a business plan in startup success.",
        "How does market segmentation benefit a company?",
        "Explain the concept of brand equity.",
        "What are the advantages of franchising a business?",
        "What are Michael Porter's five forces and how do they impact strategy for tech startups?",
        # Science and Technology
        "Discuss the potential impacts of quantum computing on data security.",
        "How could CRISPR technology change the future of medical treatments?",
        "Explain the significance of graphene in the development of future electronics.",
        "How do renewable energy sources compare to fossil fuels in terms of environmental impact?",
        "What are the most promising technologies for carbon capture and storage?",
        "Explain why the sky is blue.",
        "What is the principle behind the operation of a microwave oven?",
        "How does Newton's third law apply to rocket propulsion?",
        "What causes iron to rust?",
        "Describe the process of photosynthesis in simple terms.",
        "What is the role of a catalyst in a chemical reaction?",
        "What is the basic structure of a DNA molecule?",
        "How do vaccines work to protect the body from disease?",
        "Explain the significance of mitosis in cellular reproduction.",
        "What are tectonic plates and how do they affect earthquakes?",
        "How does the greenhouse effect contribute to global warming?",
        "Describe the water cycle and its importance to Earth's climate.",
        "What causes the phases of the Moon?",
        "How do black holes form?",
        "Explain the significance of the Big Bang theory.",
        "What is the function of the CPU in a computer system?",
        "Explain the difference between RAM and ROM.",
        "How does a solid-state drive (SSD) differ from a hard disk drive (HDD)?",
        "What role does the motherboard play in a computer system?",
        "Describe the purpose and function of a GPU.",
        "What is TensorRT? What role does it play in neural network inference?",
    ]

    prefixes = [
        "Hi! ",
        "Hello! ",
        "Hi. ",
        "Hello. ",
        "Hi: ",
        "Hello: ",
        "Greetings. ",
    ]
    # prepending any string that causes a tokenization change is enough to invalidate KV cache
    for ii, prefix in enumerate(prefixes):
        questions += [prefix + question for question in questions[:128]]

    model = Model()
    model.generate.remote(questions)
    # if you're calling this service from another Python project,
    # use [`Model.lookup`](https://modal.com/docs/reference/modal.Cls#lookup)


# ### Calling inference via an API

# We can use `modal.fastapi_endpoint` with `app.function` to turn any Python function into a web API.

# This API wrapper doesn't need all the dependencies of the core inference service,
# so we switch images here to a basic Linux image, `debian_slim`, and add the FastAPI stack.

web_image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "fastapi[standard]==0.115.4",
    "pydantic==2.9.2",
    "starlette==0.41.2",
)


# From there, we can take the same remote generation logic we used in `main`
# and serve it with only a few more lines of code.


class GenerateRequest(pydantic.BaseModel):
    prompts: list[str]
    settings: Optional[dict] = None


@app.function(image=web_image)
@modal.fastapi_endpoint(
    method="POST", label=f"{MODEL_ID.lower().split('/')[-1]}-web", docs=True
)
def generate_web(data: GenerateRequest) -> list[str]:
    """Generate responses to a batch of prompts, optionally with custom inference settings."""
    return Model.generate.remote(data.prompts, settings=None)


# To set our function up as a web endpoint, we need to run this file --
# with `modal serve` to create a hot-reloading development server or `modal deploy` to deploy it to production.

# ```bash
# modal serve trtllm_throughput.py
# ```

# The URL for the endpoint appears in the output of the `modal serve` or `modal deploy` command.
# Add `/docs` to the end of this URL to see the interactive Swagger documentation for the endpoint.

# You can also test the endpoint by sending a POST request with `curl` from another terminal:

# ```bash
# curl -X POST url-from-output-of-modal-serve-here \
# -H "Content-Type: application/json" \
# -d '{
#     "prompts": ["Tell me a joke", "Describe a dream you had recently", "Share your favorite childhood memory"]
# }' | python -m json.tool # python for pretty-printing, optional
# ```

# And now you have a high-throughput, low-latency, autoscaling API for serving LLM completions!

# ## Footer

# The rest of the code in this example is utility code.


COLOR = {
    "HEADER": "\033[95m",
    "BLUE": "\033[94m",
    "GREEN": "\033[92m",
    "RED": "\033[91m",
    "ENDC": "\033[0m",
}


def extract_assistant_response(output_text):
    """Model-specific code to extract model responses.

    See this doc for LLaMA 3: https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/."""
    # Split the output text by the assistant header token
    parts = output_text.split("<|start_header_id|>assistant<|end_header_id|>")

    if len(parts) > 1:
        # Join the parts after the first occurrence of the assistant header token
        response = parts[1].split("<|eot_id|>")[0].strip()

        # Remove any remaining special tokens and whitespace
        response = response.replace("<|eot_id|>", "").strip()

        return response
    else:
        return output_text


=== GITHUB: 06_gpu_and_ml/llm-serving/llama_cpp.py ===
# ---
# args: ["--n-predict", "1024"]
# ---

# # Run large and small language models with llama.cpp (DeepSeek-R1, Phi-4)

# This example demonstrate how to run small (Phi-4) and large (DeepSeek-R1)
# language models on Modal with [`llama.cpp`](https://github.com/ggerganov/llama.cpp).

# By default, this example uses DeepSeek-R1 to produce a "Flappy Bird" game in Python --
# see the video below. The code used in the video is [here](https://gist.github.com/charlesfrye/a3788c61019c32cb7947f4f5b1c04818),
# along with the model's raw outputs.
# Note that getting the game to run required a small bugfix from a human --
# our jobs are still safe, for now.

# <center>
# <a href="https://gist.github.com/charlesfrye/a3788c61019c32cb7947f4f5b1c04818"> <video controls autoplay loop muted> <source src="https://modal-cdn.com/example-flap-py.mp4" type="video/mp4"> </video> </a>
# </center>

from pathlib import Path
from typing import Optional

import modal

# ## What GPU can run DeepSeek-R1? What GPU can run Phi-4?

# Our large model is a real whale:
# [DeepSeek-R1](https://api-docs.deepseek.com/news/news250120),
# which has 671B total parameters and so consumes over 100GB of storage,
# even when [quantized down to one ternary digit (1.58 bits)](https://unsloth.ai/blog/deepseekr1-dynamic)
# per parameter.

# To make sure we have enough room for it and its activations/KV cache,
# we select four L40S GPUs, which together have 192 GB of memory.

# [Phi-4](https://huggingface.co/microsoft/phi-4),
# on the other hand, is a svelte 14B total parameters,
# or roughly 5 GB when quantized down to
# [two bits per parameter](https://huggingface.co/unsloth/phi-4-GGUF).

# That's small enough that it can be comfortably run on a CPU,
# especially for a single-user setup like the one we'll build here.

GPU_CONFIG = "L40S:4"  # for DeepSeek-R1, literal `None` for phi-4

# ## Calling a Modal Function from the command line

# To start, we define our `main` function --
# the Python function that we'll run locally to
# trigger our inference to run on Modal's cloud infrastructure.

# This function, like the others that form our inference service
# running on Modal, is part of a Modal [App](https://modal.com/docs/guide/apps).
# Specifically, it is a `local_entrypoint`.
# Any Python code can call Modal Functions remotely,
# but local entrypoints get a command-line interface for free.

app = modal.App("example-llama-cpp")


@app.local_entrypoint()
def main(
    prompt: Optional[str] = None,
    model: str = "DeepSeek-R1",  # or "phi-4"
    n_predict: int = -1,  # max number of tokens to predict, -1 is infinite
    args: Optional[str] = None,  # string of arguments to pass to llama.cpp's cli
):
    """Run llama.cpp inference on Modal for phi-4 or deepseek r1."""
    import shlex

    org_name = "unsloth"
    # two sample models: the diminuitive phi-4 and the chonky deepseek r1
    if model.lower() == "phi-4":
        model_name = "phi-4-GGUF"
        quant = "Q2_K"
        model_entrypoint_file = f"phi-4-{quant}.gguf"
        model_pattern = f"*{quant}*"
        revision = None
        parsed_args = DEFAULT_PHI_ARGS if args is None else shlex.split(args)
    elif model.lower() == "deepseek-r1":
        model_name = "DeepSeek-R1-GGUF"
        quant = "UD-IQ1_S"
        model_entrypoint_file = (
            f"{model}-{quant}/DeepSeek-R1-{quant}-00001-of-00003.gguf"
        )
        model_pattern = f"*{quant}*"
        revision = "02656f62d2aa9da4d3f0cdb34c341d30dd87c3b6"
        parsed_args = DEFAULT_DEEPSEEK_R1_ARGS if args is None else shlex.split(args)
    else:
        raise ValueError(f"Unknown model {model}")

    repo_id = f"{org_name}/{model_name}"
    download_model.remote(repo_id, [model_pattern], revision)

    # call out to a `.remote` Function on Modal for inference
    result = llama_cpp_inference.remote(
        model_entrypoint_file,
        prompt,
        n_predict,
        parsed_args,
        store_output=model.lower() == "deepseek-r1",
    )
    output_path = Path("/tmp") / f"llama-cpp-{model}.txt"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    print(f"🦙 writing response to {output_path}")
    output_path.write_text(result)


# You can trigger inference from the command line with

# ```bash
# modal run llama_cpp.py
# ```

# To try out Phi-4 instead, use the `--model` argument:

# ```bash
# modal run llama_cpp.py --model="phi-4"
# ```

# Note that this will run for up to 30 minutes, which costs ~$5.
# To allow it to proceed even if your local terminal fails,
# add the `--detach` flag after `modal run`.
# See below for details on getting the outputs.

# You can pass prompts with the `--prompt` argument and set the maximum number of tokens
# with the `--n-predict` argument.

# Additional arguments for `llama-cli` are passed as a string like `--args="--foo 1 --bar"`.

# For convenience, we set a number of sensible defaults for DeepSeek-R1,
# following the suggestions by the team at unsloth,
# who [quantized the model to 1.58 bit](https://unsloth.ai/blog/deepseekr1-dynamic).


DEFAULT_DEEPSEEK_R1_ARGS = [  # good default llama.cpp cli args for deepseek-r1
    "--cache-type-k",
    "q4_0",
    "--threads",
    "12",
    "-no-cnv",
    "--prio",
    "2",
    "--temp",
    "0.6",
    "--ctx-size",
    "8192",
]

DEFAULT_PHI_ARGS = [  # good default llama.cpp cli args for phi-4
    "--threads",
    "16",
    "-no-cnv",
    "--ctx-size",
    "16384",
]

# ## Compiling llama.cpp with CUDA support

# In order to run inference, we need the model's weights
# and we need code to run inference with those weights.

# [`llama.cpp`](https://github.com/ggerganov/llama.cpp)
# is a no-frills C++ library for running large language models.
# It supports highly-quantized versions of models ideal for running
# single-user language modeling services on CPU or GPU.

# We compile it, with CUDA support, and add it to a Modal
# [container image](https://modal.com/docs/guide/images)
# using the code below.

# For more details on using CUDA on Modal, including why
# we need to use the `nvidia/cuda` registry image in this case
# (hint: it's for the [`nvcc` compiler](https://modal.com/gpu-glossary/host-software/nvcc)),
# see the [Modal guide to using CUDA](https://modal.com/docs/guide/cuda).

LLAMA_CPP_RELEASE = "b4568"
MINUTES = 60

cuda_version = "12.4.0"  # should be no greater than host CUDA version
flavor = "devel"  #  includes full CUDA toolkit
operating_sys = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{operating_sys}"


image = (
    modal.Image.from_registry(f"nvidia/cuda:{tag}", add_python="3.12")
    .apt_install("git", "build-essential", "cmake", "curl", "libcurl4-openssl-dev")
    .run_commands("git clone https://github.com/ggerganov/llama.cpp")
    .run_commands(
        "cmake llama.cpp -B llama.cpp/build "
        "-DBUILD_SHARED_LIBS=OFF -DGGML_CUDA=ON -DLLAMA_CURL=ON "
    )
    .run_commands(  # this one takes a few minutes!
        "cmake --build llama.cpp/build --config Release -j --clean-first --target llama-quantize llama-cli"
    )
    .run_commands("cp llama.cpp/build/bin/llama-* llama.cpp")
    .entrypoint([])  # remove NVIDIA base container entrypoint
)

# ## Storing models on Modal

# To make the model weights available on Modal,
# we download them from Hugging Face.

# Modal is serverless, so disks are by default ephemeral.
# To make sure our weights don't disappear between runs,
# which would trigger a long download, we store them in a
# Modal [Volume](https://modal.com/docs/guide/volumes).

# For more on how to use Modal Volumes to store model weights,
# see [this guide](https://modal.com/docs/guide/model-weights).

model_cache = modal.Volume.from_name("llamacpp-cache", create_if_missing=True)
cache_dir = "/root/.cache/llama.cpp"

download_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("huggingface_hub[hf_transfer]==0.26.2")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
)


@app.function(
    image=download_image, volumes={cache_dir: model_cache}, timeout=30 * MINUTES
)
def download_model(repo_id, allow_patterns, revision: Optional[str] = None):
    from huggingface_hub import snapshot_download

    print(f"🦙 downloading model from {repo_id} if not present")

    snapshot_download(
        repo_id=repo_id,
        revision=revision,
        local_dir=cache_dir,
        allow_patterns=allow_patterns,
    )

    model_cache.commit()  # ensure other Modal Functions can see our writes before we quit

    print("🦙 model loaded")


# ## Storing model outputs on Modal

# Contemporary large reasoning models are slow --
# for the sample "flappy bird" prompt we provide,
# results are sometimes produced only after several (or even tens of) minutes.

# That makes their outputs worth storing.
# In addition to sending them back to clients,
# like our local command line,
# we'll store the results on a Modal Volume for safe-keeping.

results = modal.Volume.from_name("llamacpp-results", create_if_missing=True)
results_dir = "/root/results"

# You can retrieve the results later in a number of ways.

# You can use the Volume CLI:

# ```bash
# modal volume ls llamacpp-results
# ```

# You can attach the Volume to a Modal `shell`
# to poke around in a familiar terminal environment:

# ```bash
# modal shell --volume llamacpp-results
# # then cd into /mnt
# ```

# Or you can access it from any other Python environment
# by using the same `modal.Volume` call as above to instantiate it:

# ```python
# results = modal.Volume.from_name("llamacpp-results")
# print(dir(results))  # show methods
# ```

# ## Running llama.cpp as a Modal Function

# Now, let's put it all together.

# At the top of our `llama_cpp_inference` function,
# we add an `app.function` decorator to attach all of our infrastructure:

# - the `image` with the dependencies
# - the `volumes` with the weights and where we can put outputs
# - the `gpu` we want, if any

# We also specify a `timeout` after which to cancel the run.

# Inside the function, we call the `llama.cpp` CLI
# with `subprocess.Popen`. This requires a bit of extra ceremony
# because we want to both show the output as we run
# and store the output to save and return to the local caller.
# For details, see the [Addenda section](#addenda) below.

# Alternatively, you might set up an OpenAI-compatible server
# using base `llama.cpp` or its [Python wrapper library](https://github.com/abetlen/llama-cpp-python)
# along with one of [Modal's decorators for web hosting](https://modal.com/docs/guide/webhooks).


@app.function(
    image=image,
    volumes={cache_dir: model_cache, results_dir: results},
    gpu=GPU_CONFIG,
    timeout=30 * MINUTES,
)
def llama_cpp_inference(
    model_entrypoint_file: str,
    prompt: Optional[str] = None,
    n_predict: int = -1,
    args: Optional[list[str]] = None,
    store_output: bool = True,
):
    import subprocess
    from uuid import uuid4

    if prompt is None:
        prompt = DEFAULT_PROMPT  # see end of file
    if "deepseek" in model_entrypoint_file.lower():
        prompt = "<｜User｜>" + prompt + "<think>"
    if args is None:
        args = []

    # set layers to "off-load to", aka run on, GPU
    if GPU_CONFIG is not None:
        n_gpu_layers = 9999  # all
    else:
        n_gpu_layers = 0

    if store_output:
        result_id = str(uuid4())
        print(f"🦙 running inference with id:{result_id}")

    command = [
        "/llama.cpp/llama-cli",
        "--model",
        f"{cache_dir}/{model_entrypoint_file}",
        "--n-gpu-layers",
        str(n_gpu_layers),
        "--prompt",
        prompt,
        "--n-predict",
        str(n_predict),
    ] + args

    print("🦙 running commmand:", command, sep="\n\t")
    p = subprocess.Popen(
        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=False
    )

    stdout, stderr = collect_output(p)

    if p.returncode != 0:
        raise subprocess.CalledProcessError(p.returncode, command, stdout, stderr)

    if store_output:  # save results to a Modal Volume if requested
        print(f"🦙 saving results for {result_id}")
        result_dir = Path(results_dir) / result_id
        result_dir.mkdir(
            parents=True,
        )
        (result_dir / "out.txt").write_text(stdout)
        (result_dir / "err.txt").write_text(stderr)

    return stdout


# # Addenda

# The remainder of this code is less interesting from the perspective
# of running LLM inference on Modal but necessary for the code to run.

# For example, it includes the default "Flappy Bird in Python" prompt included in
# [unsloth's announcement](https://unsloth.ai/blog/deepseekr1-dynamic)
# of their 1.58 bit quantization of DeepSeek-R1.

DEFAULT_PROMPT = """Create a Flappy Bird game in Python. You must include these things:

    You must use pygame.
    The background color should be randomly chosen and is a light shade. Start with a light blue color.
    Pressing SPACE multiple times will accelerate the bird.
    The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.
    Place on the bottom some land colored as dark brown or yellow chosen randomly.
    Make a score shown on the top right side. Increment if you pass pipes and don't hit them.
    Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.
    When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.

The final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section."""


def stream_output(stream, queue, write_stream):
    """Reads lines from a stream and writes to a queue and a write stream."""
    for line in iter(stream.readline, b""):
        line = line.decode("utf-8", errors="replace")
        write_stream.write(line)
        write_stream.flush()
        queue.put(line)
    stream.close()


def collect_output(process):
    """Collect up the stdout and stderr of a process while still streaming it out."""
    import sys
    from queue import Queue
    from threading import Thread

    stdout_queue = Queue()
    stderr_queue = Queue()

    stdout_thread = Thread(
        target=stream_output, args=(process.stdout, stdout_queue, sys.stdout)
    )
    stderr_thread = Thread(
        target=stream_output, args=(process.stderr, stderr_queue, sys.stderr)
    )
    stdout_thread.start()
    stderr_thread.start()

    stdout_thread.join()
    stderr_thread.join()
    process.wait()

    stdout_collected = "".join(stdout_queue.queue)
    stderr_collected = "".join(stderr_queue.queue)

    return stdout_collected, stderr_collected


=== GITHUB: 06_gpu_and_ml/llm-serving/trtllm_latency.py ===
# ---
# deploy: true
# ---
# # Serve an interactive language model app with latency-optimized TensorRT-LLM (LLaMA 3 8B)

# In this example, we demonstrate how to configure the TensorRT-LLM framework to serve
# Meta's LLaMA 3 8B model at interactive latencies on Modal.

# Many popular language model applications, like chatbots and code editing,
# put humans and models in direct interaction. According to an
# [oft-cited](https://lawsofux.com/doherty-threshold/)
# if [scientifically dubious](https://www.flashover.blog/posts/dohertys-threshold-is-a-lie)
# rule of thumb, computer systems need to keep their response times under 400ms
# in order to match pace with their human users.

# To hit this target, we use the [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)
# inference framework from NVIDIA. TensorRT-LLM is the Lamborghini of inference engines:
# it achieves seriously impressive latency, but only if you tune it carefully.
# With the out-of-the-box defaults we observe an unacceptable median time
# to last token of over a second, but with careful configuration,
# we'll bring that down to under 250ms  -- over a 4x speed up!
# These latencies were measured on a single NVIDIA H100 GPU
# running LLaMA 3 8B on prompts and generations of a few dozen to a few hundred tokens.

# Here's what that looks like in a terminal chat interface:

# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/example-trtllm-latency.mp4" type="video/mp4">
# </video>

# ## Overview

# This guide is intended to document two things:

# 1. the [Python API](https://nvidia.github.io/TensorRT-LLM/llm-api)
# for building and running TensorRT-LLM engines, and

# 2. how to use recommendations from the
# [TensorRT-LLM performance guide](https://github.com/NVIDIA/TensorRT-LLM/blob/b763051ba429d60263949da95c701efe8acf7b9c/docs/source/performance/performance-tuning-guide/useful-build-time-flags.md)
# to optimize the engine for low latency.

# Be sure to check out TensorRT-LLM's
# [examples](https://nvidia.github.io/TensorRT-LLM/llm-api-examples)
# for sample code beyond what we cover here, like low-rank adapters (LoRAs).

# ### What is a TRT-LLM engine?

# The first step in running TensorRT-LLM is to build an "engine" from a model.
# Engines have a large number of parameters that must be tuned on a per-workload basis,
# so we carefully document the choices we made here and point you to additional resources
# that can help you optimize for your specific workload.

# Historically, this process was done with a clunky command-line-interface (CLI),
# but things have changed for the better!
# 2025 is [the year of CUDA Python](https://twitter.com/blelbach/status/1902842146232865280),
# including a new-and-improved Python SDK for TensorRT-LLM, supporting
# all the same features as the CLI -- quantization, speculative decoding, in-flight batching,
# and much more.

# ## Installing TensorRT-LLM

# To run TensorRT-LLM, we must first install it. Easier said than done!

# To run code on Modal, we define [container images](https://modal.com/docs/guide/images).
# All Modal containers have access to GPU drivers via the underlying host environment,
# but we still need to install the software stack on top of the drivers, from the CUDA runtime up.

# We start from an official `nvidia/cuda` container image,
# which includes the CUDA runtime & development libraries
# and the environment configuration necessary to run them.

import time
from pathlib import Path

import modal

tensorrt_image = modal.Image.from_registry(
    "nvidia/cuda:12.8.1-devel-ubuntu22.04",
    add_python="3.12",  # TRT-LLM requires Python 3.12
).entrypoint([])  # remove verbose logging by base image on entry

# On top of that, we add some system dependencies of TensorRT-LLM,
# including OpenMPI for distributed communication, some core software like `git`,
# and the `tensorrt_llm` package itself.

tensorrt_image = tensorrt_image.apt_install(
    "openmpi-bin", "libopenmpi-dev", "git", "git-lfs", "wget"
).pip_install(
    "tensorrt-llm==0.18.0",
    "pynvml<12",  # avoid breaking change to pynvml version API
    pre=True,
    extra_index_url="https://pypi.nvidia.com",
)

# Note that we're doing this by [method-chaining](https://quanticdev.com/articles/method-chaining/)
# a number of calls to methods on the `modal.Image`. If you're familiar with
# Dockerfiles, you can think of this as a Pythonic interface to instructions like `RUN` and `CMD`.

# End-to-end, this step takes about five minutes on first run.
# If you're reading this from top to bottom,
# you might want to stop here and execute the example
# with `modal run` so that it runs in the background while you read the rest.

# ## Downloading the model

# Next, we'll set up a few things to download the model to persistent storage and do it quickly --
# this is a latency-optimized example after all! For persistent, distributed storage, we use
# [Modal Volumes](https://modal.com/docs/guide/volumes), which can be accessed from any container
# with read speeds in excess of a gigabyte per second.

# We also set the `HF_HOME` environment variable to point to the Volume so that the model
# is cached there. And we install `hf-transfer` to get maximum download throughput from
# the Hugging Face Hub, in the hundreds of megabytes per second.

volume = modal.Volume.from_name(
    "example-trtllm-inference-volume", create_if_missing=True
)
VOLUME_PATH = Path("/vol")
MODELS_PATH = VOLUME_PATH / "models"

MODEL_ID = "NousResearch/Meta-Llama-3-8B-Instruct"  # fork without repo gating
MODEL_REVISION = "53346005fb0ef11d3b6a83b12c895cca40156b6c"

tensorrt_image = tensorrt_image.pip_install(
    "hf-transfer==0.1.9",
    "huggingface_hub==0.28.1",
).env(
    {
        "HF_HUB_ENABLE_HF_TRANSFER": "1",
        "HF_HOME": str(MODELS_PATH),
    }
)

with tensorrt_image.imports():
    import os

    import torch
    from tensorrt_llm import LLM, SamplingParams

# ## Setting up the engine

# ### Quantization

# The amount of [GPU RAM](https://modal.com/gpu-glossary/device-hardware/gpu-ram)
# on a single card is a tight constraint for large models:
# RAM is measured in billions of bytes and large models have billions of parameters,
# each of which is two to four bytes.
# The performance cliff if you need to spill to CPU memory is steep,
# so all of those parameters must fit in the GPU memory,
# along with other things like the KV cache built up while processing prompts.

# The simplest way to reduce LLM inference's RAM requirements is to make the model's parameters smaller,
# fitting their values in a smaller number of bits, like four or eight. This is known as _quantization_.

# NVIDIA's [Ada Lovelace/Hopper chips](https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor-architecture),
# like the L40S and H100, are capable of native 8bit floating point calculations
# in their [Tensor Cores](https://modal.com/gpu-glossary/device-hardware/tensor-core),
# so we choose that as our quantization format.
# These GPUs are capable of twice as many floating point operations per second in 8bit as in 16bit --
# about two quadrillion per second on an H100 SXM.

# Quantization buys us two things:

# - faster startup, since less data has to be moved over the network onto CPU and GPU RAM

# - faster inference, since we get twice the FLOP/s and less data has to be moved from GPU RAM into
# [on-chip memory](https://modal.com/gpu-glossary/device-hardware/l1-data-cache) and
# [registers](https://modal.com/gpu-glossary/device-hardware/register-file)
# with each computation

# We'll use TensorRT-LLM's `QuantConfig` to specify that we want `FP8` quantization.
# [See their code](https://github.com/NVIDIA/TensorRT-LLM/blob/88e1c90fd0484de061ecfbacfc78a4a8900a4ace/tensorrt_llm/models/modeling_utils.py#L184)
# for more options.

N_GPUS = 1  # Bumping this to 2 will improve latencies further but not 2x
GPU_CONFIG = f"H100:{N_GPUS}"


def get_quant_config():
    from tensorrt_llm.llmapi import QuantConfig

    return QuantConfig(quant_algo="FP8")


# Quantization is a lossy compression technique. The impact on model quality can be
# minimized by tuning the quantization parameters on even a small dataset. Typically, we
# see less than 2% degradation in evaluation metrics when using `fp8`. We'll use the
# `CalibrationConfig` class to specify the calibration dataset.


def get_calib_config():
    from tensorrt_llm.llmapi import CalibConfig

    return CalibConfig(
        calib_batches=512,
        calib_batch_size=1,
        calib_max_seq_length=2048,
        tokenizer_max_seq_length=4096,
    )


# ### Configure plugins

# TensorRT-LLM is an LLM inference framework built on top of NVIDIA's TensorRT,
# which is a generic inference framework for neural networks.

# TensorRT includes a "plugin" extension system that allows you to adjust behavior,
# like configuring the [CUDA kernels](https://modal.com/gpu-glossary/device-software/kernel)
# used by the engine.
# The [General Matrix Multiply (GEMM)](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html)
# plugin, for instance, adds heavily-optimized matrix multiplication kernels
# from NVIDIA's [cuBLAS library of linear algebra routines](https://docs.nvidia.com/cuda/cublas/).

# We'll specify a number of plugins for our engine implementation.
# The first is
# [multiple profiles](https://github.com/NVIDIA/TensorRT-LLM/blob/b763051ba429d60263949da95c701efe8acf7b9c/docs/source/performance/performance-tuning-guide/useful-build-time-flags.md#multiple-profiles),
# which configures TensorRT to prepare multiple kernels for each high-level operation,
# where different kernels are optimized for different input sizes.
# The second is `paged_kv_cache` which enables a
# [paged attention algorithm](https://arxiv.org/abs/2309.06180)
# for the key-value (KV) cache.

# The last two parameters are GEMM plugins optimized specifically for low latency,
# rather than the more typical high arithmetic throughput,
# the `low_latency` plugins for `gemm` and `gemm_swiglu`.

# The `low_latency_gemm_swiglu_plugin` plugin fuses the two matmul operations
# and non-linearity of the feedforward component of the Transformer block into a single kernel,
# reducing round trips between GPU
# [cache memory](https://modal.com/gpu-glossary/device-hardware/l1-data-cache)
# and RAM. For details on kernel fusion, see
# [this blog post by Horace He of Thinking Machines](https://horace.io/brrr_intro.html).
# Note that at the time of writing, this only works for `FP8` on Hopper GPUs.

# The `low_latency_gemm_plugin` is a variant of the GEMM plugin that brings in latency-optimized
# kernels from NVIDIA's [CUTLASS library](https://github.com/NVIDIA/cutlass).


def get_plugin_config():
    from tensorrt_llm.plugin.plugin import PluginConfig

    return PluginConfig.from_dict(
        {
            "multiple_profiles": True,
            "paged_kv_cache": True,
            "low_latency_gemm_swiglu_plugin": "fp8",
            "low_latency_gemm_plugin": "fp8",
        }
    )


# ### Configure speculative decoding

# Speculative decoding is a technique for generating multiple tokens per step,
# avoiding the auto-regressive bottleneck in the Transformer architecture.
# Generating multiple tokens in parallel exposes more parallelism to the GPU.
# It works best for text that has predicable patterns, like code,
# but it's worth testing for any workload where latency is critical.

# Speculative decoding can use any technique to guess tokens, including running another,
# smaller language model. Here, we'll use a simple, but popular and effective
# speculative decoding strategy called "lookahead decoding",
# which essentially guesses that token sequences from the past will occur again.


def get_speculative_config():
    from tensorrt_llm.llmapi import LookaheadDecodingConfig

    return LookaheadDecodingConfig(
        max_window_size=8,
        max_ngram_size=6,
        max_verification_set_size=8,
    )


# ### Set the build config

# Finally, we'll specify the overall build configuration for the engine. This includes
# more obvious parameters such as the maximum input length, the maximum number of tokens
# to process at once before queueing occurs, and the maximum number of sequences
# to process at once before queueing occurs.

# To minimize latency, we set the maximum number of sequences (the "batch size")
# to just one. We enforce this maximum by setting the number of inputs that the
# Modal Function is allowed to process at once -- `max_concurrent_inputs`.
# The default is `1`, so we don't need to set it, but we are setting it explicitly
# here in case you want to run this code with a different balance of latency and throughput.

MAX_BATCH_SIZE = MAX_CONCURRENT_INPUTS = 1


def get_build_config():
    from tensorrt_llm import BuildConfig

    return BuildConfig(
        plugin_config=get_plugin_config(),
        speculative_decoding_mode="LOOKAHEAD_DECODING",
        max_input_len=8192,
        max_num_tokens=16384,
        max_batch_size=MAX_BATCH_SIZE,
    )


# ## Serving inference under the Doherty Threshold

# Now that we have written the code to compile the engine, we can
# serve it with Modal!

# We start by creating an `App`.

app = modal.App("trtllm-latency")

# Thanks to our [custom container runtime system](https://modal.com/blog/jono-containers-talk),
# even this large container boots in seconds.

# On the first container start, we mount the Volume, download the model, and build the engine,
# which takes a few minutes. Subsequent starts will be much faster,
# as the engine is cached in the Volume and loaded in seconds.

# Container starts are triggered when Modal scales up your Function,
# like the first time you run this code or the first time a request comes in after a period of inactivity.
# For details on optimizing container start latency, see
# [this guide](https://modal.com/docs/guide/cold-start).

# Container lifecycles in Modal are managed via our `Cls` interface, so we define one below
# to separate out the engine startup (`enter`) and engine execution (`generate`).
# For details, see [this guide](https://modal.com/docs/guide/lifecycle-functions).

MINUTES = 60  # seconds


@app.cls(
    image=tensorrt_image,
    gpu=GPU_CONFIG,
    scaledown_window=10 * MINUTES,
    timeout=10 * MINUTES,
    volumes={VOLUME_PATH: volume},
)
@modal.concurrent(max_inputs=MAX_CONCURRENT_INPUTS)
class Model:
    mode: str = modal.parameter(default="fast")

    def build_engine(self, engine_path, engine_kwargs) -> None:
        llm = LLM(model=self.model_path, **engine_kwargs)
        llm.save(engine_path)
        return llm

    @modal.enter()
    def enter(self):
        from huggingface_hub import snapshot_download
        from transformers import AutoTokenizer

        self.model_path = MODELS_PATH / MODEL_ID

        print("downloading base model if necessary")
        snapshot_download(
            MODEL_ID,
            local_dir=self.model_path,
            ignore_patterns=["*.pt", "*.bin"],  # using safetensors
            revision=MODEL_REVISION,
        )
        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)

        if self.mode == "fast":
            engine_kwargs = {
                "quant_config": get_quant_config(),
                "calib_config": get_calib_config(),
                "build_config": get_build_config(),
                "speculative_config": get_speculative_config(),
                "tensor_parallel_size": torch.cuda.device_count(),
            }
        else:
            engine_kwargs = {
                "tensor_parallel_size": torch.cuda.device_count(),
            }

        self.sampling_params = SamplingParams(
            temperature=0.8,
            top_p=0.95,
            max_tokens=1024,  # max generated tokens
            lookahead_config=engine_kwargs.get("speculative_config"),
        )

        engine_path = self.model_path / "trtllm_engine" / self.mode
        if not os.path.exists(engine_path):
            print(f"building new engine at {engine_path}")
            self.llm = self.build_engine(engine_path, engine_kwargs)
        else:
            print(f"loading engine from {engine_path}")
            self.llm = LLM(model=engine_path, **engine_kwargs)

    @modal.method()
    def generate(self, prompt) -> dict:
        start_time = time.perf_counter()
        text = self.text_from_prompt(prompt)
        output = self.llm.generate(text, self.sampling_params)
        latency_ms = (time.perf_counter() - start_time) * 1000

        return output.outputs[0].text, latency_ms

    @modal.method()
    async def generate_async(self, prompt):
        text = self.text_from_prompt(prompt)
        async for output in self.llm.generate_async(
            text, self.sampling_params, streaming=True
        ):
            yield output.outputs[0].text_diff

    def text_from_prompt(self, prompt):
        SYSTEM_PROMPT = (
            "You are a helpful, harmless, and honest AI assistant created by Meta."
        )

        if isinstance(prompt, str):
            prompt = [{"role": "user", "content": prompt}]

        messages = [{"role": "system", "content": SYSTEM_PROMPT}] + prompt

        return self.tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

    @modal.method()
    def boot(self):
        pass  # no-op to start up containers

    @modal.exit()
    def shutdown(self):
        self.llm.shutdown()
        del self.llm


# ## Calling our inference function

# To run our `Model`'s `.generate` method from Python, we just need to call it --
# with `.remote` appended to run it on Modal.

# We wrap that logic in a `local_entrypoint` so you can run it from the command line with

# ```bash
# modal run trtllm_latency.py
# ```

# which will output something like:

# ```
# mode=fast inference latency (p50, p90): (211.17ms, 883.27ms)
# ```

# Use `--mode=slow` to see model latency without optimizations.

# ```bash
# modal run trtllm_latency.py --mode=slow
# ```

# which will output something like

# ```
# mode=slow inference latency (p50, p90): (1140.88ms, 2274.24ms)
# ```

# For simplicity, we hard-code 10 questions to ask the model,
# then run them one by one while recording the latency of each call.
# But the code in the `local_entrypoint` is just regular Python code
# that runs on your machine -- we wrap it in a CLI automatically --
# so feel free to customize it to your liking.


@app.local_entrypoint()
def main(mode: str = "fast"):
    prompts = [
        "What atoms are in water?",
        "Which F1 team won in 2011?",
        "What is 12 * 9?",
        "Python function to print odd numbers between 1 and 10. Answer with code only.",
        "What is the capital of California?",
        "What's the tallest building in new york city?",
        "What year did the European Union form?",
        "How old was Geoff Hinton in 2022?",
        "Where is Berkeley?",
        "Are greyhounds or poodles faster?",
    ]

    print(f"🏎️  creating container with mode={mode}")
    model = Model(mode=mode)

    print("🏎️  cold booting container")
    model.boot.remote()

    print_queue = []
    latencies_ms = []
    for prompt in prompts:
        generated_text, latency_ms = model.generate.remote(prompt)

        print_queue.append((prompt, generated_text, latency_ms))
        latencies_ms.append(latency_ms)

    time.sleep(3)  # allow remote prints to clear
    for prompt, generated_text, latency_ms in print_queue:
        print(f"Processed prompt in {latency_ms:.2f}ms")
        print(f"Prompt: {prompt}")
        print(f"Generated Text: {generated_text}")
        print("🏎️ " * 20)

    p50 = sorted(latencies_ms)[int(len(latencies_ms) * 0.5) - 1]
    p90 = sorted(latencies_ms)[int(len(latencies_ms) * 0.9) - 1]
    print(f"🏎️  mode={mode} inference latency (p50, p90): ({p50:.2f}ms, {p90:.2f}ms)")


# Once deployed with `modal deploy`, this `Model.generate` function
# can be called from other Python code. It can also be converted to an HTTP endpoint
# for invocation over the Internet by any client.
# For details, see [this guide](https://modal.com/docs/guide/trigger-deployed-functions).

# As a quick demo, we've included some sample chat client code in the
# Python main entrypoint below. To use it, first deploy with

# ```bash
# modal deploy trtllm_latency.py
# ```

# and then run the client with

# ```python notest
# python trtllm_latency.py
# ```


if __name__ == "__main__":
    import sys

    try:
        Model = modal.Cls.from_name("trtllm-latency", "Model")
        print("🏎️  connecting to model")
        model = Model(mode=sys.argv[1] if len(sys.argv) > 1 else "fast")
        model.boot.remote()
    except modal.exception.NotFoundError as e:
        raise SystemError("Deploy this app first with modal deploy") from e

    print("🏎️  starting chat. exit with :q, ctrl+C, or ctrl+D")
    try:
        prompt = []
        while (nxt := input("🏎️  > ")) != ":q":
            prompt.append({"role": "user", "content": nxt})
            resp = ""
            for out in model.generate_async.remote_gen(prompt):
                print(out, end="", flush=True)
                resp += out
            print("\n")
            prompt.append({"role": "assistant", "content": resp})
    except KeyboardInterrupt:
        pass
    except SystemExit:
        pass
    finally:
        print("\n")
        sys.exit(0)


=== GITHUB: 06_gpu_and_ml/llm-serving/sgl_vlm.py ===
# # Run Qwen2-VL on SGLang for Visual QA

# Vision-Language Models (VLMs) are like LLMs with eyes:
# they can generate text based not just on other text,
# but on images as well.

# This example shows how to run a VLM on Modal using the
# [SGLang](https://github.com/sgl-project/sglang) library.

# Here's a sample inference, with the image rendered directly (and at low resolution) in the terminal:

# ![Sample output answering a question about a photo of the Statue of Liberty](https://modal-public-assets.s3.amazonaws.com/sgl_vlm_qa_sol.png)

# ## Setup

# First, we'll import the libraries we need locally
# and define some constants.

import os
import time
import warnings
from typing import Optional
from uuid import uuid4

import modal

# VLMs are generally larger than LLMs with the same cognitive capability.
# LLMs are already hard to run effectively on CPUs, so we'll use a GPU here.
# We find that inference for a single input takes about 3-4 seconds on an A10G.

# You can customize the GPU type and count using the `GPU_TYPE` and `GPU_COUNT` environment variables.
# If you want to see the model really rip, try an `"a100-80gb"` or an `"h100"`
# on a large batch.

GPU_TYPE = os.environ.get("GPU_TYPE", "l40s")
GPU_COUNT = os.environ.get("GPU_COUNT", 1)

GPU_CONFIG = f"{GPU_TYPE}:{GPU_COUNT}"

SGL_LOG_LEVEL = "error"  # try "debug" or "info" if you have issues

MINUTES = 60  # seconds

# We use the [Qwen2-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct)
# model by Alibaba.

MODEL_PATH = "Qwen/Qwen2-VL-7B-Instruct"
MODEL_REVISION = "a7a06a1cc11b4514ce9edcde0e3ca1d16e5ff2fc"
TOKENIZER_PATH = "Qwen/Qwen2-VL-7B-Instruct"
MODEL_CHAT_TEMPLATE = "qwen2-vl"

# We download it from the Hugging Face Hub using the Python function below.


def download_model_to_image():
    import transformers
    from huggingface_hub import snapshot_download

    snapshot_download(
        MODEL_PATH,
        revision=MODEL_REVISION,
        ignore_patterns=["*.pt", "*.bin"],
    )

    # otherwise, this happens on first inference
    transformers.utils.move_cache()


# Modal runs Python functions on containers in the cloud.
# The environment those functions run in is defined by the container's `Image`.
# The block of code below defines our example's `Image`.
cuda_version = "12.8.0"  # should be no greater than host CUDA version
flavor = "devel"  #  includes full CUDA toolkit
operating_sys = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{operating_sys}"

vlm_image = (
    modal.Image.from_registry(f"nvidia/cuda:{tag}", add_python="3.11")
    .pip_install(  # add sglang and some Python dependencies
        "transformers==4.47.1",
        "numpy<2",
        "fastapi[standard]==0.115.4",
        "pydantic==2.9.2",
        "requests==2.32.3",
        "starlette==0.41.2",
        "torch==2.4.0",
        "sglang[all]==0.4.1",
        "sgl-kernel==0.1.0",
        # as per sglang website: https://sgl-project.github.io/start/install.html
        extra_options="--find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/",
    )
    .run_function(  # download the model by running a Python function
        download_model_to_image
    )
    .pip_install(  # add an optional extra that renders images in the terminal
        "term-image==0.7.1"
    )
)

# ## Defining a Visual QA service

# Running an inference service on Modal is as easy as writing inference in Python.

# The code below adds a modal `Cls` to an `App` that runs the VLM.

# We define a method `generate` that takes a URL for an image and a question
# about the image as inputs and returns the VLM's answer.

# By decorating it with `@modal.fastapi_endpoint`, we expose it as an HTTP endpoint,
# so it can be accessed over the public Internet from any client.

app = modal.App("example-sgl-vlm")


@app.cls(
    gpu=GPU_CONFIG,
    timeout=20 * MINUTES,
    scaledown_window=20 * MINUTES,
    image=vlm_image,
)
@modal.concurrent(max_inputs=100)
class Model:
    @modal.enter()  # what should a container do after it starts but before it gets input?
    def start_runtime(self):
        """Starts an SGL runtime to execute inference."""
        import sglang as sgl

        self.runtime = sgl.Runtime(
            model_path=MODEL_PATH,
            tokenizer_path=TOKENIZER_PATH,
            tp_size=GPU_COUNT,  # t_ensor p_arallel size, number of GPUs to split the model over
            log_level=SGL_LOG_LEVEL,
        )
        self.runtime.endpoint.chat_template = sgl.lang.chat_template.get_chat_template(
            MODEL_CHAT_TEMPLATE
        )
        sgl.set_default_backend(self.runtime)

    @modal.fastapi_endpoint(method="POST", docs=True)
    def generate(self, request: dict) -> str:
        from pathlib import Path

        import requests
        import sglang as sgl
        from term_image.image import from_file

        start = time.monotonic_ns()
        request_id = uuid4()
        print(f"Generating response to request {request_id}")

        image_url = request.get("image_url")
        if image_url is None:
            image_url = (
                "https://modal-public-assets.s3.amazonaws.com/golden-gate-bridge.jpg"
            )

        response = requests.get(image_url)
        response.raise_for_status()

        image_filename = image_url.split("/")[-1]
        image_path = Path(f"/tmp/{uuid4()}-{image_filename}")
        image_path.write_bytes(response.content)

        @sgl.function
        def image_qa(s, image_path, question):
            s += sgl.user(sgl.image(str(image_path)) + question)
            s += sgl.assistant(sgl.gen("answer"))

        question = request.get("question")
        if question is None:
            question = "What is this?"

        state = image_qa.run(
            image_path=image_path, question=question, max_new_tokens=128
        )
        # show the question and image in the terminal for demonstration purposes
        print(Colors.BOLD, Colors.GRAY, "Question: ", question, Colors.END, sep="")
        terminal_image = from_file(image_path)
        terminal_image.draw()
        print(
            f"request {request_id} completed in {round((time.monotonic_ns() - start) / 1e9, 2)} seconds"
        )

        return state["answer"]

    @modal.exit()  # what should a container do before it shuts down?
    def shutdown_runtime(self):
        self.runtime.shutdown()


# ## Asking questions about images via POST

# Now, we can send this Modal Function a POST request with an image and a question
# and get back an answer.

# The code below will start up the inference service
# so that it can be run from the terminal as a one-off,
# like a local script would be, using `modal run`:

# ```bash
# modal run sgl_vlm.py
# ```

# By default, we hit the endpoint twice to demonstrate how much faster
# the inference is once the server is running.


@app.local_entrypoint()
def main(
    image_url: Optional[str] = None, question: Optional[str] = None, twice: bool = True
):
    import json
    import urllib.request

    model = Model()

    payload = json.dumps(
        {
            "image_url": image_url,
            "question": question,
        },
    )

    req = urllib.request.Request(
        model.generate.get_web_url(),
        data=payload.encode("utf-8"),
        headers={"Content-Type": "application/json"},
        method="POST",
    )

    with urllib.request.urlopen(req) as response:
        assert response.getcode() == 200, response.getcode()
        print(json.loads(response.read().decode()))

    if twice:
        # second response is faster, because the Function is already running
        with urllib.request.urlopen(req) as response:
            assert response.getcode() == 200, response.getcode()
            print(json.loads(response.read().decode()))


# ## Deployment

# To set this up as a long-running, but serverless, service, we can deploy it to Modal:

# ```bash
# modal deploy sgl_vlm.py
# ```

# And then send requests from anywhere. See the [docs](https://modal.com/docs/guide/webhook-urls)
# for details on the `web_url` of the function, which also appears in the terminal output
# when running `modal deploy`.

# You can also find interactive documentation for the endpoint at the `/docs` route of the web endpoint URL.

# ## Addenda

# The rest of the code in this example is just utility code.

warnings.filterwarnings(  # filter warning from the terminal image library
    "ignore",
    message="It seems this process is not running within a terminal. Hence, some features will behave differently or be disabled.",
    category=UserWarning,
)


class Colors:
    """ANSI color codes"""

    GREEN = "\033[0;32m"
    BLUE = "\033[0;34m"
    GRAY = "\033[0;90m"
    BOLD = "\033[1m"
    END = "\033[0m"


=== GITHUB: 06_gpu_and_ml/llm-serving/vllm_inference.py ===
# ---
# pytest: false
# ---

# # Run OpenAI-compatible LLM inference with LLaMA 3.1-8B and vLLM

# LLMs do more than just model language: they chat, they produce JSON and XML, they run code, and more.
# This has complicated their interface far beyond "text-in, text-out".
# OpenAI's API has emerged as a standard for that interface,
# and it is supported by open source LLM serving frameworks like [vLLM](https://docs.vllm.ai/en/latest/).

# In this example, we show how to run a vLLM server in OpenAI-compatible mode on Modal.

# Our examples repository also includes scripts for running clients and load-testing for OpenAI-compatible APIs
# [here](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/llm-serving/openai_compatible).

# You can find a (somewhat out-of-date) video walkthrough of this example and the related scripts on the Modal YouTube channel
# [here](https://www.youtube.com/watch?v=QmY_7ePR1hM).

# ## Set up the container image

# Our first order of business is to define the environment our server will run in:
# the [container `Image`](https://modal.com/docs/guide/custom-container).
# vLLM can be installed with `pip`, since Modal [provides the CUDA drivers](https://modal.com/docs/guide/cuda).

# To take advantage of optimized kernels for CUDA 12.8, we install PyTorch, flashinfer, and their dependencies
# via an `extra` Python package index.

import json
from typing import Any

import aiohttp
import modal

vllm_image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "vllm==0.9.1",
        "huggingface_hub[hf_transfer]==0.32.0",
        "flashinfer-python==0.2.6.post1",
        extra_index_url="https://download.pytorch.org/whl/cu128",
    )
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})  # faster model transfers
)

# ## Download the model weights

# We'll be running a pretrained foundation model -- Meta's LLaMA 3.1 8B
# in the Instruct variant that's trained to chat and follow instructions.

# Model parameters are often quantized to a lower precision during training
# than they are run at during inference.
# We'll use an eight bit floating point quantization from Neural Magic/Red Hat.
# Native hardware support for FP8 formats in [Tensor Cores](https://modal.com/gpu-glossary/device-hardware/tensor-core)
# is limited to the latest [Streaming Multiprocessor architectures](https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor-architecture),
# like those of Modal's [Hopper H100/H200 and Blackwell B200 GPUs](https://modal.com/blog/announcing-h200-b200).

# You can swap this model out for another by changing the strings below.
# A single B200 GPUs has enough VRAM to store a 70,000,000,000 parameter model,
# like Llama 3.3, in eight bit precision, along with a very large KV cache.

MODEL_NAME = "RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8"
MODEL_REVISION = "12fd6884d2585dd4d020373e7f39f74507b31866"  # avoid nasty surprises when repos update!

# Although vLLM will download weights from Hugging Face on-demand,
# we want to cache them so we don't do it every time our server starts.
# We'll use [Modal Volumes](https://modal.com/docs/guide/volumes) for our cache.
# Modal Volumes are essentially a "shared disk" that all Modal Functions can access like it's a regular disk.

hf_cache_vol = modal.Volume.from_name("huggingface-cache", create_if_missing=True)

# We'll also cache some of vLLM's JIT compilation artifacts in a Modal Volume.

vllm_cache_vol = modal.Volume.from_name("vllm-cache", create_if_missing=True)

# ## Configuring vLLM

# ### The V1 engine

# In its 0.7 release, in early 2025, vLLM added a new version of its backend infrastructure,
# the [V1 Engine](https://blog.vllm.ai/2025/01/27/v1-alpha-release.html).
# Using this new engine can lead to some [impressive speedups](https://github.com/modal-labs/modal-examples/pull/1064).
# It was made the default in version 0.8 and is [slated for complete removal by 0.11](https://github.com/vllm-project/vllm/issues/18571),
# in late summer of 2025.

# A small number of features, described in the RFC above, may still require the V0 engine prior to removal.
# Until deprecation, you can use it by setting the below environment variable to `0`.

vllm_image = vllm_image.env({"VLLM_USE_V1": "1"})

# ### Trading off fast boots and token generation performance

# vLLM has embraced dynamic and just-in-time compilation to eke out additional performance without having to write too many custom kernels,
# e.g. via the Torch compiler and CUDA graph capture.
# These compilation features incur latency at startup in exchange for lowered latency and higher throughput during generation.
# We make this trade-off controllable with the `FAST_BOOT` variable below.

FAST_BOOT = True

# If you're running an LLM service that frequently scales from 0 (frequent ["cold starts"](https://modal.com/docs/guide/cold-start))
# then you'll want to set this to `True`.

# If you're running an LLM service that usually has multiple replicas running, then set this to `False` for improved performance.

# See the code below for details on the parameters that `FAST_BOOT` controls.

# For more on the performance you can expect when serving your own LLMs, see
# [our LLM engine performance benchmarks](https://modal.com/llm-almanac).

# ## Build a vLLM engine and serve it

# The function below spawns a vLLM instance listening at port 8000, serving requests to our model.
# We wrap it in the [`@modal.web_server` decorator](https://modal.com/docs/guide/webhooks#non-asgi-web-servers)
# to connect it to the Internet.

# The server runs in an independent process, via `subprocess.Popen`, and only starts accepting requests
# once the model is spun up and the `serve` function returns.


app = modal.App("example-vllm-openai-compatible")

N_GPU = 1
MINUTES = 60  # seconds
VLLM_PORT = 8000


@app.function(
    image=vllm_image,
    gpu=f"B200:{N_GPU}",
    scaledown_window=15 * MINUTES,  # how long should we stay up with no requests?
    timeout=10 * MINUTES,  # how long should we wait for container start?
    volumes={
        "/root/.cache/huggingface": hf_cache_vol,
        "/root/.cache/vllm": vllm_cache_vol,
    },
)
@modal.concurrent(  # how many requests can one replica handle? tune carefully!
    max_inputs=32
)
@modal.web_server(port=VLLM_PORT, startup_timeout=10 * MINUTES)
def serve():
    import subprocess

    cmd = [
        "vllm",
        "serve",
        "--uvicorn-log-level=info",
        MODEL_NAME,
        "--revision",
        MODEL_REVISION,
        "--served-model-name",
        MODEL_NAME,
        "llm",
        "--host",
        "0.0.0.0",
        "--port",
        str(VLLM_PORT),
    ]

    # enforce-eager disables both Torch compilation and CUDA graph capture
    # default is no-enforce-eager. see the --compilation-config flag for tighter control
    cmd += ["--enforce-eager" if FAST_BOOT else "--no-enforce-eager"]

    # assume multiple GPUs are for splitting up large matrix multiplications
    cmd += ["--tensor-parallel-size", str(N_GPU)]

    print(cmd)

    subprocess.Popen(" ".join(cmd), shell=True)


# ## Deploy the server

# To deploy the API on Modal, just run
# ```bash
# modal deploy vllm_inference.py
# ```

# This will create a new app on Modal, build the container image for it if it hasn't been built yet,
# and deploy the app.

# ## Interact with the server

# Once it is deployed, you'll see a URL appear in the command line,
# something like `https://your-workspace-name--example-vllm-openai-compatible-serve.modal.run`.

# You can find [interactive Swagger UI docs](https://swagger.io/tools/swagger-ui/)
# at the `/docs` route of that URL, i.e. `https://your-workspace-name--example-vllm-openai-compatible-serve.modal.run/docs`.
# These docs describe each route and indicate the expected input and output
# and translate requests into `curl` commands.

# For simple routes like `/health`, which checks whether the server is responding,
# you can even send a request directly from the docs.

# To interact with the API programmatically in Python, we recommend the `openai` library.

# See the `client.py` script in the examples repository
# [here](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/llm-serving/openai_compatible)
# to take it for a spin:

# ```bash
# # pip install openai==1.76.0
# python openai_compatible/client.py
# ```


# ## Testing the server

# To make it easier to test the server setup, we also include a `local_entrypoint`
# that does a healthcheck and then hits the server.

# If you execute the command

# ```bash
# modal run vllm_inference.py
# ```

# a fresh replica of the server will be spun up on Modal while
# the code below executes on your local machine.

# Think of this like writing simple tests inside of the `if __name__ == "__main__"`
# block of a Python script, but for cloud deployments!


@app.local_entrypoint()
async def test(test_timeout=10 * MINUTES, content=None, twice=True):
    url = serve.get_web_url()

    system_prompt = {
        "role": "system",
        "content": "You are a pirate who can't help but drop sly reminders that he went to Harvard.",
    }
    if content is None:
        content = "Explain the singular value decomposition."

    messages = [  # OpenAI chat format
        system_prompt,
        {"role": "user", "content": content},
    ]

    async with aiohttp.ClientSession(base_url=url) as session:
        print(f"Running health check for server at {url}")
        async with session.get("/health", timeout=test_timeout - 1 * MINUTES) as resp:
            up = resp.status == 200
        assert up, f"Failed health check for server at {url}"
        print(f"Successful health check for server at {url}")

        print(f"Sending messages to {url}:", *messages, sep="\n\t")
        await _send_request(session, "llm", messages)
        if twice:
            messages[0]["content"] = "You are Jar Jar Binks."
            print(f"Sending messages to {url}:", *messages, sep="\n\t")
            await _send_request(session, "llm", messages)


async def _send_request(
    session: aiohttp.ClientSession, model: str, messages: list
) -> None:
    # `stream=True` tells an OpenAI-compatible backend to stream chunks
    payload: dict[str, Any] = {"messages": messages, "model": model, "stream": True}

    headers = {"Content-Type": "application/json", "Accept": "text/event-stream"}

    async with session.post(
        "/v1/chat/completions", json=payload, headers=headers, timeout=1 * MINUTES
    ) as resp:
        async for raw in resp.content:
            resp.raise_for_status()
            # extract new content and stream it
            line = raw.decode().strip()
            if not line or line == "data: [DONE]":
                continue
            if line.startswith("data: "):  # SSE prefix
                line = line[len("data: ") :]

            chunk = json.loads(line)
            assert (
                chunk["object"] == "chat.completion.chunk"
            )  # or something went horribly wrong
            print(chunk["choices"][0]["delta"]["content"], end="")
    print()


# We also include a basic example of a load-testing setup using
# `locust` in the `load_test.py` script [here](https://github.com/modal-labs/modal-examples/tree/main/06_gpu_and_ml/llm-serving/openai_compatible):

# ```bash
# modal run openai_compatible/load_test.py
# ```


=== GITHUB: 06_gpu_and_ml/llm-serving/ollama.py ===
# ---
# ---

# # Run open-source LLMs with Ollama on Modal

# [Ollama](https://ollama.com/) is a popular tool for running open-source large language models (LLMs) locally.
# It provides a simple API, including OpenAI compatibility, allowing you to interact with various models like
# Llama, Mistral, Phi, and more.

# In this example, we demonstrate how to run Ollama on Modal's cloud infrastructure, leveraging:
#
# 1. Modal's powerful GPU resources that far exceed what's available on most local machines
# 2. Serverless design that scales to zero when not in use (saving costs)
# 3. Persistent model storage using Modal Volumes
# 4. Web-accessible endpoints that expose Ollama's OpenAI-compatible API

# Since the Ollama server provides its own REST API, we use Modal's web_server decorator
# to expose these endpoints directly to the internet.

import asyncio
import subprocess
from typing import List

import modal

# ## Configuration and Constants

# Directory for Ollama models within the container and volume
MODEL_DIR = "/ollama_models"

# Define the models we want to work with
# You can specify different model versions using the format "model:tag"
MODELS_TO_DOWNLOAD = ["llama3.1:8b", "llama3.3:70b"]  # Downloaded at startup
MODELS_TO_TEST = ["llama3.1:8b", "llama3.3:70b"]  # Tested in our example

# Ollama version to install - you may need to update this for the latest models
OLLAMA_VERSION = "0.6.5"
# Ollama's default port - we'll expose this through Modal
OLLAMA_PORT = 11434

# ## Building the Container Image

# First, we create a Modal Image that includes Ollama and its dependencies.
# We use the official Ollama installation script to set up the Ollama binary.

ollama_image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("curl", "ca-certificates")
    .pip_install(
        "fastapi==0.115.8",
        "uvicorn[standard]==0.34.0",
        "openai~=1.30",  # Pin OpenAI version for compatibility
    )
    .run_commands(
        "echo 'Installing Ollama...'",
        f"OLLAMA_VERSION={OLLAMA_VERSION} curl -fsSL https://ollama.com/install.sh | sh",
        "echo 'Ollama installed at $(which ollama)'",
        f"mkdir -p {MODEL_DIR}",
    )
    .env(
        {
            # Configure Ollama to serve on its default port
            "OLLAMA_HOST": f"0.0.0.0:{OLLAMA_PORT}",
            "OLLAMA_MODELS": MODEL_DIR,  # Tell Ollama where to store models
        }
    )
)

# Create a Modal App, which groups our functions together
app = modal.App("ollama-server", image=ollama_image)

# ## Persistent Storage for Models

# We use a Modal Volume to cache downloaded models between runs.
# This prevents needing to re-download large model files each time.

model_volume = modal.Volume.from_name("ollama-models-store", create_if_missing=True)

# ## The Ollama Server Class

# We define an OllamaServer class to manage the Ollama process.
# This class handles:
# - Starting the Ollama server
# - Downloading required models
# - Exposing the API via Modal's web_server
# - Running test requests against the served models


@app.cls(
    gpu="H100",  # Use H100 GPUs for best performance
    volumes={MODEL_DIR: model_volume},  # Mount our model storage
    timeout=60 * 5,  # 5 minutes max input runtime
    min_containers=1,  # Keep at least one container running for fast startup
)
class OllamaServer:
    ollama_process: subprocess.Popen | None = None

    @modal.enter()
    async def start_ollama(self):
        """Starts the Ollama server and ensures required models are downloaded."""
        print("Starting Ollama setup...")

        print(f"Starting Ollama server on port {OLLAMA_PORT}...")
        cmd = ["ollama", "serve"]
        self.ollama_process = subprocess.Popen(cmd)
        print(f"Ollama server started with PID: {self.ollama_process.pid}")

        # Wait for server to initialize
        await asyncio.sleep(10)
        print("Ollama server should be ready.")

        # --- Model Management ---
        # Check which models are already downloaded, and pull any that are missing
        loop = asyncio.get_running_loop()
        models_pulled = False  # Track if we pulled any model

        # Get list of currently available models
        ollama_list_proc = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True
        )

        if ollama_list_proc.returncode != 0:
            print(f"Error: 'ollama list' failed: {ollama_list_proc.stderr}")
            raise RuntimeError(
                f"Failed to list Ollama models: {ollama_list_proc.stderr}"
            )

        current_models_output = ollama_list_proc.stdout
        print("Current models detected:", current_models_output)

        # Download each requested model if not already present
        for model_name in MODELS_TO_DOWNLOAD:
            print(f"Checking for model: {model_name}")
            model_tag_to_check = (
                model_name if ":" in model_name else f"{model_name}:latest"
            )

            if model_tag_to_check not in current_models_output:
                print(
                    f"Model '{model_name}' not found. Pulling (output will stream directly)..."
                )
                models_pulled = True  # Mark that a pull is happening

                # Pull the model - this can take a while for large models
                pull_process = await asyncio.create_subprocess_exec(
                    "ollama",
                    "pull",
                    model_name,
                )

                # Wait for the pull process to complete
                retcode = await pull_process.wait()

                if retcode != 0:
                    print(f"Error pulling model '{model_name}': exit code {retcode}")
                else:
                    print(f"Model '{model_name}' pulled successfully.")
            else:
                print(f"Model '{model_name}' already exists.")

            # Commit the volume only if we actually pulled new models
            if models_pulled:
                print("Committing model volume...")
                await loop.run_in_executor(None, model_volume.commit)
                print("Volume commit finished.")

        print("Ollama setup complete.")

    @modal.exit()
    def stop_ollama(self):
        """Terminates the Ollama server process on shutdown."""
        print("Shutting down Ollama server...")
        if self.ollama_process and self.ollama_process.poll() is None:
            print(f"Terminating Ollama server (PID: {self.ollama_process.pid})...")
            try:
                self.ollama_process.terminate()
                self.ollama_process.wait(timeout=10)
                print("Ollama server terminated.")
            except subprocess.TimeoutExpired:
                print("Ollama server kill required.")
                self.ollama_process.kill()
                self.ollama_process.wait()
            except Exception as e:
                print(f"Error shutting down Ollama server: {e}")
        else:
            print("Ollama server process already exited or not found.")
        print("Shutdown complete.")

    @modal.web_server(port=OLLAMA_PORT, startup_timeout=180)
    def serve(self):
        """
        Exposes the Ollama server's API endpoints through Modal's web_server.

        This is the key function that makes Ollama's API accessible over the internet.
        The web_server decorator maps Modal's HTTPS endpoint to Ollama's internal port.
        """
        print(f"Serving Ollama API on port {OLLAMA_PORT}")

    # ## Running prompt tests
    #
    # The following method allows us to run test prompts against our Ollama models.
    # This is useful for verifying that the models are working correctly and
    # to see how they respond to different types of prompts.

    @modal.method()
    async def run_tests(self):
        import openai
        from openai.types.chat import ChatCompletionMessageParam

        """
        Tests the Ollama server by sending various prompts to each configured model.
        Returns a dictionary of results organized by model.
        """
        print("Running tests inside OllamaServer container...")
        all_results = {}  # Store results per model

        # Configure OpenAI client to use our Ollama server
        base_api_url = f"http://localhost:{OLLAMA_PORT}/v1"
        print(f"Configuring OpenAI client for: {base_api_url}")
        client = openai.AsyncOpenAI(
            base_url=base_api_url,
            api_key="not-needed",  # Ollama doesn't require API keys
        )

        # Define some test prompts
        test_prompts = [
            "Explain the theory of relativity in simple terms.",
            "Write a short poem about a cat watching rain.",
            "What are the main benefits of using Python?",
        ]

        # Test each model with each prompt
        for model_name in MODELS_TO_TEST:
            print(f"\n===== Testing Model: {model_name} =====")
            model_results = []
            all_results[model_name] = model_results

            for prompt in test_prompts:
                print(f"\n--- Testing Prompt ---\n{prompt}\n----------------------")

                # Create message in OpenAI format
                messages: List[ChatCompletionMessageParam] = [
                    {"role": "user", "content": prompt}
                ]

                try:
                    # Call the Ollama API through the OpenAI client
                    response = await client.chat.completions.create(
                        model=model_name,
                        messages=messages,
                        stream=False,
                    )
                    assistant_message = response.choices[0].message.content
                    print(f"Assistant Response:\n{assistant_message}")
                    model_results.append(
                        {
                            "prompt": prompt,
                            "status": "success",
                            "response": assistant_message,
                        }
                    )
                except Exception as e:
                    print(
                        f"Error during API call for model '{model_name}', prompt '{prompt}': {e}"
                    )
                    model_results.append(
                        {"prompt": prompt, "status": "error", "error": str(e)}
                    )

        print("Internal tests finished.")
        return all_results


# ## Running the Example

# This local entrypoint function provides a simple way to test the Ollama server.
# When you run `modal run ollama.py`, this function will:
# 1. Start an OllamaServer instance in the cloud
# 2. Run test prompts against each configured model
# 3. Print a summary of the results


@app.local_entrypoint()
async def local_main():
    """
    Tests the Ollama server with sample prompts and prints the results.

    Run with: `modal run ollama.py`
    """
    print("Triggering test suite on the OllamaServer...")
    all_test_results = await OllamaServer().run_tests.remote.aio()
    print("\n--- Test Suite Summary ---")

    if all_test_results:
        for model_name, results in all_test_results.items():
            print(f"\n===== Results for Model: {model_name} =====")
            successful_tests = 0
            if results:
                for result in results:
                    print(f"Prompt: {result['prompt']}")
                    print(f"Status: {result['status']}")
                    if result["status"] == "error":
                        print(f"Error: {result['error']}")
                    else:
                        successful_tests += 1
                    print("----")
                print(
                    f"\nSummary for {model_name}: Total tests: {len(results)}, Successful: {successful_tests}"
                )
            else:
                print("No results returned for this model.")
    else:
        print("No results returned from test function.")

    print("\nTest finished. Your Ollama server is ready to use!")


# ## Deploying to Production
#
# While the local entrypoint is great for testing, for production use you'll want to deploy
# this application persistently. You can do this with:
#
# ```bash
# modal deploy ollama.py
# ```
#
# This creates a persistent deployment that:
#
# 1. Provides a stable URL endpoint for your Ollama API
# 2. Keeps at least one container warm for fast responses
# 3. Scales automatically based on usage
# 4. Preserves your models in the persistent volume between invocations
#
# After deployment, you can find your endpoint URL in your Modal dashboard.
#
# You can then use this endpoint with any OpenAI-compatible client by setting:
#
# ```
# OPENAI_API_BASE=https://your-endpoint-url
# OPENAI_API_KEY=any-value  # Ollama doesn't require authentication
# ```


=== GITHUB: 06_gpu_and_ml/llm-serving/openai_compatible/locustfile.py ===
import logging
import random

import locust

messages = [
    {
        "role": "system",
        "content": "You are a salesman for Modal, the cloud-native serverless Python computing platform.",
    },
    {
        "role": "user",
        "content": "Give me two fun date ideas.",
    },
]


class WebsiteUser(locust.HttpUser):
    wait_time = locust.between(1, 5)
    headers = {
        "Authorization": "Bearer super-secret-key",
        "Accept": "application/json",
    }

    @locust.task
    def chat_completion(self):
        payload = {
            "model": "neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16",
            "messages": messages,
        }

        response = self.client.request(
            "POST", "/v1/chat/completions", json=payload, headers=self.headers
        )
        response.raise_for_status()
        if random.random() < 0.01:
            logging.info(response.json()["choices"][0]["message"]["content"])


=== GITHUB: 06_gpu_and_ml/llm-serving/openai_compatible/client.py ===
"""This simple script shows how to interact with an OpenAI-compatible server from a client."""

import argparse

import modal
from openai import OpenAI


class Colors:
    """ANSI color codes"""

    GREEN = "\033[0;32m"
    RED = "\033[0;31m"
    BLUE = "\033[0;34m"
    GRAY = "\033[0;90m"
    BOLD = "\033[1m"
    END = "\033[0m"


def get_completion(client, model_id, messages, args):
    completion_args = {
        "model": model_id,
        "messages": messages,
        "frequency_penalty": args.frequency_penalty,
        "max_tokens": args.max_tokens,
        "n": args.n,
        "presence_penalty": args.presence_penalty,
        "seed": args.seed,
        "stop": args.stop,
        "stream": args.stream,
        "temperature": args.temperature,
        "top_p": args.top_p,
    }

    completion_args = {k: v for k, v in completion_args.items() if v is not None}

    try:
        response = client.chat.completions.create(**completion_args)
        return response
    except Exception as e:
        print(Colors.RED, f"Error during API call: {e}", Colors.END, sep="")
        return None


def main():
    parser = argparse.ArgumentParser(description="OpenAI Client CLI")

    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="The model to use for completion, defaults to the first available model",
    )
    parser.add_argument(
        "--workspace",
        type=str,
        default=None,
        help="The workspace where the LLM server app is hosted, defaults to your current Modal workspace",
    )
    parser.add_argument(
        "--environment",
        type=str,
        default=None,
        help="The environment in your Modal workspace where the LLM server app is hosted, defaults to your current environment",
    )
    parser.add_argument(
        "--app-name",
        type=str,
        default="example-vllm-openai-compatible",
        help="A Modal App serving an OpenAI-compatible API",
    )
    parser.add_argument(
        "--function-name",
        type=str,
        default="serve",
        help="A Modal Function serving an OpenAI-compatible API. Append `-dev` to use a `modal serve`d Function.",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default="super-secret-key",
        help="The API key to use for authentication, set in your api.py",
    )

    # Completion parameters
    parser.add_argument("--max-tokens", type=int, default=None)
    parser.add_argument("--temperature", type=float, default=0.7)
    parser.add_argument("--top-p", type=float, default=0.9)
    parser.add_argument("--top-k", type=int, default=0)
    parser.add_argument("--frequency-penalty", type=float, default=0)
    parser.add_argument("--presence-penalty", type=float, default=0)
    parser.add_argument(
        "--n",
        type=int,
        default=1,
        help="Number of completions to generate. Streaming and chat mode only support n=1.",
    )
    parser.add_argument("--stop", type=str, default=None)
    parser.add_argument("--seed", type=int, default=None)

    # Prompting
    parser.add_argument(
        "--prompt",
        type=str,
        default="Compose a limerick about baboons and racoons.",
        help="The user prompt for the chat completion",
    )
    parser.add_argument(
        "--system-prompt",
        type=str,
        default="You are a poetic assistant, skilled in writing satirical doggerel with creative flair.",
        help="The system prompt for the chat completion",
    )

    # UI options
    parser.add_argument(
        "--no-stream",
        dest="stream",
        action="store_false",
        help="Disable streaming of response chunks",
    )
    parser.add_argument(
        "--chat", action="store_true", help="Enable interactive chat mode"
    )

    args = parser.parse_args()

    client = OpenAI(api_key=args.api_key)

    workspace = args.workspace or modal.config._profile

    environment = args.environment or modal.config.config["environment"]

    prefix = workspace + (f"-{environment}" if environment else "")

    client.base_url = (
        f"https://{prefix}--{args.app_name}-{args.function_name}.modal.run/v1"
    )

    if args.model:
        model_id = args.model
        print(
            Colors.BOLD,
            f"🧠: Using model {model_id}. This may trigger a model load on first call!",
            Colors.END,
            sep="",
        )
    else:
        print(
            Colors.BOLD,
            f"🔎: Looking up available models on server at {client.base_url}. This may trigger a model load!",
            Colors.END,
            sep="",
        )
        model = client.models.list().data[0]
        model_id = model.id
        print(
            Colors.BOLD,
            f"🧠: Using {model_id}",
            Colors.END,
            sep="",
        )

    messages = [
        {
            "role": "system",
            "content": args.system_prompt,
        }
    ]

    print(Colors.BOLD + "🧠: Using system prompt: " + args.system_prompt + Colors.END)

    if args.chat:
        print(
            Colors.GREEN
            + Colors.BOLD
            + "\nEntering chat mode. Type 'bye' to end the conversation."
            + Colors.END
        )
        while True:
            user_input = input("\nYou: ")
            if user_input.lower() in ["bye"]:
                break

            MAX_HISTORY = 10
            if len(messages) > MAX_HISTORY:
                messages = messages[:1] + messages[-MAX_HISTORY + 1 :]

            messages.append({"role": "user", "content": user_input})

            response = get_completion(client, model_id, messages, args)

            if response:
                if args.stream:
                    # only stream assuming n=1
                    print(Colors.BLUE + "\n🤖: ", end="")
                    assistant_message = ""
                    for chunk in response:
                        if chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            print(content, end="")
                            assistant_message += content
                    print(Colors.END)
                else:
                    assistant_message = response.choices[0].message.content
                    print(
                        Colors.BLUE + "\n🤖:" + assistant_message + Colors.END,
                        sep="",
                    )

                messages.append({"role": "assistant", "content": assistant_message})
    else:
        messages.append({"role": "user", "content": args.prompt})
        print(Colors.GREEN + f"\nYou: {args.prompt}" + Colors.END)
        response = get_completion(client, model_id, messages, args)
        if response:
            if args.stream:
                print(Colors.BLUE + "\n🤖:", end="")
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        print(chunk.choices[0].delta.content, end="")
                print(Colors.END)
            else:
                # only case where multiple completions are returned
                for i, response in enumerate(response.choices):
                    print(
                        Colors.BLUE
                        + f"\n🤖 Choice {i + 1}:{response.message.content}"
                        + Colors.END,
                        sep="",
                    )


if __name__ == "__main__":
    main()


=== GITHUB: 06_gpu_and_ml/llm-serving/openai_compatible/load_test.py ===
import os
from datetime import datetime, timezone
from pathlib import Path, PosixPath

import modal

if modal.is_local():
    workspace = modal.config._profile
    environment = modal.config.config.get("environment") or ""
else:
    workspace = os.environ["MODAL_WORKSPACE"]
    environment = os.environ["MODAL_ENVIRONMENT"]


image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("locust~=2.36.2", "openai~=1.37.1")
    .env({"MODAL_WORKSPACE": workspace, "MODAL_ENVIRONMENT": environment})
    .add_local_file(
        Path(__file__).parent / "locustfile.py",
        remote_path="/root/locustfile.py",
    )
)

volume = modal.Volume.from_name("loadtest-vllm-oai-results", create_if_missing=True)
remote_path = Path("/root") / "loadtests"
OUT_DIRECTORY = (
    remote_path / datetime.now(timezone.utc).replace(microsecond=0).isoformat()
)

app = modal.App("loadtest-vllm-oai", image=image, volumes={remote_path: volume})

workers = 8

prefix = workspace + (f"-{environment}" if environment else "")
host = f"https://{prefix}--example-vllm-openai-compatible-serve.modal.run"

csv_file = OUT_DIRECTORY / "stats.csv"
default_args = [
    "-H",
    host,
    "--processes",
    str(workers),
    "--csv",
    csv_file,
]

MINUTES = 60  # seconds


@app.function(cpu=workers)
@modal.concurrent(max_inputs=1000)
@modal.web_server(port=8089)
def serve():
    run_locust.local(default_args)


@app.function(cpu=workers, timeout=60 * MINUTES)
def run_locust(args: list, wait=False):
    import subprocess

    process = subprocess.Popen(["locust"] + args)
    if wait:
        process.wait()
        return process.returncode


@app.local_entrypoint()
def main(
    r: float = 1.0,
    u: int = 36,
    t: str = "1m",  # no more than the timeout of run_locust, one hour
):
    args = default_args + [
        "--spawn-rate",
        str(r),
        "--users",
        str(u),
        "--run-time",
        t,
    ]

    html_report_file = str(PosixPath(OUT_DIRECTORY / "report.html"))
    args += [
        "--headless",  # run without browser UI
        "--autostart",  # start test immediately
        "--autoquit",  # stop once finished...
        "10",  # ...but wait ten seconds
        "--html",  # output an HTML-formatted report
        html_report_file,  # to this location
    ]

    if exit_code := run_locust.remote(args, wait=True):
        SystemExit(exit_code)
    else:
        print("finished successfully")


=== GITHUB: 06_gpu_and_ml/dreambooth/instance_example_urls.txt ===
https://modal-public-assets.s3.amazonaws.com/example-dreambooth-app/fkRYgv6.png
https://modal-public-assets.s3.amazonaws.com/example-dreambooth-app/98k9yDg.jpg
https://modal-public-assets.s3.amazonaws.com/example-dreambooth-app/gHlW8Kw.jpg


=== GITHUB: 06_gpu_and_ml/dreambooth/diffusers_lora_finetune.py ===
# ---
# deploy: true
# ---

# # Fine-tune Flux on your pet using LoRA

# This example finetunes the [Flux.1-dev model](https://huggingface.co/black-forest-labs/FLUX.1-dev)
# on images of a pet (by default, a puppy named Qwerty)
# using a technique called textual inversion from [the "Dreambooth" paper](https://dreambooth.github.io/).
# Effectively, it teaches a general image generation model a new "proper noun",
# allowing for the personalized generation of art and photos.
# We supplement textual inversion with low-rank adaptation (LoRA)
# for increased efficiency during training.

# It then makes the model shareable with others -- without costing $25/day for a GPU server--
# by hosting a [Gradio app](https://gradio.app/) on Modal.

# It demonstrates a simple, productive, and cost-effective pathway
# to building on large pretrained models using Modal's building blocks, like
# [GPU-accelerated](https://modal.com/docs/guide/gpu) Modal Functions and Clses for compute-intensive work,
# [Volumes](https://modal.com/docs/guide/volumes) for storage,
# and [web endpoints](https://modal.com/docs/guide/webhooks) for serving.

# And with some light customization, you can use it to generate images of your pet!

# ![Gradio.app image generation interface](./gradio-image-generate.png)

# You can find a video walkthrough of this example on the Modal YouTube channel
# [here](https://www.youtube.com/watch?v=df-8fiByXMI).

# ## Imports and setup

# We start by importing the necessary libraries and setting up the environment.

from dataclasses import dataclass
from pathlib import Path

import modal

# ## Building up the environment

# Machine learning environments are complex, and the dependencies can be hard to manage.
# Modal makes creating and working with environments easy via
# [containers and container images](https://modal.com/docs/guide/custom-container).

# We start from a base image and specify all of our dependencies.
# We'll call out the interesting ones as they come up below.
# Note that these dependencies are not installed locally
# -- they are only installed in the remote environment where our Modal App runs.

app = modal.App(name="example-lora-flux")

image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "accelerate==0.31.0",
    "datasets~=2.13.0",
    "fastapi[standard]==0.115.4",
    "ftfy~=6.1.0",
    "gradio~=5.5.0",
    "huggingface-hub==0.26.2",
    "hf_transfer==0.1.8",
    "numpy<2",
    "peft==0.11.1",
    "pydantic==2.9.2",
    "sentencepiece>=0.1.91,!=0.1.92",
    "smart_open~=6.4.0",
    "starlette==0.41.2",
    "transformers~=4.41.2",
    "torch~=2.2.0",
    "torchvision~=0.16",
    "triton~=2.2.0",
    "wandb==0.17.6",
)

# ### Downloading scripts and installing a git repo with `run_commands`

# We'll use an example script from the `diffusers` library to train the model.
# We acquire it from GitHub and install it in our environment with a series of commands.
# The container environments Modal Functions run in are highly flexible --
# see [the docs](https://modal.com/docs/guide/custom-container) for more details.

GIT_SHA = "e649678bf55aeaa4b60bd1f68b1ee726278c0304"  # specify the commit to fetch

image = (
    image.apt_install("git")
    # Perform a shallow fetch of just the target `diffusers` commit, checking out
    # the commit in the container's home directory, /root. Then install `diffusers`
    .run_commands(
        "cd /root && git init .",
        "cd /root && git remote add origin https://github.com/huggingface/diffusers",
        f"cd /root && git fetch --depth=1 origin {GIT_SHA} && git checkout {GIT_SHA}",
        "cd /root && pip install -e .",
    )
)

# ### Configuration with `dataclass`es

# Machine learning apps often have a lot of configuration information.
# We collect up all of our configuration into dataclasses to avoid scattering special/magic values throughout code.


@dataclass
class SharedConfig:
    """Configuration information shared across project components."""

    # The instance name is the "proper noun" we're teaching the model
    instance_name: str = "Qwerty"
    # That proper noun is usually a member of some class (person, bird),
    # and sharing that information with the model helps it generalize better.
    class_name: str = "Golden Retriever"
    # identifier for pretrained models on Hugging Face
    model_name: str = "black-forest-labs/FLUX.1-dev"


# ### Storing data created by our app with `modal.Volume`

# The tools we've used so far work well for fetching external information,
# which defines the environment our app runs in,
# but what about data that we create or modify during the app's execution?
# A persisted [`modal.Volume`](https://modal.com/docs/guide/volumes) can store and share data across Modal Apps and Functions.

# We'll use one to store both the original and fine-tuned weights we create during training
# and then load them back in for inference.

volume = modal.Volume.from_name(
    "dreambooth-finetuning-volume-flux", create_if_missing=True
)
MODEL_DIR = "/model"

# Note that access to the Flux.1-dev model on Hugging Face is
# [gated by a license agreement](https://huggingface.co/docs/hub/en/models-gated) which
# you must agree to [here](https://huggingface.co/black-forest-labs/FLUX.1-dev).
# After you have accepted the license, [create a Modal Secret](https://modal.com/secrets)
# with the name `huggingface-secret` following the instructions in the template.

huggingface_secret = modal.Secret.from_name(
    "huggingface-secret", required_keys=["HF_TOKEN"]
)

image = image.env(
    {"HF_HUB_ENABLE_HF_TRANSFER": "1"}  # turn on faster downloads from HF
)


@app.function(
    volumes={MODEL_DIR: volume},
    image=image,
    secrets=[huggingface_secret],
    timeout=600,  # 10 minutes
)
def download_models(config):
    import torch
    from diffusers import DiffusionPipeline
    from huggingface_hub import snapshot_download

    snapshot_download(
        config.model_name,
        local_dir=MODEL_DIR,
        ignore_patterns=["*.pt", "*.bin"],  # using safetensors
    )

    DiffusionPipeline.from_pretrained(MODEL_DIR, torch_dtype=torch.bfloat16)


# ### Load fine-tuning dataset

# Part of the magic of the low-rank fine-tuning is that we only need 3-10 images for fine-tuning.
# So we can fetch just a few images, stored on consumer platforms like Imgur or Google Drive,
# whenever we need them -- no need for expensive, hard-to-maintain data pipelines.


def load_images(image_urls: list[str]) -> Path:
    import PIL.Image
    from smart_open import open

    img_path = Path("/img")

    img_path.mkdir(parents=True, exist_ok=True)
    for ii, url in enumerate(image_urls):
        with open(url, "rb") as f:
            image = PIL.Image.open(f)
            image.save(img_path / f"{ii}.png")
    print(f"{ii + 1} images loaded")

    return img_path


# ## Low-Rank Adapation (LoRA) fine-tuning for a text-to-image model

# The base model we start from is trained to do a sort of "reverse [ekphrasis](https://en.wikipedia.org/wiki/Ekphrasis)":
# it attempts to recreate a visual work of art or image from only its description.

# We can use the model to synthesize wholly new images
# by combining the concepts it has learned from the training data.

# We use a pretrained model, the Flux model from Black Forest Labs.
# In this example, we "finetune" Flux, making only small adjustments to the weights.
# Furthermore, we don't change all the weights in the model.
# Instead, using a technique called [_low-rank adaptation_](https://arxiv.org/abs/2106.09685),
# we change a much smaller matrix that works "alongside" the existing weights, nudging the model in the direction we want.

# We can get away with such a small and simple training process because we're just teach the model the meaning of a single new word: the name of our pet.

# The result is a model that can generate novel images of our pet:
# as an astronaut in space, as painted by Van Gogh or Bastiat, etc.

# ### Finetuning with Hugging Face 🧨 Diffusers and Accelerate

# The model weights, training libraries, and training script are all provided by [🤗 Hugging Face](https://huggingface.co).

# You can kick off a training job with the command `modal run dreambooth_app.py::app.train`.
# It should take about ten minutes.

# Training machine learning models takes time and produces a lot of metadata --
# metrics for performance and resource utilization,
# metrics for model quality and training stability,
# and model inputs and outputs like images and text.
# This is especially important if you're fiddling around with the configuration parameters.

# This example can optionally use [Weights & Biases](https://wandb.ai) to track all of this training information.
# Just sign up for an account, switch the flag below, and add your API key as a [Modal Secret](https://modal.com/secrets).

USE_WANDB = False

# You can see an example W&B dashboard [here](https://wandb.ai/cfrye59/dreambooth-lora-sd-xl).
# Check out [this run](https://wandb.ai/cfrye59/dreambooth-lora-sd-xl/runs/ca3v1lsh?workspace=user-cfrye59),
# which [despite having high GPU utilization](https://wandb.ai/cfrye59/dreambooth-lora-sd-xl/runs/ca3v1lsh/system)
# suffered from numerical instability during training and produced only black images -- hard to debug without experiment management logs!

# You can read more about how the values in `TrainConfig` are chosen and adjusted [in this blog post on Hugging Face](https://huggingface.co/blog/dreambooth).
# To run training on images of your own pet, upload the images to separate URLs and edit the contents of the file at `TrainConfig.instance_example_urls_file` to point to them.

# Tip: if the results you're seeing don't match the prompt too well, and instead produce an image
# of your subject without taking the prompt into account, the model has likely overfit. In this case, repeat training with a lower
# value of `max_train_steps`. If you used W&B, look back at results earlier in training to determine where to stop.
# On the other hand, if the results don't look like your subject, you might need to increase `max_train_steps`.


@dataclass
class TrainConfig(SharedConfig):
    """Configuration for the finetuning step."""

    # training prompt looks like `{PREFIX} {INSTANCE_NAME} the {CLASS_NAME} {POSTFIX}`
    prefix: str = "a photo of"
    postfix: str = ""

    # locator for plaintext file with urls for images of target instance
    instance_example_urls_file: str = str(
        Path(__file__).parent / "instance_example_urls.txt"
    )

    # Hyperparameters/constants from the huggingface training example
    resolution: int = 512
    train_batch_size: int = 3
    rank: int = 16  # lora rank
    gradient_accumulation_steps: int = 1
    learning_rate: float = 4e-4
    lr_scheduler: str = "constant"
    lr_warmup_steps: int = 0
    max_train_steps: int = 500
    checkpointing_steps: int = 1000
    seed: int = 117


@app.function(
    image=image,
    gpu="A100-80GB",  # fine-tuning is VRAM-heavy and requires a high-VRAM GPU
    volumes={MODEL_DIR: volume},  # stores fine-tuned model
    timeout=1800,  # 30 minutes
    secrets=[huggingface_secret]
    + (
        [modal.Secret.from_name("wandb-secret", required_keys=["WANDB_API_KEY"])]
        if USE_WANDB
        else []
    ),
)
def train(instance_example_urls, config):
    import subprocess

    from accelerate.utils import write_basic_config

    # load data locally
    img_path = load_images(instance_example_urls)

    # set up hugging face accelerate library for fast training
    write_basic_config(mixed_precision="bf16")

    # define the training prompt
    instance_phrase = f"{config.instance_name} the {config.class_name}"
    prompt = f"{config.prefix} {instance_phrase} {config.postfix}".strip()

    # the model training is packaged as a script, so we have to execute it as a subprocess, which adds some boilerplate
    def _exec_subprocess(cmd: list[str]):
        """Executes subprocess and prints log to terminal while subprocess is running."""
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        )
        with process.stdout as pipe:
            for line in iter(pipe.readline, b""):
                line_str = line.decode()
                print(f"{line_str}", end="")

        if exitcode := process.wait() != 0:
            raise subprocess.CalledProcessError(exitcode, "\n".join(cmd))

    # run training -- see huggingface accelerate docs for details
    print("launching dreambooth training script")
    _exec_subprocess(
        [
            "accelerate",
            "launch",
            "examples/dreambooth/train_dreambooth_lora_flux.py",
            "--mixed_precision=bf16",  # half-precision floats most of the time for faster training
            f"--pretrained_model_name_or_path={MODEL_DIR}",
            f"--instance_data_dir={img_path}",
            f"--output_dir={MODEL_DIR}",
            f"--instance_prompt={prompt}",
            f"--resolution={config.resolution}",
            f"--train_batch_size={config.train_batch_size}",
            f"--gradient_accumulation_steps={config.gradient_accumulation_steps}",
            f"--learning_rate={config.learning_rate}",
            f"--lr_scheduler={config.lr_scheduler}",
            f"--lr_warmup_steps={config.lr_warmup_steps}",
            f"--max_train_steps={config.max_train_steps}",
            f"--checkpointing_steps={config.checkpointing_steps}",
            f"--seed={config.seed}",  # increased reproducibility by seeding the RNG
        ]
        + (
            [
                "--report_to=wandb",
                # validation output tracking is useful, but currently broken for Flux LoRA training
                # f"--validation_prompt={prompt} in space",  # simple test prompt
                # f"--validation_epochs={config.max_train_steps // 5}",
            ]
            if USE_WANDB
            else []
        ),
    )
    # The trained model information has been output to the volume mounted at `MODEL_DIR`.
    # To persist this data for use in our web app, we 'commit' the changes
    # to the volume.
    volume.commit()


# ## Running our model

# To generate images from prompts using our fine-tuned model, we define a Modal Function called `inference`.

# Naively, this would seem to be a bad fit for the flexible, serverless infrastructure of Modal:
# wouldn't you need to include the steps to load the model and spin it up in every function call?

# In order to initialize the model just once on container startup,
# we use Modal's [container lifecycle](https://modal.com/docs/guide/lifecycle-functions) features, which require the function to be part
# of a class. Note that the `modal.Volume` we saved the model to is mounted here as well,
# so that the fine-tuned model created  by `train` is available to us.


@app.cls(image=image, gpu="A100", volumes={MODEL_DIR: volume})
class Model:
    @modal.enter()
    def load_model(self):
        import torch
        from diffusers import DiffusionPipeline

        # Reload the modal.Volume to ensure the latest state is accessible.
        volume.reload()

        # set up a hugging face inference pipeline using our model
        pipe = DiffusionPipeline.from_pretrained(
            MODEL_DIR,
            torch_dtype=torch.bfloat16,
        ).to("cuda")
        pipe.load_lora_weights(MODEL_DIR)
        self.pipe = pipe

    @modal.method()
    def inference(self, text, config):
        image = self.pipe(
            text,
            num_inference_steps=config.num_inference_steps,
            guidance_scale=config.guidance_scale,
        ).images[0]

        return image


# ## Wrap the trained model in a Gradio web UI

# [Gradio](https://gradio.app) makes it super easy to expose a model's functionality
# in an easy-to-use, responsive web interface.

# This model is a text-to-image generator,
# so we set up an interface that includes a user-entry text box
# and a frame for displaying images.

# We also provide some example text inputs to help
# guide users and to kick-start their creative juices.

# And we couldn't resist adding some Modal style to it as well!

# You can deploy the app on Modal with the command
# `modal deploy dreambooth_app.py`.
# You'll be able to come back days, weeks, or months later and find it still ready to go,
# even though you don't have to pay for a server to run while you're not using it.


@dataclass
class AppConfig(SharedConfig):
    """Configuration information for inference."""

    num_inference_steps: int = 50
    guidance_scale: float = 6


web_image = image.add_local_dir(
    # Add local web assets to the image
    Path(__file__).parent / "assets",
    remote_path="/assets",
)


@app.function(
    image=web_image,
    max_containers=1,
)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def fastapi_app():
    import gradio as gr
    from fastapi import FastAPI
    from fastapi.responses import FileResponse
    from gradio.routes import mount_gradio_app

    web_app = FastAPI()

    # Call out to the inference in a separate Modal environment with a GPU
    def go(text=""):
        if not text:
            text = example_prompts[0]
        return Model().inference.remote(text, config)

    # set up AppConfig
    config = AppConfig()

    instance_phrase = f"{config.instance_name} the {config.class_name}"

    example_prompts = [
        f"{instance_phrase}",
        f"a painting of {instance_phrase.title()} With A Pearl Earring, by Vermeer",
        f"oil painting of {instance_phrase} flying through space as an astronaut",
        f"a painting of {instance_phrase} in cyberpunk city. character design by cory loftis. volumetric light, detailed, rendered in octane",
        f"drawing of {instance_phrase} high quality, cartoon, path traced, by studio ghibli and don bluth",
    ]

    modal_docs_url = "https://modal.com/docs"
    modal_example_url = f"{modal_docs_url}/examples/dreambooth_app"

    description = f"""Describe what they are doing or how a particular artist or style would depict them. Be fantastical! Try the examples below for inspiration.

### Learn how to make a "Dreambooth" for your own pet [here]({modal_example_url}).
    """

    # custom styles: an icon, a background, and a theme
    @web_app.get("/favicon.ico", include_in_schema=False)
    async def favicon():
        return FileResponse("/assets/favicon.svg")

    @web_app.get("/assets/background.svg", include_in_schema=False)
    async def background():
        return FileResponse("/assets/background.svg")

    with open("/assets/index.css") as f:
        css = f.read()

    theme = gr.themes.Default(
        primary_hue="green", secondary_hue="emerald", neutral_hue="neutral"
    )

    # add a gradio UI around inference
    with gr.Blocks(
        theme=theme,
        css=css,
        title=f"Generate images of {config.instance_name} on Modal",
    ) as interface:
        gr.Markdown(
            f"# Generate images of {instance_phrase}.\n\n{description}",
        )
        with gr.Row():
            inp = gr.Textbox(  # input text component
                label="",
                placeholder=f"Describe the version of {instance_phrase} you'd like to see",
                lines=10,
            )
            out = gr.Image(  # output image component
                height=512, width=512, label="", min_width=512, elem_id="output"
            )
        with gr.Row():
            btn = gr.Button("Dream", variant="primary", scale=2)
            btn.click(
                fn=go, inputs=inp, outputs=out
            )  # connect inputs and outputs with inference function

            gr.Button(  # shameless plug
                "⚡️ Powered by Modal",
                variant="secondary",
                link="https://modal.com",
            )

        with gr.Column(variant="compact"):
            # add in a few examples to inspire users
            for ii, prompt in enumerate(example_prompts):
                btn = gr.Button(prompt, variant="secondary")
                btn.click(fn=lambda idx=ii: example_prompts[idx], outputs=inp)

    # mount for execution on Modal
    return mount_gradio_app(
        app=web_app,
        blocks=interface,
        path="/",
    )


# ## Running your fine-tuned model from the command line

# You can use the `modal` command-line interface to set up, customize, and deploy this app:

# - `modal run diffusers_lora_finetune.py` will train the model. Change the `instance_example_urls_file` to point to your own pet's images.
# - `modal serve diffusers_lora_finetune.py` will [serve](https://modal.com/docs/guide/webhooks#developing-with-modal-serve) the Gradio interface at a temporary location. Great for iterating on code!
# - `modal shell diffusers_lora_finetune.py` is a convenient helper to open a bash [shell](https://modal.com/docs/guide/developing-debugging#interactive-shell) in our image. Great for debugging environment issues.

# Remember, once you've trained your own fine-tuned model, you can deploy it permanently -- for no cost when it is not being used! --
# using `modal deploy diffusers_lora_finetune.py`.

# If you just want to try the app out, you can find our deployment [here](https://modal-labs--example-lora-flux-fastapi-app.modal.run).


@app.local_entrypoint()
def run(  # add more config params here to make training configurable
    max_train_steps: int = 250,
):
    print("🎨 loading model")
    download_models.remote(SharedConfig())
    print("🎨 setting up training")
    config = TrainConfig(max_train_steps=max_train_steps)
    instance_example_urls = (
        Path(TrainConfig.instance_example_urls_file).read_text().splitlines()
    )
    train.remote(instance_example_urls, config)
    print("🎨 training finished")


=== GITHUB: 06_gpu_and_ml/yolo/finetune_yolo.py ===
# ---
# args: ["--no-quick-check"]
# mypy: ignore-errors
# ---

# # Fine-tune open source YOLO models for object detection

# Example by [@Erik-Dunteman](https://github.com/erik-dunteman) and [@AnirudhRahul](https://github.com/AnirudhRahul/).

# The popular "You Only Look Once" (YOLO) model line provides high-quality object detection in an economical package.
# In this example, we use the [YOLOv10](https://docs.ultralytics.com/models/yolov10/) model, released on May 23, 2024.

# We will:

# - Download two custom datasets from the [Roboflow](https://roboflow.com/) computer vision platform: a dataset of birds and a dataset of bees

# - Fine-tune the model on those datasets, in parallel, using the [Ultralytics package](https://docs.ultralytics.com/)

# - Run inference with the fine-tuned models on single images and on streaming frames

# For commercial use, be sure to consult the [Ultralytics software license options](https://docs.ultralytics.com/#yolo-licenses-how-is-ultralytics-yolo-licensed),
# which include AGPL-3.0.

# ## Set up the environment

import warnings
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

import modal

# Modal runs your code in the cloud inside containers. So to use it, we have to define the dependencies
# of our code as part of the container's [image](https://modal.com/docs/guide/custom-container).

image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install(  # install system libraries for graphics handling
        ["libgl1-mesa-glx", "libglib2.0-0"]
    )
    .pip_install(  # install python libraries for computer vision
        ["ultralytics~=8.2.68", "roboflow~=1.1.37", "opencv-python~=4.10.0"]
    )
    .pip_install(  # add an optional extra that renders images in the terminal
        "term-image==0.7.1"
    )
)

# We also create a persistent [Volume](https://modal.com/docs/guide/volumes) for storing datasets, trained weights, and inference outputs.

volume = modal.Volume.from_name("yolo-finetune", create_if_missing=True)
volume_path = (  # the path to the volume from within the container
    Path("/root") / "data"
)

# We attach both of these to a Modal [App](https://modal.com/docs/guide/apps).
app = modal.App("yolo-finetune", image=image, volumes={volume_path: volume})


# ## Download a dataset

# We'll be downloading our data from the [Roboflow](https://roboflow.com/) computer vision platform, so to follow along you'll need to:

# - Create a free account on [Roboflow](https://app.roboflow.com/)

# - [Generate a Private API key](https://app.roboflow.com/settings/api)

# - Set up a Modal [Secret](https://modal.com/docs/guide/secrets) called `roboflow-api-key` in the Modal UI [here](https://modal.com/secrets),
# setting the `ROBOFLOW_API_KEY` to the value of your API key.

# You're also free to bring your own dataset with a config in YOLOv10-compatible yaml format.

# We'll be training on the medium size model, but you're free to experiment with [other model sizes](https://docs.ultralytics.com/models/yolov10/#model-variants).


@dataclass
class DatasetConfig:
    """Information required to download a dataset from Roboflow."""

    workspace_id: str
    project_id: str
    version: int
    format: str
    target_class: str

    @property
    def id(self) -> str:
        return f"{self.workspace_id}/{self.project_id}/{self.version}"


@app.function(
    secrets=[
        modal.Secret.from_name("roboflow-api-key", required_keys=["ROBOFLOW_API_KEY"])
    ]
)
def download_dataset(config: DatasetConfig):
    import os

    from roboflow import Roboflow

    rf = Roboflow(api_key=os.getenv("ROBOFLOW_API_KEY"))
    project = (
        rf.workspace(config.workspace_id)
        .project(config.project_id)
        .version(config.version)
    )
    dataset_dir = volume_path / "dataset" / config.id
    project.download(config.format, location=str(dataset_dir))


# ## Train a model

# We train the model on a single A100 GPU. Training usually takes only a few minutes.

MINUTES = 60

TRAIN_GPU_COUNT = 1
TRAIN_GPU = f"A100:{TRAIN_GPU_COUNT}"
TRAIN_CPU_COUNT = 4


@app.function(
    gpu=TRAIN_GPU,
    cpu=TRAIN_CPU_COUNT,
    timeout=60 * MINUTES,
)
def train(
    model_id: str,
    dataset: DatasetConfig,
    model_size="yolov10m.pt",
    quick_check=False,
):
    from ultralytics import YOLO

    volume.reload()  # make sure volume is synced

    model_path = volume_path / "runs" / model_id
    model_path.mkdir(parents=True, exist_ok=True)

    data_path = volume_path / "dataset" / dataset.id / "data.yaml"

    model = YOLO(model_size)
    model.train(
        # dataset config
        data=data_path,
        fraction=0.4
        if not quick_check
        else 0.04,  # fraction of dataset to use for training/validation
        # optimization config
        device=list(range(TRAIN_GPU_COUNT)),  # use the GPU(s)
        epochs=8 if not quick_check else 1,  # pass over entire dataset this many times
        batch=0.95,  # automatic batch size to target fraction of GPU util
        seed=117,  # set seed for reproducibility
        # data processing config
        workers=max(
            TRAIN_CPU_COUNT // TRAIN_GPU_COUNT, 1
        ),  # split CPUs evenly across GPUs
        cache=False,  # cache preprocessed images in RAM?
        # model saving config
        project=f"{volume_path}/runs",
        name=model_id,
        exist_ok=True,  # overwrite previous model if it exists
        verbose=True,  # detailed logs
    )


# ## Run inference on single inputs and on streams

# We demonstrate two different ways to run inference -- on single images and on a stream of images.

# The images we use for inference are loaded from the test set, which was added to our Volume when we downloaded the dataset.
# Each image read takes ~50ms, and inference can take ~5ms, so the disk read would be our biggest bottleneck if we just looped over the image paths.
# To avoid it, we parallelize the disk reads across many workers using Modal's [`.map`](https://modal.com/docs/guide/scale),
# streaming the images to the model. This roughly mimics the behavior of an interactive object detection pipeline.
# This can increase throughput up to ~60 images/s, or ~17 milliseconds/image, depending on image size.


@app.function()
def read_image(image_path: str):
    import cv2

    source = cv2.imread(image_path)
    return source


# We use the `@enter` feature of [`modal.Cls`](https://modal.com/docs/guide/lifecycle-functions)
# to load the model only once on container start and reuse it for future inferences.
# We use a generator to stream images to the model.


@app.cls(gpu="a10g")
class Inference:
    weights_path: str = modal.parameter()

    @modal.enter()
    def load_model(self):
        from ultralytics import YOLO

        self.model = YOLO(self.weights_path)

    @modal.method()
    def predict(self, model_id: str, image_path: str, display: bool = False):
        """A simple method for running inference on one image at a time."""
        results = self.model.predict(
            image_path,
            half=True,  # use fp16
            save=True,
            exist_ok=True,
            project=f"{volume_path}/predictions/{model_id}",
        )
        if display:
            from term_image.image import from_file

            terminal_image = from_file(results[0].path)
            terminal_image.draw()
        # you can view the output file via the Volumes UI in the Modal dashboard -- https://modal.com/storage

    @modal.method()
    def streaming_count(self, batch_dir: str, threshold: float | None = None):
        """Counts the number of objects in a directory of images.

        Intended as a demonstration of high-throughput streaming inference."""
        import os
        import time

        image_files = [os.path.join(batch_dir, f) for f in os.listdir(batch_dir)]

        completed, start = 0, time.monotonic_ns()
        for image in read_image.map(image_files):
            # note that we run predict on a single input at a time.
            # each individual inference is usually done before the next image arrives, so there's no throughput benefit to batching.
            results = self.model.predict(
                image,
                half=True,  # use fp16
                save=False,  # don't save to disk, as it slows down the pipeline significantly
                verbose=False,
            )
            completed += 1
            for res in results:
                for conf in res.boxes.conf:
                    if threshold is None:
                        yield 1
                        continue
                    if conf.item() >= threshold:
                        yield 1
            yield 0

        elapsed_seconds = (time.monotonic_ns() - start) / 1e9
        print(
            "Inferences per second:",
            round(completed / elapsed_seconds, 2),
        )


# ## Running the example

# We'll kick off our parallel training jobs and run inference from the command line.

# ```bash
# modal run finetune_yolo.py
# ```

# This runs the training in `quick_check` mode, useful for debugging the pipeline and getting a feel for it.
# To do a longer run that actually meaningfully improves performance, use:

# ```bash
# modal run finetune_yolo.py --no-quick-check
# ```


@app.local_entrypoint()
def main(quick_check: bool = True, inference_only: bool = False):
    """Run fine-tuning and inference on two datasets.

    Args:
        quick_check: fine-tune on a small subset. Lower quality results, but faster iteration.
        inference_only: skip fine-tuning and only run inference
    """

    birds = DatasetConfig(
        workspace_id="birds-s35xe",
        project_id="birds-u8mti",
        version=2,
        format="yolov9",
        target_class="🐥",
    )
    bees = DatasetConfig(
        workspace_id="bees-tbdsg",
        project_id="bee-counting",
        version=11,
        format="yolov9",
        target_class="🐝",
    )
    datasets = [birds, bees]

    # .for_each runs a function once on each element of the input iterators
    # here, that means download each dataset, in parallel
    if not inference_only:
        download_dataset.for_each(datasets)

    today = datetime.now().strftime("%Y-%m-%d")
    model_ids = [dataset.id + f"/{today}" for dataset in datasets]

    if not inference_only:
        train.for_each(model_ids, datasets, kwargs={"quick_check": quick_check})

    # let's run inference!
    for model_id, dataset in zip(model_ids, datasets):
        inference = Inference(
            weights_path=str(volume_path / "runs" / model_id / "weights" / "best.pt")
        )

        # predict on a single image and save output to the volume
        test_images = volume.listdir(
            str(Path("dataset") / dataset.id / "test" / "images")
        )
        # run inference on the first 5 images
        for ii, image in enumerate(test_images):
            print(f"{model_id}: Single image prediction on image", image.path)
            inference.predict.remote(
                model_id=model_id,
                image_path=f"{volume_path}/{image.path}",
                display=(
                    ii == 0  # display inference results only on first image
                ),
            )
            if ii >= 4:
                break

        # streaming inference on images from the test set
        print(f"{model_id}: Streaming inferences on all images in the test set...")
        count = 0
        for detection in inference.streaming_count.remote_gen(
            batch_dir=f"{volume_path}/dataset/{dataset.id}/test/images"
        ):
            if detection:
                print(f"{dataset.target_class}", end="")
                count += 1
            else:
                print("🎞️", end="", flush=True)
        print(f"\n{model_id}: Counted {count} {dataset.target_class}s!")


# ## Addenda

# The rest of the code in this example is utility code.

warnings.filterwarnings(  # filter warning from the terminal image library
    "ignore",
    message="It seems this process is not running within a terminal. Hence, some features will behave differently or be disabled.",
    category=UserWarning,
)


=== GITHUB: 06_gpu_and_ml/blender/blender_video.py ===
# ---
# output-directory: "/tmp/render"
# args: ["--frame-skip", "2"]
# ---

# # Render a video with Blender on many GPUs or CPUs in parallel

# This example shows how you can render an animated 3D scene using
# [Blender](https://www.blender.org/)'s Python interface.

# You can run it on CPUs to scale out on one hundred containers
# or run it on GPUs to get higher throughput per node.
# Even for this simple scene, GPUs render >10x faster than CPUs.

# The final render looks something like this:

# <center>
# <video controls autoplay loop muted>
# <source src="https://modal-cdn.com/modal-blender-video.mp4" type="video/mp4">
# </video>
# </center>

# ## Defining a Modal app

from pathlib import Path

import modal

# Modal runs your Python functions for you in the cloud.
# You organize your code into apps, collections of functions that work together.

app = modal.App("examples-blender-video")

# We need to define the environment each function runs in --  its container image.
# The block below defines a container image, starting from a basic Debian Linux image
# adding Blender's system-level dependencies
# and then installing the `bpy` package, which is Blender's Python API.

rendering_image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("xorg", "libxkbcommon0")  # X11 (Unix GUI) dependencies
    .pip_install("bpy==4.1.0")  # Blender as a Python package
)

# ## Rendering a single frame

# We define a function that renders a single frame. We'll scale this function out on Modal later.

# Functions in Modal are defined along with their hardware and their dependencies.
# This function can be run with GPU acceleration or without it, and we'll use a global flag in the code to switch between the two.

WITH_GPU = (
    True  # try changing this to False to run rendering massively in parallel on CPUs!
)

# We decorate the function with `@app.function` to define it as a Modal function.
# Note that in addition to defining the hardware requirements of the function,
# we also specify the container image that the function runs in (the one we defined above).

# The details of the scene aren't too important for this example, but we'll load
# a .blend file that we created earlier. This scene contains a rotating
# Modal logo made of a transmissive ice-like material, with a generated displacement map. The
# animation keyframes were defined in Blender.


@app.function(
    gpu="L40S" if WITH_GPU else None,
    # default limits on Modal free tier
    max_containers=10 if WITH_GPU else 100,
    image=rendering_image,
)
def render(blend_file: bytes, frame_number: int = 0) -> bytes:
    """Renders the n-th frame of a Blender file as a PNG."""
    import bpy

    input_path = "/tmp/input.blend"
    output_path = f"/tmp/output-{frame_number}.png"

    # Blender requires input as a file.
    Path(input_path).write_bytes(blend_file)

    bpy.ops.wm.open_mainfile(filepath=input_path)
    bpy.context.scene.frame_set(frame_number)
    bpy.context.scene.render.filepath = output_path
    configure_rendering(bpy.context, with_gpu=WITH_GPU)
    bpy.ops.render.render(write_still=True)

    # Blender renders image outputs to a file as well.
    return Path(output_path).read_bytes()


# ### Rendering with acceleration

# We can configure the rendering process to use GPU acceleration with NVIDIA CUDA.
# We select the [Cycles rendering engine](https://www.cycles-renderer.org/), which is compatible with CUDA,
# and then activate the GPU.


def configure_rendering(ctx, with_gpu: bool):
    # configure the rendering process
    ctx.scene.render.engine = "CYCLES"
    ctx.scene.render.resolution_x = 3000
    ctx.scene.render.resolution_y = 2000
    ctx.scene.render.resolution_percentage = 50
    ctx.scene.cycles.samples = 128

    cycles = ctx.preferences.addons["cycles"]

    # Use GPU acceleration if available.
    if with_gpu:
        cycles.preferences.compute_device_type = "CUDA"
        ctx.scene.cycles.device = "GPU"

        # reload the devices to update the configuration
        cycles.preferences.get_devices()
        for device in cycles.preferences.devices:
            device.use = True

    else:
        ctx.scene.cycles.device = "CPU"

    # report rendering devices -- a nice snippet for debugging and ensuring the accelerators are being used
    for dev in cycles.preferences.devices:
        print(f"ID:{dev['id']} Name:{dev['name']} Type:{dev['type']} Use:{dev['use']}")


# ## Combining frames into a video

# Rendering 3D images is fun, and GPUs can make it faster, but rendering 3D videos is better!
# We add another function to our app, running on a different, simpler container image
# and different hardware, to combine the frames into a video.

combination_image = modal.Image.debian_slim(python_version="3.11").apt_install("ffmpeg")

# The function to combine the frames into a video takes a sequence of byte sequences, one for each rendered frame,
# and converts them into a single sequence of bytes, the MP4 file.


@app.function(image=combination_image)
def combine(frames_bytes: list[bytes], fps: int = 60) -> bytes:
    import subprocess
    import tempfile

    with tempfile.TemporaryDirectory() as tmpdir:
        for i, frame_bytes in enumerate(frames_bytes):
            frame_path = Path(tmpdir) / f"frame_{i:05}.png"
            frame_path.write_bytes(frame_bytes)
        out_path = Path(tmpdir) / "output.mp4"
        subprocess.run(
            f"ffmpeg -framerate {fps} -pattern_type glob -i '{tmpdir}/*.png' -c:v libx264 -pix_fmt yuv420p {out_path}",
            shell=True,
        )
        return out_path.read_bytes()


# ## Rendering in parallel in the cloud from the comfort of the command line

# With these two functions defined, we need only a few more lines to run our rendering at scale on Modal.

# First, we need a function that coordinates our functions to `render` frames and `combine` them.
# We decorate that function with `@app.local_entrypoint` so that we can run it with `modal run blender_video.py`.

# In that function, we use `render.map` to map the `render` function over the range of frames.

# We give the `local_entrypoint` two parameters to control the render -- the number of frames to render and how many frames to skip.
# These demonstrate a basic pattern for controlling Functions on Modal from a local client.

# We collect the bytes from each frame into a `list` locally and then send it to `combine` with `.remote`.

# The bytes for the video come back to our local machine, and we write them to a file.

# The whole rendering process (for four seconds of 1080p 60 FPS video) takes about three minutes to run on 10 L40S GPUs,
# with a per-frame latency of about six seconds, and about five minutes to run on 100 CPUs, with a per-frame latency of about one minute.


@app.local_entrypoint()
def main(frame_count: int = 250, frame_skip: int = 1):
    output_directory = Path("/tmp") / "render"
    output_directory.mkdir(parents=True, exist_ok=True)

    input_path = Path(__file__).parent / "IceModal.blend"
    blend_bytes = input_path.read_bytes()
    args = [(blend_bytes, frame) for frame in range(1, frame_count + 1, frame_skip)]
    images = list(render.starmap(args))
    for i, image in enumerate(images):
        frame_path = output_directory / f"frame_{i + 1}.png"
        frame_path.write_bytes(image)
        print(f"Frame saved to {frame_path}")

    video_path = output_directory / "output.mp4"
    video_bytes = combine.remote(images)
    video_path.write_bytes(video_bytes)
    print(f"Video saved to {video_path}")



=== CATEGORY: WEB_ENDPOINTS ===

=== GITHUB: 07_web_endpoints/fastrtc_flip_webcam.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/fastrtc_flip_webcam.py"]
# deploy: true
# ---

# # Run a FastRTC app on Modal

# [FastRTC](https://fastrtc.org/) is a Python library for real-time communication on the web.
# This example demonstrates how to run a simple FastRTC app in the cloud on Modal.

# It's intended to help you get up and running with real-time streaming applications on Modal
# as quickly as possible. If you're interested in running a production-grade WebRTC app on Modal,
# see [this example](https://modal.com/docs/examples/webrtc_yolo).

# In this example, we stream webcam video from a browser to a container on Modal,
# where the video is flipped, annotated, and sent back with under 100ms of delay.
# You can try it out [here](https://modal-labs-examples--fastrtc-flip-webcam-ui.modal.run/)
# or just dive straight into the code to run it yourself.

# ## Set up FastRTC on Modal

# First, we import the `modal` SDK
# and use it to define a [container image](https://modal.com/docs/guide/images)
# with FastRTC and related dependencies.

import modal

web_image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "fastapi[standard]==0.115.4",
    "fastrtc==0.0.23",
    "gradio==5.7.1",
    "opencv-python-headless==4.11.0.86",
)

# Then, we set that as the default Image on our Modal [App](https://modal.com/docs/guide/apps).

app = modal.App("fastrtc-flip-webcam", image=web_image)

# ### Configure WebRTC streaming on Modal

# Under the hood, FastRTC uses the WebRTC
# [APIs](https://www.w3.org/TR/webrtc/) and
# [protocols](https://datatracker.ietf.org/doc/html/rfc8825).

# WebRTC provides low latency ("real-time") peer-to-peer communication
# for Web applications, focusing on audio and video.
# Considering that the Web is a platform originally designed
# for high-latency, client-server communication of text and images,
# that's no mean feat!

# In addition to protocols that implement this communication,
# WebRTC includes APIs for describing and manipulating audio/video streams.
# In this demo, we set a few simple parameters, like the direction of the webcam
# and the minimum frame rate. See the
# [MDN Web Docs for `MediaTrackConstraints`](https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackConstraints)
# for more.

TRACK_CONSTRAINTS = {
    "width": {"exact": 640},
    "height": {"exact": 480},
    "frameRate": {"min": 30},
    "facingMode": {  # https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings/facingMode
        "ideal": "user"
    },
}

# In theory, the Internet is designed for peer-to-peer communication
# all the way down to its heart, the Internet Protocol (IP): just send packets between IP addresses.
# In practice, peer-to-peer communication on the contemporary Internet is fraught with difficulites,
# from restrictive firewalls to finicky work-arounds for
# [the exhaustion of IPv4 addresses](https://www.a10networks.com/glossary/what-is-ipv4-exhaustion/),
# like [Carrier-Grade Network Address Translation (CGNAT)](https://en.wikipedia.org/wiki/Carrier-grade_NAT).

# So establishing peer-to-peer connections can be quite involved.
# The protocol for doing so is called Interactive Connectivity Establishment (ICE).
# It is described in [this RFC](https://datatracker.ietf.org/doc/html/rfc8445#section-2).

# ICE involves the peers exchanging a list of connections that might be used.
# We use a fairly simple setup here, where our peer on Modal uses the
# [Session Traversal Utilities for NAT (STUN)](https://datatracker.ietf.org/doc/html/rfc5389)
# server provided by Google. A STUN server basically just reflects back to a client what their
# IP address and port number appear to be when they talk to it. The peer on Modal communicates
# that information to the other peer trying to connect to it -- in this case, a browser trying to share a webcam feed.
# Note the use of `stun` and port `19302` in the URL in place of
# something more familiar, like `http` and port `80`.

RTC_CONFIG = {"iceServers": [{"url": "stun:stun.l.google.com:19302"}]}


# ## Running a FastRTC app on Modal

# FastRTC builds on top of the [Gradio](https://www.gradio.app/docs)
# library for defining Web UIs in Python.
# Gradio in turn is compatible with the
# [Asynchronous Server Gateway Interface (ASGI)](https://asgi.readthedocs.io/en/latest/)
# protocol for asynchronous Python web servers, like
# [FastAPI](https://fastrtc.org/userguide/streams/),
# so we can host it on Modal's cloud platform using the
# [`modal.asgi_app` decorator](https://modal.com/docs/guide/webhooks#serving-asgi-and-wsgi-apps)
# with [Modal Function](https://modal.com/docs/guide/apps).

# But before we do that, we need to consider limits:
# on how many peers can connect to one instance on Modal
# and on how long they can stay connected.
# We picked some sensible defaults to show how they interact
# with the deployment parameters of the Modal Function.
# You'll want to tune these for your application!

MAX_CONCURRENT_STREAMS = 10  # number of peers per instance on Modal

MINUTES = 60  # seconds
TIME_LIMIT = 10 * MINUTES  # time limit


@app.function(
    # gradio requires sticky sessions
    # so we limit the number of concurrent containers to 1
    # and allow that container to handle concurrent streams
    max_containers=1,
    scaledown_window=TIME_LIMIT + 1 * MINUTES,  # add a small buffer to time limit
)
@modal.concurrent(max_inputs=MAX_CONCURRENT_STREAMS)  # inputs per container
@modal.asgi_app()  # ASGI on Modal
def ui():
    import fastrtc  # WebRTC in Gradio
    import gradio as gr  # WebUIs in Python
    from fastapi import FastAPI  # asynchronous ASGI server framework
    from gradio.routes import mount_gradio_app  # connects Gradio and FastAPI

    with gr.Blocks() as blocks:  # block-wise UI definition
        gr.HTML(  # simple HTML header
            "<h1 style='text-align: center'>"
            "Streaming Video Processing with Modal and FastRTC"
            "</h1>"
        )

        with gr.Column():  # a column of UI elements
            fastrtc.Stream(  # high-level media streaming UI element
                modality="video",
                mode="send-receive",
                handler=flip_vertically,  # handler -- handle incoming frame, produce outgoing frame
                ui_args={"title": "Click 'Record' to flip your webcam in the cloud"},
                rtc_configuration=RTC_CONFIG,
                track_constraints=TRACK_CONSTRAINTS,
                concurrency_limit=MAX_CONCURRENT_STREAMS,  # limit simultaneous connections
                time_limit=TIME_LIMIT,  # limit time per connection
            )

    return mount_gradio_app(app=FastAPI(), blocks=blocks, path="/")


# To try this out for yourself, run

# ```bash
# modal serve 07_web_endpoints/fastrtc_flip_webcam.py
# ```

# and head to the `modal.run` URL that appears in your terminal.
# You can also check on the application's dashboard
# via the `modal.com` URL thatappears below it.

# The `modal serve` command produces a hot-reloading development server --
# try editing the `title` in the `ui_args` above and watch the server redeploy.

# This temporary deployment is tied to your terminal session.
# To deploy permanently, run

# ```bash
# modal deploy 07_web_endponts/fastrtc_flip_webcam.py
# ```

# Note that Modal is a serverless platform with [usage-based pricing](https://modal.com/pricing),
# so this application will spin down and cost you nothing when it is not in use.

# ## Addenda

# This FastRTC app is very much the "hello world" or "echo server"
# of FastRTC: it just flips the incoming webcam stream and adds a "hello" message.
# That logic appears below.


def flip_vertically(image):
    import cv2
    import numpy as np

    image = image.astype(np.uint8)

    if image is None:
        print("failed to decode image")
        return

    # flip vertically and caption to show video was processed on Modal
    image = cv2.flip(image, 0)
    lines = ["Hello from Modal!"]
    caption_image(image, lines)

    return image


def caption_image(
    img, lines, font_scale=0.8, thickness=2, margin=10, font=None, color=None
):
    import cv2

    if font is None:
        font = cv2.FONT_HERSHEY_SIMPLEX
    if color is None:
        color = (127, 238, 100, 128)  # Modal Green

    # get text sizes
    sizes = [cv2.getTextSize(line, font, font_scale, thickness)[0] for line in lines]
    if not sizes:
        return

    # position text in bottom right
    pos_xs = [img.shape[1] - size[0] - margin for size in sizes]

    pos_ys = [img.shape[0] - margin]
    for _width, height in reversed(sizes[:-1]):
        next_pos = pos_ys[-1] - 2 * height
        pos_ys.append(next_pos)

    for line, pos in zip(lines, zip(pos_xs, reversed(pos_ys))):
        cv2.putText(img, line, pos, font, font_scale, color, thickness)


=== GITHUB: 07_web_endpoints/fasthtml_app.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/fasthtml_app.py"]
# ---

# # Deploy a FastHTML app with Modal

# This example shows how you can deploy a FastHTML app with Modal.
# [FastHTML](https://www.fastht.ml/) is a Python library built on top of [HTMX](https://htmx.org/)
# which allows you to create entire web applications using only Python.

# The integration is pretty simple, thanks to the ASGI standard.
# You just need to define a function returns your FastHTML app
# and is decorated with `app.function` and `modal.asgi_app`.

import modal

app = modal.App("example-fasthtml")


@app.function(
    image=modal.Image.debian_slim(python_version="3.12").pip_install(
        "python-fasthtml==0.5.2"
    )
)
@modal.asgi_app()
def serve():
    import fasthtml.common as fh

    app = fh.FastHTML()

    @app.get("/")
    def home():
        return fh.Div(fh.P("Hello World!"), hx_get="/change")

    return app


=== GITHUB: 07_web_endpoints/count_faces.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/count_faces.py"]
# ---

# # Run OpenCV face detection on an image

# This example shows how you can use OpenCV on Modal to detect faces in an image. We use
# the `opencv-python` package to load the image and the `opencv` library to
# detect faces. The function `count_faces` takes an image as input and returns
# the number of faces detected in the image.

# The code below also shows how you can create wrap this function
# in a simple FastAPI server to create a web interface.

import os

import modal

app = modal.App("example-count-faces")


open_cv_image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("python3-opencv")
    .pip_install(
        "fastapi[standard]==0.115.4",
        "opencv-python~=4.10.0",
        "numpy<2",
    )
)


@app.function(image=open_cv_image)
def count_faces(image_bytes: bytes) -> int:
    import cv2
    import numpy as np

    # Example borrowed from https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81
    # Load the cascade
    face_cascade = cv2.CascadeClassifier(
        os.path.join(cv2.data.haarcascades, "haarcascade_frontalface_default.xml")
    )
    # Read the input image
    np_bytes = np.frombuffer(image_bytes, dtype=np.uint8)
    img = cv2.imdecode(np_bytes, cv2.IMREAD_COLOR)
    # Convert into grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect faces
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
    return len(faces)


@app.function(
    image=modal.Image.debian_slim(python_version="3.11").pip_install("inflect")
)
@modal.asgi_app()
def web():
    import inflect
    from fastapi import FastAPI, File, HTTPException, UploadFile
    from fastapi.responses import HTMLResponse

    app = FastAPI()

    @app.get("/", response_class=HTMLResponse)
    async def index():
        """
        Render an HTML form for file upload.
        """
        return """
        <html>
            <head>
                <title>Face Counter</title>
            </head>
            <body>
                <h1>Upload an Image to Count Faces</h1>
                <form action="/process" method="post" enctype="multipart/form-data">
                    <input type="file" name="file" id="file" accept="image/*" required />
                    <button type="submit">Upload</button>
                </form>
            </body>
        </html>
        """

    @app.post("/process", response_class=HTMLResponse)
    async def process(file: UploadFile = File(...)):
        """
        Process the uploaded image and return the number of faces detected.
        """
        try:
            file_content = await file.read()
            num_faces = await count_faces.remote.aio(file_content)
            return f"""
            <html>
                <head>
                    <title>Face Counter Result</title>
                </head>
                <body>
                    <h1>{inflect.engine().number_to_words(num_faces).title()} {"Face" if num_faces == 1 else "Faces"} Detected</h1>
                    <h2>{"😀" * num_faces}</h2>
                    <a href="/">Go back</a>
                </body>
            </html>
            """
        except Exception as e:
            raise HTTPException(
                status_code=400, detail=f"Error processing image: {str(e)}"
            )

    return app


=== GITHUB: 07_web_endpoints/discord_bot.py ===
# ---
# deploy: true
# ---

# # Serve a Discord Bot on Modal

# In this example we will demonstrate how to use Modal to build and serve a Discord bot that uses
# [slash commands](https://discord.com/developers/docs/interactions/application-commands).

# Slash commands send information from Discord server members to a service at a URL.
# Here, we set up a simple [FastAPI app](https://fastapi.tiangolo.com/)
# to run that service and deploy it easily  Modal’s
# [`@asgi_app`](https://modal.com/docs/guide/webhooks#serving-asgi-and-wsgi-apps) decorator.

# As our example service, we hit a simple free API:
# the [Free Public APIs API](https://www.freepublicapis.com/api),
# a directory of free public APIs.

# [Try it out on Discord](https://discord.gg/PmG7P47EPQ)!

# ## Set up our App and its Image

# First, we define the [container image](https://modal.com/docs/guide/images)
# that all the pieces of our bot will run in.

# We set that as the default image for a Modal [App](https://modal.com/docs/guide/apps).
# The App is where we'll attach all the components of our bot.

import json
from enum import Enum

import modal

image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "fastapi[standard]==0.115.4", "pynacl~=1.5.0", "requests~=2.32.3"
)

app = modal.App("example-discord-bot", image=image)

# ## Hit the Free Public APIs API

# We start by defining the core service that our bot will provide.

# In a real application, this might be [music generation](https://modal.com/docs/examples/musicgen),
# a [chatbot](https://modal.com/docs/examples/chat_with_pdf_vision),
# or [interacting with a database](https://modal.com/docs/examples/cron_datasette).

# Here, we just hit a simple free public API:
# the [Free Public APIs](https://www.freepublicapis.com) API,
# an "API of APIs" that returns information about free public APIs,
# like the [Global Shark Attack API](https://www.freepublicapis.com/global-shark-attack-api)
# and the [Corporate Bullshit Generator](https://www.freepublicapis.com/corporate-bullshit-generator).
# We convert the response into a Markdown-formatted message.

# We turn our Python function into a Modal Function by attaching the `app.function` decorator.
# We make the function `async` and add `@modal.concurrent()` with a large `max_inputs` value, because
# communicating with an external API is a classic case for better performance from asynchronous execution.
# Modal handles things like the async event loop for us.


@app.function()
@modal.concurrent(max_inputs=1000)
async def fetch_api() -> str:
    import aiohttp

    url = "https://www.freepublicapis.com/api/random"

    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url) as response:
                response.raise_for_status()
                data = await response.json()
                message = (
                    f"# {data.get('emoji') or '🤖'} [{data['title']}]({data['source']})"
                )
                message += f"\n _{''.join(data['description'].splitlines())}_"
        except Exception as e:
            message = f"# 🤖: Oops! {e}"

    return message


# This core component has nothing to do with Discord,
# and it's nice to be able to interact with and test it in isolation.

# For that, we add a `local_entrypoint` that calls the Modal Function.
# Notice that we add `.remote` to the function's name.

# Later, when you replace this component of the app with something more interesting,
# test it by triggering this entrypoint with  `modal run discord_bot.py`.


@app.local_entrypoint()
def test_fetch_api():
    result = fetch_api.remote()
    if result.startswith("# 🤖: Oops! "):
        raise Exception(result)
    else:
        print(result)


# ## Integrate our Modal Function with Discord Interactions

# Now we need to map this function onto Discord's interface --
# in particular the [Interactions API](https://discord.com/developers/docs/interactions/overview).

# Reviewing the documentation, we see that we need to send a JSON payload
# to a specific API URL that will include an `app_id` that identifies our bot
# and a `token` that identifies the interaction (loosely, message) that we're participating in.

# So let's write that out. This function doesn't need to live on Modal,
# since it's just encapsulating some logic -- we don't want to turn it into a service or an API on its own.
# That means we don't need any Modal decorators.


async def send_to_discord(payload: dict, app_id: str, interaction_token: str):
    import aiohttp

    interaction_url = f"https://discord.com/api/v10/webhooks/{app_id}/{interaction_token}/messages/@original"

    async with aiohttp.ClientSession() as session:
        async with session.patch(interaction_url, json=payload) as resp:
            print("🤖 Discord response: " + await resp.text())


# Other parts of our application might want to both hit the Free Public APIs API and send the result to Discord,
# so we both write a Python function for this and we promote it to a Modal Function with a decorator.

# Notice that we use the `.local` suffix to call our `fetch_api` Function. That means we run
# the Function the same way we run all the other Python functions, rather than treating it as a special
# Modal Function. This reduces a bit of extra latency, but couples these two Functions more tightly.


@app.function()
@modal.concurrent(max_inputs=1000)
async def reply(app_id: str, interaction_token: str):
    message = await fetch_api.local()
    await send_to_discord({"content": message}, app_id, interaction_token)


# ## Set up a Discord app

# Now, we need to actually connect to Discord.
# We start by creating an application on the Discord Developer Portal.

# 1. Go to the
#    [Discord Developer Portal](https://discord.com/developers/applications) and
#    log in with your Discord account.
# 2. On the portal, go to **Applications** and create a new application by
#    clicking **New Application** in the top right next to your profile picture.
# 3. [Create a custom Modal Secret](https://modal.com/docs/guide/secrets) for your Discord bot.
#    On Modal's Secret creation page, select 'Discord'. Copy your Discord application’s
#    **Public Key** and **Application ID** (from the **General Information** tab in the Discord Developer Portal)
#    and paste them as the value of `DISCORD_PUBLIC_KEY` and `DISCORD_CLIENT_ID`.
#    Additionally, head to the **Bot** tab and use the **Reset Token** button to create a new bot token.
#    Paste this in the value of an additional key in the Secret, `DISCORD_BOT_TOKEN`.
#    Name this Secret `discord-secret`.

# We access that Secret in code like so:

discord_secret = modal.Secret.from_name(
    "discord-secret",
    required_keys=[  # included so we get nice error messages if we forgot a key
        "DISCORD_BOT_TOKEN",
        "DISCORD_CLIENT_ID",
        "DISCORD_PUBLIC_KEY",
    ],
)

# ## Register a Slash Command

# Next, we’re going to register a [Slash Command](https://discord.com/developers/docs/interactions/application-commands#slash-commands)
# for our Discord app. Slash Commands are triggered by users in servers typing `/` and the name of the command.

# The Modal Function below will register a Slash Command for your bot named `bored`.
# More information about Slash Commands can be found in the Discord docs
# [here](https://discord.com/developers/docs/interactions/application-commands).

# You can run this Function with

# ```bash
# modal run discord_bot::create_slash_command
# ```


@app.function(secrets=[discord_secret], image=image)
def create_slash_command(force: bool = False):
    """Registers the slash command with Discord. Pass the force flag to re-register."""
    import os

    import requests

    BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
    CLIENT_ID = os.getenv("DISCORD_CLIENT_ID")

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bot {BOT_TOKEN}",
    }
    url = f"https://discord.com/api/v10/applications/{CLIENT_ID}/commands"

    command_description = {
        "name": "api",
        "description": "Information about a random free, public API",
    }

    # first, check if the command already exists
    response = requests.get(url, headers=headers)
    try:
        response.raise_for_status()
    except Exception as e:
        raise Exception("Failed to create slash command") from e

    commands = response.json()
    command_exists = any(
        command.get("name") == command_description["name"] for command in commands
    )

    # and only recreate it if the force flag is set
    if command_exists and not force:
        print(f"🤖: command {command_description['name']} exists")
        return

    response = requests.post(url, headers=headers, json=command_description)
    try:
        response.raise_for_status()
    except Exception as e:
        raise Exception("Failed to create slash command") from e
    print(f"🤖: command {command_description['name']} created")


# ## Host a Discord Interactions endpoint on Modal

# If you look carefully at the definition of the Slash Command above,
# you'll notice that it doesn't know anything about our bot besides an ID.

# To hook the Slash Commands in the Discord UI up to our logic for hitting the Bored API,
# we need to set up a service that listens at some URL and follows a specific protocol,
# described [here](https://discord.com/developers/docs/interactions/overview#configuring-an-interactions-endpoint-url).

# Here are some of the most important facets:

# 1. We'll need to respond within five seconds or Discord will assume we are dead.
# Modal's fast-booting serverless containers usually start faster than that,
# but it's not guaranteed. So we'll add the `min_containers` parameter to our
# Function so that there's at least one live copy ready to respond quickly at any time.
# Modal charges a minimum of about 2¢ an hour for live containers (pricing details [here](https://modal.com/pricing)).
# Note that that still fits within Modal's $30/month of credits on the free tier.

# 2. We have to respond to Discord that quickly, but we don't have to respond to the user that quickly.
# We instead send an acknowledgement so that they know we're alive and they can close their connection to us.
# We also trigger our `reply` Modal Function, which will respond to the user via Discord's Interactions API,
# but we don't wait for the result, we just `spawn` the call.

# 3. The protocol includes some authentication logic that is mandatory
# and checked by Discord. We'll explain in more detail in the next section.

# We can set up our interaction endpoint by deploying a FastAPI app on Modal.
# This is as easy as creating a Python Function that returns a FastAPI app
# and adding the `modal.asgi_app` decorator.
# For more details on serving Python web apps on Modal, see
# [this guide](https://modal.com/docs/guide/webhooks).


@app.function(secrets=[discord_secret], min_containers=1)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def web_app():
    from fastapi import FastAPI, HTTPException, Request
    from fastapi.middleware.cors import CORSMiddleware

    web_app = FastAPI()

    # must allow requests from other domains, e.g. from Discord's servers
    web_app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    @web_app.post("/api")
    async def get_api(request: Request):
        body = await request.body()

        # confirm this is a request from Discord
        authenticate(request.headers, body)

        print("🤖: parsing request")
        data = json.loads(body.decode())
        if data.get("type") == DiscordInteractionType.PING.value:
            print("🤖: acking PING from Discord during auth check")
            return {"type": DiscordResponseType.PONG.value}

        if data.get("type") == DiscordInteractionType.APPLICATION_COMMAND.value:
            print("🤖: handling slash command")
            app_id = data["application_id"]
            interaction_token = data["token"]

            # kick off request asynchronously, will respond when ready
            reply.spawn(app_id, interaction_token)

            # respond immediately with defer message
            return {
                "type": DiscordResponseType.DEFERRED_CHANNEL_MESSAGE_WITH_SOURCE.value
            }

        print(f"🤖: unable to parse request with type {data.get('type')}")
        raise HTTPException(status_code=400, detail="Bad request")

    return web_app


# The authentication for Discord is a bit involved and there aren't,
# to our knowledge, any good Python libraries for it.

# So we have to implement the protocol "by hand".

# Essentially, Discord sends a header in their request
# that we can use to verify the request comes from them.
# For that, we use the `DISCORD_PUBLIC_KEY` from
# our Application Information page.

# The details aren't super important, but they appear in the `authenticate` function below
# (which defers the real cryptography work to [PyNaCl](https://pypi.org/project/PyNaCl/),
# a Python wrapper for [`libsodium`](https://github.com/jedisct1/libsodium)).

# Discord will also check that we reject unauthorized requests,
# so we have to be sure to get this right!


def authenticate(headers, body):
    import os

    from fastapi.exceptions import HTTPException
    from nacl.exceptions import BadSignatureError
    from nacl.signing import VerifyKey

    print("🤖: authenticating request")
    # verify the request is from Discord using their public key
    public_key = os.getenv("DISCORD_PUBLIC_KEY")
    verify_key = VerifyKey(bytes.fromhex(public_key))

    signature = headers.get("X-Signature-Ed25519")
    timestamp = headers.get("X-Signature-Timestamp")

    message = timestamp.encode() + body

    try:
        verify_key.verify(message, bytes.fromhex(signature))
    except BadSignatureError:
        # either an unauthorized request or Discord's "negative control" check
        raise HTTPException(status_code=401, detail="Invalid request")


# The code above used a few enums to abstract bits of the Discord protocol.
# Now that we've walked through all of it,
# we're in a position to understand what those are
# and so the code for them appears below.


class DiscordInteractionType(Enum):
    PING = 1  # hello from Discord during auth check
    APPLICATION_COMMAND = 2  # an actual command


class DiscordResponseType(Enum):
    PONG = 1  # hello back during auth check
    DEFERRED_CHANNEL_MESSAGE_WITH_SOURCE = 5  # we'll send a message later


# ## Deploy on Modal

# You can deploy this app on Modal by running the following commands:

# ``` shell
# modal run discord_bot.py  # checks the API wrapper, little test
# modal run discord_bot.py::create_slash_command  # creates the slash command, if missing
# modal deploy discord_bot.py  # deploys the web app and the API wrapper
# ```

# Copy the Modal URL that is printed in the output and go back to the **General Information** section on the
# [Discord Developer Portal](https://discord.com/developers/applications).
# Paste the URL, making sure to append the path of your `POST` route (here, `/api`), in the
# **Interactions Endpoint URL** field, then click **Save Changes**. If your
# endpoint URL is incorrect or if authentication is incorrectly implemented,
# Discord will refuse to save the URL. Once it saves, you can start
# handling interactions!

# ## Finish setting up Discord bot

# To start using the Slash Command you just set up, you need to invite the bot to
# a Discord server. To do so, go to your application's **Installation** section on the
# [Discord Developer Portal](https://discord.com/developers/applications).
# Copy the **Discored Provided Link** and visit it to invite the bot to your bot to the server.

# Now you can open your Discord server and type `/api` in a channel to trigger the bot.
# You can see a working version [in our test Discord server](https://discord.gg/PmG7P47EPQ).


=== GITHUB: 07_web_endpoints/basic_web.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/basic_web.py"]
# ---

# # Hello world wide web!

# Modal makes it easy to turn your Python functions into serverless web services:
# access them via a browser or call them from any client that speaks HTTP, all
# without having to worry about setting up servers or managing infrastructure.

# This tutorial shows the path with the shortest ["time to 200"](https://shkspr.mobi/blog/2021/05/whats-your-apis-time-to-200/):
# [`modal.fastapi_endpoint`](https://modal.com/docs/reference/modal.fastapi_endpoint).

# On Modal, web endpoints have all the superpowers of Modal Functions:
# they can be [accelerated with GPUs](https://modal.com/docs/guide/gpu),
# they can access [Secrets](https://modal.com/docs/guide/secrets) or [Volumes](https://modal.com/docs/guide/volumes),
# and they [automatically scale](https://modal.com/docs/guide/cold-start) to handle more traffic.

# Under the hood, we use the [FastAPI library](https://fastapi.tiangolo.com/),
# which has [high-quality documentation](https://fastapi.tiangolo.com/tutorial/),
# linked throughout this tutorial.

# ## Turn a Modal Function into an API endpoint with a single decorator

# Modal Functions are already accessible remotely -- when you add the `@app.function` decorator to a Python function
# and run `modal deploy`, you make it possible for your [other Python functions to call it](https://modal.com/docs/guide/trigger-deployed-functions).

# That's great, but it's not much help if you want to share what you've written with someone running code in a different language --
# or not running code at all!

# And that's where most of the power of the Internet comes from: sharing information and functionality across different computer systems.

# So we provide the `fastapi_endpoint` decorator to wrap your Modal Functions in the lingua franca of the web: HTTP.
# Here's what that looks like:

import modal

image = modal.Image.debian_slim().pip_install("fastapi[standard]")
app = modal.App(name="example-lifecycle-web", image=image)


@app.function()
@modal.fastapi_endpoint(
    docs=True  # adds interactive documentation in the browser
)
def hello():
    return "Hello world!"


# You can turn this function into a web endpoint by running `modal serve basic_web.py`.
# In the output, you should see a URL that ends with `hello-dev.modal.run`.
# If you navigate to this URL, you should see the `"Hello world!"` message appear in your browser.

# You can also find interactive documentation, powered by OpenAPI and Swagger,
# if you add `/docs` to the end of the URL.
# From this documentation, you can interact with your endpoint, sending HTTP requests and receiving HTTP responses.
# For more details, see the [FastAPI documentation](https://fastapi.tiangolo.com/features/#automatic-docs).

# By running the endpoint with `modal serve`, you created a temporary endpoint that will disappear if you interrupt your terminal.
# These temporary endpoints are great for debugging -- when you save a change to any of your dependent files, the endpoint will redeploy.
# Try changing the message to something else, hitting save, and then hitting refresh in your browser or re-sending
# the request from `/docs` or the command line. You should see the new message, along with logs in your terminal showing the redeploy and the request.

# When you're ready to deploy this endpoint permanently, run `modal deploy basic_web.py`.
# Now, your function will be available even when you've closed your terminal or turned off your computer.

# ## Send data to a web endpoint

# The web endpoint above was a bit silly: it always returns the same message.

# Most endpoints need an input to be useful. There are two ways to send data to a web endpoint:
# - in the URL as a [query parameter](#sending-data-in-query-parameters)
# - in the [body of the request](#sending-data-in-the-request-body) as JSON

# ### Sending data in query parameters

# By default, your function's arguments are treated as query parameters:
# they are extracted from the end of the URL, where they should be added in the form
# `?arg1=foo&arg2=bar`.

# From the Python side, there's hardly anything to do:


@app.function()
@modal.fastapi_endpoint(docs=True)
def greet(user: str) -> str:
    return f"Hello {user}!"


# If you are already running `modal serve basic_web.py`, this endpoint will be available at a URL, printed in your terminal, that ends with `greet-dev.modal.run`.

# We provide Python type-hints to get type information in the docs and
# [automatic validation](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/).
# For example, if you navigate directly to the URL for `greet`, you will get a detailed error message
# indicating that the `user` parameter is missing. Navigate instead to `/docs` to see how to invoke the endpoint properly.

# You can read more about query parameters in the [FastAPI documentation](https://fastapi.tiangolo.com/tutorial/query-params/).


# ### Sending data in the request body

# For larger and more complex data, it is generally preferrable to send data in the body of the HTTP request.
# This body is formatted as [JSON](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/JSON),
# the most common data interchange format on the web.

# To set up an endpoint that accepts JSON data, add an argument with a `dict` type-hint to your function.
# This argument will be populated with the data sent in the request body.


@app.function()
@modal.fastapi_endpoint(method="POST", docs=True)
def goodbye(data: dict) -> str:
    name = data.get("name") or "world"
    return f"Goodbye {name}!"


# Note that we gave a value of `"POST"` for the `method` argument here.
# This argument defines the HTTP request method that the endpoint will respond to,
# and it defaults to `"GET"`.
# If you head to the URL for the `goodbye` endpoint in your browser,
# you will get a 405 Method Not Allowed error, because browsers only send GET requests by default.
# While this is technically a separate concern from query parameters versus request bodies
# and you can define an endpoint that accepts GET requests and uses data from the body,
# it is [considered bad form](https://stackoverflow.com/a/983458).

# Navigate to `/docs` for more on how to invoke the endpoint properly.
# You will need to send a POST request with a JSON body containing a `name` key.
# To get the same typing and validation benefits as with query parameters,
# use a [Pydantic model](https://fastapi.tiangolo.com/tutorial/body/)
# for this argument.

# You can read more about request bodies in the [FastAPI documentation](https://fastapi.tiangolo.com/tutorial/body/).

# ## Handle expensive startup with `modal.Cls`

# Sometimes your endpoint needs to do something before it can handle its first request,
# like get a value from a database or set the value of a variable.
# If that step is expensive, like [loading a large ML model](https://modal.com/docs/guide/model-weights),
# it'd be a shame to have to do it every time a request comes in!

# Web endpoints can be methods on a [`modal.Cls`](https://modal.com/docs/guide/lifecycle-functions#container-lifecycle-functions-and-parameters),
# which allows you to manage the container's lifecycle independently from processing individual requests.

# This example will only set the `start_time` instance variable once, on container startup.


@app.cls()
class WebApp:
    @modal.enter()
    def startup(self):
        from datetime import datetime, timezone

        print("🏁 Starting up!")
        self.start_time = datetime.now(timezone.utc)

    @modal.fastapi_endpoint(docs=True)
    def web(self):
        from datetime import datetime, timezone

        current_time = datetime.now(timezone.utc)
        return {"start_time": self.start_time, "current_time": current_time}


# ## Protect web endpoints with proxy authentication

# Sharing your Python functions on the web is great, but it's not always a good idea
# to make those functions available to just anyone.

# For example, you might have a function like the one below that
# is more expensive to run than to call (and so might be abused by your enemies)
# or reveals information that you would rather keep secret.

# To protect your Modal web endpoints so that they can't be triggered except
# by members of your [Modal workspace](https://modal.com/docs/guide/workspaces),
# add the `requires_proxy_auth=True` flag to the `fastapi_endpoint` decorator.


@app.function(gpu="h100")
@modal.fastapi_endpoint(requires_proxy_auth=True, docs=False)
def expensive_secret():
    return "I didn't care for 'The Godfather'. It insists upon itself."


# The `expensive-secret` endpoint URL will still be printed to the output when you `modal serve` or `modal deploy`,
# along with a "🔑" emoji indicating that it is secured with proxy authentication.
# If you head to that URL via the browser, you will get a
# [`401 Unauthorized`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401) error code in response.
# You should also check the dashboard page for this app (at the URL printed at the very top of the `modal` command output)
# so you can see that no containers were spun up to handle the request -- this authorization is handled entirely inside Modal's infrastructure.

# You can trigger the web endpoint by [creating a Proxy Auth Token](https://modal.com/settings/proxy-auth-tokens)
# and then including the token ID and secret in the `Modal-Key` and `Modal-Secret` headers.

# From the command line, that might look like

# ```shell
# export TOKEN_ID=wk-1234abcd
# export TOKEN_SECRET=ws-1234abcd
# curl -H "Modal-Key: $TOKEN_ID" \
#      -H "Modal-Secret: $TOKEN_SECRET" \
#      https://your-workspace-name--expensive-secret.modal.run
# ```

# For more details, see the
# [guide to proxy authentication](https://modal.com/docs/guide/webhook-proxy-auth).

# ## What next?

# Modal's `fastapi_endpoint` decorator is opinionated and designed for relatively simple web applications --
# one or a few independent Python functions that you want to expose to the web.

# Three additional decorators allow you to serve more complex web applications with greater control:
# - [`asgi_app`](https://modal.com/docs/guide/webhooks#asgi) to serve applications compliant with the ASGI standard,
# like [FastAPI](https://fastapi.tiangolo.com/)
# - [`wsgi_app`](https://modal.com/docs/guide/webhooks#wsgi) to serve applications compliant with the WSGI standard,
# like [Flask](https://flask.palletsprojects.com/)
# - [`web_server`](https://modal.com/docs/guide/webhooks#non-asgi-web-servers) to serve any application that listens on a port


=== GITHUB: 07_web_endpoints/badges.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/badges.py"]
# ---

# # Serve a dynamic SVG badge

# In this example, we use Modal's [webhook](https://modal.com/docs/guide/webhooks) capability to host a dynamic SVG badge that shows
# you the current number of downloads for a Python package.

# First let's start off by creating a Modal app, and defining an image with the Python packages we're going to be using:

import modal

image = modal.Image.debian_slim().pip_install(
    "fastapi[standard]", "pybadges", "pypistats"
)

app = modal.App("example-web-badges", image=image)

# ## Defining the web endpoint

# In addition to using `@app.function()` to decorate our function, we use the
# [`@modal.fastapi_endpoint` decorator](https://modal.com/docs/guide/webhooks)
# which instructs Modal to create a REST endpoint that serves this function.
# Note that the default method is `GET`, but this can be overridden using the `method` argument.


@app.function()
@modal.fastapi_endpoint()
async def package_downloads(package_name: str):
    import json

    import pypistats
    from fastapi import Response
    from pybadges import badge

    stats = json.loads(pypistats.recent(package_name, format="json"))
    svg = badge(
        left_text=f"{package_name} downloads",
        right_text=str(stats["data"]["last_month"]),
        right_color="blue",
    )

    return Response(content=svg, media_type="image/svg+xml")


# In this function, we use `pypistats` to query the most recent stats for our package, and then
# use that as the text for a SVG badge, rendered using `pybadges`.
# Since Modal web endpoints are FastAPI functions under the hood, we return this SVG wrapped in a FastAPI response with the correct media type.
# Also note that FastAPI automatically interprets `package_name` as a [query param](https://fastapi.tiangolo.com/tutorial/query-params/).

# ## Running and deploying

# We can now run an ephemeral app on the command line using:

# ```shell
# modal serve badges.py
# ```

# This will create a short-lived web url that exists until you terminate the script.
# It will also hot-reload the code if you make changes to it.

# If you want to create a persistent URL, you have to deploy the script.
# To deploy using the Modal CLI by running `modal deploy badges.py`,

# Either way, as soon as we run this command, Modal gives us the link to our brand new
# web endpoint in the output:

# ![web badge deployment](./badges_deploy.png)

# We can now visit the link using a web browser, using a `package_name` of our choice in the URL query params.
# For example:
# - `https://YOUR_SUBDOMAIN.modal.run/?package_name=synchronicity`
# - `https://YOUR_SUBDOMAIN.modal.run/?package_name=torch`


=== GITHUB: 07_web_endpoints/flask_streaming.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/flask_streaming.py"]
# ---

# # Deploy Flask app with streaming results with Modal

# This example shows how you can deploy a [Flask](https://flask.palletsprojects.com/en/3.0.x/) app with Modal that streams results back to the client.

import modal

app = modal.App(
    "example-web-flask-stream",
    image=modal.Image.debian_slim().pip_install("flask"),
)


@app.function()
def generate_rows():
    """
    This creates a large CSV file, about 10MB, which will be streaming downloaded
    by a web client.
    """
    for i in range(10_000):
        line = ",".join(str((j + i) * i) for j in range(128))
        yield f"{line}\n"


@app.function()
@modal.wsgi_app()
def flask_app():
    from flask import Flask

    web_app = Flask(__name__)

    # These web handlers follow the example from
    # https://flask.palletsprojects.com/en/2.2.x/patterns/streaming/

    @web_app.route("/")
    def generate_large_csv():
        # Run the function locally in the web app's container.
        return generate_rows.local(), {"Content-Type": "text/csv"}

    @web_app.route("/remote")
    def generate_large_csv_in_container():
        # Run the function remotely in a separate container,
        # which will stream back results to the web app container,
        # which will stream back to the web client.
        #
        # This is less efficient, but demonstrates how web serving
        # containers can be separated from and cooperate with other
        # containers.
        return generate_rows.remote(), {"Content-Type": "text/csv"}

    return web_app


=== GITHUB: 07_web_endpoints/streaming.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/streaming.py"]
# ---

# # Deploy a FastAPI app with streaming responses

# This example shows how you can deploy a [FastAPI](https://fastapi.tiangolo.com/) app with Modal that streams results back to the client.

import asyncio
import time

import modal
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

image = modal.Image.debian_slim().pip_install("fastapi[standard]")
app = modal.App("example-fastapi-streaming", image=image)

web_app = FastAPI()

# This asynchronous generator function simulates
# progressively returning data to the client. The `asyncio.sleep`
# is not necessary, but makes it easier to see the iterative behavior
# of the response.


async def fake_video_streamer():
    for i in range(10):
        yield f"frame {i}: hello world!".encode()
        await asyncio.sleep(1.0)


# ASGI app with streaming handler.

# This `fastapi_app` also uses the fake video streamer async generator,
# passing it directly into `StreamingResponse`.


@web_app.get("/")
async def main():
    return StreamingResponse(fake_video_streamer(), media_type="text/event-stream")


@app.function()
@modal.asgi_app()
def fastapi_app():
    return web_app


# This `hook` web endpoint Modal function calls *another* Modal function,
# and it just works!


@app.function()
def sync_fake_video_streamer():
    for i in range(10):
        yield f"frame {i}: some data\n".encode()
        time.sleep(1)


@app.function()
@modal.fastapi_endpoint()
def hook():
    return StreamingResponse(
        sync_fake_video_streamer.remote_gen(), media_type="text/event-stream"
    )


# This `mapped` web endpoint Modal function does a parallel `.map` on a simple
# Modal function. Using `.starmap` also would work in the same fashion.


@app.function()
def map_me(i):
    time.sleep(i)  # stagger the results for demo purposes
    return f"hello from {i}\n"


@app.function()
@modal.fastapi_endpoint()
def mapped():
    return StreamingResponse(map_me.map(range(10)), media_type="text/event-stream")


# To try for yourself, run

# ```shell
# modal serve streaming.py
# ```

# and then send requests to the URLs that appear in the terminal output.

# Make sure that your client is not buffering the server response
# until it gets newline (\n) characters. By default browsers and `curl` are buffering,
# though modern browsers should respect the "text/event-stream" content type header being set.


=== GITHUB: 07_web_endpoints/fastapi_app.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/fastapi_app.py"]
# ---

# # Deploy FastAPI app with Modal

# This example shows how you can deploy a [FastAPI](https://fastapi.tiangolo.com/) app with Modal.
# You can serve any app written in an ASGI-compatible web framework (like FastAPI) using this pattern or you can server WSGI-compatible frameworks like Flask with [`wsgi_app`](https://modal.com/docs/guide/webhooks#wsgi).

from typing import Optional

import modal
from fastapi import FastAPI, Header
from pydantic import BaseModel

image = modal.Image.debian_slim().pip_install("fastapi[standard]", "pydantic")
app = modal.App("example-fastapi-app", image=image)
web_app = FastAPI()


class Item(BaseModel):
    name: str


@web_app.get("/")
async def handle_root(user_agent: Optional[str] = Header(None)):
    print(f"GET /     - received user_agent={user_agent}")
    return "Hello World"


@web_app.post("/foo")
async def handle_foo(item: Item, user_agent: Optional[str] = Header(None)):
    print(f"POST /foo - received user_agent={user_agent}, item.name={item.name}")
    return item


@app.function()
@modal.asgi_app()
def fastapi_app():
    return web_app


@app.function()
@modal.fastapi_endpoint(method="POST")
def f(item: Item):
    return "Hello " + item.name


if __name__ == "__main__":
    app.deploy("webapp")


=== GITHUB: 07_web_endpoints/flask_app.py ===
# ---
# cmd: ["modal", "serve", "07_web_endpoints/flask_app.py"]
# ---

# # Deploy Flask app with Modal

# This example shows how you can deploy a [Flask](https://flask.palletsprojects.com/en/3.0.x/) app with Modal.
# You can serve any app written in a WSGI-compatible web framework (like Flask) on Modal with this pattern. You can serve an app written in an ASGI-compatible framework, like FastAPI, with [`asgi_app`](https://modal.com/docs/guide/webhooks#asgi).

import modal

app = modal.App(
    "example-web-flask",
    image=modal.Image.debian_slim().pip_install("flask"),
)


@app.function()
@modal.wsgi_app()
def flask_app():
    from flask import Flask, request

    web_app = Flask(__name__)

    @web_app.get("/")
    def home():
        return "Hello Flask World!"

    @web_app.post("/foo")
    def foo():
        return request.json

    return web_app


=== GITHUB: 07_web_endpoints/fasthtml-checkboxes/constants.py ===
# ---
# lambda-test: false  # auxiliary-file
# ---
N_CHECKBOXES = 100_000  # feel free to increase, if you dare!


=== GITHUB: 07_web_endpoints/fasthtml-checkboxes/cbx_locustfile.py ===
# ---
# lambda-test: false  # auxiliary-file
# pytest: false
# ---
import random

from bs4 import BeautifulSoup
from constants import N_CHECKBOXES
from locust import HttpUser, between, task


class CheckboxesUser(HttpUser):
    wait_time = between(0.01, 0.1)  # Simulates a wait time between requests

    def load_homepage(self):
        """
        Simulates a user loading the homepage and fetching the state of the checkboxes.
        """
        response = self.client.get("/")
        soup = BeautifulSoup(response.text, "lxml")
        main_div = soup.find("main")
        self.id = main_div["hx-get"].split("/")[-1]

    @task(10)
    def toggle_random_checkboxes(self):
        """
        Simulates a user toggling a random checkbox.
        """
        n_checkboxes = random.binomialvariate(  # approximately poisson at 10
            n=100,
            p=0.1,
        )
        for _ in range(min(n_checkboxes, 1)):
            checkbox_id = int(
                N_CHECKBOXES * random.random() ** 2
            )  # Choose a random checkbox between 0 and 9999, more likely to be closer to 0
            self.client.post(
                f"/checkbox/toggle/{checkbox_id}",
                name="/checkbox/toggle",
            )

    @task(1)
    def poll_for_diffs(self):
        """
        Simulates a user polling for any outstanding diffs.
        """
        self.client.get(f"/diffs/{self.id}", name="/diffs")

    def on_start(self):
        """
        Called when a simulated user starts, typically used to initialize or login a user.
        """
        self.id = str(random.randint(1, 9999))
        self.load_homepage()


=== GITHUB: 07_web_endpoints/fasthtml-checkboxes/fasthtml_checkboxes.py ===
# ---
# cmd: ["modal", "serve", "-m", "07_web_endpoints.fasthtml-checkboxes.fasthtml_checkboxes"]
# deploy: true
# mypy: ignore-errors
# ---

# # Deploy 100,000 multiplayer checkboxes on Modal with FastHTML

# [![Screenshot of FastHTML Checkboxes UI](./ui.png)](https://modal-labs-examples--example-checkboxes-web.modal.run)

# This example shows how you can deploy a multiplayer checkbox game with FastHTML on Modal.

# [FastHTML](https://www.fastht.ml/) is a Python library built on top of [HTMX](https://htmx.org/)
# which allows you to create entire web applications using only Python.
# For a simpler template for using FastHTML with Modal, check out
# [this example](https://modal.com/docs/examples/fasthtml_app).

# Our example is inspired by [1 Million Checkboxes](https://onemillioncheckboxes.com/).

import time
from asyncio import Lock
from pathlib import Path
from uuid import uuid4

import modal

from .constants import N_CHECKBOXES

app = modal.App("example-checkboxes")
db = modal.Dict.from_name("example-checkboxes-db", create_if_missing=True)

css_path_local = Path(__file__).parent / "styles.css"
css_path_remote = "/assets/styles.css"


@app.function(
    image=modal.Image.debian_slim(python_version="3.12")
    .pip_install("python-fasthtml==0.6.9", "inflect~=7.4.0")
    .add_local_file(css_path_local, remote_path=css_path_remote),
    max_containers=1,  # we currently maintain state in memory, so we restrict the server to one worker
)
@modal.concurrent(max_inputs=1000)
@modal.asgi_app()
def web():
    import fasthtml.common as fh
    import inflect

    # Connected clients are tracked in-memory
    clients = {}
    clients_mutex = Lock()

    # We keep all checkbox fasthtml elements in memory during operation, and persist to modal dict across restarts
    checkboxes = db.get("checkboxes", [])
    checkbox_mutex = Lock()

    if len(checkboxes) == N_CHECKBOXES:
        print("Restored checkbox state from previous session.")
    else:
        print("Initializing checkbox state.")
        checkboxes = []
        for i in range(N_CHECKBOXES):
            checkboxes.append(
                fh.Input(
                    id=f"cb-{i}",
                    type="checkbox",
                    checked=False,
                    # when clicked, that checkbox will send a POST request to the server with its index
                    hx_post=f"/checkbox/toggle/{i}",
                    hx_swap_oob="true",  # allows us to later push diffs to arbitrary checkboxes by id
                )
            )

    async def on_shutdown():
        # Handle the shutdown event by persisting current state to modal dict
        async with checkbox_mutex:
            db["checkboxes"] = checkboxes
        print("Checkbox state persisted.")

    style = open(css_path_remote, "r").read()
    app, _ = fh.fast_app(
        # FastHTML uses the ASGI spec, which allows handling of shutdown events
        on_shutdown=[on_shutdown],
        hdrs=[fh.Style(style)],
    )

    # handler run on initial page load
    @app.get("/")
    async def get():
        # register a new client
        client = Client()
        async with clients_mutex:
            clients[client.id] = client

        return (
            fh.Title(f"{N_CHECKBOXES // 1000}k Checkboxes"),
            fh.Main(
                fh.H1(
                    f"{inflect.engine().number_to_words(N_CHECKBOXES).title()} Checkboxes"
                ),
                fh.Div(
                    *checkboxes,
                    id="checkbox-array",
                ),
                cls="container",
                # use HTMX to poll for diffs to apply
                hx_trigger="every 1s",  # poll every second
                hx_get=f"/diffs/{client.id}",  # call the diffs endpoint
                hx_swap="none",  # don't replace the entire page
            ),
        )

    # users submitting checkbox toggles
    @app.post("/checkbox/toggle/{i}")
    async def toggle(i: int):
        async with checkbox_mutex:
            cb = checkboxes[i]
            cb.checked = not cb.checked
            checkboxes[i] = cb

        async with clients_mutex:
            expired = []
            for client in clients.values():
                # clean up old clients
                if not client.is_active():
                    expired.append(client.id)

                # add diff to client for when they next poll
                client.add_diff(i)

            for client_id in expired:
                del clients[client_id]
        return

    # clients polling for any outstanding diffs
    @app.get("/diffs/{client_id}")
    async def diffs(client_id: str):
        # we use the `hx_swap_oob='true'` feature to
        # push updates only for the checkboxes that changed
        async with clients_mutex:
            client = clients.get(client_id, None)
            if client is None or len(client.diffs) == 0:
                return

            client.heartbeat()
            diffs = client.pull_diffs()

        async with checkbox_mutex:
            diff_array = [checkboxes[i] for i in diffs]

        return diff_array

    return app


# Class for tracking state to push out to connected clients
class Client:
    def __init__(self):
        self.id = str(uuid4())
        self.diffs = []
        self.inactive_deadline = time.time() + 30

    def is_active(self):
        return time.time() < self.inactive_deadline

    def heartbeat(self):
        self.inactive_deadline = time.time() + 30

    def add_diff(self, i):
        if i not in self.diffs:
            self.diffs.append(i)

    def pull_diffs(self):
        # return a copy of the diffs and clear them
        diffs = self.diffs
        self.diffs = []
        return diffs


=== GITHUB: 07_web_endpoints/fasthtml-checkboxes/cbx_load_test.py ===
import os
from datetime import datetime
from pathlib import Path

import modal

if modal.is_local():
    workspace = modal.config._profile or ""
    environment = modal.config.config["environment"] or ""
else:
    workspace = os.environ["MODAL_WORKSPACE"] or ""
    environment = os.environ["MODAL_ENVIRONMENT"] or ""


image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install("locust~=2.29.1", "beautifulsoup4~=4.12.3", "lxml~=5.3.0")
    .env({"MODAL_WORKSPACE": workspace, "MODAL_ENVIRONMENT": environment})
    .add_local_file(
        Path(__file__).parent / "cbx_locustfile.py",
        remote_path="/root/locustfile.py",
    )
    .add_local_file(
        Path(__file__).parent / "constants.py",
        remote_path="/root/constants.py",
    )
)
volume = modal.Volume.from_name("loadtest-checkboxes-results", create_if_missing=True)
remote_path = Path("/root") / "loadtests"
OUT_DIRECTORY = remote_path / datetime.utcnow().replace(microsecond=0).isoformat()

app = modal.App("loadtest-checkbox", image=image, volumes={remote_path: volume})

workers = 8
host = f"https://{workspace}{'-' + environment if environment else ''}--example-checkboxes-web.modal.run"
csv_file = OUT_DIRECTORY / "stats.csv"
default_args = [
    "-H",
    host,
    "--processes",
    str(workers),
    "--csv",
    csv_file,
]

MINUTES = 60  # seconds


@app.function(cpu=workers)
@modal.concurrent(max_inputs=1000)
@modal.web_server(port=8089)
def serve():
    run_locust.local(default_args)


@app.function(cpu=workers, timeout=60 * MINUTES)
def run_locust(args: list, wait=False):
    import subprocess

    process = subprocess.Popen(["locust"] + args)
    if wait:
        process.wait()
        return process.returncode


@app.local_entrypoint()
def main(
    r: float = 1.0,
    u: int = 36,
    t: str = "1m",  # no more than the timeout of run_locust, one hour
):
    args = default_args + [
        "--spawn-rate",
        str(r),
        "--users",
        str(u),
        "--run-time",
        t,
    ]

    html_report_file = OUT_DIRECTORY / "report.html"
    args += [
        "--headless",  # run without browser UI
        "--autostart",  # start test immediately
        "--autoquit",  # stop once finished...
        "10",  # ...but wait ten seconds
        "--html",  # output an HTML-formatted report
        html_report_file,  # to this location
    ]

    if exit_code := run_locust.remote(args, wait=True):
        SystemExit(exit_code)
    else:
        print("finished successfully")


=== GITHUB: 07_web_endpoints/webrtc/webrtc_yolo_test.py ===
# ---
# cmd: ["modal", "run", "-m", "07_web_endpoints.webrtc.webrtc_yolo_test"]
# ---


import modal

from .modal_webrtc import ModalWebRtcPeer
from .webrtc_yolo import (
    CACHE_PATH,
    WebcamObjDet,
    app,
    base_image,
    cache,
)

# ## Testing WebRTC and Modal

# First we define a `local_entrypoint` to run and evaluate the test.
# Our test will stream an .mp4 file to the cloud peer and record the annoated video to a new file.
# The test itself ensurse that the new video is no more than five frames shorter than the source file.
# The difference is due to dropped frames while the connection is starting up.


@app.local_entrypoint()
def test():
    input_frames, output_frames = TestPeer().run_video_processing_test.remote()
    # allow a few dropped frames from the connection starting up
    assert input_frames - output_frames < 5, (
        f"Streaming failed. Frame difference: {input_frames} - {output_frames} = {input_frames - output_frames}"
    )


# Because our test will require Python dependencies outside the standard library, we'll run the test itself in a container on Modal.
# In fact, this will be another `ModalWebRtcPeer` class. So the test will also demonstrate how to setup WebRTC between Modal containers.
# There are some details in here regarding the use of `aiortc`'s `MediaPlayer` and `MediaRecorder` classes that won't cover here.
# Just know that these are `aiortc` specific classes - not a WebRTC thing.

# That said, using these classes does require us to manually `start` and `stop` streams.
# For example, we'll need to override the `run_streams` method to start the source stream, and we'll make use of the `on_ended` callback to stop the recording.


@app.cls(image=base_image, volumes=cache)
class TestPeer(ModalWebRtcPeer):
    TEST_VIDEO_SOURCE_URL = "https://modal-cdn.com/cliff_jumping.mp4"
    TEST_VIDEO_RECORD_FILE = CACHE_PATH / "test_video.mp4"
    # extra time to run streams beyond input video duration
    VIDEO_DURATION_BUFFER_SECS = 5.0
    # allow time for container to spin up (can timeout with default 10)
    WS_OPEN_TIMEOUT = 300  # seconds

    async def initialize(self) -> None:
        import cv2

        # get input video duration in seconds
        self.input_video = cv2.VideoCapture(self.TEST_VIDEO_SOURCE_URL)
        self.input_video_duration_frames = self.input_video.get(
            cv2.CAP_PROP_FRAME_COUNT
        )
        self.input_video_duration_seconds = (
            self.input_video_duration_frames / self.input_video.get(cv2.CAP_PROP_FPS)
        )
        self.input_video.release()

        # set streaming duration to input video duration plus a buffer
        self.stream_duration = (
            self.input_video_duration_seconds + self.VIDEO_DURATION_BUFFER_SECS
        )

        self.player = None  # video stream source
        self.recorder = None  # processed video stream sink

    async def setup_streams(self, peer_id: str) -> None:
        import os

        from aiortc import MediaStreamTrack
        from aiortc.contrib.media import MediaPlayer, MediaRecorder

        # setup video player and to peer connection
        self.video_src = MediaPlayer(self.TEST_VIDEO_SOURCE_URL)
        self.pcs[peer_id].addTrack(self.video_src.video)

        # setup video recorder
        if os.path.exists(self.TEST_VIDEO_RECORD_FILE):
            os.remove(self.TEST_VIDEO_RECORD_FILE)
        self.recorder = MediaRecorder(self.TEST_VIDEO_RECORD_FILE)

        # keep us notified on connection state changes
        @self.pcs[peer_id].on("connectionstatechange")
        async def on_connectionstatechange() -> None:
            print(
                f"Video Tester connection state updated: {self.pcs[peer_id].connectionState}"
            )

        # when we receive a track back from
        # the video processing peer we record it
        # to the output file
        @self.pcs[peer_id].on("track")
        def on_track(track: MediaStreamTrack) -> None:
            print(f"Video Tester received {track.kind} track from {peer_id}")
            # record track to file
            self.recorder.addTrack(track)

            @track.on("ended")
            async def on_ended() -> None:
                print("Video Tester's processed video stream ended")
                # stop recording when incoming track ends to finish writing video
                await self.recorder.stop()
                # reset recorder and player
                self.recorder = None
                self.video_src = None

    async def run_streams(self, peer_id: str) -> None:
        import asyncio

        print(f"Video Tester running streams for {peer_id}...")

        # MediaRecorders need to be started manually
        # but in most cases the track is already streaming
        await self.recorder.start()

        # run until sufficient time has passed
        await asyncio.sleep(self.stream_duration)

        # close peer connection manually
        await self.pcs[peer_id].close()

    def count_frames(self):
        import cv2

        # compare output video length to input video length
        output_video = cv2.VideoCapture(self.TEST_VIDEO_RECORD_FILE)
        output_video_duration_frames = int(output_video.get(cv2.CAP_PROP_FRAME_COUNT))
        output_video.release()

        return self.input_video_duration_frames, output_video_duration_frames

    @modal.method()
    async def run_video_processing_test(self) -> bool:
        import asyncio
        import json

        import websockets

        peer_id = None
        # connect to server via websocket
        ws_uri = (
            WebcamObjDet().web.get_web_url().replace("http", "ws") + f"/ws/{self.id}"
        )
        async with websockets.connect(
            ws_uri, open_timeout=self.WS_OPEN_TIMEOUT
        ) as websocket:
            await websocket.send(json.dumps({"type": "identify", "peer_id": self.id}))
            peer_id = json.loads(await websocket.recv())["peer_id"]

            offer_msg = await self.generate_offer(peer_id)
            await websocket.send(json.dumps(offer_msg))

            try:
                # receive answer
                answer = json.loads(await websocket.recv())

                if answer.get("type") == "answer":
                    await self.handle_answer(peer_id, answer)

            except websockets.exceptions.ConnectionClosed:
                await websocket.close()

        # loop until video player is finished
        if self.pcs.get(peer_id) and self.pcs[peer_id].connectionState == "connected":
            await self.run_streams(peer_id)

            # wait for peer to finish processing video
            await asyncio.sleep(5.0)

        return self.count_frames()


=== GITHUB: 07_web_endpoints/webrtc/webrtc_yolo.py ===
# ---
# cmd: ["modal", "serve", "-m", "07_web_endpoints.webrtc.webrtc_yolo"]
# deploy: true
# ---

# # Real-time object detection with WebRTC and YOLO

# This example demonstrates how to architect a serverless real-time streaming application with Modal and WebRTC.
# The sample application detects objects in webcam video with YOLO.

# See the clip below from a live demo of this example in a course by [Kwindla Kramer](https://machine-theory.com/), WebRTC OG and co-founder of [Daily](https://www.daily.co/).

# <center>
# <video controls autoplay muted>
# <source src="https://modal-cdn.com/example-webrtc_yolo.mp4" type="video/mp4">
# </video>
# </center>

# You can also try our deployment [here](https://modal-labs-examples--example-webrtc-yolo-webcamobjdet-web.modal.run).

# ## What is WebRTC?

# WebRTC (Web Real-Time Communication) is an [IETF Internet protocol](https://www.rfc-editor.org/rfc/rfc8825) and a [W3C API specification](https://www.w3.org/TR/webrtc/) for real-time media streaming between peers
# over internets or the World Wide Web.
# What makes it so effective and different from other bidirectional web-based communication protocols (e.g. WebSockets) is that it's purpose-built for media streaming in real time.
# It's primarily designed for browser applications using the JavaScript API, but [APIs exist for other languages](https://www.webrtc-developers.com/did-i-choose-the-right-webrtc-stack/).
# We'll build our app using Python's [`aiortc`](https://aiortc.readthedocs.io/en/latest/) package.

# ### What makes up a WebRTC application?

# A simple WebRTC app generally consists of three players:
# 1. a peer that initiates the connection,
# 2. a peer that responds to the connection, and
# 3. a server that passes some initial messages between the two peers.

# First, one peer initiates the connection by offering up a description of itself - its media sources, codec capabilities, Internet Protocol (IP) addressing info, etc - which is relayed to another peer through the server.
# The other peer then either accepts the offer by providing a compatible description of its own capabilities or rejects it if no compatible configuration is possible.
# This process is called "signaling" or sometimes the "negotiation" in the WebRTC world, and the server that mediates it is usually called the "signaling server".

# Once the peers have agreed on a configuration there's a brief pause to establish communication... and then you're live.

# ![Basic WebRTC architecture](https://modal-cdn.com/cdnbot/just_webrtc-1oic3iems_a4a8e77c.webp)
# <small>A basic WebRTC app architecture</small>

# Obviously there’s more going on under the hood.
# If you want to get into the details, we recommend checking out the [RFCs](https://www.rfc-editor.org/rfc/rfc8825) or a [more-thorough explainer](https://webrtcforthecurious.com/).
# In this document, we'll focus on how to architect a WebRTC application where one or more peer is running on Modal's serverless cloud infrastructure.

# If you just want to quickly get started with WebRTC for a small internal service or a hack project, check out
# [our FastRTC example](https://modal.com/docs/examples/fastrtc_flip_webcam) instead.

# ## How do I run a WebRTC app on Modal?

# Modal turns Python code into scalable cloud services.
# When you call a Modal Function, you get one replica.
# If you call it 999 more times before it returns, you have 1000 replicas.
# When your Functions all return, you spin down to 0 replicas.

# The core constraints of the Modal programming model that make this possible are that Function Calls are stateless and self-contained.
# In other words, correctly-written Modal Functions don't store information in memory between runs (though they might cache data to the ephemeral local disk for efficiency) and they don't create processes or tasks which must continue to run after the Function Call returns in order for the application to be correct.

# WebRTC apps, on the other hand, require passing messages back and forth in a multi-step protocol, and APIs spawn several "agents" (no, AI is not involved, just processes) which do work behind the scenes - including managing the peer-to-peer (P2P) connection itself.
# This means that streaming may have only just begun when the application logic in our Function has finished.

# ![Modal programming model and WebRTC signaling](https://modal-cdn.com/cdnbot/flow_comparisong6iibzq3_638bdd84.webp)
# <small>Modal's stateless programming model (left) and WebRTC's stateful signaling (right)</small>

# To ensure we properly leverage Modal's autoscaling and concurrency features, we need to align the signaling and streaming lifetimes with Modal Function Call lifetimes.

# The architecture we recommend for this appears below.

# ![WebRTC on Modal](https://modal-cdn.com/cdnbot/webrtc_with_modal-2horb680q_eab69b28.webp)
# <small>A clean architecture for WebRTC on Modal</small>

# It handles passing messages between the client peer and the signaling server using a
# [WebSocket](https://modal.com/docs/guide/webhooks#websockets) for persistent, bidirectional communication over the Web within a single Function Call.
# (Modal's Web layer maps HTTP and WS onto Function Calls, details [here](https://modal.com/blog/serverless-http)).
# We [`.spawn`](https://modal.com/docs/reference/modal.Function#spawn) the cloud peer inside the WebSocket endpoint
# and communicate it using a [`modal.Queue`](https://modal.com/docs/reference/modal.Queue).

# We can then use the state of the P2P connection to determine when to return from the calls to both the signaling server and the cloud peer.
# When the P2P connection has been _established_, we'll close the WebSocket which in turn ends the call to the signaling server.
# And when the P2P connection has been _closed_, we'll return from the call to the cloud peer.
# That way, our WebRTC application benefits from all the autoscaling and concurrency logic built into Modal
# that enables users to deliver efficient cloud applications.

# We wrote two classes, `ModalWebRtcPeer` and `ModalWebRtcSignalingServer`, to abstract away that boilerplate as well as a lot of the `aiortc` implementation details.
# They're also decorated with Modal [lifetime hooks](https://modal.com/docs/guide/lifecycle-functions).
# Add the [`app.cls`](https://modal.com/docs/reference/modal.App#cls) decorator and some custom logic, and you're ready to deploy on Modal.

# You can find them in the [`modal_webrtc.py` file](https://github.com/modal-labs/modal-examples/blob/main/07_web_endpoints/webrtc/modal_webrtc.py) provided alongside this example in the [GitHub repo](https://github.com/modal-labs/modal-examples/tree/main/07_web_endpoints/webrtc/modal_webrtc.py).

# ## Using `modal_webrtc` to detect objects in webcam footage

# For our WebRTC app, we'll take a client's video stream, run a [YOLO](https://docs.ultralytics.com/tasks/detect/) object detector on it with an A100 GPU on Modal, and then stream the annotated video back to the client.
# With this setup, we can achieve inference times between 2-4 milliseconds per frame and RTTs below video frame rates (usually around 30 milliseconds per frame).

# Let's get started!

# ### Setup

# We'll start with a simple container [Image](https://modal.com/docs/guide/images) and then

# - set it up to properly use TensorRT and the ONNX Runtime, which keep latency minimal,
# - install the necessary libs for processing video, `opencv` and `ffmpeg`, and
# - install the necessary Python packages.

import os
from pathlib import Path

import modal

from .modal_webrtc import ModalWebRtcPeer, ModalWebRtcSignalingServer

py_version = "3.12"
tensorrt_ld_path = f"/usr/local/lib/python{py_version}/site-packages/tensorrt_libs"

video_processing_image = (
    modal.Image.debian_slim(python_version=py_version)  # matching ld path
    # update locale as required by onnx
    .apt_install("locales")
    .run_commands(
        "sed -i '/^#\\s*en_US.UTF-8 UTF-8/ s/^#//' /etc/locale.gen",  # use sed to uncomment
        "locale-gen en_US.UTF-8",  # set locale
        "update-locale LANG=en_US.UTF-8",
    )
    .env({"LD_LIBRARY_PATH": tensorrt_ld_path, "LANG": "en_US.UTF-8"})
    # install system dependencies
    .apt_install("python3-opencv", "ffmpeg")
    # install Python dependencies
    .pip_install(
        "aiortc==1.11.0",
        "fastapi==0.115.12",
        "huggingface-hub[hf_xet]==0.30.2",
        "onnxruntime-gpu==1.21.0",
        "opencv-python==4.11.0.86",
        "tensorrt==10.9.0.34",
        "torch==2.7.0",
        "shortuuid==1.0.13",
    )
)

# ### Cache weights and compute graphs on a Volume

# We also need to create a Modal [Volume](https://modal.com/docs/guide/volumes) to store things we need across replicas --
# primarily the model weights and ONNX inference graph, but also a few other artifacts like a video file where
# we'll write out the processed video stream for testing.

# The very first time we run the app, downloading the model and building the ONNX inference graph will take a few minutes.
# After that, we can load the cached weights and graph from the Volume, which reduces the startup time to about 15 seconds per container.

CACHE_VOLUME = modal.Volume.from_name("webrtc-yolo-cache", create_if_missing=True)
CACHE_PATH = Path("/cache")
cache = {CACHE_PATH: CACHE_VOLUME}

app = modal.App("example-webrtc-yolo")

# ### Implement YOLO object detection as a `ModalWebRtcPeer`

# Our application needs to process an incoming video track with YOLO and return an annotated video track to the source peer.

# To implement a `ModalWebRtcPeer`, we need to:

# - Decorate our subclass with `@app.cls`. We provision it with an A100 GPU and a [Secret](https://modal.com/docs/guide/secrets) credential, described below.
# - Implement the method `setup_streams`. This is where we'll use `aiortc` to add the logic for processing the incoming video track with YOLO
# and returning an annotated video track to the source peer.

# `ModalWebRtcPeer` has a few other methods that users can optionally implement:

# - `initialize()`: This contains any custom initialization logic, called when `@modal.enter()` is called.
# - `run_streams()`: Logic for starting streams. This is necessary when the peer is the source of the stream.
# This is where you'd ensure a webcam was running, start playing a video file, or spin up a [video generative model](https://modal.com/docs/examples/image_to_video).
# - `get_turn_servers()`: We haven't talked about [TURN servers](https://datatracker.ietf.org/doc/html/rfc5766),
# but just know that they're necessary if you want to use WebRTC across complex (e.g. carrier-grade) NAT or firewall configurations.
# Free services have tight limits because TURN servers are expensive to run (lots of bandwidth and state management required).
# [STUN](https://datatracker.ietf.org/doc/html/rfc5389) servers, on the other hand, are essentially just echo servers, and so there are many free services available.
# If you don't provide TURN servers you can still serve your app on many networks using any of a number of free STUN servers for NAT traversal.
# - `exit()`: This contains any custom cleanup logic, called when `@modal.exit()` is called.

# In our case, we load the YOLO model in `initialize` and provide server information for the free [Open Relay TURN server](https://www.metered.ca/tools/openrelay/).
# If you want to use it, you'll need to create an account [here](https://dashboard.metered.ca/login?tool=turnserver)
# and then create a Modal [Secret](https://modal.com/docs/guide/secrets) called `turn-credentials` [here](https://modal.com/secrets).
# We also use the `@modal.concurrent` decorator to allow multiple instances of our peer to run on one GPU.

# **Setting the Region**

# Much of the latency in Internet applications comes from distance between communicating parties --
# the Internet operates within a factor of two of the speed of light, but that's just not that fast.
# To minimize latency under this constraint, the physical distance of the P2P connection
# between the webcam-using peer and the GPU container needs to be kept as short as possible.
# We'll use the `region` parameter of the `cls` decorator to set the region of the GPU container.
# You should set this to the closest region to your users.
# See the [region selection](https://modal.com/docs/guide/region-selection) guide for more information.


@app.cls(
    image=video_processing_image,
    gpu="A100-40GB",
    volumes=cache,
    secrets=[modal.Secret.from_name("turn-credentials")],
    region="us-east",  # set to your region
)
@modal.concurrent(
    target_inputs=2,  # try to stick to just two peers per GPU container
    max_inputs=3,  # but allow up to three
)
class ObjDet(ModalWebRtcPeer):
    async def initialize(self):
        self.yolo_model = get_yolo_model(CACHE_PATH)

    async def setup_streams(self, peer_id: str):
        from aiortc import MediaStreamTrack

        # keep us notified on connection state changes
        @self.pcs[peer_id].on("connectionstatechange")
        async def on_connectionstatechange() -> None:
            if self.pcs[peer_id]:
                print(
                    f"Video Processor, {self.id}, connection state to {peer_id}: {self.pcs[peer_id].connectionState}"
                )

        # when we receive a track from the source peer
        # we create a processed track and add it to our stream
        # back to the source peer
        @self.pcs[peer_id].on("track")
        def on_track(track: MediaStreamTrack) -> None:
            print(
                f"Video Processor, {self.id}, received {track.kind} track from {peer_id}"
            )

            output_track = get_yolo_track(track, self.yolo_model)  # see Addenda
            self.pcs[peer_id].addTrack(output_track)

            # keep us notified when the incoming track ends
            @track.on("ended")
            async def on_ended() -> None:
                print(
                    f"Video Processor, {self.id}, incoming video track from {peer_id} ended"
                )

    async def get_turn_servers(self, peer_id=None, msg=None) -> dict:
        creds = {
            "username": os.environ["TURN_USERNAME"],
            "credential": os.environ["TURN_CREDENTIAL"],
        }

        turn_servers = [
            {"urls": "stun:stun.relay.metered.ca:80"},  # STUN is free, no creds neeeded
            # for TURN, sign up for the free service here: https://www.metered.ca/tools/openrelay/
            {"urls": "turn:standard.relay.metered.ca:80"} | creds,
            {"urls": "turn:standard.relay.metered.ca:80?transport=tcp"} | creds,
            {"urls": "turn:standard.relay.metered.ca:443"} | creds,
            {"urls": "turns:standard.relay.metered.ca:443?transport=tcp"} | creds,
        ]

        return {"type": "turn_servers", "ice_servers": turn_servers}


# ### Implement a `SignalingServer`

# The `ModalWebRtcSignalingServer` class is much simpler to implement.
# The main thing we need to do is implement the `get_modal_peer_class` method which will return our implementation of the `ModalWebRtcPeer` class, `ObjDet`.
#
# It also has an `initialize()` method we can optionally override (called at the beginning of the [container lifecycle](https://modal.com/docs/guide/lifecycle-functions))
# as well as a `web_app` property which will be [served by Modal](https://modal.com/docs/guide/webhooks#asgi-apps---fastapi-fasthtml-starlette).
# We'll use these to add a frontend which uses the WebRTC JavaScript API to stream a peer's webcam from the browser.
#
# The JavaScript and HTML files are alongside this example in the [Github repo](https://github.com/modal-labs/modal-examples/tree/main/07_web_endpoints/webrtc/frontend).

base_image = (
    modal.Image.debian_slim(python_version="3.12")
    .apt_install("python3-opencv", "ffmpeg")
    .pip_install(
        "fastapi[standard]==0.115.4",
        "aiortc==1.11.0",
        "opencv-python==4.11.0.86",
        "shortuuid==1.0.13",
    )
)

this_directory = Path(__file__).parent.resolve()

server_image = base_image.add_local_dir(
    this_directory / "frontend", remote_path="/frontend"
)


@app.cls(image=server_image)
class WebcamObjDet(ModalWebRtcSignalingServer):
    def get_modal_peer_class(self):
        return ObjDet

    def initialize(self):
        from fastapi.responses import HTMLResponse
        from fastapi.staticfiles import StaticFiles

        self.web_app.mount("/static", StaticFiles(directory="/frontend"))

        @self.web_app.get("/")
        async def root():
            html = open("/frontend/index.html").read()
            return HTMLResponse(content=html)


# ## Addenda

# The remainder of this page is not central to running a WebRTC application on Modal,
# but is included for completeness.

# ### YOLO helper functions

# The two functions below are used to set up the YOLO model and create our custom [`MediaStreamTrack`](https://aiortc.readthedocs.io/en/latest/api.html#aiortc.MediaStreamTrack).

# The first, `get_yolo_model`, sets up the ONNXRuntime and loads the model weights.
# We call this in the `initialize` method of the `ModalWebRtcPeer` class
# so that it only happens once per container.


def get_yolo_model(cache_path):
    import onnxruntime

    from .yolo import YOLOv10

    onnxruntime.preload_dlls()
    return YOLOv10(cache_path)


# The second, `get_yolo_track`, creates a custom `MediaStreamTrack` that performs object detection on the video stream.
# We call this in the `setup_streams` method of the `ModalWebRtcPeer` class
# so it happens once per peer connection.


def get_yolo_track(track, yolo_model=None):
    import numpy as np
    import onnxruntime
    from aiortc import MediaStreamTrack
    from aiortc.contrib.media import VideoFrame

    from .yolo import YOLOv10

    class YOLOTrack(MediaStreamTrack):
        """
        Custom media stream track performs object detection
        on the video stream and passes it back to the source peer
        """

        kind: str = "video"
        conf_threshold: float = 0.15

        def __init__(self, track: MediaStreamTrack, yolo_model=None) -> None:
            super().__init__()

            self.track = track
            if yolo_model is None:
                onnxruntime.preload_dlls()
                self.yolo_model = YOLOv10(CACHE_PATH)
            else:
                self.yolo_model = yolo_model

        def detection(self, image: np.ndarray) -> np.ndarray:
            import cv2

            orig_shape = image.shape[:-1]

            image = cv2.resize(
                image,
                (self.yolo_model.input_width, self.yolo_model.input_height),
            )

            image = self.yolo_model.detect_objects(image, self.conf_threshold)

            image = cv2.resize(image, (orig_shape[1], orig_shape[0]))

            return image

        # this is the essential method we need to implement
        # to create a custom MediaStreamTrack
        async def recv(self) -> VideoFrame:
            frame = await self.track.recv()
            img = frame.to_ndarray(format="bgr24")

            processed_img = self.detection(img)

            # VideoFrames are from a really nice package called av
            # which is a pythonic wrapper around ffmpeg
            # and a dependency of aiortc
            new_frame = VideoFrame.from_ndarray(processed_img, format="bgr24")
            new_frame.pts = frame.pts
            new_frame.time_base = frame.time_base

            return new_frame

    return YOLOTrack(track, yolo_model)


# ### Testing a WebRTC application on Modal

# As any seasoned developer of real-time applications on the Web will tell you,
# testing and ensuring correctness is quite difficult. We spent nearly as much time
# designing and troubleshooting an appropriate testing process for this application as we did writing
# the application itself!

# You can find the testing code in the GitHub repository [here](https://github.com/modal-labs/modal-examples/tree/main/07_web_endpoints/webrtc/webrtc_yolo_test.py).


=== GITHUB: 07_web_endpoints/webrtc/modal_webrtc.py ===
# ---
# lambda-test: false  # auxiliary-file
# ---

import asyncio
import json
import queue
from abc import ABC, abstractmethod
from typing import Optional

import modal
from fastapi import FastAPI, WebSocket
from fastapi.websockets import WebSocketState


class ModalWebRtcPeer(ABC):
    """
    Base class for implementing WebRTC peer connections in Modal using aiortc.
    Implement using the `app.cls` decorator.

    This class provides a complete WebRTC peer implementation that handles:
    - Peer connection lifecycle management (creation, negotiation, cleanup)
    - Signaling via Modal Queue for SDP offer/answer exchange and ICE candidate handling
    - Automatic STUN server configuration (defaults to Google's STUN server)
    - Stream setup and management

    Required methods to override:
    - setup_streams(): Implementation for setting up media tracks and streams

    Optional methods to override:
    - initialize(): Custom initialization logic when peer is created
    - run_streams(): Implementation for stream runtime logic
    - get_turn_servers(): Implementation to provide custom TURN server configuration
    - exit(): Custom cleanup logic when peer is shutting down

    The peer connection is established through a ModalWebRtcSignalingServer that manages
    the signaling process between this peer and client peers.
    """

    @modal.enter()
    async def _initialize(self):
        import shortuuid

        self.id = shortuuid.uuid()
        self.pcs = {}
        self.pending_candidates = {}

        # call custom init logic
        await self.initialize()

    async def initialize(self):
        """Override to add custom logic when creating a peer"""

    @abstractmethod
    async def setup_streams(self, peer_id):
        """Override to add custom logic when creating a connection and setting up streams"""
        raise NotImplementedError

    async def run_streams(self, peer_id):
        """Override to add custom logic when running streams"""

    async def get_turn_servers(self, peer_id=None, msg=None) -> Optional[list]:
        """Override to customize TURN servers"""

    async def _setup_peer_connection(self, peer_id):
        """Creates an RTC peer connection via an ICE server"""
        from aiortc import RTCConfiguration, RTCIceServer, RTCPeerConnection

        # aiortc automatically uses google's STUN server,
        # but we can also specify our own
        config = RTCConfiguration(
            iceServers=[RTCIceServer(urls="stun:stun.l.google.com:19302")]
        )
        self.pcs[peer_id] = RTCPeerConnection(configuration=config)
        self.pending_candidates[peer_id] = []
        await self.setup_streams(peer_id)

        print(
            f"{self.id}: Created peer connection and setup streams from {self.id} to {peer_id}"
        )

    @modal.method()
    async def run(self, q: modal.Queue, peer_id: str):
        """Run the RTC peer after establishing a connection by passing WebSocket messages over a Queue."""
        print(f"{self.id}: Running modal peer instance for client peer: {peer_id}...")

        await self._connect_over_queue(q, peer_id)
        await self._run_streams(peer_id)

    async def _connect_over_queue(self, q, peer_id):
        """Connect this peer to another by passing messages along a Modal Queue."""

        msg_handlers = {  # message types we need to handle
            "offer": self.handle_offer,  # SDP offer
            "ice_candidate": self.handle_ice_candidate,  # trickled ICE candidate
            "identify": self.get_identity,  # identify challenge
            "get_turn_servers": self.get_turn_servers,  # TURN server request
        }

        while True:
            try:
                if self.pcs.get(peer_id) and (
                    self.pcs[peer_id].connectionState
                    in ["connected", "closed", "failed"]
                ):
                    print(f"{self.id}: Closing connection to {peer_id} over queue...")
                    q.put("close", partition="server")
                    break

                # read and parse websocket message passed over queue
                msg = json.loads(await q.get.aio(partition=peer_id, timeout=0.5))
                # dispatch the message to its handler
                if handler := msg_handlers.get(msg.get("type")):
                    response = await handler(peer_id, msg)
                else:
                    print(f"{self.id}: Unknown message type: {msg.get('type')}")
                    response = None

                # pass the message back over the queue to the server
                if response is not None:
                    await q.put.aio(json.dumps(response), partition="server")
            except queue.Empty:
                print(f"{self.id}: Queue empty, waiting for message...")
                pass
            except Exception as e:
                print(
                    f"{self.id}: Error handling message from {peer_id}: {type(e)}: {e}"
                )
                continue

    async def _run_streams(self, peer_id):
        """Run WebRTC streaming with a peer."""
        print(f"{self.id}:  running streams to {peer_id}...")

        await self.run_streams(peer_id)

        # run until connection is closed or broken
        while self.pcs[peer_id].connectionState == "connected":
            await asyncio.sleep(0.1)

        print(f"{self.id}:  ending streaming to {peer_id}")

    async def handle_offer(self, peer_id, msg):
        """Handles a peers SDP offer message by producing an SDP answer."""
        from aiortc import RTCSessionDescription

        print(f"{self.id}:  handling SDP offer from {peer_id}...")

        await self._setup_peer_connection(peer_id)
        await self.pcs[peer_id].setRemoteDescription(
            RTCSessionDescription(msg["sdp"], msg["type"])
        )
        answer = await self.pcs[peer_id].createAnswer()
        await self.pcs[peer_id].setLocalDescription(answer)
        sdp = self.pcs[peer_id].localDescription.sdp

        return {"sdp": sdp, "type": answer.type, "peer_id": self.id}

    async def handle_ice_candidate(self, peer_id, msg):
        """Add an ICE candidate sent by a peer."""
        from aiortc import RTCIceCandidate
        from aiortc.sdp import candidate_from_sdp

        candidate = msg.get("candidate")

        if not candidate:
            raise ValueError

        print(
            f"{self.id}:  received ice candidate from {peer_id}: {candidate['candidate_sdp']}..."
        )

        # parse ice candidate
        ice_candidate: RTCIceCandidate = candidate_from_sdp(candidate["candidate_sdp"])
        ice_candidate.sdpMid = candidate["sdpMid"]
        ice_candidate.sdpMLineIndex = candidate["sdpMLineIndex"]

        if not self.pcs.get(peer_id):
            self.pending_candidates[peer_id].append(ice_candidate)
        else:
            if len(self.pending_candidates[peer_id]) > 0:
                [
                    await self.pcs[peer_id].addIceCandidate(c)
                    for c in self.pending_candidates[peer_id]
                ]
                self.pending_candidates[peer_id] = []
            await self.pcs[peer_id].addIceCandidate(ice_candidate)

    async def get_identity(self, peer_id=None, msg=None):
        """Reply to an identify message with own id."""
        return {"type": "identify", "peer_id": self.id}

    async def generate_offer(self, peer_id):
        print(f"{self.id}:  generating offer for {peer_id}...")

        await self._setup_peer_connection(peer_id)
        offer = await self.pcs[peer_id].createOffer()
        await self.pcs[peer_id].setLocalDescription(offer)
        sdp = self.pcs[peer_id].localDescription.sdp

        return {"sdp": sdp, "type": offer.type, "peer_id": self.id}

    async def handle_answer(self, peer_id, answer):
        from aiortc import RTCSessionDescription

        print(f"{self.id}:  handling answer from {peer_id}...")
        # set remote peer description
        await self.pcs[peer_id].setRemoteDescription(
            RTCSessionDescription(sdp=answer["sdp"], type=answer["type"])
        )

    @modal.exit()
    async def _exit(self):
        print(f"{self.id}: Shutting down...")
        await self.exit()

        if self.pcs:
            print(f"{self.id}: Closing peer connections...")
            await asyncio.gather(*[pc.close() for pc in self.pcs.values()])
            self.pcs = {}

    async def exit(self):
        """Override with any custom logic when shutting down container."""


class ModalWebRtcSignalingServer:
    """
    WebRTC signaling server implementation that mediates connections between client peers
    and Modal-based WebRTC peers. Implement using the `app.cls` decorator.

    This server:
    - Provides a WebSocket endpoint (/ws/{peer_id}) for client connections
    - Spawns Modal-based peer instances for each client connection
    - Handles the WebRTC signaling process by relaying messages between clients and Modal peers
    - Manages the lifecycle of Modal peer instances

    To use this class:
    1. Create a subclass implementing get_modal_peer_class() to return your ModalWebRtcPeer implementation
    2. Optionally override initialize() for custom server setup
    3. Optionally add a frontend route to the `web_app` attribute
    """

    @modal.enter()
    def _initialize(self):
        self.web_app = FastAPI()

        # handle signaling through websocket endpoint
        @self.web_app.websocket("/ws/{peer_id}")
        async def ws(client_websocket: WebSocket, peer_id: str):
            try:
                await client_websocket.accept()
                print(f"Server: Accepted websocket connection from {peer_id}...")
                await self._mediate_negotiation(client_websocket, peer_id)
            except Exception as e:
                print(
                    f"Server: Error accepting websocket connection from {peer_id}: {type(e)}: {e}"
                )
                await client_websocket.close()

        self.initialize()

    def initialize(self):
        pass

    @abstractmethod
    def get_modal_peer_class(self) -> type[ModalWebRtcPeer]:
        """
        Abstract method to return the `ModalWebRtcPeer` implementation to use.
        """
        raise NotImplementedError(
            "Implement `get_modal_peer` to use `ModalWebRtcSignalingServer`"
        )

    @modal.asgi_app()
    def web(self):
        return self.web_app

    async def _mediate_negotiation(self, websocket: WebSocket, peer_id: str):
        modal_peer_class = self.get_modal_peer_class()
        if not any(
            base.__name__ == "ModalWebRtcPeer" for base in modal_peer_class.__bases__
        ):
            raise ValueError(
                "Modal peer class must be an implementation of `ModalWebRtcPeer`"
            )

        with modal.Queue.ephemeral() as q:
            print(f"Server: Spawning modal peer instance for client peer {peer_id}...")
            modal_peer = modal_peer_class()
            modal_peer.run.spawn(q, peer_id)

            await asyncio.gather(
                relay_websocket_to_queue(websocket, q, peer_id),
                relay_queue_to_websocket(websocket, q, peer_id),
            )


async def relay_websocket_to_queue(websocket: WebSocket, q: modal.Queue, peer_id: str):
    while True:
        try:
            # get websocket message off queue and parse as json
            msg = await asyncio.wait_for(websocket.receive_text(), timeout=0.5)
            await q.put.aio(msg, partition=peer_id)
        except asyncio.TimeoutError:
            pass
        except Exception as e:
            if WebSocketState.DISCONNECTED in [
                websocket.application_state,
                websocket.client_state,
            ]:
                print("Server: Websocket connection closed")
                return
            else:
                print(f"Server: Error relaying from websocket to queue: {type(e)}: {e}")


async def relay_queue_to_websocket(websocket: WebSocket, q: modal.Queue, peer_id: str):
    while True:
        try:
            # get websocket message off queue and parse from json
            modal_peer_msg = await q.get.aio(partition="server", timeout=0.5)
            if modal_peer_msg.startswith("close"):
                print(
                    "Server: Close received on queue, closing websocket connection..."
                )
                await websocket.close()
                return

            await websocket.send_text(modal_peer_msg)
        except queue.Empty:
            pass
        except Exception as e:
            if WebSocketState.DISCONNECTED in [
                websocket.application_state,
                websocket.client_state,
            ]:
                print("Server: Websocket connection closed")
                return
            else:
                print(f"Server: Error relaying from queue to websocket: {type(e)}: {e}")


=== GITHUB: 07_web_endpoints/webrtc/yolo/__init__.py ===
from .yolo import YOLOv10 as YOLOv10


=== GITHUB: 07_web_endpoints/webrtc/yolo/yolo.py ===
# ---
# lambda-test: false
# ---
from pathlib import Path

import cv2
import numpy as np
import onnxruntime

this_dir = Path(__file__).parent.resolve()


class YOLOv10:
    def __init__(self, cache_dir):
        from huggingface_hub import hf_hub_download

        # Initialize model
        self.cache_dir = cache_dir
        print(f"Initializing YOLO model from {self.cache_dir}")
        model_file = hf_hub_download(
            repo_id="onnx-community/yolov10n",
            filename="onnx/model.onnx",
            cache_dir=self.cache_dir,
        )
        self.initialize_model(model_file)
        print("YOLO model initialized")

    def initialize_model(self, model_file):
        self.session = onnxruntime.InferenceSession(
            model_file,
            providers=[
                (
                    "TensorrtExecutionProvider",
                    {
                        "trt_engine_cache_enable": True,
                        "trt_engine_cache_path": self.cache_dir / "onnx.cache",
                    },
                ),
                "CUDAExecutionProvider",
            ],
        )
        # Get model info
        self.get_input_details()
        self.get_output_details()

        # get class names
        with open(this_dir / "yolo_classes.txt", "r") as f:
            self.class_names = f.read().splitlines()
        rng = np.random.default_rng(3)
        self.colors = rng.uniform(0, 255, size=(len(self.class_names), 3))

    def detect_objects(self, image, conf_threshold=0.3):
        input_tensor = self.prepare_input(image)

        # Perform inference on the image
        new_image = self.inference(image, input_tensor, conf_threshold)

        return new_image

    def prepare_input(self, image):
        self.img_height, self.img_width = image.shape[:2]

        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Resize input image
        input_img = cv2.resize(input_img, (self.input_width, self.input_height))

        # Scale input pixel values to 0 to 1
        input_img = input_img / 255.0
        input_img = input_img.transpose(2, 0, 1)
        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)

        return input_tensor

    def inference(self, image, input_tensor, conf_threshold=0.3):
        # set seed to potentially create smoother output in RT setting
        onnxruntime.set_seed(42)
        # start = time.perf_counter()
        outputs = self.session.run(
            self.output_names, {self.input_names[0]: input_tensor}
        )

        # print(f"Inference time: {(time.perf_counter() - start) * 1000:.2f} ms")
        (
            boxes,
            scores,
            class_ids,
        ) = self.process_output(outputs, conf_threshold)
        return self.draw_detections(image, boxes, scores, class_ids)

    def process_output(self, output, conf_threshold=0.3):
        predictions = np.squeeze(output[0])

        # Filter out object confidence scores below threshold
        scores = predictions[:, 4]
        predictions = predictions[scores > conf_threshold, :]
        scores = scores[scores > conf_threshold]

        if len(scores) == 0:
            return [], [], []

        # Get the class with the highest confidence
        class_ids = predictions[:, 5].astype(int)

        # Get bounding boxes for each object
        boxes = self.extract_boxes(predictions)

        return boxes, scores, class_ids

    def extract_boxes(self, predictions):
        # Extract boxes from predictions
        boxes = predictions[:, :4]

        # Scale boxes to original image dimensions
        boxes = self.rescale_boxes(boxes)

        # Convert boxes to xyxy format
        # boxes = xywh2xyxy(boxes)

        return boxes

    def rescale_boxes(self, boxes):
        # Rescale boxes to original image dimensions
        input_shape = np.array(
            [
                self.input_width,
                self.input_height,
                self.input_width,
                self.input_height,
            ]
        )
        boxes = np.divide(boxes, input_shape, dtype=np.float32)
        boxes *= np.array(
            [self.img_width, self.img_height, self.img_width, self.img_height]
        )
        return boxes

    def draw_detections(
        self, image, boxes, scores, class_ids, draw_scores=True, mask_alpha=0.4
    ):
        det_img = image.copy()

        img_height, img_width = image.shape[:2]
        font_size = min([img_height, img_width]) * 0.0012
        text_thickness = int(min([img_height, img_width]) * 0.004)

        # Draw bounding boxes and labels of detections
        for class_id, box, score in zip(class_ids, boxes, scores):
            color = self.colors[class_id]

            self.draw_box(det_img, box, color)  # type: ignore

            label = self.class_names[class_id]
            caption = f"{label} {int(score * 100)}%"
            self.draw_text(det_img, caption, box, color, font_size, text_thickness)  # type: ignore

        return det_img

    def get_input_details(self):
        model_inputs = self.session.get_inputs()
        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]

        self.input_shape = model_inputs[0].shape
        self.input_height = self.input_shape[2]
        self.input_width = self.input_shape[3]

    def get_output_details(self):
        model_outputs = self.session.get_outputs()
        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]

    def draw_box(
        self,
        image: np.ndarray,
        box: np.ndarray,
        color: tuple[int, int, int] = (0, 0, 255),
        thickness: int = 5,
    ) -> np.ndarray:
        x1, y1, x2, y2 = box.astype(int)
        return cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

    def draw_text(
        self,
        image: np.ndarray,
        text: str,
        box: np.ndarray,
        color: tuple[int, int, int] = (0, 0, 255),
        font_size: float = 0.100,
        text_thickness: int = 5,
        box_thickness: int = 5,
    ) -> np.ndarray:
        x1, y1, x2, y2 = box.astype(int)
        (tw, th), _ = cv2.getTextSize(
            text=text,
            fontFace=cv2.FONT_HERSHEY_SIMPLEX,
            fontScale=font_size,
            thickness=text_thickness,
        )
        x1 = x1 - box_thickness
        th = int(th * 1.2)

        cv2.rectangle(image, (x1, y1), (x1 + tw, y1 - th), color, -1)

        return cv2.putText(
            image,
            text,
            (x1, y1),
            cv2.FONT_HERSHEY_SIMPLEX,
            font_size,
            (255, 255, 255),
            text_thickness,
            cv2.LINE_AA,
        )


=== GITHUB: 07_web_endpoints/webrtc/yolo/yolo_classes.txt ===
person
bicycle
car
motorcycle
airplane
bus
train
truck
boat
traffic light
fire hydrant
stop sign
parking meter
bench
bird
cat
dog
horse
sheep
cow
elephant
bear
zebra
giraffe
backpack
umbrella
handbag
tie
suitcase
frisbee
skis
snowboard
sports ball
kite
baseball bat
baseball glove
skateboard
surfboard
tennis racket
bottle
wine glass
cup
fork
knife
spoon
bowl
banana
apple
sandwich
orange
broccoli
carrot
hot dog
pizza
donut
cake
chair
couch
potted plant
bed
dining table
toilet
tv
laptop
mouse
remote
keyboard
cell phone
microwave
oven
toaster
sink
refrigerator
book
clock
vase
scissors
teddy bear
hair drier
toothbrush



=== CATEGORY: ADVANCED ===

=== GITHUB: 08_advanced/hello_world_async.py ===
# # Async functions
#
# Modal natively supports async/await syntax using asyncio.

# First, let's import some global stuff.

import sys

import modal

app = modal.App("example-hello-world-async")


# ## Defining a function
#
# Now, let's define a function. The wrapped function can be synchronous or
# asynchronous, but calling it in either context will still work.
# Let's stick to a normal synchronous function


@app.function()
def f(i):
    if i % 2 == 0:
        print("hello", i)
    else:
        print("world", i, file=sys.stderr)

    return i * i


# ## Running the app with asyncio
#
# Let's make the main entrypoint asynchronous. In async contexts, we should
# call the function using `await` or iterate over the map using `async for`.
# Otherwise we would block the event loop while our call is being run.


@app.local_entrypoint()
async def run_async():
    # Call the function using .remote.aio() in order to run it asynchronously
    print(await f.remote.aio(1000))

    # Parallel map.
    total = 0
    # Call .map asynchronously using using f.map.aio(...)
    async for ret in f.map.aio(range(20)):
        total += ret

    print(total)


=== GITHUB: 08_advanced/parallel_execution.py ===
# # Parallel execution on Modal with `spawn` and `gather`

# This example shows how you can run multiple functions in parallel on Modal.
# We use the `spawn` method to start a function and return a handle to its result.
# The `get` method is used to retrieve the result of the function call.

import time

import modal

app = modal.App("example-parallel")


@app.function()
def step1(word):
    time.sleep(2)
    print("step1 done")
    return word


@app.function()
def step2(number):
    time.sleep(1)
    print("step2 done")
    if number == 0:
        raise ValueError("custom error")
    return number


@app.local_entrypoint()
def main():
    # Start running a function and return a handle to its result.
    word_call = step1.spawn("foo")
    number_call = step2.spawn(2)

    # Print "foofoo" after 2 seconds.
    print(word_call.get() * number_call.get())

    # Alternatively, use `modal.FunctionCall.gather(...)` as a convenience wrapper,
    # which returns an error if either call fails.
    results = modal.FunctionCall.gather(step1.spawn("bar"), step2.spawn(4))
    assert results == ["bar", 4]

    # Raise exception after 2 seconds.
    try:
        modal.FunctionCall.gather(step1.spawn("bar"), step2.spawn(0))
    except ValueError as exc:
        assert str(exc) == "custom error"


=== GITHUB: 08_advanced/generators_async.py ===
# # Run async generator function on Modal

# This example shows how you can run an async generator function on Modal.
# Modal natively supports async/await syntax using asyncio.

import modal

app = modal.App("example-generators-async")


@app.function()
def f(i):
    for j in range(i):
        yield j


@app.local_entrypoint()
async def run_async():
    async for r in f.remote_gen.aio(10):
        print(r)


=== GITHUB: 08_advanced/poll_delayed_result.py ===
# ---
# cmd: ["modal", "serve", "08_advanced/poll_delayed_result.py"]
# ---

# # Polling for a delayed result on Modal

# This example shows how you can poll for a delayed result on Modal.

# The function `factor_number` takes a number as input and returns the prime factors of the number. The function could take a long time to run, so we don't want to wait for the result in the web server.
# Instead, we return a URL that the client can poll to get the result.

import fastapi
import modal
from modal.functions import FunctionCall
from starlette.responses import HTMLResponse, RedirectResponse

app = modal.App("example-poll")

web_app = fastapi.FastAPI()


@app.function(image=modal.Image.debian_slim().pip_install("primefac"))
def factor_number(number):
    import primefac

    return list(primefac.primefac(number))  # could take a long time


@web_app.get("/")
async def index():
    return HTMLResponse(
        """
    <form method="get" action="/factors">
        Enter a number: <input name="number" />
        <input type="submit" value="Factorize!"/>
    </form>
    """
    )


@web_app.get("/factors")
async def web_submit(request: fastapi.Request, number: int):
    call = factor_number.spawn(
        number
    )  # returns a FunctionCall without waiting for result
    polling_url = request.url.replace(
        path="/result", query=f"function_id={call.object_id}"
    )
    return RedirectResponse(polling_url)


@web_app.get("/result")
async def web_poll(function_id: str):
    function_call = FunctionCall.from_id(function_id)
    try:
        result = function_call.get(timeout=0)
    except TimeoutError:
        result = "not ready"

    return result


@app.function()
@modal.asgi_app()
def fastapi_app():
    return web_app



=== CATEGORY: JOB_QUEUES ===

=== GITHUB: 09_job_queues/doc_ocr_jobs.py ===
# ---
# deploy: true
# mypy: ignore-errors
# ---

# # Run a job queue for GOT-OCR

# This tutorial shows you how to use Modal as an infinitely scalable job queue
# that can service async tasks from a web app. For the purpose of this tutorial,
# we've also built a [React + FastAPI web app on Modal](https://modal.com/docs/examples/doc_ocr_webapp)
# that works together with it, but note that you don't need a web app running on Modal
# to use this pattern. You can submit async tasks to Modal from any Python
# application (for example, a regular Django app running on Kubernetes).

# Our job queue will handle a single task: running OCR transcription for images of receipts.
# We'll make use of a pre-trained model:
# the [General OCR Theory (GOT) 2.0 model](https://huggingface.co/stepfun-ai/GOT-OCR2_0).

# Try it out for yourself [here](https://modal-labs-examples--example-doc-ocr-webapp-wrapper.modal.run/).

# [![Webapp frontend](https://modal-cdn.com/doc_ocr_frontend.jpg)](https://modal-labs-examples--example-doc-ocr-webapp-wrapper.modal.run/)

# ## Define an App

# Let's first import `modal` and define an [`App`](https://modal.com/docs/reference/modal.App).
# Later, we'll use the name provided for our `App` to find it from our web app and submit tasks to it.

from typing import Optional

import modal

app = modal.App("example-doc-ocr-jobs")

# We also define the dependencies for our Function by specifying an
# [Image](https://modal.com/docs/guide/images).

inference_image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "accelerate==0.28.0",
    "huggingface_hub[hf_transfer]==0.27.1",
    "numpy<2",
    "tiktoken==0.6.0",
    "torch==2.5.1",
    "torchvision==0.20.1",
    "transformers==4.48.0",
    "verovio==4.3.1",
)

# ## Cache the pre-trained model on a Modal Volume

# We can obtain the pre-trained model we want to run from Hugging Face
# using its name and a revision identifier.

MODEL_NAME = "ucaslcl/GOT-OCR2_0"
MODEL_REVISION = "cf6b7386bc89a54f09785612ba74cb12de6fa17c"

# The logic for loading the model based on this information
# is encapsulated in the `setup` function below.


def setup():
    import warnings

    from transformers import AutoModel, AutoTokenizer

    with warnings.catch_warnings():  # filter noisy warnings from GOT modeling code
        warnings.simplefilter("ignore")
        tokenizer = AutoTokenizer.from_pretrained(
            MODEL_NAME, revision=MODEL_REVISION, trust_remote_code=True
        )

        model = AutoModel.from_pretrained(
            MODEL_NAME,
            revision=MODEL_REVISION,
            trust_remote_code=True,
            device_map="cuda",
            use_safetensors=True,
            pad_token_id=tokenizer.eos_token_id,
        )

    return tokenizer, model


# The `.from_pretrained` methods from Hugging Face are smart enough
# to only download models if they haven't been downloaded before.
# But in Modal's serverless environment, filesystems are ephemeral,
# and so using this code alone would mean that models need to get downloaded
# on every request.

# So instead, we create a Modal [Volume](https://modal.com/docs/guide/volumes)
# to store the model -- a durable filesystem that any Modal Function can access.

model_cache = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

# We also update the environment variables for our Function
# to include this new path for the model cache --
# and to enable fast downloads with the `hf_transfer` library.

MODEL_CACHE_PATH = "/root/models"
inference_image = inference_image.env(
    {"HF_HUB_CACHE": MODEL_CACHE_PATH, "HF_HUB_ENABLE_HF_TRANSFER": "1"}
)


# ## Run OCR inference on Modal by wrapping with `app.function`

# Now let's set up the actual OCR inference.

# Using the [`@app.function`](https://modal.com/docs/reference/modal.App#function)
# decorator, we set up a Modal [Function](https://modal.com/docs/reference/modal.Function).
# We provide arguments to that decorator to customize the hardware, scaling, and other features
# of the Function.

# Here, we say that this Function should use NVIDIA L40S [GPUs](https://modal.com/docs/guide/gpu),
# automatically [retry](https://modal.com/docs/guide/retries#function-retries) failures up to 3 times,
# and have access to our [shared model cache](https://modal.com/docs/guide/volumes).


@app.function(
    gpu="l40s",
    retries=3,
    volumes={MODEL_CACHE_PATH: model_cache},
    image=inference_image,
)
def parse_receipt(image: bytes) -> str:
    from tempfile import NamedTemporaryFile

    tokenizer, model = setup()

    with NamedTemporaryFile(delete=False, mode="wb+") as temp_img_file:
        temp_img_file.write(image)
        output = model.chat(tokenizer, temp_img_file.name, ocr_type="format")

    print("Result: ", output)

    return output


# ## Deploy

# Now that we have a function, we can publish it by deploying the app:

# ```shell
# modal deploy doc_ocr_jobs.py
# ```

# Once it's published, we can [look up](https://modal.com/docs/guide/trigger-deployed-functions) this Function
# from another Python process and submit tasks to it:

# ```python
# fn = modal.Function.from_name("example-doc-ocr-jobs", "parse_receipt")
# fn.spawn(my_image)
# ```

# Modal will auto-scale to handle all the tasks queued, and
# then scale back down to 0 when there's no work left. To see how you could use this from a Python web
# app, take a look at the [receipt parser frontend](https://modal.com/docs/examples/doc_ocr_webapp)
# tutorial.

# ## Run manually

# We can also trigger `parse_receipt` manually for easier debugging:

# ```shell
# modal run doc_ocr_jobs
# ```

# To try it out, you can find some
# example receipts [here](https://drive.google.com/drive/folders/1S2D1gXd4YIft4a5wDtW99jfl38e85ouW).


@app.local_entrypoint()
def main(receipt_filename: Optional[str] = None):
    import urllib.request
    from pathlib import Path

    if receipt_filename is None:
        receipt_filename = Path(__file__).parent / "receipt.png"
    else:
        receipt_filename = Path(receipt_filename)

    if receipt_filename.exists():
        image = receipt_filename.read_bytes()
        print(f"running OCR on {receipt_filename}")
    else:
        receipt_url = "https://modal-cdn.com/cdnbot/Brandys-walmart-receipt-8g68_a_hk_f9c25fce.webp"
        request = urllib.request.Request(receipt_url)
        with urllib.request.urlopen(request) as response:
            image = response.read()
        print(f"running OCR on sample from URL {receipt_url}")
    print(parse_receipt.remote(image))


=== GITHUB: 09_job_queues/dicts_and_queues.py ===
# ---
# mypy: ignore-errors
# ---

# # Use Modal Dicts and Queues together

# Modal Dicts and Queues store and communicate objects in distributed applications on Modal.

# To illustrate how Dicts and Queues can interact together in a simple distributed
# system, consider the following example program that crawls the web, starting
# from some initial page and traversing links to many sites in breadth-first order.

# The Modal Queue acts as a job queue, accepting new pages to crawl as they are discovered
# by the crawlers and doling them out to be crawled via [`.spawn`](https://modal.com/docs/reference/modal.Function#spawn).

# The Dict is used to coordinate termination once the maximum number of URLs to crawl is reached.

# Starting from Wikipedia, this spawns several dozen containers (auto-scaled on
# demand) and crawls about 100,000 URLs per minute.

import queue
import sys
from datetime import datetime

import modal

app = modal.App(
    image=modal.Image.debian_slim().pip_install(
        "requests~=2.32.4", "beautifulsoup4~=4.13.4"
    )
)


def extract_links(url: str) -> list[str]:
    """Extract links from a given URL."""
    import urllib.parse

    import requests
    from bs4 import BeautifulSoup

    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    links = []
    for link in soup.find_all("a"):
        links.append(urllib.parse.urljoin(url, link.get("href")))
    return links


@app.function()
def crawl_pages(q: modal.Queue, d: modal.Dict, urls: set[str]) -> None:
    for url in urls:
        if "stop" in d:
            return
        try:
            s = datetime.now()
            links = extract_links(url)
            print(f"Crawled: {url} in {datetime.now() - s}, with {len(links)} links")
            q.put_many(links)
        except Exception as exc:
            print(
                f"Failed to crawl: {url} with error {exc}, skipping...", file=sys.stderr
            )


@app.function()
def scrape(url: str, max_urls: int = 50_000):
    start_time = datetime.now()

    # Create ephemeral dicts and queues
    with modal.Dict.ephemeral() as d, modal.Queue.ephemeral() as q:
        # The dict is used to signal the scraping to stop
        # The queue contains the URLs that have been crawled

        # Initialize queue with a starting URL
        q.put(url)

        # Crawl until the queue is empty, or reaching some number of URLs
        visited = set()
        max_urls = min(max_urls, 50_000)
        while True:
            try:
                next_urls = q.get_many(2000, timeout=5)
            except queue.Empty:
                break
            new_urls = set(next_urls) - visited
            visited |= new_urls
            if len(visited) < max_urls:
                crawl_pages.spawn(q, d, new_urls)
            else:
                d["stop"] = True

        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"Crawled {len(visited)} URLs in {elapsed:.2f} seconds")


@app.local_entrypoint()
def main(starting_url=None, max_urls: int = 10_000):
    starting_url = starting_url or "https://www.wikipedia.org/"
    scrape.remote(starting_url, max_urls=max_urls)


=== GITHUB: 09_job_queues/doc_ocr_webapp.py ===
# ---
# deploy: true
# cmd: ["modal", "serve", "09_job_queues/doc_ocr_webapp.py"]
# ---

# # Serve a document OCR web app

# This tutorial shows you how to use Modal to deploy a fully serverless
# [React](https://reactjs.org/) + [FastAPI](https://fastapi.tiangolo.com/) application.
# We're going to build a simple "Receipt Parser" web app that submits OCR transcription
# tasks to a separate Modal app defined in [another example](https://modal.com/docs/examples/doc_ocr_jobs),
# polls until the task is completed, and displays
# the results. Try it out for yourself
# [here](https://modal-labs-examples--example-doc-ocr-webapp-wrapper.modal.run/).

# [![Webapp frontend](https://modal-cdn.com/doc_ocr_frontend.jpg)](https://modal-labs-examples--example-doc-ocr-webapp-wrapper.modal.run/)

# ## Basic setup

# Let's get the imports out of the way and define an [`App`](https://modal.com/docs/reference/modal.App).

from pathlib import Path

import fastapi
import fastapi.staticfiles
import modal

app = modal.App("example-doc-ocr-webapp")

# Modal works with any [ASGI](https://modal.com/docs/guide/webhooks#serving-asgi-and-wsgi-apps) or
# [WSGI](https://modal.com/docs/guide/webhooks#wsgi) web framework. Here, we choose to use [FastAPI](https://fastapi.tiangolo.com/).

web_app = fastapi.FastAPI()

# ## Define endpoints

# We need two endpoints: one to accept an image and submit it to the Modal job queue,
# and another to poll for the results of the job.

# In `parse`, we're going to submit tasks to the function defined in the [Job
# Queue tutorial](https://modal.com/docs/examples/doc_ocr_jobs), so we import it first using
# [`Function.lookup`](https://modal.com/docs/reference/modal.Function#lookup).

# We call [`.spawn()`](https://modal.com/docs/reference/modal.Function#spawn) on the function handle
# we imported above to kick off our function without blocking on the results. `spawn` returns
# a unique ID for the function call, which we then use
# to poll for its result.


@web_app.post("/parse")
async def parse(request: fastapi.Request):
    parse_receipt = modal.Function.from_name("example-doc-ocr-jobs", "parse_receipt")

    form = await request.form()
    receipt = await form["receipt"].read()  # type: ignore
    call = parse_receipt.spawn(receipt)
    return {"call_id": call.object_id}


# `/result` uses the provided `call_id` to instantiate a `modal.FunctionCall` object, and attempt
# to get its result. If the call hasn't finished yet, we return a `202` status code, which indicates
# that the server is still working on the job.


@web_app.get("/result/{call_id}")
async def poll_results(call_id: str):
    function_call = modal.functions.FunctionCall.from_id(call_id)
    try:
        result = function_call.get(timeout=0)
    except TimeoutError:
        return fastapi.responses.JSONResponse(content="", status_code=202)

    return result


# Now that we've defined our endpoints, we're ready to host them on Modal.
# First, we specify our dependencies -- here, a basic Debian Linux
# environment with FastAPI installed.

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "fastapi[standard]==0.115.4"
)

# Then, we add the static files for our front-end. We've made [a simple React
# app](https://github.com/modal-labs/modal-examples/tree/main/09_job_queues/doc_ocr_frontend)
# that hits the two endpoints defined above. To package these files with our app, we use
# `add_local_dir` with the local directory of the assets, and specify that we want them
# in the `/assets` directory inside our container (the `remote_path`). Then, we instruct FastAPI to [serve
# this static file directory](https://fastapi.tiangolo.com/tutorial/static-files/) at our root path.

local_assets_path = Path(__file__).parent / "doc_ocr_frontend"
image = image.add_local_dir(local_assets_path, remote_path="/assets")


@app.function(image=image)
@modal.asgi_app()
def wrapper():
    web_app.mount("/", fastapi.staticfiles.StaticFiles(directory="/assets", html=True))
    return web_app


# ## Running

# While developing, you can run this as an ephemeral app by executing the command

# ```shell
# modal serve doc_ocr_webapp.py
# ```

# Modal watches all the mounted files and updates the app if anything changes.
# See [these docs](https://modal.com/docs/guide/webhooks#developing-with-modal-serve)
# for more details.

# ## Deploy

# To deploy your application, run

# ```shell
# modal deploy doc_ocr_webapp.py
# ```

# That's all!

# If successful, this will print a URL for your app that you can navigate to in
# your browser 🎉 .

# [![Webapp frontend](https://modal-cdn.com/doc_ocr_frontend.jpg)](https://modal-labs-examples--example-doc-ocr-webapp-wrapper.modal.run/)



=== CATEGORY: INTEGRATIONS ===

=== GITHUB: 10_integrations/multion_news_agent.py ===
# ---
# lambda-test: false  # missing-secret
# ---

# # MultiOn: Twitter News Agent

# In this example, we use Modal to deploy a cron job that periodically checks for AI news everyday and tweets it on Twitter using the MultiOn Agent API.

# ## Import and define the app

# Let's start off with imports, and defining a Modal app.

import os

import modal

app = modal.App("multion-news-tweet-agent")

# ## Searching for AI News

# Let's also define an image that has the `multion` package installed, so we can query the API.

multion_image = modal.Image.debian_slim().pip_install("multion")

# We can now define our main entrypoint, which uses [MultiOn](https://www.multion.ai/)
# to scrape AI news everyday and post it on our Twitter account.
# We specify a [schedule](https://modal.com/docs/guide/cron) in the function decorator, which
# means that our function will run automatically at the given interval.

# ## Set up MultiOn

# [MultiOn](https://multion.ai/) is a Web Action Agent that can take actions on behalf of the user.
# You can watch it in action [here](https://www.youtube.com/watch?v=Rm67ry6bogw).

# The MultiOn API enables building the next level of web automation & custom AI agents capable of performing complex actions on the internet with just a few lines of code.

# To get started, first create an account with [MultiOn](https://www.multion.ai/),
# install the [MultiOn chrome extension](https://chrome.google.com/webstore/detail/ddmjhdbknfidiopmbaceghhhbgbpenmm)
# and login to your Twitter account in your browser.
# To use the API, create a MultiOn API Key
# and store it as a Modal Secret on [the dashboard](https://modal.com/secrets)


@app.function(image=multion_image, secrets=[modal.Secret.from_name("MULTION_API_KEY")])
def news_tweet_agent():
    # Import MultiOn
    import multion

    # Login to MultiOn using the API key
    multion.login(use_api=True, multion_api_key=os.environ["MULTION_API_KEY"])

    # Enable the Agent to run locally
    multion.set_remote(False)

    params = {
        "url": "https://www.multion.ai",
        "cmd": "Go to twitter (im already signed in). Search for the last tweets i made (check the last 10 tweets). Remember them so then you can go a search for super interesting AI news. Search the news on up to 3 different sources. If you see that the source has not really interesting AI news or i already made a tweet about that, then go to a different one. When you finish the research, go and make a few small and interesting AI tweets with the info you gathered. Make sure the tweet is small but informative and interesting for AI enthusiasts. Don't do more than 5 tweets",
        "maxSteps": 100,
    }

    response = multion.browse(params)

    print(f"MultiOn response: {response}")


# ## Test running

# We can now test run our scheduled function as follows: `modal run multion_news_agent.py.py::app.news_tweet_agent`

# ## Defining the schedule and deploying

# Let's define a function that will be called by Modal every day.


@app.function(schedule=modal.Cron("0 9 * * *"))
def run_daily():
    news_tweet_agent.remote()


# In order to deploy this as a persistent cron job, you can run `modal deploy multion_news_agent.py`.

# Once the job is deployed, visit the [apps page](https://modal.com/apps) page to see
# its execution history, logs and other stats.


=== GITHUB: 10_integrations/pushgateway.py ===
# ---
# deploy: true
# cmd: ["modal", "serve", "10_integrations/pushgateway.py"]
# ---

# # Publish custom metrics with Prometheus Pushgateway

# This example shows how to publish custom metrics to a Prometheus instance with Modal.
# Due to a Modal container's ephemeral nature, it's not a good fit for a traditional
# scraping-based Prometheus setup. Instead, we'll use a [Prometheus Pushgateway](https://github.com/prometheus/pushgateway)
# to collect and store metrics from our Modal container. We can run the Pushgateway in Modal
# as a separate process and have our application push metrics to it.

# ![Prometheus Pushgateway diagram](./pushgateway_diagram.png)

# ## Install Prometheus Pushgateway

# Since the official Prometheus pushgateway image does not have Python installed, we'll
# use a custom image that includes Python to push metrics to the Pushgateway. Pushgateway
# ships a single binary, so it's easy to get it into a Modal container.

import os
import subprocess

import modal

PUSHGATEWAY_VERSION = "1.9.0"

gw_image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install("wget", "tar")
    .run_commands(
        f"wget https://github.com/prometheus/pushgateway/releases/download/v{PUSHGATEWAY_VERSION}/pushgateway-{PUSHGATEWAY_VERSION}.linux-amd64.tar.gz",
        f"tar xvfz pushgateway-{PUSHGATEWAY_VERSION}.linux-amd64.tar.gz",
        f"cp pushgateway-{PUSHGATEWAY_VERSION}.linux-amd64/pushgateway /usr/local/bin/",
        f"rm -rf pushgateway-{PUSHGATEWAY_VERSION}.linux-amd64 pushgateway-{PUSHGATEWAY_VERSION}.linux-amd64.tar.gz",
        "mkdir /pushgateway",
    )
)

# ## Start the Pushgateway

# We'll start the Pushgateway as a separate Modal app. This way, we can run the Pushgateway
# in the background and have our main app push metrics to it. We'll use the `web_server`
# decorator to expose the Pushgateway's web interface. Note that we must set `max_containers=1`
# as the Pushgateway is a single-process application. If we spin up multiple instances, they'll
# conflict with each other.

# This is an example configuration, but a production-ready configuration will differ in two respects:

# 1. You should set up authentication for the Pushgateway. Pushgateway has support for [basic authentication](https://github.com/prometheus/pushgateway/blob/42c4075fc5e2564031f2852885cdb2f5d570f672/README.md#tls-and-basic-authentication)
#    out of the box. If you need more advanced authentication, consider using a [web endpoint with authentication](https://modal.com/docs/guide/webhooks#authentication)
#    which proxies requests to the Pushgateway.

# 2. The Pushgateway should listen on a [custom domain](https://modal.com/docs/guide/webhook-urls#custom-domains).
#    This will allow you to configure Prometheus to scrape metrics from a predictable URL rather than
#    the autogenerated URL Modal assigns to your app.

gw_app = modal.App(
    "example-pushgateway-server",
    image=gw_image,
)


@gw_app.function(min_containers=1, max_containers=1)
@modal.web_server(9091)
def serve():
    subprocess.Popen("/usr/local/bin/pushgateway")


# ## Push metrics to the Pushgateway

# Now that we have the Pushgateway running, we can push metrics to it. We'll use the `prometheus_client`
# library to create a simple counter and push it to the Pushgateway. This example is a simple counter,
# but you can push any metric type to the Pushgateway.

# Note that we use the `grouping_key` argument to distinguish between different instances of the same
# metric. This is useful when you have multiple instances of the same app pushing metrics to the Pushgateway.
# Without this, the Pushgateway will overwrite the metric with the latest value.

client_image = modal.Image.debian_slim().pip_install(
    "prometheus-client==0.20.0", "fastapi[standard]==0.115.4"
)
app = modal.App(
    "example-pushgateway",
    image=client_image,
)

with client_image.imports():
    from prometheus_client import (
        CollectorRegistry,
        Counter,
        delete_from_gateway,
        push_to_gateway,
    )


@app.cls(min_containers=3)
class ExampleClientApplication:
    @modal.enter()
    def init(self):
        self.registry = CollectorRegistry()
        self.web_url = serve.get_web_url()
        self.instance_id = os.environ["MODAL_TASK_ID"]
        self.counter = Counter(
            "hello_counter",
            "This is a counter",
            registry=self.registry,
        )

    # We must explicitly clean up the metric when the app exits so Prometheus doesn't
    # keep stale metrics around.
    @modal.exit()
    def cleanup(self):
        delete_from_gateway(
            self.web_url,
            job="hello",
            grouping_key={"instance": self.instance_id},
        )

    @modal.fastapi_endpoint(label="hello-pushgateway")
    def hello(self):
        self.counter.inc()
        push_to_gateway(
            self.web_url,
            job="hello",
            grouping_key={"instance": self.instance_id},
            registry=self.registry,
        )
        return f"Hello world from {self.instance_id}!"


app.include(gw_app)

# Now, we can deploy the app and see the metrics in the Pushgateway's web interface.

# ```shell
# $ modal deploy pushgateway.py
# ✓ Created objects.
# ├── 🔨 Created mount /home/ec2-user/modal/examples/10_integrations/pushgateway.py
# ├── 🔨 Created function ExampleClientApplication.*.
# ├── 🔨 Created web function serve => https://modal-labs-examples--example-pushgateway-serve.modal.run
# └── 🔨 Created web endpoint for ExampleClientApplication.hello => https://modal-labs-examples--hello-pushgateway.modal.run
# ✓ App deployed! 🎉
# ```

# You can now go to both the [client application](https://modal-labs-examples--hello-pushgateway.modal.run)
# and [Pushgateway](https://modal-labs-examples--example-pushgateway-serve.modal.run) URLs to see the metrics being pushed.

# ## Hooking up Prometheus

# Now that we have metrics in the Pushgateway, we can configure Prometheus to scrape them. This
# is as simple as adding a new job to your Prometheus configuration. Here's an example configuration
# snippet:

# ```yaml
# scrape_configs:
# - job_name: 'pushgateway'
#   honor_labels: true # required so that the instance label is preserved
#   static_configs:
#   - targets: ['modal-labs-examples--example-pushgateway-serve.modal.run']
# ```

# Note that the target will be different if you have a custom domain set up for the Pushgateway,
# and you may need to configure authentication.

# Once you've added the job to your Prometheus configuration, Prometheus will start scraping metrics
# from the Pushgateway. You can then use Grafana or another visualization tool to create dashboards
# and alerts based on these metrics!

# ![Grafana example](./pushgateway_grafana.png)


=== GITHUB: 10_integrations/webscraper.py ===
# # Web Scraping on Modal

# This example shows how you can scrape links from a website and post them to a Slack channel using Modal.

import os

import modal

app = modal.App("example-linkscraper")


playwright_image = modal.Image.debian_slim(
    python_version="3.10"
).run_commands(  # Doesn't work with 3.11 yet
    "apt-get update",
    "apt-get install -y software-properties-common",
    "apt-add-repository non-free",
    "apt-add-repository contrib",
    "pip install playwright==1.42.0",
    "playwright install-deps chromium",
    "playwright install chromium",
)


@app.function(image=playwright_image)
async def get_links(url: str) -> set[str]:
    from playwright.async_api import async_playwright

    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.goto(url)
        links = await page.eval_on_selector_all(
            "a[href]", "elements => elements.map(element => element.href)"
        )
        await browser.close()

    return set(links)


slack_sdk_image = modal.Image.debian_slim(python_version="3.10").pip_install(
    "slack-sdk==3.27.1"
)


@app.function(
    image=slack_sdk_image,
    secrets=[
        modal.Secret.from_name(
            "scraper-slack-secret", required_keys=["SLACK_BOT_TOKEN"]
        )
    ],
)
def bot_token_msg(channel, message):
    import slack_sdk
    from slack_sdk.http_retry.builtin_handlers import RateLimitErrorRetryHandler

    client = slack_sdk.WebClient(token=os.environ["SLACK_BOT_TOKEN"])
    rate_limit_handler = RateLimitErrorRetryHandler(max_retry_count=3)
    client.retry_handlers.append(rate_limit_handler)

    print(f"Posting {message} to #{channel}")
    client.chat_postMessage(channel=channel, text=message)


@app.function()
def scrape():
    links_of_interest = ["http://modal.com"]

    for links in get_links.map(links_of_interest):
        for link in links:
            bot_token_msg.remote("scraped-links", link)


@app.function(schedule=modal.Period(days=1))
def daily_scrape():
    scrape.remote()


@app.local_entrypoint()
def run():
    scrape.remote()


=== GITHUB: 10_integrations/s3_bucket_mount.py ===
# ---
# output-directory: "/tmp/s3_bucket_mount"
# ---

# # Analyze NYC yellow taxi data with DuckDB on Parquet files from S3

# This example shows how to use Modal for a classic data science task: loading table-structured data into cloud stores,
# analyzing it, and plotting the results.

# In particular, we'll load public NYC taxi ride data into S3 as Parquet files,
# then run SQL queries on it with DuckDB.

# We'll mount the S3 bucket in a Modal app with [`CloudBucketMount`](https://modal.com/docs/reference/modal.CloudBucketMount).
# We will write to and then read from that bucket, in each case using
# Modal's [parallel execution features](https://modal.com/docs/guide/scale) to handle many files at once.

# ## Basic setup

# You will need to have an S3 bucket and AWS credentials to run this example. Refer to the documentation
# for the exact [IAM permissions](https://modal.com/docs/guide/cloud-bucket-mounts#iam-permissions) your credentials will need.

# After you are done creating a bucket and configuring IAM settings,
# you now need to create a [`Secret`](https://modal.com/docs/guide/secrets) to share
# the relevant AWS credentials with your Modal apps.

from datetime import datetime
from pathlib import Path, PosixPath

import modal

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "requests==2.31.0", "duckdb==0.10.0", "matplotlib==3.8.3"
)
app = modal.App(image=image)

secret = modal.Secret.from_name(
    "s3-bucket-secret",
    required_keys=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"],
)

MOUNT_PATH = PosixPath("/bucket")
YELLOW_TAXI_DATA_PATH = MOUNT_PATH / "yellow_taxi"

# The dependencies installed above are not available locally. The following block instructs Modal
# to only import them inside the container.

with image.imports():
    import duckdb
    import requests


# ## Download New York City's taxi data

# NYC makes data about taxi rides publicly available. The city's [Taxi & Limousine Commission (TLC)](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
# publishes files in the Parquet format. Files are organized by year and month.

# We are going to download all available files and store them in an S3 bucket. We do this by
# attaching a `modal.CloudBucketMount` with the S3 bucket name and its respective credentials.
# The files in the bucket will then be available at `MOUNT_PATH`.

# As we'll see below, this operation can be massively sped up by running it in parallel on Modal.


@app.function(
    volumes={
        MOUNT_PATH: modal.CloudBucketMount("modal-s3mount-test-bucket", secret=secret),
    },
)
def download_data(year: int, month: int) -> str:
    filename = f"yellow_tripdata_{year}-{month:02d}.parquet"
    url = f"https://d37ci6vzurychx.cloudfront.net/trip-data/{filename}"
    s3_path = MOUNT_PATH / filename
    # Skip downloading if file exists.
    if not s3_path.exists():
        if not YELLOW_TAXI_DATA_PATH.exists():
            YELLOW_TAXI_DATA_PATH.mkdir(parents=True, exist_ok=True)
            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                print(f"downloading => {s3_path}")
                # It looks like we writing locally, but this is actually writing to S3!
                with open(s3_path, "wb") as file:
                    for chunk in r.iter_content(chunk_size=8192):
                        file.write(chunk)

    return s3_path.as_posix()


# ## Analyze data with DuckDB

# [DuckDB](https://duckdb.org/) is an analytical database with rich support for Parquet files.
# It is also very fast. Below, we define a Modal Function that aggregates yellow taxi trips
# within a month (each file contains all the rides from a specific month).


@app.function(
    volumes={
        MOUNT_PATH: modal.CloudBucketMount(
            "modal-s3mount-test-bucket",
            secret=modal.Secret.from_name("s3-bucket-secret"),
        )
    },
)
def aggregate_data(path: str) -> list[tuple[datetime, int]]:
    print(f"processing => {path}")

    # Parse file.
    year_month_part = path.split("yellow_tripdata_")[1]
    year, month = year_month_part.split("-")
    month = month.replace(".parquet", "")

    # Make DuckDB query using in-memory storage.
    con = duckdb.connect(database=":memory:")
    q = """
    with sub as (
        select tpep_pickup_datetime::date d, count(1) c
        from read_parquet(?)
        group by 1
    )
    select d, c from sub
    where date_part('year', d) = ?  -- filter out garbage
    and date_part('month', d) = ?   -- same
    """
    con.execute(q, (path, year, month))
    return list(con.fetchall())


# ## Plot daily taxi rides

# Finally, we want to plot our results.
# The plot created shows the number of yellow taxi rides per day in NYC.
# This function runs remotely, on Modal, so we don't need to install plotting libraries locally.


@app.function()
def plot(dataset) -> bytes:
    import io

    import matplotlib.pyplot as plt

    # Sorting data by date
    dataset.sort(key=lambda x: x[0])

    # Unpacking dates and values
    dates, values = zip(*dataset)

    # Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(dates, values)
    plt.title("Number of NYC yellow taxi trips by weekday, 2018-2023")
    plt.ylabel("Number of daily trips")
    plt.grid(True)
    plt.tight_layout()

    # Saving plot as raw bytes to send back
    buf = io.BytesIO()

    plt.savefig(buf, format="png")

    buf.seek(0)

    return buf.getvalue()


# ## Run everything

# The `@app.local_entrypoint()` defines what happens when we run our Modal program locally.
# We invoke it from the CLI by calling `modal run s3_bucket_mount.py`.
# We first call `download_data()` and `starmap` (named because it's kind of like `map(*args)`)
# on tuples of inputs `(year, month)`. This will download, in parallel,
# all yellow taxi data files into our locally mounted S3 bucket and return a list of
# Parquet file paths. Then, we call `aggregate_data()` with `map` on that list. These files are
# also read from our S3 bucket. So one function writes files to S3 and the other
# reads files from S3 in; both run across many files in parallel.

# Finally, we call `plot` to generate the following figure:
#
# ![Number of NYC yellow taxi trips by weekday, 2018-2023](./nyc_yellow_taxi_trips_s3_mount.png)

# This program should run in less than 30 seconds.


@app.local_entrypoint()
def main():
    # List of tuples[year, month].
    inputs = [(year, month) for year in range(2018, 2023) for month in range(1, 13)]

    # List of file paths in S3.
    parquet_files: list[str] = []
    for path in download_data.starmap(inputs):
        print(f"done => {path}")
        parquet_files.append(path)

    # List of datetimes and number of yellow taxi trips.
    dataset = []
    for r in aggregate_data.map(parquet_files):
        dataset += r

    dir = Path("/tmp") / "s3_bucket_mount"
    if not dir.exists():
        dir.mkdir(exist_ok=True, parents=True)

    figure = plot.remote(dataset)
    path = dir / "nyc_yellow_taxi_trips_s3_mount.png"
    with open(path, "wb") as file:
        print(f"Saving figure to {path}")
        file.write(figure)


=== GITHUB: 10_integrations/algolia_indexer.py ===
# ---
# deploy: true
# env: {"MODAL_ENVIRONMENT": "main"}
# ---

# # Algolia docsearch crawler

# This tutorial shows you how to use Modal to run the [Algolia docsearch
# crawler](https://docsearch.algolia.com/docs/legacy/run-your-own/) to index your
# website and make it searchable. This is not just example code - we run the same
# code in production to power search on this page (`Ctrl+K` to try it out!).

# ## Basic setup

# Let's get the imports out of the way.

import json
import os
import subprocess

import modal

# Modal lets you [use and extend existing Docker images](https://modal.com/docs/guide/custom-container#use-an-existing-container-image-with-from_registry),
# as long as they have `python` and `pip` available. We'll use the official crawler image built by Algolia, with a small
# adjustment: since this image has `python` symlinked to `python3.6` and Modal is not compatible with Python 3.6, we
# install Python 3.11 and symlink that as the `python` executable instead.

algolia_image = modal.Image.from_registry(
    "algolia/docsearch-scraper:v1.16.0",
    add_python="3.11",
    setup_dockerfile_commands=["ENTRYPOINT []"],
)

app = modal.App("example-algolia-indexer")

# ## Configure the crawler

# Now, let's configure the crawler with the website we want to index, and which
# CSS selectors we want to scrape. Complete documentation for crawler configuration is available
# [here](https://docsearch.algolia.com/docs/legacy/config-file).

CONFIG = {
    "index_name": "modal_docs",
    "custom_settings": {
        "separatorsToIndex": "._",
        "synonyms": [["cls", "class"]],
    },
    "stop_urls": [
        "https://modal.com/docs/reference/modal.Stub",
        "https://modal.com/gpu-glossary",
        "https://modal.com/docs/reference/changelog",
    ],
    "start_urls": [
        {
            "url": "https://modal.com/docs/guide",
            "selectors_key": "default",
            "page_rank": 2,
        },
        {
            "url": "https://modal.com/docs/examples",
            "selectors_key": "examples",
            "page_rank": 1,
        },
        {
            "url": "https://modal.com/docs/reference",
            "selectors_key": "reference",
            "page_rank": 1,
        },
    ],
    "selectors": {
        "default": {
            "lvl0": {
                "selector": "header .navlink-active",
                "global": True,
            },
            "lvl1": "article h1",
            "lvl2": "article h2",
            "lvl3": "article h3",
            "text": "article p,article ol,article ul",
        },
        "examples": {
            "lvl0": {
                "selector": "header .navlink-active",
                "global": True,
            },
            "lvl1": "article h1",
            "text": "article p,article ol,article ul",
        },
        "reference": {
            "lvl0": {
                "selector": "//div[contains(@class, 'sidebar')]//a[contains(@class, 'active')]//preceding::a[contains(@class, 'header')][1]",
                "type": "xpath",
                "global": True,
                "default_value": "",
                "skip": {"when": {"value": ""}},
            },
            "lvl1": "article h1",
            "lvl2": "article h2",
            "lvl3": "article h3",
            "text": "article p,article ol,article ul",
        },
    },
}

# ## Create an API key

# If you don't already have one, sign up for an account on [Algolia](https://www.algolia.com/). Set up
# a project and create an API key with `write` access to your index, and with the ACL permissions
# `addObject`, `editSettings` and `deleteIndex`. Now, create a Secret on the Modal [Secrets](https://modal.com/secrets)
# page with the `API_KEY` and `APPLICATION_ID` you just created. You can name this anything you want,
# but we named it `algolia-secret` and so that's what the code below expects.

# ## The actual function

# We want to trigger our crawler from our CI/CD pipeline, so we're serving it as a
# [web endpoint](https://modal.com/docs/guide/webhooks) that can be triggered by a `GET` request during deploy.
# You could also consider running the crawler on a [schedule](https://modal.com/docs/guide/cron).

# The Algolia crawler is written for Python 3.6 and needs to run in the `pipenv` created for it,
# so we're invoking it using a subprocess.


@app.function(
    image=algolia_image,
    secrets=[modal.Secret.from_name("algolia-secret")],
)
def crawl():
    # Installed with a 3.6 venv; Python 3.6 is unsupported by Modal, so use a subprocess instead.
    subprocess.run(
        ["pipenv", "run", "python", "-m", "src.index"],
        env={**os.environ, "CONFIG": json.dumps(CONFIG)},
    )


# We want to be able to trigger this function through a webhook.


@app.function(image=modal.Image.debian_slim().pip_install("fastapi[standard]"))
@modal.fastapi_endpoint()
def crawl_webhook():
    crawl.remote()
    return "Finished indexing docs"


# ## Deploy the indexer

# That's all the code we need! To deploy your application, run

# ```shell
# modal deploy algolia_indexer.py
# ```

# If successful, this will print a URL for your new webhook, that you can hit using
# `curl` or a browser. Logs from webhook invocations can be found from the [apps](https://modal.com/apps)
# page.

# The indexed contents can be found at https://www.algolia.com/apps/APP_ID/explorer/browse/, for your
# APP_ID. Once you're happy with the results, you can [set up the `docsearch` package with your
# website](https://docsearch.algolia.com/docs/docsearch-v3/), and create a search component that uses this index.

# ## Entrypoint for development

# To make it easier to test this, we also have an entrypoint for when you run
# `modal run algolia_indexer.py`


@app.local_entrypoint()
def run():
    crawl.remote()


=== GITHUB: 10_integrations/cron_datasette.py ===
# ---
# deploy: true
# ---

# # Publish interactive datasets with Datasette

# ![Datasette user interface](https://modal-cdn.com/cdnbot/imdb_datasetteqzaj3q9d_a83d82fd.webp)

# Build and deploy an interactive movie database that automatically updates daily with the latest IMDb data.
# This example shows how to serve a Datasette application on Modal with millions of movie and TV show records.

# Try it out for yourself [here](https://modal-labs-examples--example-cron-datasette-ui.modal.run).

# Along the way, we will learn how to use the following Modal features:

# * [Volumes](https://modal.com/docs/guide/volumes): a persisted volume lets us store and grow the published dataset over time.

# * [Scheduled functions](https://modal.com/docs/guide/cron): the underlying dataset is refreshed daily, so we schedule a function to run daily.

# * [Web endpoints](https://modal.com/docs/guide/webhooks): exposes the Datasette application for web browser interaction and API requests.

# ## Basic setup

# Let's get started writing code.
# For the Modal container image we need a few Python packages.

import asyncio
import gzip
import pathlib
import shutil
import tempfile
from datetime import datetime
from urllib.request import urlretrieve

import modal

app = modal.App("example-cron-datasette")
cron_image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "datasette==0.65.1", "sqlite-utils==3.38", "tqdm~=4.67.1", "setuptools<80"
)

# ## Persistent dataset storage

# To separate database creation and maintenance from serving, we'll need the underlying
# database file to be stored persistently. To achieve this we use a
# [Volume](https://modal.com/docs/guide/volumes).

volume = modal.Volume.from_name(
    "example-cron-datasette-cache-vol", create_if_missing=True
)
DB_FILENAME = "imdb.db"
VOLUME_DIR = "/cache-vol"
DATA_DIR = pathlib.Path(VOLUME_DIR, "imdb-data")
DB_PATH = pathlib.Path(VOLUME_DIR, DB_FILENAME)

# ## Getting a dataset

# [IMDb Datasets](https://datasets.imdbws.com/) are available publicly and are updated daily.
# We will download the title.basics.tsv.gz file which contains basic information about all titles (movies, TV shows, etc.).
# Since we are serving an interactive database which updates daily, we will download the files into a temporary directory and then move them to the volume to prevent downtime.

BASE_URL = "https://datasets.imdbws.com/"
IMDB_FILES = [
    "title.basics.tsv.gz",
]


@app.function(
    image=cron_image,
    volumes={VOLUME_DIR: volume},
    retries=2,
    timeout=1800,
)
def download_dataset(force_refresh=False):
    """Download IMDb dataset files."""
    if DATA_DIR.exists() and not force_refresh:
        print(
            f"Dataset already present and force_refresh={force_refresh}. Skipping download."
        )
        return

    TEMP_DATA_DIR = pathlib.Path(VOLUME_DIR, "imdb-data-temp")
    if TEMP_DATA_DIR.exists():
        shutil.rmtree(TEMP_DATA_DIR)

    TEMP_DATA_DIR.mkdir(parents=True, exist_ok=True)

    print("Downloading IMDb dataset...")

    try:
        for filename in IMDB_FILES:
            print(f"Downloading {filename}...")
            url = BASE_URL + filename
            output_path = TEMP_DATA_DIR / filename

            urlretrieve(url, output_path)
            print(f"Successfully downloaded {filename}")

        if DATA_DIR.exists():
            # move the current data to a backup location
            OLD_DATA_DIR = pathlib.Path(VOLUME_DIR, "imdb-data-old")
            if OLD_DATA_DIR.exists():
                shutil.rmtree(OLD_DATA_DIR)
            shutil.move(DATA_DIR, OLD_DATA_DIR)

            # move the new data into place
            shutil.move(TEMP_DATA_DIR, DATA_DIR)

            # clean up the old data
            shutil.rmtree(OLD_DATA_DIR)
        else:
            shutil.move(TEMP_DATA_DIR, DATA_DIR)

        volume.commit()
        print("Finished downloading dataset.")

    except Exception as e:
        print(f"Error during download: {e}")
        if TEMP_DATA_DIR.exists():
            shutil.rmtree(TEMP_DATA_DIR)
        raise


# ## Data processing

# This dataset is no swamp, but a bit of data cleaning is still in order.
# The following function reads a .tsv file, cleans the data and yields batches of records.


def parse_tsv_file(filepath, batch_size=50000, filter_year=None):
    """Parse a gzipped TSV file and yield batches of records."""
    import csv

    with gzip.open(filepath, "rt", encoding="utf-8") as gz_file:
        reader = csv.DictReader(gz_file, delimiter="\t")
        batch = []
        total_processed = 0

        for row in reader:
            # map missing values to None
            row = {k: (None if v == "\\N" else v) for k, v in row.items()}

            # remove nsfw data
            if row.get("isAdult") == "1":
                continue

            if filter_year:
                start_year = int(row.get("startYear", 0) or 0)
                if start_year < filter_year:
                    continue

            batch.append(row)
            total_processed += 1

            if len(batch) >= batch_size:
                yield batch
                batch = []

        # Yield any remaining records
        if batch:
            yield batch

        print(f"Finished processing {total_processed:,} titles.")


# ## Inserting into SQLite

# With the TSV processing out of the way, we’re ready to create a SQLite database and feed data into it.

# Importantly, the `prep_db` function mounts the same volume used by `download_dataset`, and rows are batch inserted with progress logged after each batch,
# as the full IMDb dataset has millions of rows and does take some time to be fully inserted.

# A more sophisticated implementation would only load new data instead of performing a full refresh,
# but we’re keeping things simple for this example!
# We will also create indexes for the titles table to speed up queries.


@app.function(
    image=cron_image,
    volumes={VOLUME_DIR: volume},
    timeout=900,
)
def prep_db(filter_year=None):
    """Process IMDb data files and create SQLite database."""
    import sqlite_utils
    import tqdm

    volume.reload()

    # Create database in a temporary directory first
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = pathlib.Path(tmpdir)
        tmp_db_path = tmpdir_path / DB_FILENAME

        db = sqlite_utils.Database(tmp_db_path)

        # Process title.basics.tsv.gz
        titles_file = DATA_DIR / "title.basics.tsv.gz"

        if titles_file.exists():
            titles_table = db["titles"]
            batch_count = 0
            total_processed = 0

            with tqdm.tqdm(desc="Processing titles", unit="batch", leave=True) as pbar:
                for i, batch in enumerate(
                    parse_tsv_file(
                        titles_file, batch_size=50000, filter_year=filter_year
                    )
                ):
                    titles_table.insert_all(batch, batch_size=50000, truncate=(i == 0))
                    batch_count += len(batch)
                    total_processed += len(batch)
                    pbar.update(1)
                    pbar.set_postfix({"titles": f"{total_processed:,}"})

            print(f"Total titles in database: {batch_count:,}")

            # Create indexes for titles so we can query the database faster
            print("Creating indexes...")
            titles_table.create_index(["tconst"], if_not_exists=True, unique=True)
            titles_table.create_index(["primaryTitle"], if_not_exists=True)
            titles_table.create_index(["titleType"], if_not_exists=True)
            titles_table.create_index(["startYear"], if_not_exists=True)
            titles_table.create_index(["genres"], if_not_exists=True)
            print("Created indexes for titles table")

        db.close()

        # Copy the database to the volume
        DB_PATH.parent.mkdir(parents=True, exist_ok=True)
        shutil.copyfile(tmp_db_path, DB_PATH)

    print("Syncing DB with volume.")
    volume.commit()
    print("Volume changes committed.")


# ## Keep it fresh

# IMDb updates their data daily, so we set up
# a [scheduled](https://modal.com/docs/guide/cron) function to automatically refresh the database
# every 24 hours.


@app.function(schedule=modal.Period(hours=24), timeout=4000)
def refresh_db():
    """Scheduled function to refresh the database daily."""
    print(f"Running scheduled refresh at {datetime.now()}")
    download_dataset.remote(force_refresh=True)
    prep_db.remote()


# ## Web endpoint

# Hooking up the SQLite database to a Modal webhook is as simple as it gets.
# The Modal `@asgi_app` decorator wraps a few lines of code: one `import` and a few
# lines to instantiate the `Datasette` instance and return its app server.

# First, let's define a metadata object for the database.
# This will be used to configure Datasette to display a custom UI with some pre-defined queries.

columns = {
    "tconst": "Unique identifier",
    "titleType": "Type (movie, tvSeries, short, etc.)",
    "primaryTitle": "Main title",
    "originalTitle": "Original language title",
    "startYear": "Release year",
    "endYear": "End year (for TV series)",
    "runtimeMinutes": "Runtime in minutes",
    "genres": "Comma-separated genres",
}

queries = {
    "movies_2024": {
        "sql": """
                        SELECT
                            primaryTitle as title,
                            genres,
                            runtimeMinutes as runtime
                        FROM titles
                        WHERE titleType = 'movie'
                        AND startYear = 2024
                        ORDER BY primaryTitle
                        LIMIT 100
                    """,
        "title": "Movies Released in 2024",
    },
    "longest_movies": {
        "sql": """
                        SELECT
                            primaryTitle as title,
                            startYear as year,
                            runtimeMinutes as runtime,
                            genres
                        FROM titles
                        WHERE titleType = 'movie'
                        AND runtimeMinutes IS NOT NULL
                        AND runtimeMinutes > 180
                        ORDER BY runtimeMinutes DESC
                        LIMIT 50
                    """,
        "title": "Longest Movies (3+ hours)",
    },
    "genre_breakdown": {
        "sql": """
                        SELECT
                            genres,
                            COUNT(*) as count
                        FROM titles
                        WHERE titleType = 'movie'
                        AND genres IS NOT NULL
                        GROUP BY genres
                        ORDER BY count DESC
                        LIMIT 25
                    """,
        "title": "Popular Genres",
    },
}


metadata = {
    "title": "IMDb Database Explorer",
    "description": "Explore IMDb movie and TV show data",
    "databases": {
        "imdb": {
            "tables": {
                "titles": {
                    "description": "Basic information about all titles (movies, TV shows, etc.)",
                    "columns": columns,
                }
            },
            "queries": {
                "movies_2024": queries["movies_2024"],
                "longest_movies": queries["longest_movies"],
                "genre_breakdown": queries["genre_breakdown"],
            },
        }
    },
}

# Now we can define the web endpoint that will serve the Datasette application


@app.function(
    image=cron_image,
    volumes={VOLUME_DIR: volume},
)
@modal.concurrent(max_inputs=16)
@modal.asgi_app()
def ui():
    """Web endpoint for Datasette UI."""
    from datasette.app import Datasette

    ds = Datasette(
        files=[DB_PATH],
        settings={
            "sql_time_limit_ms": 60000,
            "max_returned_rows": 10000,
            "allow_download": True,
            "facet_time_limit_ms": 5000,
            "allow_facet": True,
        },
        metadata=metadata,
    )
    asyncio.run(ds.invoke_startup())
    return ds.app()


# ## Publishing to the web

# Run this script using `modal run cron_datasette.py` and it will create the database under 5 minutes!

# If you would like to force a refresh of the dataset, you can use:

# `modal run cron_datasette.py --force-refresh`

# If you would like to filter the data to be after a specific year, you can use:

# `modal run cron_datasette.py --filter-year year`

# You can then use `modal serve cron_datasette.py` to create a short-lived web URL
# that exists until you terminate the script.

# When publishing the interactive Datasette app you'll want to create a persistent URL.
# Just run `modal deploy cron_datasette.py` and your app will be deployed in seconds!


@app.local_entrypoint()
def run(force_refresh: bool = False, filter_year: int = None):
    if force_refresh:
        print("Force refreshing the dataset...")

    if filter_year:
        print(f"Filtering data to be after {filter_year}")

    print("Downloading IMDb dataset...")
    download_dataset.remote(force_refresh=force_refresh)
    print("Processing data and creating SQLite DB...")
    prep_db.remote(filter_year=filter_year)
    print("\nDatabase ready! You can now run:")
    print("  modal serve cron_datasette.py  # For development")
    print("  modal deploy cron_datasette.py  # For production deployment")


# You can explore the data at the [deployed web endpoint](https://modal-labs-examples--example-cron-datasette-ui.modal.run).


=== GITHUB: 10_integrations/cloud_bucket_mount_loras.py ===
# ---
# output-directory: "/tmp/stable-diffusion-xl"
# deploy: true
# ---

# # LoRAs Galore: Create a LoRA Playground with Modal, Gradio, and S3

# This example shows how to mount an S3 bucket in a Modal app using [`CloudBucketMount`](https://modal.com/docs/reference/modal.CloudBucketMount).
# We will download a bunch of LoRA adapters from the [HuggingFace Hub](https://huggingface.co/models) into our S3 bucket
# then read from that bucket, on the fly, when doing inference.

# By default, we use the [IKEA instructions LoRA](https://huggingface.co/ostris/ikea-instructions-lora-sdxl) as an example,
# which produces the following image when prompted to generate "IKEA instructions for building a GPU rig for deep learning":

# ![IKEA instructions for building a GPU rig for deep learning](./ikea-instructions-for-building-a-gpu-rig-for-deep-learning.png)

# By the end of this example, we've deployed a "playground" app where anyone with a browser can try
# out these custom models. That's the power of Modal: custom, autoscaling AI applications, deployed in seconds.
# You can try out our deployment [here](https://modal-labs-examples--loras-galore-ui.modal.run).

# ## Basic setup

import io
import os
from pathlib import Path
from typing import Optional

import modal

# You will need to have an S3 bucket and AWS credentials to run this example. Refer to the documentation
# for the detailed [IAM permissions](https://modal.com/docs/guide/cloud-bucket-mounts#iam-permissions) those credentials will need.

# After you are done creating a bucket and configuring IAM settings,
# you now need to create a [Modal Secret](https://modal.com/docs/guide/secrets). Navigate to the "Secrets" tab and
# click on the AWS card, then fill in the fields with the AWS key and secret created
# previously. Name the Secret `s3-bucket-secret`.

bucket_secret = modal.Secret.from_name(
    "s3-bucket-secret",
    required_keys=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"],
)

MOUNT_PATH: Path = Path("/mnt/bucket")
LORAS_PATH: Path = MOUNT_PATH / "loras/v5"

BASE_MODEL = "stabilityai/stable-diffusion-xl-base-1.0"
CACHE_DIR = "/hf-cache"

# Modal runs serverless functions inside containers.
# The environments those functions run in are defined by
# the container `Image`. The line below constructs an image
# with the dependencies we need -- no need to install them locally.

image = (
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(
        "huggingface_hub==0.21.4",
        "transformers==4.38.2",
        "diffusers==0.26.3",
        "peft==0.9.0",
        "accelerate==0.27.2",
    )
    .env({"HF_HUB_CACHE": CACHE_DIR})
)

with image.imports():
    # we import these dependencies only inside the container
    import diffusers
    import huggingface_hub
    import torch

# We attach the S3 bucket to all the Modal functions in this app by mounting it on the filesystem they see,
# passing a `CloudBucketMount` to the `volumes` dictionary argument. We can read and write to this mounted bucket
# (almost) as if it were a local directory.

app = modal.App(
    "loras-galore",
    image=image,
    volumes={
        MOUNT_PATH: modal.CloudBucketMount(
            "modal-s3mount-test-bucket",
            secret=bucket_secret,
        )
    },
)


# For the base model, we'll use a modal.Volume to store the Hugging Face cache.
cache_volume = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)


@app.function(image=image, volumes={CACHE_DIR: cache_volume})
def download_model():
    loc = huggingface_hub.snapshot_download(repo_id=BASE_MODEL)
    print(f"Saved model to {loc}")


# ## Acquiring LoRA weights

# `search_loras()` will use the Hub API to search for LoRAs. We limit LoRAs
# to a maximum size to avoid downloading very large model weights.
# We went with 800 MiB, but feel free to adapt to what works best for you.


@app.function(secrets=[bucket_secret])
def search_loras(limit: int, max_model_size: int = 1024 * 1024 * 1024):
    api = huggingface_hub.HfApi()

    model_ids: list[str] = []
    for model in api.list_models(
        tags=["lora", f"base_model:{BASE_MODEL}"],
        library="diffusers",
        sort="downloads",  # sort by most downloaded
    ):
        try:
            model_size = 0
            for file in api.list_files_info(model.id):
                model_size += file.size

        except huggingface_hub.utils.GatedRepoError:
            print(f"gated model ({model.id}); skipping")
            continue

        # Skip models that are larger than file limit.
        if model_size > max_model_size:
            print(f"model {model.id} is too large; skipping")
            continue

        model_ids.append(model.id)
        if len(model_ids) >= limit:
            return model_ids

    return model_ids


# We want to take the LoRA weights we found and move them from Hugging Face onto S3,
# where they'll be accessible, at short latency and high throughput, for our Modal functions.
# Downloading files in this mount will automatically upload files to S3.
# To speed things up, we will run this function in parallel using Modal's
# [`map`](https://modal.com/docs/reference/modal.Function#map).
@app.function()
def download_lora(repository_id: str) -> Optional[str]:
    os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

    # CloudBucketMounts will report 0 bytes of available space leading to many
    # unnecessary warnings, so we patch the method that emits those warnings.
    from huggingface_hub import file_download

    file_download._check_disk_space = lambda x, y: False

    repository_path = LORAS_PATH / repository_id
    try:
        # skip models we've already downloaded
        if not repository_path.exists():
            huggingface_hub.snapshot_download(
                repository_id,
                local_dir=repository_path.as_posix().replace(".", "_"),
                allow_patterns=["*.safetensors"],
            )
        downloaded_lora = len(list(repository_path.rglob("*.safetensors"))) > 0
    except OSError:
        downloaded_lora = False
    except FileNotFoundError:
        downloaded_lora = False
    if downloaded_lora:
        return repository_id
    else:
        return None


# ## Inference with LoRAs

# We define a `StableDiffusionLoRA` class to organize our inference code.
# We load Stable Diffusion XL 1.0 as a base model, then, when doing inference,
# we load whichever LoRA the user specifies from the S3 bucket.
# For more on the decorators we use on the methods below to speed up building and booting,
# check out the [container lifecycle hooks guide](https://modal.com/docs/guide/lifecycle-functions).


@app.cls(
    gpu="a10g",  # A10G GPUs are great for inference
    volumes={CACHE_DIR: cache_volume},  # We cache the base model
)
class StableDiffusionLoRA:
    @modal.enter()  # when a new container starts, we load the base model into the GPU
    def load(self):
        self.pipe = diffusers.DiffusionPipeline.from_pretrained(
            BASE_MODEL, torch_dtype=torch.float16
        ).to("cuda")

    @modal.method()  # at inference time, we pull in the LoRA weights and pass the final model the prompt
    def run_inference_with_lora(
        self, lora_id: str, prompt: str, seed: int = 8888
    ) -> bytes:
        for file in (LORAS_PATH / lora_id).rglob("*.safetensors"):
            self.pipe.load_lora_weights(lora_id, weight_name=file.name)
            break

        lora_scale = 0.9
        image = self.pipe(
            prompt,
            num_inference_steps=10,
            cross_attention_kwargs={"scale": lora_scale},
            generator=torch.manual_seed(seed),
        ).images[0]

        buffer = io.BytesIO()
        image.save(buffer, format="PNG")

        return buffer.getvalue()


# ## Try it locally!

# To use our inference code from our local command line, we add a `local_entrypoint` to our `app`.
# Run it using `modal run cloud_bucket_mount_loras.py`, and pass `--help`
# to see the available options.

# The inference code will run on our machines, but the results will be available on yours.


@app.local_entrypoint()
def main(
    limit: int = 100,
    example_lora: str = "ostris/ikea-instructions-lora-sdxl",
    prompt: str = "IKEA instructions for building a GPU rig for deep learning",
    seed: int = 8888,
):
    # Download LoRAs in parallel.
    lora_model_ids = [example_lora]
    lora_model_ids += search_loras.remote(limit)

    downloaded_loras = []
    for model in download_lora.map(lora_model_ids):
        if model:
            downloaded_loras.append(model)

    print(f"downloaded {len(downloaded_loras)} loras => {downloaded_loras}")

    # Run inference using one of the downloaded LoRAs.
    byte_stream = StableDiffusionLoRA().run_inference_with_lora.remote(
        example_lora, prompt, seed
    )
    dir = Path("/tmp/stable-diffusion-xl")
    if not dir.exists():
        dir.mkdir(exist_ok=True, parents=True)

    output_path = dir / f"{as_slug(prompt.lower())}.png"
    print(f"Saving it to {output_path}")
    with open(output_path, "wb") as f:
        f.write(byte_stream)


# ## LoRA Exploradora: A hosted Gradio interface
#
# Command line tools are cool, but we can do better!
# With the Gradio library by Hugging Face, we can create a simple web interface
# around our Python inference function, then use Modal to host it for anyone to try out.
#
# To set up your own, run `modal deploy cloud_bucket_mount_loras.py` and navigate to the URL it prints out.
# If you're playing with the code, use `modal serve` instead to see changes live.

web_image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "fastapi[standard]==0.115.4",
    "gradio~=5.7.1",
    "pillow~=10.2.0",
)


@app.function(
    image=web_image,
    min_containers=1,
    scaledown_window=60 * 20,
    # gradio requires sticky sessions
    # so we limit the number of concurrent containers to 1
    # and allow it to scale to 100 concurrent inputs
    max_containers=1,
)
@modal.concurrent(max_inputs=100)
@modal.asgi_app()
def ui():
    """A simple Gradio interface around our LoRA inference."""
    import io

    import gradio as gr
    from fastapi import FastAPI
    from gradio.routes import mount_gradio_app
    from PIL import Image

    # determine which loras are available
    lora_ids = [
        f"{lora_dir.parent.stem}/{lora_dir.stem}" for lora_dir in LORAS_PATH.glob("*/*")
    ]

    # pick one to be default, set a default prompt
    default_lora_id = (
        "ostris/ikea-instructions-lora-sdxl"
        if "ostris/ikea-instructions-lora-sdxl" in lora_ids
        else lora_ids[0]
    )
    default_prompt = (
        "IKEA instructions for building a GPU rig for deep learning"
        if default_lora_id == "ostris/ikea-instructions-lora-sdxl"
        else "text"
    )

    # the simple path to making an app on Gradio is an Interface: a UI wrapped around a function.
    def go(lora_id: str, prompt: str, seed: int) -> Image:
        return Image.open(
            io.BytesIO(
                StableDiffusionLoRA().run_inference_with_lora.remote(
                    lora_id, prompt, seed
                )
            ),
        )

    iface = gr.Interface(
        go,
        inputs=[  # the inputs to go/our inference function
            gr.Dropdown(choices=lora_ids, value=default_lora_id, label="👉 LoRA ID"),
            gr.Textbox(default_prompt, label="🎨 Prompt"),
            gr.Number(value=8888, label="🎲 Random Seed"),
        ],
        outputs=gr.Image(label="Generated Image"),
        # some extra bits to make it look nicer
        title="LoRAs Galore",
        description="# Try out some of the top custom SDXL models!"
        "\n\nPick a LoRA finetune of SDXL from the dropdown, then prompt it to generate an image."
        "\n\nCheck out [the code on GitHub](https://github.com/modal-labs/modal-examples/blob/main/10_integrations/cloud_bucket_mount_loras.py)"
        " if you want to create your own version or just see how it works."
        "\n\nPowered by [Modal](https://modal.com) 🚀",
        theme="soft",
        allow_flagging="never",
    )

    return mount_gradio_app(app=FastAPI(), blocks=iface, path="/")


def as_slug(name):
    """Converts a string, e.g. a prompt, into something we can use as a filename."""
    import re

    s = str(name).strip().replace(" ", "-")
    s = re.sub(r"(?u)[^-\w.]", "", s)
    return s


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference.py ===
# # LLM inference within your data warehouse using dbt python models

# In this example we demonstrate how you could combine [dbt's python models](https://docs.getdbt.com/docs/build/python-models)
# with LLM inference models powered by Modal, allowing you to run serverless gpu workloads within dbt.

# This example runs [dbt](https://docs.getdbt.com/docs/introduction) with a [DuckDB](https://duckdb.org)
# backend directly on top of Modal, but could be translated to run on any dbt-compatible
# database that supports python models. Similarly you could make these requests from UDFs
# directly in SQL instead if you don't want to use dbt's python models.

# In this example we use an LLM deployed in a previous example: [Serverless TensorRT-LLM (LLaMA 3 8B)](https://modal.com/docs/examples/trtllm_llama)
# but you could easily swap this for whichever Modal Function you wish. We use this to classify the sentiment
# for free-text product reviews and aggregate them in subsequent dbt sql models. These product names, descriptions and reviews
# were also generated by an LLM running on Modal!

# ## Configure Modal and dbt

# We set up the environment variables necessary for dbt and
# create a slim debian and install the packages necessary to run.

import pathlib

import modal

LOCAL_DBT_PROJECT = (  # local path
    pathlib.Path(__file__).parent / "dbt_modal_inference_proj"
)
PROJ_PATH = "/root/dbt"  # remote paths
VOL_PATH = "/root/vol"
DB_PATH = f"{VOL_PATH}/db"
PROFILES_PATH = "/root/dbt_profile"
TARGET_PATH = f"{VOL_PATH}/target"

# We also define the environment our application will run in --
# a container image, similar to Docker.
# See [this guide](https://modal.com/docs/guide/custom-container) for details.

dbt_image = (  # start from a slim Linux image
    modal.Image.debian_slim(python_version="3.12")
    .pip_install(  # install python packages
        "dbt-duckdb==1.8.1",  # dbt with duckdb connector
        "pandas==2.2.2",  # dataframes
        "pyarrow==17.0.0",  # columnar data lib
        "requests==2.32.3",  # http library
    )
    .env(  # configure dbt environment variables
        {
            "DBT_PROJECT_DIR": PROJ_PATH,
            "DBT_PROFILES_DIR": PROFILES_PATH,
            "DBT_TARGET_PATH": TARGET_PATH,
            "DB_PATH": DB_PATH,
        }
    )
    # We add the local code and configuration into the image
    # so that it will be available when we run dbt
    .add_local_dir(LOCAL_DBT_PROJECT, remote_path=PROJ_PATH)
    .add_local_file(
        local_path=LOCAL_DBT_PROJECT / "profiles.yml",
        remote_path=f"{PROFILES_PATH}/profiles.yml",
    )
)

app = modal.App("duckdb-dbt-inference", image=dbt_image)


# Create a modal.Volume so that we can persist our data
dbt_vol = modal.Volume.from_name("dbt-inference-vol", create_if_missing=True)

# ## Run dbt in a serverless Modal Function

# With Modal it's easy to run python code serverless
# and with dbt's [programmatic invocations](https://docs.getdbt.com/reference/programmatic-invocations)
# you can easily run dbt from python instead of using the command line

# Using the above configuration we can invoke dbt from Modal
# and use this to run transformations in our warehouse.

# The `dbt_run` function does a few things, it:

# 1. creates the directories for storing the DuckDB database and dbt target files

# 2. gets a reference to a deployed Modal Function that serves an LLM inference endpoint

# 3. runs dbt with a variable for the inference url

# 4. prints the output of the final dbt table in the DuckDB parquet output


@app.function(
    volumes={VOL_PATH: dbt_vol},
)
def dbt_run() -> None:
    import os

    import duckdb
    from dbt.cli.main import dbtRunner

    os.makedirs(DB_PATH, exist_ok=True)
    os.makedirs(TARGET_PATH, exist_ok=True)

    # Remember to either deploy the llama dependency app in your environment
    # first, or change this to use another web endpoint you have:
    ref = modal.Function.from_name(
        "example-trtllm-Meta-Llama-3-8B-Instruct", "generate_web"
    )

    res = dbtRunner().invoke(
        ["run", "--vars", f"{{'inference_url': '{ref.get_web_url()}'}}"]
    )
    if res.exception:
        print(res.exception)

    duckdb.sql(
        f"select * from '{DB_PATH}/product_reviews_sentiment_agg.parquet';"
    ).show()


# Running the Modal Function with

# ```sh
# modal run dbt_modal_inference.py
# ```

# will result in something like:

# ```
# 21:25:21  Running with dbt=1.8.4
# 21:25:21  Registered adapter: duckdb=1.8.1
# 21:25:23  Found 5 models, 2 seeds, 6 data tests, 2 sources, 408 macros
# 21:25:23
# 21:25:23  Concurrency: 1 threads (target='dev')
# 21:25:23
# 21:25:23  1 of 5 START sql table model main.stg_products ................................. [RUN]
# 21:25:23  1 of 5 OK created sql table model main.stg_products ............................ [OK in 0.22s]
# 21:25:23  2 of 5 START sql table model main.stg_reviews .................................. [RUN]
# 21:25:23  2 of 5 OK created sql table model main.stg_reviews ............................. [OK in 0.17s]
# 21:25:23  3 of 5 START sql table model main.product_reviews .............................. [RUN]
# 21:25:23  3 of 5 OK created sql table model main.product_reviews ......................... [OK in 0.17s]
# 21:25:23  4 of 5 START python external model main.product_reviews_sentiment .............. [RUN]
# 21:25:32  4 of 5 OK created python external model main.product_reviews_sentiment ......... [OK in 8.83s]
# 21:25:32  5 of 5 START sql external model main.product_reviews_sentiment_agg ............. [RUN]
# 21:25:32  5 of 5 OK created sql external model main.product_reviews_sentiment_agg ........ [OK in 0.16s]
# 21:25:32
# 21:25:32  Finished running 3 table models, 2 external models in 0 hours 0 minutes and 9.76 seconds (9.76s).
# 21:25:33
# 21:25:33  Completed successfully
# 21:25:33
# 21:25:33  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
# ┌──────────────┬──────────────────┬─────────────────┬──────────────────┐
# │ product_name │ positive_reviews │ neutral_reviews │ negative_reviews │
# │   varchar    │      int64       │      int64      │      int64       │
# ├──────────────┼──────────────────┼─────────────────┼──────────────────┤
# │ Splishy      │                3 │               0 │                1 │
# │ Blerp        │                3 │               1 │                1 │
# │ Zinga        │                2 │               0 │                0 │
# │ Jinkle       │                2 │               1 │                1 │
# │ Flish        │                2 │               2 │                1 │
# │ Kablooie     │                2 │               1 │                1 │
# │ Wizzle       │                2 │               1 │                0 │
# │ Snurfle      │                2 │               1 │                0 │
# │ Glint        │                2 │               0 │                0 │
# │ Flumplenook  │                2 │               1 │                1 │
# │ Whirlybird   │                2 │               0 │                1 │
# ├──────────────┴──────────────────┴─────────────────┴──────────────────┤
# │ 11 rows                                                    4 columns │
# └──────────────────────────────────────────────────────────────────────┘
# ```

# Here we can see that the LLM classified the results into three different categories
# that we could then aggregate in a subsequent sql model!

# ## Python dbt model

# The python dbt model in [`dbt_modal_inference_proj/models/product_reviews_sentiment.py`](https://github.com/modal-labs/modal-examples/blob/main/10_integrations/dbt_modal_inference/dbt_modal_inference_proj/models/product_reviews_sentiment.py) is quite simple.

# It defines a python dbt model that reads a record batch of product reviews,
# generates a prompt for each review and makes an inference call to a Modal Function
# that serves an LLM inference endpoint. It then stores the output in a new column
# and writes the data to a parquet file.

# And it's that simple to call a Modal web endpoint from dbt!

# ## View the stored output

# Since we're using a [Volume](https://modal.com/docs/guide/volumes) for storing our dbt target results
# and our DuckDB parquet files
# you can view the results and use them outside the Modal Function too.

# View the target directory by:
# ```sh
# modal volume ls dbt-inference-vol target/
#            Directory listing of 'target/' in 'dbt-inference-vol'
# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓
# ┃ Filename                      ┃ Type ┃ Created/Modified      ┃ Size      ┃
# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩
# │ target/run                    │ dir  │ 2024-07-19 22:59 CEST │ 14 B      │
# │ target/compiled               │ dir  │ 2024-07-19 22:59 CEST │ 14 B      │
# │ target/semantic_manifest.json │ file │ 2024-07-19 23:25 CEST │ 234 B     │
# │ target/run_results.json       │ file │ 2024-07-19 23:25 CEST │ 10.1 KiB  │
# │ target/manifest.json          │ file │ 2024-07-19 23:25 CEST │ 419.7 KiB │
# │ target/partial_parse.msgpack  │ file │ 2024-07-19 23:25 CEST │ 412.7 KiB │
# │ target/graph_summary.json     │ file │ 2024-07-19 23:25 CEST │ 1.4 KiB   │
# │ target/graph.gpickle          │ file │ 2024-07-19 23:25 CEST │ 15.7 KiB  │
# └───────────────────────────────┴──────┴───────────────────────┴───────────┘
# ```

# And the db directory:
# ```sh
# modal volume ls dbt-inference-vol db/
#                   Directory listing of 'db/' in 'dbt-inference-vol'
# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓
# ┃ Filename                                 ┃ Type ┃ Created/Modified      ┃ Size    ┃
# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩
# │ db/review_sentiments.parquet             │ file │ 2024-07-19 23:25 CEST │ 9.6 KiB │
# │ db/product_reviews_sentiment_agg.parquet │ file │ 2024-07-19 23:25 CEST │ 756 B   │
# └──────────────────────────────────────────┴──────┴───────────────────────┴─────────┘
# ```
#


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/profiles.yml ===
modal:
  outputs:
    dev:
      type: duckdb
  target: dev


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/dbt_project.yml ===
name: "sentiment_shop"
version: "1.0.0"
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: "modal"

# These configurations specify where dbt should look for different types of files.
# The `model-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target" # directory which will store compiled SQL files
clean-targets: # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models
models:
  +materialized: table

seeds:



=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/models/product_reviews_sentiment.py ===
import json

import pyarrow as pa
import requests


def get_prompt(review):
    """
    This function takes a review and returns a prompt for the review sentiment classification.

    Args:
        review: A product review.

    Returns:
        A prompt for the review sentiment classification.
    """
    return (
        """
You are an expert at analyzing product reviews sentiment.
Your task is to classify the given product review into one of the following labels: ["positive", "negative", "neutral"]
Here are some examples:
1. "example": "Packed with innovative features and reliable performance, this product exceeds expectations, making it a worthwhile investment."
   "label": "positive"
2. "example": "Despite promising features, the product's build quality and performance were disappointing, failing to meet expectations."
   "label": "negative"
3. "example": "While the product offers some useful functionalities, its overall usability and durability may vary depending on individual needs and preferences."
   "label": "neutral"
Label the following review:
"""
        + '"'
        + review
        + '"'
        + """
Respond in a single word with the label.
"""
    )


def batcher(batch_reader: pa.RecordBatchReader, inference_url: str):
    """
    This function takes a batch reader and an inference url and yields a record batch with the review sentiment.

    Args:
        batch_reader: A record batch reader.
        inference_url: The url of the inference service.

    Yields:
        A record batch with the review sentiment.
    """
    for batch in batch_reader:
        df = batch.to_pandas()

        prompts = df["product_review"].apply(lambda review: get_prompt(review)).tolist()

        res = requests.post(  # request to the inference service running on Modal
            inference_url,
            json={"prompts": prompts},
        )

        df["review_sentiment"] = json.loads(res.content)

        yield pa.RecordBatch.from_pandas(df)


def model(dbt, session):
    """
    This function defines the model for the product reviews sentiment.

    Args:
        dbt: The dbt object.
        session: The session object.

    Returns:
        A record batch reader with the review sentiment.
    """
    dbt.config(
        materialized="external",
        location="/root/vol/db/review_sentiments.parquet",
    )
    inference_url = dbt.config.get("inference_url")

    big_model = dbt.ref("product_reviews")
    batch_reader = big_model.record_batch(100)
    batch_iter = batcher(batch_reader, inference_url)
    new_schema = batch_reader.schema.append(pa.field("review_sentiment", pa.string()))
    return pa.RecordBatchReader.from_batches(new_schema, batch_iter)


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/models/models.yml ===
version: 2

models:
  - name: product_reviews_sentiment
    config:
      materialized: external
      location: "{{ env_var('DB_PATH') }}/product_reviews_sentiment.parquet"
      inference_url: "{{ var('inference_url') }}"
  - name: product_reviews_sentiment_agg
    config:
      materialized: external
      location: "{{ env_var('DB_PATH') }}/product_reviews_sentiment_agg.parquet"


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/models/sources.yml ===
version: 2

sources:
  - name: external_source
    meta:
      external_location: "{{ env_var('DBT_PROJECT_DIR') }}/seeds/{name}.csv"
    tables:
      - name: raw_reviews
      - name: raw_products


=== GITHUB: 10_integrations/dbt_modal_inference/dbt_modal_inference_proj/models/staging/schema.yml ===
version: 2

models:
  - name: stg_products
    columns:
      - name: id
        tests:
          - not_null
          - unique
      - name: name
        tests:
          - not_null
      - name: description
        tests:
          - not_null
  - name: stg_reviews
    columns:
      - name: product_id
        tests:
          - not_null
      - name: review
        tests:
          - not_null


=== GITHUB: 10_integrations/streamlit/app.py ===
# ---
# lambda-test: false  # auxiliary-file
# ---
# ## Demo Streamlit application.
#
# This application is the example from https://docs.streamlit.io/library/get-started/create-an-app.
#
# Streamlit is designed to run its apps as Python scripts, not functions, so we separate the Streamlit
# code into this module, away from the Modal application code.


def main():
    import numpy as np
    import pandas as pd
    import streamlit as st

    st.title("Uber pickups in NYC!")

    DATE_COLUMN = "date/time"
    DATA_URL = (
        "https://s3-us-west-2.amazonaws.com/"
        "streamlit-demo-data/uber-raw-data-sep14.csv.gz"
    )

    @st.cache_data
    def load_data(nrows):
        data = pd.read_csv(DATA_URL, nrows=nrows)

        def lowercase(x):
            return str(x).lower()

        data.rename(lowercase, axis="columns", inplace=True)
        data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
        return data

    data_load_state = st.text("Loading data...")
    data = load_data(10000)
    data_load_state.text("Done! (using st.cache_data)")

    if st.checkbox("Show raw data"):
        st.subheader("Raw data")
        st.write(data)

    st.subheader("Number of pickups by hour")
    hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0, 24))[0]
    st.bar_chart(hist_values)

    # Some number in the range 0-23
    hour_to_filter = st.slider("hour", 0, 23, 17)
    filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]

    st.subheader("Map of all pickups at %s:00" % hour_to_filter)
    st.map(filtered_data)


if __name__ == "__main__":
    main()


=== GITHUB: 10_integrations/streamlit/serve_streamlit.py ===
# ---
# deploy: true
# cmd: ["modal", "serve", "10_integrations/streamlit/serve_streamlit.py"]
# ---

# # Run and share Streamlit apps

# This example shows you how to run a Streamlit app with `modal serve`, and then deploy it as a serverless web app.

# ![example streamlit app](./streamlit.png)

# This example is structured as two files:

# 1. This module, which defines the Modal objects (name the script `serve_streamlit.py` locally).

# 2. `app.py`, which is any Streamlit script to be mounted into the Modal
# function ([download script](https://github.com/modal-labs/modal-examples/blob/main/10_integrations/streamlit/app.py)).

import shlex
import subprocess
from pathlib import Path

import modal

# ## Define container dependencies

# The `app.py` script imports three third-party packages, so we include these in the example's
# image definition and then add the `app.py` file itself to the image.

streamlit_script_local_path = Path(__file__).parent / "app.py"
streamlit_script_remote_path = "/root/app.py"

image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("streamlit~=1.35.0", "numpy~=1.26.4", "pandas~=2.2.2")
    .add_local_file(
        streamlit_script_local_path,
        streamlit_script_remote_path,
    )
)

app = modal.App(name="example-modal-streamlit", image=image)

if not streamlit_script_local_path.exists():
    raise RuntimeError(
        "app.py not found! Place the script with your streamlit app in the same directory."
    )

# ## Spawning the Streamlit server

# Inside the container, we will run the Streamlit server in a background subprocess using
# `subprocess.Popen`. We also expose port 8000 using the `@web_server` decorator.


@app.function()
@modal.concurrent(max_inputs=100)
@modal.web_server(8000)
def run():
    target = shlex.quote(streamlit_script_remote_path)
    cmd = f"streamlit run {target} --server.port 8000 --server.enableCORS=false --server.enableXsrfProtection=false"
    subprocess.Popen(cmd, shell=True)


# ## Iterate and Deploy

# While you're iterating on your screamlit app, you can run it "ephemerally" with `modal serve`. This will
# run a local process that watches your files and updates the app if anything changes.

# ```shell
# modal serve serve_streamlit.py
# ```

# Once you're happy with your changes, you can deploy your application with

# ```shell
# modal deploy serve_streamlit.py
# ```

# If successful, this will print a URL for your app that you can navigate to from
# your browser 🎉 .


=== GITHUB: 10_integrations/dbt/dbt_duckdb.py ===
# ---
# deploy: true
# ---

# # Build your own data warehouse with DuckDB, DBT, and Modal

# This example contains a minimal but capable [data warehouse](https://en.wikipedia.org/wiki/Data_warehouse).
# It's comprised of the following:

# - [DuckDB](https://duckdb.org) as the warehouse's [OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing) database engine

# - [AWS S3](https://aws.amazon.com/s3/) as the data storage provider

# - [DBT](https://docs.getdbt.com/docs/introduction) as the data transformation tool

# Meet your new serverless cloud data warehouse, powered by Modal!

# ## Configure Modal, S3, and DBT

# The only thing in the source code that you must update is the S3 bucket name.
# AWS S3 bucket names are globally unique, and the one in this source is used by us to host this example.

# Update the `BUCKET_NAME` variable below and also any references to the original value
# within `sample_proj_duckdb_s3/models/`. The AWS IAM policy below also includes the bucket
# name and that must be updated.

from pathlib import Path

import modal

BUCKET_NAME = "modal-example-dbt-duckdb-s3"
LOCAL_DBT_PROJECT = (  # local path
    Path(__file__).parent / "sample_proj_duckdb_s3"
)
PROJ_PATH = "/root/dbt"  # remote paths
PROFILES_PATH = "/root/dbt_profile"
TARGET_PATH = "/root/target"
# Most of the DBT code and configuration is taken directly from the classic
# [Jaffle Shop](https://github.com/dbt-labs/jaffle_shop) demo and modified to support
# using `dbt-duckdb` with an S3 bucket.

# The DBT `profiles.yml` configuration is taken from
# [the `dbt-duckdb` docs](https://github.com/jwills/dbt-duckdb#configuring-your-profile).

# We also define the environment our application will run in --
# a container image, as in Docker.
# See [this guide](https://modal.com/docs/guide/custom-container) for details.

dbt_image = (  # start from a slim Linux image
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(  # install python packages
        "boto3~=1.34",  # aws client sdk
        "dbt-duckdb~=1.8.1",  # dbt and duckdb and a connector
        "pandas~=2.2.2",  # dataframes
        "pyarrow~=16.1.0",  # columnar data lib
        "fastapi[standard]~=0.115.4",  # web app
    )
    .env(  # configure DBT environment variables
        {
            "DBT_PROJECT_DIR": PROJ_PATH,
            "DBT_PROFILES_DIR": PROFILES_PATH,
            "DBT_TARGET_PATH": TARGET_PATH,
        }
    )
    # Here we add all local code and configuration into the Modal Image
    # so that it will be available when we run DBT on Modal.
    .add_local_dir(LOCAL_DBT_PROJECT, remote_path=PROJ_PATH)
    .add_local_file(
        LOCAL_DBT_PROJECT / "profiles.yml",
        remote_path=f"{PROFILES_PATH}/profiles.yml",
    )
)

app = modal.App(name="example-dbt-duckdb-s3", image=dbt_image)

dbt_target = modal.Volume.from_name("dbt-target-vol", create_if_missing=True)

# We'll also need to authenticate with AWS to store data in S3.

s3_secret = modal.Secret.from_name(
    "modal-examples-aws-user",
    required_keys=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY", "AWS_REGION"],
)

# Create this Secret using the "AWS" template from the [Secrets dashboard](https://modal.com/secrets).
# Below we will use the provided credentials in a Modal Function to create an S3 bucket and
# populate it with `.parquet` data, so be sure to provide credentials for a user
# with permission to create S3 buckets and read & write data from them.

# The policy required for this example is the following.
# Not that you *must* update the bucket name listed in the policy to your
# own bucket name.

# ```json
# {
#     "Statement": [
#         {
#             "Action": "s3:*",
#             "Effect": "Allow",
#             "Resource": [
#                 "arn:aws:s3:::modal-example-dbt-duckdb-s3/*",
#                 "arn:aws:s3:::modal-example-dbt-duckdb-s3"
#             ],
#             "Sid": "duckdbs3access"
#         }
#     ],
#     "Version": "2012-10-17"
# }
# ```

# ## Upload seed data

# In order to provide source data for DBT to ingest and transform,
# we have the below `create_source_data` function which creates an AWS S3 bucket and
# populates it with Parquet files based off the CSV data in the `seeds/` directory.

# You can kick it off by running this script on Modal:

# ```bash
# modal run dbt_duckdb.py
# ```

# This script also runs the full data warehouse setup, and the whole process takes a minute or two.
# We'll walk through the rest of the steps below. See the `app.local_entrypoint`
# below for details.

# Note that this is not the typical way that `seeds/` data is used, but it's useful for this
# demonstration. See [the DBT docs](https://docs.getdbt.com/docs/build/seeds) for more info.


@app.function(
    secrets=[s3_secret],
)
def create_source_data():
    import boto3
    import pandas as pd
    from botocore.exceptions import ClientError

    s3_client = boto3.client("s3")
    s3_client.create_bucket(Bucket=BUCKET_NAME)

    for seed_csv_path in Path(PROJ_PATH, "seeds").glob("*.csv"):
        print(f"Found seed file {seed_csv_path}")
        name = seed_csv_path.stem
        parquet_filename = f"{name}.parquet"
        object_key = f"sources/{parquet_filename}"
        try:
            s3_client.head_object(Bucket=BUCKET_NAME, Key=object_key)
            print(
                f"File '{object_key}' already exists in bucket '{BUCKET_NAME}'. Skipping."
            )
        except ClientError:
            df = pd.read_csv(seed_csv_path)
            df.to_parquet(parquet_filename)
            print(f"Uploading '{object_key}' to S3 bucket '{BUCKET_NAME}'")
            s3_client.upload_file(parquet_filename, BUCKET_NAME, object_key)
            print(f"File '{object_key}' uploaded successfully.")


# ## Run DBT on the cloud with Modal

# Modal makes it easy to run Python code in the cloud.
# And DBT is a Python tool, so it's easy to run DBT with Modal:
# below, we import the `dbt` library's `dbtRunner` to pass commands from our
# Python code, running on Modal, the same way we'd pass commands on a command line.
#
# Note that this Modal Function has access to our AWS S3 Secret,
# the local files associated with our DBT project and profiles,
# and a remote Modal Volume that acts as a distributed file system.


@app.function(
    secrets=[s3_secret],
    volumes={TARGET_PATH: dbt_target},
)
def run(command: str) -> None:
    from dbt.cli.main import dbtRunner

    res = dbtRunner().invoke(command.split(" "))
    if res.exception:
        print(res.exception)


# You can run this Modal Function from the command line with

# `modal run dbt_duckdb.py::run --command run`

# A successful run will log something like the following:

# ```
# 03:41:04  Running with dbt=1.5.0
# 03:41:05  Found 5 models, 8 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 3 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
# 03:41:05
# 03:41:06  Concurrency: 1 threads (target='modal')
# 03:41:06
# 03:41:06  1 of 5 START sql table model main.stg_customers ................................ [RUN]
# 03:41:06  1 of 5 OK created sql table model main.stg_customers ........................... [OK in 0.45s]
# 03:41:06  2 of 5 START sql table model main.stg_orders ................................... [RUN]
# 03:41:06  2 of 5 OK created sql table model main.stg_orders .............................. [OK in 0.34s]
# 03:41:06  3 of 5 START sql table model main.stg_payments ................................. [RUN]
# 03:41:07  3 of 5 OK created sql table model main.stg_payments ............................ [OK in 0.36s]
# 03:41:07  4 of 5 START sql external model main.customers ................................. [RUN]
# 03:41:07  4 of 5 OK created sql external model main.customers ............................ [OK in 0.72s]
# 03:41:07  5 of 5 START sql table model main.orders ....................................... [RUN]
# 03:41:08  5 of 5 OK created sql table model main.orders .................................. [OK in 0.22s]
# 03:41:08
# 03:41:08  Finished running 4 table models, 1 external model in 0 hours 0 minutes and 3.15 seconds (3.15s).
# 03:41:08  Completed successfully
# 03:41:08
# 03:41:08  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
# ```

# Look for the `'materialized='external'` DBT config in the SQL templates
# to see how `dbt-duckdb` is able to write back the transformed data to AWS S3!

# After running the `run` command and seeing it succeed, check what's contained
# under the bucket's `out/` key prefix. You'll see that DBT has run the transformations
# defined in `sample_proj_duckdb_s3/models/` and produced output `.parquet` files.

# ## Serve fresh data documentation with FastAPI and Modal

# DBT also automatically generates [rich, interactive data docs](https://docs.getdbt.com/docs/collaborate/explore-projects).
# You can serve these docs on Modal.
# Just define a simple [FastAPI](https://fastapi.tiangolo.com/) app:


@app.function(volumes={TARGET_PATH: dbt_target})
@modal.concurrent(max_inputs=100)
@modal.asgi_app()  # wrap a function that returns a FastAPI app in this decorator to host on Modal
def serve_dbt_docs():
    import fastapi
    from fastapi.staticfiles import StaticFiles

    web_app = fastapi.FastAPI()
    web_app.mount(
        "/",
        StaticFiles(  # dbt docs are automatically generated and sitting in the Volume
            directory=TARGET_PATH, html=True
        ),
        name="static",
    )

    return web_app


# And deploy that app to Modal with

# ```bash
# modal deploy dbt_duckdb.py
# # ...
# # Created web function serve_dbt_docs => <output-url>
# ```

# If you navigate to the output URL, you should see something like
# [![example dbt docs](./dbt_docs.png)](https://modal-labs-examples--example-dbt-duckdb-s3-serve-dbt-docs.modal.run)

# You can also check out our instance of the docs [here](https://modal-labs-examples--example-dbt-duckdb-s3-serve-dbt-docs.modal.run).
# The app will be served "serverlessly" -- it will automatically scale up or down
# during periods of increased or decreased usage, and you won't be charged at all
# when it has scaled to zero.


# ## Schedule daily updates

# The following `daily_build` function [runs on a schedule](https://modal.com/docs/guide/cron)
# to keep the DuckDB data warehouse up-to-date. It is also deployed by the same `modal deploy` command for the docs app.

# The source data for this warehouse is static,
# so the daily executions don't really "update" anything, just re-build. But this example could be extended
# to have sources which continually provide new data across time.
# It will also generate the DBT docs daily to keep them fresh.


@app.function(
    schedule=modal.Period(days=1),
    secrets=[s3_secret],
    volumes={TARGET_PATH: dbt_target},
)
def daily_build() -> None:
    run.remote("build")
    run.remote("docs generate")


@app.local_entrypoint()
def main():
    create_source_data.remote()
    run.remote("run")
    daily_build.remote()


=== GITHUB: 10_integrations/dbt/sample_proj_duckdb_s3/profiles.yml ===
{
  "sample_proj":
    {
      "target": "modal",
      "outputs":
        {
          "modal":
            {
              "type": "duckdb",
              "path": "/tmp/dbt.duckdb",
              "extensions": ["httpfs", "parquet"],
              "settings":
                {
                  "s3_region": "us-east-1",
                  "s3_access_key_id": "{{ env_var('AWS_ACCESS_KEY_ID') }}",
                  "s3_secret_access_key": "{{ env_var('AWS_SECRET_ACCESS_KEY') }}",
                },
            },
        },
    },
}


=== GITHUB: 10_integrations/dbt/sample_proj_duckdb_s3/dbt_project.yml ===
name: "jaffle_shop"
version: "1.0.0"
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: "sample_proj"

# These configurations specify where dbt should look for different types of files.
# The `model-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target" # directory which will store compiled SQL files
clean-targets: # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models
models:
  +materialized: table


=== GITHUB: 10_integrations/dbt/sample_proj_duckdb_s3/models/sources.yml ===
version: 2

sources:
  - name: external_source
    meta:
      external_location: "s3://modal-example-dbt-duckdb-s3/sources/{name}.parquet"
    tables:
      - name: raw_customers
      - name: raw_orders
      - name: raw_payments


=== GITHUB: 10_integrations/dbt/sample_proj_duckdb_s3/models/staging/schema.yml ===
version: 2

models:
  - name: stg_customers
    columns:
      - name: customer_id
        tests:
          - unique
          - not_null

  - name: stg_orders
    columns:
      - name: order_id
        tests:
          - unique
          - not_null
      - name: status
        tests:
          - accepted_values:
              values:
                ["placed", "shipped", "completed", "return_pending", "returned"]

  - name: stg_payments
    columns:
      - name: payment_id
        tests:
          - unique
          - not_null
      - name: payment_method
        tests:
          - accepted_values:
              values: ["credit_card", "coupon", "bank_transfer", "gift_card"]


=== GITHUB: 10_integrations/tailscale/modal_tailscale.py ===
# ---
# lambda-test: false  # missing-secret
# ---

# # Add Modal Apps to Tailscale

# This example demonstrates how to integrate Modal with Tailscale (https://tailscale.com).
# It outlines the steps to configure Modal containers so that they join the Tailscale network.

# We use a custom entrypoint to automatically add containers to a Tailscale network (tailnet).
# This configuration enables the containers to interact with one another and with
# additional applications within the same tailnet.


import modal

# Install Tailscale and copy custom entrypoint script ([entrypoint.sh](https://github.com/modal-labs/modal-examples/blob/main/10_integrations/tailscale/entrypoint.sh)). The script must be
# executable.
image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("curl")
    .run_commands("curl -fsSL https://tailscale.com/install.sh | sh")
    .pip_install("requests==2.32.3", "PySocks==1.7.1")
    .add_local_file("./entrypoint.sh", "/root/entrypoint.sh", copy=True)
    .dockerfile_commands(
        "RUN chmod a+x /root/entrypoint.sh",
        'ENTRYPOINT ["/root/entrypoint.sh"]',
    )
)
app = modal.App(image=image)

# Configure Python to use the SOCKS5 proxy globally.
with image.imports():
    import socket

    import socks

    socks.set_default_proxy(socks.SOCKS5, "0.0.0.0", 1080)
    socket.socket = socks.socksocket


# Run your function adding a Tailscale secret. We suggest creating a [reusable and ephemeral key](https://tailscale.com/kb/1111/ephemeral-nodes).
@app.function(
    secrets=[
        modal.Secret.from_name("tailscale-auth", required_keys=["TAILSCALE_AUTHKEY"]),
        modal.Secret.from_dict(
            {
                "ALL_PROXY": "socks5://localhost:1080/",
                "HTTP_PROXY": "http://localhost:1080/",
                "http_proxy": "http://localhost:1080/",
            }
        ),
    ],
)
def connect_to_machine():
    import requests

    # Connect to other machines in your tailnet.
    resp = requests.get("http://my-tailscale-machine:5000")
    print(resp.content)


# Run this script with `modal run modal_tailscale.py`. You will see Tailscale logs
# when the container start indicating that you were able to login successfully and
# that the proxies (SOCKS5 and HTTP) have created been successfully. You will also
# be able to see Modal containers in your Tailscale dashboard in the "Machines" tab.
# Every new container launched will show up as a new "machine". Containers are
# individually addressable using their Tailscale name or IP address.



=== CATEGORY: NOTEBOOKS ===

=== GITHUB: 11_notebooks/jupyter_inside_modal.py ===
# ---
# args: ["--timeout", 10]
# ---

# ## Overview
#
# Quick snippet showing how to connect to a Jupyter notebook server running inside a Modal container,
# especially useful for exploring the contents of Modal Volumes.
# This uses [Modal Tunnels](https://modal.com/docs/guide/tunnels#tunnels-beta)
# to create a tunnel between the running Jupyter instance and the internet.
#
# If you want to your Jupyter notebook to run _locally_ and execute remote Modal Functions in certain cells, see the `basic.ipynb` example :)

import os
import subprocess
import time

import modal

app = modal.App(
    image=modal.Image.debian_slim(python_version="3.12").pip_install(
        "jupyter", "bing-image-downloader~=1.1.2"
    )
)
volume = modal.Volume.from_name(
    "modal-examples-jupyter-inside-modal-data", create_if_missing=True
)

CACHE_DIR = "/root/cache"
JUPYTER_TOKEN = "1234"  # Change me to something non-guessable!


@app.function(volumes={CACHE_DIR: volume})
def seed_volume():
    # Bing it!
    from bing_image_downloader import downloader

    # This will save into the Modal volume and allow you view the images
    # from within Jupyter at a path like `/root/cache/modal labs/Image_1.png`.
    downloader.download(
        query="modal labs",
        limit=10,
        output_dir=CACHE_DIR,
        force_replace=False,
        timeout=60,
        verbose=True,
    )
    volume.commit()


# This is all that's needed to create a long-lived Jupyter server process in Modal
# that you can access in your Browser through a secure network tunnel.
# This can be useful when you want to interactively engage with Volume contents
# without having to download it to your host computer.


@app.function(max_containers=1, volumes={CACHE_DIR: volume}, timeout=1_500)
def run_jupyter(timeout: int):
    jupyter_port = 8888
    with modal.forward(jupyter_port) as tunnel:
        jupyter_process = subprocess.Popen(
            [
                "jupyter",
                "notebook",
                "--no-browser",
                "--allow-root",
                "--ip=0.0.0.0",
                f"--port={jupyter_port}",
                "--NotebookApp.allow_origin='*'",
                "--NotebookApp.allow_remote_access=1",
            ],
            env={**os.environ, "JUPYTER_TOKEN": JUPYTER_TOKEN},
        )

        print(f"Jupyter available at => {tunnel.url}")

        try:
            end_time = time.time() + timeout
            while time.time() < end_time:
                time.sleep(5)
            print(f"Reached end of {timeout} second timeout period. Exiting...")
        except KeyboardInterrupt:
            print("Exiting...")
        finally:
            jupyter_process.kill()


@app.local_entrypoint()
def main(timeout: int = 10_000):
    # Write some images to a volume, for demonstration purposes.
    seed_volume.remote()
    # Run the Jupyter Notebook server
    run_jupyter.remote(timeout=timeout)


# Doing `modal run jupyter_inside_modal.py` will run a Modal app which starts
# the Juypter server at an address like https://u35iiiyqp5klbs.r3.modal.host.
# Visit this address in your browser, and enter the security token
# you set for `JUPYTER_TOKEN`.



=== CATEGORY: DATASETS ===

=== GITHUB: 12_datasets/coco.py ===
# ---
# lambda-test: false  # long-running
# ---
#
# This script demonstrates ingestion of the [COCO](https://cocodataset.org/#download) (Common Objects in Context)
# dataset.
#
# It is recommended to iterate on this code from a modal.Function running Jupyter server.
# This better supports experimentation and maintains state in the face of errors:
# 11_notebooks/jupyter_inside_modal.py
import os
import pathlib
import shutil
import subprocess
import sys
import threading
import time
import zipfile

import modal

bucket_creds = modal.Secret.from_name(
    "aws-s3-modal-examples-datasets", environment_name="main"
)
bucket_name = "modal-examples-datasets"
volume = modal.CloudBucketMount(
    bucket_name,
    secret=bucket_creds,
)
image = modal.Image.debian_slim().apt_install("wget").pip_install("tqdm")
app = modal.App(
    "example-coco-dataset-import",
    image=image,
    secrets=[],
)


def start_monitoring_disk_space(interval: int = 120) -> None:
    """Start monitoring the disk space in a separate thread."""
    task_id = os.environ["MODAL_TASK_ID"]

    def log_disk_space(interval: int) -> None:
        while True:
            statvfs = os.statvfs("/")
            free_space = statvfs.f_frsize * statvfs.f_bavail
            print(
                f"{task_id} free disk space: {free_space / (1024**3):.2f} GB",
                file=sys.stderr,
            )
            time.sleep(interval)

    monitoring_thread = threading.Thread(target=log_disk_space, args=(interval,))
    monitoring_thread.daemon = True
    monitoring_thread.start()


def extractall(fzip, dest, desc="Extracting"):
    from tqdm.auto import tqdm
    from tqdm.utils import CallbackIOWrapper

    dest = pathlib.Path(dest).expanduser()
    with (
        zipfile.ZipFile(fzip) as zipf,
        tqdm(
            desc=desc,
            unit="B",
            unit_scale=True,
            unit_divisor=1024,
            total=sum(getattr(i, "file_size", 0) for i in zipf.infolist()),
        ) as pbar,
    ):
        for i in zipf.infolist():
            if not getattr(i, "file_size", 0):  # directory
                zipf.extract(i, os.fspath(dest))
            else:
                full_path = dest / i.filename
                full_path.parent.mkdir(exist_ok=True, parents=True)
                with zipf.open(i) as fi, open(full_path, "wb") as fo:
                    shutil.copyfileobj(CallbackIOWrapper(pbar.update, fi), fo)


def copy_concurrent(src: pathlib.Path, dest: pathlib.Path) -> None:
    from multiprocessing.pool import ThreadPool

    class MultithreadedCopier:
        def __init__(self, max_threads):
            self.pool = ThreadPool(max_threads)

        def copy(self, source, dest):
            self.pool.apply_async(shutil.copy2, args=(source, dest))

        def __enter__(self):
            return self

        def __exit__(self, exc_type, exc_val, exc_tb):
            self.pool.close()
            self.pool.join()

    with MultithreadedCopier(max_threads=48) as copier:
        shutil.copytree(src, dest, copy_function=copier.copy, dirs_exist_ok=True)


# This script uses wget to download ZIP files over HTTP because while the official
# website recommends using gsutil to download from a bucket (https://cocodataset.org/#download)
# that bucket no longer exists.


@app.function(
    volumes={"/vol/": volume},
    timeout=60 * 60 * 5,  # 5 hours
    ephemeral_disk=600 * 1024,  # 600 GiB,
)
def _do_part(url: str) -> None:
    start_monitoring_disk_space()
    part = url.replace("http://images.cocodataset.org/", "")
    name = pathlib.Path(part).name.replace(".zip", "")
    zip_path = pathlib.Path("/tmp/") / pathlib.Path(part).name
    extract_tmp_path = pathlib.Path("/tmp", name)
    dest_path = pathlib.Path("/vol/coco/", name)

    print(f"Downloading {name} from {url}")
    command = f"wget {url} -O {zip_path}"
    subprocess.run(command, shell=True, check=True)
    print(f"Download of {name} completed successfully.")
    extract_tmp_path.mkdir()
    extractall(
        zip_path, extract_tmp_path, desc=f"Extracting {name}"
    )  # extract into /tmp/
    zip_path.unlink()  # free up disk space by deleting the zip
    print(f"Copying extract {name} data to volume.")
    copy_concurrent(extract_tmp_path, dest_path)  # copy from /tmp/ into mounted volume


# We can process each part of the dataset in parallel, using a 'parent' Function just to execute
# the map and wait on completion of all children.


@app.function(
    timeout=60 * 60 * 5,  # 5 hours
)
def import_transform_load() -> None:
    print("Starting import, transform, and load of COCO dataset")
    list(
        _do_part.map(
            [
                "http://images.cocodataset.org/zips/train2017.zip",
                "http://images.cocodataset.org/zips/val2017.zip",
                "http://images.cocodataset.org/zips/test2017.zip",
                "http://images.cocodataset.org/zips/unlabeled2017.zip",
                "http://images.cocodataset.org/annotations/annotations_trainval2017.zip",
                "http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip",
                "http://images.cocodataset.org/annotations/image_info_test2017.zip",
                "http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip",
            ]
        )
    )
    print("✅ Done")


=== GITHUB: 12_datasets/laion400.py ===
# ---
# lambda-test: false  # long-running
# ---
#
# https://laion.ai/blog/laion-400-open-dataset/
#
# LAION-400 is a large dataset of 400M English (image, text) pairs.
#
# As described on the dataset's homepage, it consists of 32 .parquet files
# containing dataset metadata *but not* the image data itself.
#
# After downloading the .parquet files, this script fans out 32 worker jobs
# to process a single .parquet file. Processing involves fetch and transform
# of image data into 256 * 256 square JPEGs.
#
# This script is loosely based off the following instructions:
# https://github.com/rom1504/img2dataset/blob/main/dataset_examples/laion400m.md
#
# It is recommended to iterate on this code from a modal.Function running Jupyter server.
# This better supports experimentation and maintains state in the face of errors:
# 11_notebooks/jupyter_inside_modal.py
import os
import pathlib
import shutil
import subprocess
import sys
import threading
import time

import modal

bucket_creds = modal.Secret.from_name(
    "aws-s3-modal-examples-datasets", environment_name="main"
)

bucket_name = "modal-examples-datasets"

volume = modal.CloudBucketMount(
    bucket_name,
    secret=bucket_creds,
)

image = modal.Image.debian_slim().apt_install("wget").pip_install("img2dataset~=1.45.0")

app = modal.App("example-laion400-dataset-import", image=image)


def start_monitoring_disk_space(interval: int = 30) -> None:
    """Start monitoring the disk space in a separate thread, printing info to stdout"""
    task_id = os.environ["MODAL_TASK_ID"]

    def log_disk_space(interval: int) -> None:
        while True:
            statvfs = os.statvfs("/")
            free_space = statvfs.f_frsize * statvfs.f_bavail
            print(
                f"{task_id} free disk space: {free_space / (1024**3):.2f} GB",
                file=sys.stderr,
            )
            time.sleep(interval)

    monitoring_thread = threading.Thread(target=log_disk_space, args=(interval,))
    monitoring_thread.daemon = True
    monitoring_thread.start()


def copy_concurrent(src: pathlib.Path, dest: pathlib.Path) -> None:
    """
    A modified shutil.copytree which copies in parallel to increase bandwidth
    and compensate for the increased IO latency of volume mounts.
    """
    from multiprocessing.pool import ThreadPool

    class MultithreadedCopier:
        def __init__(self, max_threads):
            self.pool = ThreadPool(max_threads)
            self.copy_jobs = []

        def copy(self, source, dest):
            res = self.pool.apply_async(
                shutil.copy2,
                args=(source, dest),
                callback=lambda r: print(f"{source} copied to {dest}"),
                # NOTE: this should `raise` an exception for proper reliability.
                error_callback=lambda exc: print(
                    f"{source} failed: {exc}", file=sys.stderr
                ),
            )
            self.copy_jobs.append(res)

        def __enter__(self):
            return self

        def __exit__(self, exc_type, exc_val, exc_tb):
            self.pool.close()
            self.pool.join()

    with MultithreadedCopier(max_threads=24) as copier:
        shutil.copytree(src, dest, copy_function=copier.copy, dirs_exist_ok=True)


@app.function(
    volumes={"/mnt": volume},
    # 20 hours — img2dataset is extremely slow to work through all images.
    timeout=60 * 60 * 20,
    ephemeral_disk=512 * 1024,
)
def run_img2dataset_on_part(
    i: int,
    partfile: str,
) -> None:
    start_monitoring_disk_space(interval=60)
    while not pathlib.Path(partfile).exists():
        print(f"{partfile} not yet visible...", file=sys.stderr)
        time.sleep(1)
    # Each part works in its own subdirectory because img2dataset creates a working
    # tmpdir at <output_folder>/_tmp and we don't want consistency issues caused by
    # all concurrently processing parts read/writing from the same temp directory.
    tmp_laion400m_data_path = pathlib.Path(f"/tmp/laion400/laion400m-data/{i}/")
    tmp_laion400m_data_path.mkdir(exist_ok=True, parents=True)
    # Increasing retries comes at a *large* performance cost.
    retries = 0
    # TODO: Support --incremental mode. https://github.com/rom1504/img2dataset?tab=readme-ov-file#incremental-mode
    command = (
        f'img2dataset --url_list {partfile} --input_format "parquet" '
        '--url_col "URL" --caption_col "TEXT" --output_format webdataset '
        f"--output_folder {tmp_laion400m_data_path} --processes_count 16 --thread_count 128 --image_size 256 "
        f'--retries={retries} --save_additional_columns \'["NSFW","similarity","LICENSE"]\' --enable_wandb False'
    )
    print(f"Running img2dataset command: \n\n{command}")
    subprocess.run(command, shell=True, check=True)
    print("Completed img2dataset, copying into mounted volume...")
    laion400m_data_path = pathlib.Path("/mnt/laion400/laion400m-data/")
    copy_concurrent(tmp_laion400m_data_path, laion400m_data_path)


@app.function(
    volumes={"/mnt": volume},
    timeout=60 * 60 * 16,  # 16 hours
)
def import_transform_load() -> None:
    start_monitoring_disk_space()
    # We initially download into a tmp directory outside of the volume to avoid
    # any filesystem incompatibilities between the `wget` application and the bucket
    # filesystem mount.
    tmp_laion400m_meta_path = pathlib.Path("/tmp/laion400/laion400m-meta")
    laion400m_meta_path = pathlib.Path("/mnt/laion400/laion400m-meta")
    if not laion400m_meta_path.exists():
        laion400m_meta_path.mkdir(parents=True, exist_ok=True)
        # WARNING: We skip the certificate check for the-eye.eu because its TLS certificate expired as of mid-May 2024.
        subprocess.run(
            f"wget -l1 -r --no-check-certificate --no-parent https://the-eye.eu/public/AI/cah/laion400m-met-release/laion400m-meta/ -P {tmp_laion400m_meta_path}",
            shell=True,
            check=True,
        )

        parquet_files = list(tmp_laion400m_meta_path.glob("**/*.parquet"))
        print(
            f"Downloaded {len(parquet_files)} parquet files into {tmp_laion400m_meta_path}."
        )
        # Perform a simple copy operation to move the data into the bucket.
        copy_concurrent(tmp_laion400m_meta_path, laion400m_meta_path)

    parquet_files = list(laion400m_meta_path.glob("**/*.parquet"))
    print(f"Stored {len(parquet_files)} parquet files into {laion400m_meta_path}.")
    print(f"Spawning {len(parquet_files)} to enrich dataset...")
    list(run_img2dataset_on_part.starmap((i, f) for i, f in enumerate(parquet_files)))


=== GITHUB: 12_datasets/imagenet.py ===
# ---
# lambda-test: false  # long-running
# ---
#
# This scripts demonstrates how to ingest the famous ImageNet (https://www.image-net.org/)
# dataset into a mounted volume.
#
# It requires a Kaggle account's API token stored as a modal.Secret in order to download part
# of the dataset from Kaggle's servers using the `kaggle` CLI.
#
# It is recommended to iterate on this code from a modal.Function running Jupyter server.
# This better supports experimentation and maintains state in the face of errors:
# 11_notebooks/jupyter_inside_modal.py
import os
import pathlib
import shutil
import subprocess
import sys
import threading
import time
import zipfile

import modal

bucket_creds = modal.Secret.from_name(
    "aws-s3-modal-examples-datasets", environment_name="main"
)
bucket_name = "modal-examples-datasets"
volume = modal.CloudBucketMount(
    bucket_name,
    secret=bucket_creds,
)
image = modal.Image.debian_slim().apt_install("tree").pip_install("kaggle", "tqdm")
app = modal.App(
    "example-imagenet-dataset-import",
    image=image,
    secrets=[modal.Secret.from_name("kaggle-api-token")],
)


def start_monitoring_disk_space(interval: int = 30) -> None:
    """Start monitoring the disk space in a separate thread."""
    task_id = os.environ["MODAL_TASK_ID"]

    def log_disk_space(interval: int) -> None:
        while True:
            statvfs = os.statvfs("/")
            free_space = statvfs.f_frsize * statvfs.f_bavail
            print(
                f"{task_id} free disk space: {free_space / (1024**3):.2f} GB",
                file=sys.stderr,
            )
            time.sleep(interval)

    monitoring_thread = threading.Thread(target=log_disk_space, args=(interval,))
    monitoring_thread.daemon = True
    monitoring_thread.start()


def copy_concurrent(src: pathlib.Path, dest: pathlib.Path) -> None:
    """
    A modified shutil.copytree which copies in parallel to increase bandwidth
    and compensate for the increased IO latency of volume mounts.
    """
    from multiprocessing.pool import ThreadPool

    class MultithreadedCopier:
        def __init__(self, max_threads):
            self.pool = ThreadPool(max_threads)
            self.copy_jobs = []

        def copy(self, source, dest):
            res = self.pool.apply_async(
                shutil.copy2,
                args=(source, dest),
                callback=lambda r: print(f"{source} copied to {dest}"),
                # NOTE: this should `raise` an exception for proper reliability.
                error_callback=lambda exc: print(
                    f"{source} failed: {exc}", file=sys.stderr
                ),
            )
            self.copy_jobs.append(res)

        def __enter__(self):
            return self

        def __exit__(self, exc_type, exc_val, exc_tb):
            self.pool.close()
            self.pool.join()

    with MultithreadedCopier(max_threads=24) as copier:
        shutil.copytree(src, dest, copy_function=copier.copy, dirs_exist_ok=True)


def extractall(fzip, dest, desc="Extracting"):
    from tqdm.auto import tqdm
    from tqdm.utils import CallbackIOWrapper

    dest = pathlib.Path(dest).expanduser()
    with (
        zipfile.ZipFile(fzip) as zipf,
        tqdm(
            desc=desc,
            unit="B",
            unit_scale=True,
            unit_divisor=1024,
            total=sum(getattr(i, "file_size", 0) for i in zipf.infolist()),
        ) as pbar,
    ):
        for i in zipf.infolist():
            if not getattr(i, "file_size", 0):  # directory
                zipf.extract(i, os.fspath(dest))
            else:
                full_path = dest / i.filename
                full_path.parent.mkdir(exist_ok=True, parents=True)
                with zipf.open(i) as fi, open(full_path, "wb") as fo:
                    shutil.copyfileobj(CallbackIOWrapper(pbar.update, fi), fo)


@app.function(
    volumes={"/mnt/": volume},
    timeout=60 * 60 * 8,  # 8 hours,
    ephemeral_disk=1000 * 1024,  # 1TB
)
def import_transform_load() -> None:
    start_monitoring_disk_space()
    kaggle_api_token_data = os.environ["KAGGLE_API_TOKEN"]
    kaggle_token_filepath = pathlib.Path.home() / ".kaggle" / "kaggle.json"
    kaggle_token_filepath.parent.mkdir(exist_ok=True)
    kaggle_token_filepath.write_text(kaggle_api_token_data)

    tmp_path = pathlib.Path("/tmp/imagenet/")
    vol_path = pathlib.Path("/mnt/imagenet/")
    filename = "imagenet-object-localization-challenge.zip"
    dataset_path = vol_path / filename
    if dataset_path.exists():
        dataset_size = dataset_path.stat().st_size
        if dataset_size < (150 * 1024 * 1024 * 1024):
            dataset_size_gib = dataset_size / (1024 * 1024 * 1024)
            raise RuntimeError(
                f"Partial download of dataset .zip. It is {dataset_size_gib}GiB but should be > 150GiB"
            )
    else:
        subprocess.run(
            f"kaggle competitions download -c imagenet-object-localization-challenge --path {tmp_path}",
            shell=True,
            check=True,
        )
        vol_path.mkdir(exist_ok=True)
        shutil.copy(tmp_path / filename, dataset_path)

    # Extract dataset
    extracted_dataset_path = tmp_path / "extracted"
    extracted_dataset_path.mkdir(parents=True, exist_ok=True)
    print(f"Extracting .zip into {extracted_dataset_path}...")
    extractall(dataset_path, extracted_dataset_path)
    print(f"Extracted {dataset_path} to {extracted_dataset_path}")
    subprocess.run(f"tree -L 3 {extracted_dataset_path}", shell=True, check=True)

    final_dataset_path = vol_path / "extracted"
    final_dataset_path.mkdir(exist_ok=True)
    copy_concurrent(extracted_dataset_path, final_dataset_path)
    subprocess.run(f"tree -L 3 {final_dataset_path}", shell=True, check=True)
    print("Dataset is loaded ✅")


=== GITHUB: 12_datasets/rosettafold.py ===
# ---
# lambda-test: false  # long-running
# ---
#
# This script demonstrated how to ingest the https://github.com/RosettaCommons/RoseTTAFold protein-folding
# model's dataset into a mounted volume.

# The dataset is over 2 TiB when decompressed to the runtime of this script is quite long.
# ref: https://github.com/RosettaCommons/RoseTTAFold/issues/132.
#
# It is recommended to iterate on this code from a modal.Function running Jupyter server.
# This better supports experimentation and maintains state in the face of errors:
# 11_notebooks/jupyter_inside_modal.py
import os
import pathlib
import shutil
import subprocess
import sys
import tarfile
import threading
import time

import modal

bucket_creds = modal.Secret.from_name(
    "aws-s3-modal-examples-datasets", environment_name="main"
)
bucket_name = "modal-examples-datasets"
volume = modal.CloudBucketMount(
    bucket_name,
    secret=bucket_creds,
)
image = modal.Image.debian_slim().apt_install("wget")
app = modal.App("example-rosettafold-dataset-import", image=image)


def start_monitoring_disk_space(interval: int = 30) -> None:
    """Start monitoring the disk space in a separate thread."""
    task_id = os.environ["MODAL_TASK_ID"]

    def log_disk_space(interval: int) -> None:
        while True:
            statvfs = os.statvfs("/")
            free_space = statvfs.f_frsize * statvfs.f_bavail
            print(
                f"{task_id} free disk space: {free_space / (1024**3):.2f} GB",
                file=sys.stderr,
            )
            time.sleep(interval)

    monitoring_thread = threading.Thread(target=log_disk_space, args=(interval,))
    monitoring_thread.daemon = True
    monitoring_thread.start()


def decompress_tar_gz(file_path: pathlib.Path, extract_dir: pathlib.Path) -> None:
    print(f"Decompressing {file_path} into {extract_dir}...")
    with tarfile.open(file_path, "r:gz") as tar:
        tar.extractall(path=extract_dir)
        print(f"Decompressed {file_path} to {extract_dir}")


def copy_concurrent(src: pathlib.Path, dest: pathlib.Path) -> None:
    """
    A modified shutil.copytree which copies in parallel to increase bandwidth
    and compensate for the increased IO latency of volume mounts.
    """
    from multiprocessing.pool import ThreadPool

    class MultithreadedCopier:
        def __init__(self, max_threads):
            self.pool = ThreadPool(max_threads)
            self.copy_jobs = []

        def copy(self, source, dest):
            res = self.pool.apply_async(
                shutil.copy2,
                args=(source, dest),
                callback=lambda r: print(f"{source} copied to {dest}"),
                # NOTE: this should `raise` an exception for proper reliability.
                error_callback=lambda exc: print(
                    f"{source} failed: {exc}", file=sys.stderr
                ),
            )
            self.copy_jobs.append(res)

        def __enter__(self):
            return self

        def __exit__(self, exc_type, exc_val, exc_tb):
            self.pool.close()
            self.pool.join()

    with MultithreadedCopier(max_threads=24) as copier:
        shutil.copytree(src, dest, copy_function=copier.copy, dirs_exist_ok=True)


@app.function(
    volumes={"/mnt/": volume},
    timeout=60 * 60 * 24,
    ephemeral_disk=2560 * 1024,
)
def _do_part(url: str) -> None:
    name = url.split("/")[-1].replace(".tar.gz", "")
    print(f"Downloading {name}")
    compressed = pathlib.Path("/tmp", name)
    cmd = f"wget {url} -O {compressed}"
    p = subprocess.Popen(cmd, shell=True)
    returncode = p.wait()
    if returncode != 0:
        raise RuntimeError(f"Error in downloading. {p.args!r} failed {returncode=}")
    decompressed = pathlib.Path("/tmp/rosettafold/", name)

    # Decompression is much faster against the container's local SSD disk
    # compared with against the mounted volume. So we first compress into /tmp/.
    print(f"Decompressing {compressed} into {decompressed}.")
    decompress_tar_gz(compressed, decompressed)
    print(
        f"✅ Decompressed {compressed} into {decompressed}. Now deleting it to free up disk.."
    )
    compressed.unlink()  # delete compressed file to free up disk

    # Finally, we move the decompressed data from /tmp/ into the mounted volume.
    # There are a large mount of files to copy so this step takes a while.
    dest = pathlib.Path("/mnt/rosettafold/")
    copy_concurrent(decompressed, dest)
    shutil.rmtree(decompressed, ignore_errors=True)  # free up disk
    print(f"Dataset part {url} is loaded ✅")


@app.function(
    volumes={"/mnt/": volume},
    # Timeout for this Function is set at the maximum, 24 hours,
    # because downloading, decompressing and storing almost 2 TiB of
    # files takes a long time.
    timeout=60 * 60 * 24,
)
def import_transform_load() -> None:
    # NOTE:
    # The mmseq.com server upload speed is quite slow so this download takes a while.
    # The download speed is also quite variable, sometimes taking over 5 hours.
    list(
        _do_part.map(
            [
                "http://wwwuser.gwdg.de/~compbiol/uniclust/2020_06/UniRef30_2020_06_hhsuite.tar.gz",
                "https://bfd.mmseqs.com/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt.tar.gz",
                "https://files.ipd.uw.edu/pub/RoseTTAFold/pdb100_2021Mar03.tar.gz",
            ]
        )
    )
    print("Dataset is loaded ✅")



=== CATEGORY: SANDBOXES ===

=== GITHUB: 13_sandboxes/simple_code_interpreter.py ===
# ---
# cmd: ["python", "13_sandboxes/simple_code_interpreter.py"]
# pytest: false
# ---

# # Build a stateful, sandboxed code interpreter

# This example demonstrates how to build a stateful code interpreter using a Modal
# [Sandbox](https://modal.com/docs/guide/sandbox).

# We'll create a Modal Sandbox that listens for code to execute and then
# executes the code in a Python interpreter. Because we're running in a sandboxed
# environment, we can safely use the "unsafe" `exec()` to execute the code.

# ## Setting up a code interpreter in a Modal Sandbox

# Our code interpreter uses a Python "driver program" to listen for code
# sent in JSON format to its standard input (`stdin`), execute the code,
# and then return the results in JSON format on standard output (`stdout`).

import inspect
import json
from typing import Any

import modal
import modal.container_process


def driver_program():
    import json
    import sys
    from contextlib import redirect_stderr, redirect_stdout
    from io import StringIO

    # When you `exec` code in Python, you can pass in a dictionary
    # that defines the global variables the code has access to.

    # We'll use that to store state.

    globals: dict[str, Any] = {}
    while True:
        command = json.loads(input())  # read a line of JSON from stdin
        if (code := command.get("code")) is None:
            print(json.dumps({"error": "No code to execute"}))
            continue

        # Capture the executed code's outputs
        stdout_io, stderr_io = StringIO(), StringIO()
        with redirect_stdout(stdout_io), redirect_stderr(stderr_io):
            try:
                exec(code, globals)
            except Exception as e:
                print(f"Execution Error: {e}", file=sys.stderr)

        print(
            json.dumps(
                {
                    "stdout": stdout_io.getvalue(),
                    "stderr": stderr_io.getvalue(),
                }
            ),
            flush=True,
        )


# Now that we have the driver program, we can write a function to take a
# `ContainerProcess` that is running the driver program and execute code in it.


def run_code(p: modal.container_process.ContainerProcess, code: str):
    p.stdin.write(json.dumps({"code": code}))
    p.stdin.write("\n")
    p.stdin.drain()
    next_line = next(iter(p.stdout))
    result = json.loads(next_line)
    print(result["stdout"], end="")
    print("\033[91m" + result["stderr"] + "\033[0m", end="")


# We've got our driver program and our code runner. Now we can create a Sandbox
# and run the driver program in it.

# We have to convert the driver program to a string to pass it to the Sandbox.
# Here we use `inspect.getsource` to get the source code as a string,
# but you could also keep the driver program in a separate file and read it in.

driver_program_text = inspect.getsource(driver_program)
driver_program_command = f"""{driver_program_text}\n\ndriver_program()"""

app = modal.App.lookup("code-interpreter", create_if_missing=True)
sb = modal.Sandbox.create(app=app)
p = sb.exec("python", "-c", driver_program_command)

# ## Running code in a Modal Sandbox

# Now we can execute some code in the Sandbox!

run_code(p, "print('hello, world!')")  # hello, world!

# The Sandbox and our code interpreter are stateful,
# so we can define variables and use them in subsequent code.

run_code(p, "x = 10")
run_code(p, "y = 5")
run_code(p, "result = x + y")
run_code(p, "print(f'The result is: {result}')")  # The result is: 15

# We can also see errors when code fails.

run_code(p, "print('Attempting to divide by zero...')")
run_code(p, "1 / 0")  # Execution Error: division by zero

# Finally, let's clean up after ourselves and terminate the Sandbox.

sb.terminate()


=== GITHUB: 13_sandboxes/safe_code_execution.py ===
# ---
# cmd: ["python", "13_sandboxes/safe_code_execution.py"]
# pytest: false
# ---

# # Run arbitrary code in a sandboxed environment

# This example demonstrates how to run arbitrary code
# in multiple languages in a Modal [Sandbox](https://modal.com/docs/guide/sandbox).

# ## Setting up a multi-language environment

# Sandboxes allow us to run any kind of code in a safe environment.
# We'll use an image with a few different language runtimes to demonstrate this.

import modal

image = modal.Image.debian_slim(python_version="3.11").apt_install(
    "nodejs", "ruby", "php"
)
app = modal.App.lookup("safe-code-execution", create_if_missing=True)

# We'll now create a Sandbox with this image. We'll also enable output so we can see the image build
# logs. Note that we don't pass any commands to the Sandbox, so it will stay alive, waiting for us
# to send it commands.

with modal.enable_output():
    sandbox = modal.Sandbox.create(app=app, image=image)

print(f"Sandbox ID: {sandbox.object_id}")

# ## Running bash, Python, Node.js, Ruby, and PHP in a Sandbox

# We can now use [`Sandbox.exec`](https://modal.com/docs/reference/modal.Sandbox#exec) to run a few different
# commands in the Sandbox.

bash_ps = sandbox.exec("echo", "hello from bash")
python_ps = sandbox.exec("python", "-c", "print('hello from python')")
nodejs_ps = sandbox.exec("node", "-e", 'console.log("hello from nodejs")')
ruby_ps = sandbox.exec("ruby", "-e", "puts 'hello from ruby'")
php_ps = sandbox.exec("php", "-r", "echo 'hello from php';")

print(bash_ps.stdout.read(), end="")
print(python_ps.stdout.read(), end="")
print(nodejs_ps.stdout.read(), end="")
print(ruby_ps.stdout.read(), end="")
print(php_ps.stdout.read(), end="")
print()

# The output should look something like

# ```
# hello from bash
# hello from python
# hello from nodejs
# hello from ruby
# hello from php
# ```

# We can use multiple languages in tandem to build complex applications.
# Let's demonstrate this by piping data between Python and Node.js using bash. Here
# we generate some random numbers with Python and sum them with Node.js.

combined_process = sandbox.exec(
    "bash",
    "-c",
    """python -c 'import random; print(\" \".join(str(random.randint(1, 100)) for _ in range(10)))' |
    node -e 'const readline = require(\"readline\");
    const rl = readline.createInterface({input: process.stdin});
    rl.on(\"line\", (line) => {
      const sum = line.split(\" \").map(Number).reduce((a, b) => a + b, 0);
      console.log(`The sum of the random numbers is: ${sum}`);
      rl.close();
    });'""",
)

result = combined_process.stdout.read().strip()
print(result)

# For long-running processes, you can use stdout as an iterator to stream the output.

slow_printer = sandbox.exec(
    "ruby",
    "-e",
    """
    10.times do |i|
      puts "Line #{i + 1}: #{Time.now}"
      STDOUT.flush
      sleep(0.5)
    end
    """,
)

for line in slow_printer.stdout:
    print(line, end="")

# This should print something like

# ```
# Line 1: 2024-10-21 15:30:53 +0000
# Line 2: 2024-10-21 15:30:54 +0000
# ...
# Line 10: 2024-10-21 15:30:58 +0000
# ```

# Since Sandboxes are safely separated from the rest of our system,
# we can run very dangerous code in them!

sandbox.exec("rm", "-rfv", "/", "--no-preserve-root")

# This command has deleted the entire filesystem, so we can't run any more commands.
# Let's terminate the Sandbox to clean up after ourselves.

sandbox.terminate()


=== GITHUB: 13_sandboxes/jupyter_sandbox.py ===
# ---
# cmd: ["python", "13_sandboxes/jupyter_sandbox.py"]
# pytest: false
# ---

# # Run a Jupyter notebook in a Modal Sandbox

# This example demonstrates how to run a Jupyter notebook in a Modal
# [Sandbox](https://modal.com/docs/guide/sandbox).

# ## Setting up the Sandbox

# All Sandboxes are associated with an App.

# We look up our app by name, creating it if it doesn't exist.

import json
import secrets
import time
import urllib.request

import modal

app = modal.App.lookup("example-jupyter", create_if_missing=True)

# We define a custom Docker image that has Jupyter and some other dependencies installed.
# Using a pre-defined image allows us to avoid re-installing packages on every Sandbox startup.

image = (
    modal.Image.debian_slim(python_version="3.12").pip_install("jupyter~=1.1.0")
    # .pip_install("pandas", "numpy", "seaborn")  # Any other deps
)

# ## Starting a Jupyter server in a Sandbox

# Since we'll be exposing a Jupyter server over the Internet, we need to create a password.
# We'll use `secrets` from the standard library to create a token
# and then store it in a Modal [Secret](https://modal.com/docs/guide/secrets).

token = secrets.token_urlsafe(13)
token_secret = modal.Secret.from_dict({"JUPYTER_TOKEN": token})

# Now, we can start our Sandbox. Note our use of the `encrypted_ports` argument, which
# allows us to securely expose the Jupyter server to the public Internet. We use
# `modal.enable_output()` to print the Sandbox's image build logs to the console.

JUPYTER_PORT = 8888

print("🏖️  Creating sandbox")

with modal.enable_output():
    sandbox = modal.Sandbox.create(
        "jupyter",
        "notebook",
        "--no-browser",
        "--allow-root",
        "--ip=0.0.0.0",
        f"--port={JUPYTER_PORT}",
        "--NotebookApp.allow_origin='*'",
        "--NotebookApp.allow_remote_access=1",
        encrypted_ports=[JUPYTER_PORT],
        secrets=[token_secret],
        timeout=5 * 60,  # 5 minutes
        image=image,
        app=app,
        gpu=None,  # add a GPU if you need it!
    )

print(f"🏖️  Sandbox ID: {sandbox.object_id}")

# ## Communicating with a Jupyter server

# Next, we print out a URL that we can use to connect to our Jupyter server.
# Note that we have to call [`Sandbox.tunnels`](https://modal.com/docs/reference/modal.Sandbox#tunnels)
# to get the URL. The Sandbox is not publicly accessible until we do so.

tunnel = sandbox.tunnels()[JUPYTER_PORT]
url = f"{tunnel.url}/?token={token}"
print(f"🏖️  Jupyter notebook is running at: {url}")

# Jupyter servers expose a [REST API](https://jupyter-server.readthedocs.io/en/latest/developers/rest-api.html)
# that you can use for programmatic manipulation.

# For example, we can check the server's status by
# sending a GET request to the `/api/status` endpoint.


def is_jupyter_up():
    try:
        response = urllib.request.urlopen(f"{tunnel.url}/api/status?token={token}")
        if response.getcode() == 200:
            data = json.loads(response.read().decode())
            return data.get("started", False)
    except Exception:
        return False
    return False


# We'll now wait for the Jupyter server to be ready by hitting that endpoint.

timeout = 60  # seconds
start_time = time.time()
while time.time() - start_time < timeout:
    if is_jupyter_up():
        print("🏖️  Jupyter is up and running!")
        break
    time.sleep(1)
else:
    print("🏖️  Timed out waiting for Jupyter to start.")


# You can now open this URL in your browser to access the Jupyter notebook!

# When you're done, terminate the sandbox using your [Modal dashboard](https://modal.com/sandboxes)
# or by running `Sandbox.from_id(sandbox.object_id).terminate()`.


=== GITHUB: 13_sandboxes/codelangchain/README.md ===
# Deploying code agents without all the agonizing pain

This example deploys a "code agent": a language model that can write and execute
code in a flexible control flow aimed at completing a task or goal.

It is implemented in LangChain, using the LangGraph library to structure the
agent and the LangServe framework to turn it into a FastAPI app.

We use Modal to turn that app into a web endpoint. We also use Modal to
"sandbox" the agent's code execution, so that it can't accidentally (or when
prompt injected!) damage the application by executing some inadvisable code.

Modal's Charles Frye and LangChain's Lance Martin did a
[walkthrough webinar](https://www.youtube.com/watch?v=X3yzWtAkaeo) explaining
the project's context and implementation. Check it out if you're curious!

## How to run

To run this app, you need to `pip install modal` and then create the following
[secrets](https://modal.com/docs/guide/secrets):

- `openai-secret` with an OpenAI API key, so that we can query OpenAI's models
  to power the agent,
- and `langsmith-secret` with a LangSmith API key, so that we can monitor the
  agent's behavior with LangSmith.

Head to the [secret creation dashboard](https://modal.com/secrets/) and follow
the instructions for each secret type.

Then, you can deploy the app with:

```bash
modal deploy codelangchain.py
```

Navigate to the URL that appears in the output and you'll be dropped into an
interactive "playground" interface where you can send queries to the agent and
receive responses. You should expect it to take about a minute to respond.

You can also navigate to the `/docs` path to see OpenAPI/Swagger docs, for
everything you'd need to see how to incorporate the agent into your downstream
applications via API requests.

When developing the app, use `modal serve codelangchain.py` to get a
hot-reloading server.

## Repo structure

The web application is defined in `codelangchain.py`.

It wraps the `agent.py` module, which contains the LangChain agent's definition.
To test the agent in isolation, run `modal run agent.py` in the terminal and
provide a `--question` about Python programming as input.

Because the agent is a graph, it is defined by specifying nodes and edges, which
are found in `nodes.py` and `edges.py`, respectively.

The retrieval logic is very simple: all of the data from the relevant docs is
retrieved and put at the beginning of the language model's prompt. You can find
it in `retrieval.py`.

The definition of the Modal container images and a few other shared utilities
can be found in `common.py`.


=== GITHUB: 13_sandboxes/codelangchain/agent.py ===
# ---
# cmd: ["modal", "run", "-m", "13_sandboxes.codelangchain.agent", "--question", "Use gpt2 and transformers to generate text"]
# pytest: false
# ---

# # Build a coding agent with Modal Sandboxes and LangGraph

# This example demonstrates how to build an LLM coding "agent" that can generate and execute Python code, using
# documentation from the web to inform its approach.

# Naturally, we use the agent to generate code that runs language models.

# The agent is built with [LangGraph](https://github.com/langchain-ai/langgraph), a library for building
# directed graphs of computation popular with AI agent developers,
# and uses models from the OpenAI API.

# ## Setup

import modal

from .src import edges, nodes, retrieval
from .src.common import COLOR, PYTHON_VERSION, image

# You will need two [Modal Secrets](https://modal.com/docs/guide/secrets) to run this example:
# one to access the OpenAI API and another to access the LangSmith API for logging the agent's behavior.

# To create them, head to the [Secrets dashboard](https://modal.com/secrets), select "Create new secret",
# and use the provided templates for OpenAI and LangSmith.

app = modal.App(
    "example-code-langchain",
    image=image,
    secrets=[
        modal.Secret.from_name("openai-secret", required_keys=["OPENAI_API_KEY"]),
        modal.Secret.from_name("langsmith-secret", required_keys=["LANGCHAIN_API_KEY"]),
    ],
)

# ## Creating a Sandbox

# We execute the agent's code in a Modal [Sandbox](https://modal.com/docs/guide/sandbox), which allows us to
# run arbitrary code in a safe environment. In this example, we will use the [`transformers`](https://huggingface.co/docs/transformers/index)
# library to generate text with a pre-trained model. Let's create a Sandbox with the necessary dependencies.


def create_sandbox(app) -> modal.Sandbox:
    # Change this image (and the retrieval logic in the retrieval module)
    # if you want the agent to give coding advice on other libraries!
    agent_image = modal.Image.debian_slim(python_version=PYTHON_VERSION).pip_install(
        "torch==2.5.0",
        "transformers==4.46.0",
    )

    return modal.Sandbox.create(
        image=agent_image,
        timeout=60 * 10,  # 10 minutes
        app=app,
        # Modal sandboxes support GPUs!
        gpu="T4",
        # you can also pass secrets here -- note that the main app's secrets are not shared
    )


# We also need a way to run our code in the sandbox. For this, we'll write a simple wrapper
# around the Modal Sandox `exec` method. We use `exec` because it allows us to run code without spinning up a
# new container. And we can reuse the same container for multiple runs, preserving state.


def run(code: str, sb: modal.Sandbox) -> tuple[str, str]:
    print(
        f"{COLOR['HEADER']}📦: Running in sandbox{COLOR['ENDC']}",
        f"{COLOR['GREEN']}{code}{COLOR['ENDC']}",
        sep="\n",
    )

    exc = sb.exec("python", "-c", code)
    exc.wait()

    stdout = exc.stdout.read()
    stderr = exc.stderr.read()

    if exc.returncode != 0:
        print(
            f"{COLOR['HEADER']}📦: Failed with exitcode {sb.returncode}{COLOR['ENDC']}"
        )

    return stdout, stderr


# ## Constructing the agent's graph

# Now that we have the sandbox to execute code in, we can construct our agent's graph. Our graph is
# defined in the `edges` and `nodes` modules
# [associated with this example](https://github.com/modal-labs/modal-examples/tree/main/13_sandboxes/codelangchain).
# Nodes are actions that change the state. Edges are transitions between nodes.

# The idea is simple: we start at the node `generate`, which invokes the LLM to generate code based off documentation.
# The generated code is executed (in the sandbox) as part of an edge called `check_code_execution`
# and then the outputs are passed to the LLM for evaluation (the `evaluate_execution` node).
# If the LLM determines that the code has executed correctly -- which might mean that the code raised an exception! --
# we pass along the `decide_to_finish` edge and finish.


def construct_graph(sandbox: modal.Sandbox, debug: bool = False):
    from langgraph.graph import StateGraph

    from .src.common import GraphState

    # Crawl the transformers documentation to inform our code generation
    context = retrieval.retrieve_docs(debug=debug)

    graph = StateGraph(GraphState)

    # Attach our nodes to the graph
    graph_nodes = nodes.Nodes(context, sandbox, run, debug=debug)
    for key, value in graph_nodes.node_map.items():
        graph.add_node(key, value)

    # Construct the graph by adding edges
    graph = edges.enrich(graph)

    # Set the starting and ending nodes of the graph
    graph.set_entry_point(key="generate")
    graph.set_finish_point(key="finish")

    return graph


# We now set up the graph and compile it. See the `src` module for details
# on the content of the graph and the nodes we've defined.

DEFAULT_QUESTION = "How do I generate Python code using a pre-trained model from the transformers library?"


@app.function()
def go(
    question: str = DEFAULT_QUESTION,
    debug: bool = False,
):
    """Compiles the Python code generation agent graph and runs it, returning the result."""
    sb = create_sandbox(app)

    graph = construct_graph(sb, debug=debug)
    runnable = graph.compile()
    result = runnable.invoke(
        {"keys": {"question": question, "iterations": 0}},
        config={"recursion_limit": 50},
    )

    sb.terminate()

    return result["keys"]["response"]


# ## Running the Graph

# Now let's call the agent from the command line!

# We define a `local_entrypoint` that runs locally and triggers execution on Modal.

# You can invoke it by executing following command from a folder that contains the `codelangchain` directory
# [from our examples repo](https://github.com/modal-labs/modal-examples/tree/main/13_sandboxes/codelangchain):

# ```bash
# modal run -m codelangchain.agent --question "How do I run a pre-trained model from the transformers library?"
# ```


@app.local_entrypoint()
def main(
    question: str = DEFAULT_QUESTION,
    debug: bool = False,
):
    """Sends a question to the Python code generation agent.

    Switch to debug mode for shorter context and smaller model."""
    if debug:
        if question == DEFAULT_QUESTION:
            question = "hi there, how are you?"

    print(go.remote(question, debug=debug))


# If things are working properly, you should see output like the following:

# ```bash
# $ modal run -m codelangchain.agent --question "generate some cool output with transformers"
# ---DECISION: FINISH---
# ---FINISHING---
# To generate some cool output using transformers, we can use a pre-trained language model from the Hugging Face Transformers library. In this example, we'll use the GPT-2 model to generate text based on a given prompt. The GPT-2 model is a popular choice for text generation tasks due to its ability to produce coherent and contextually relevant text. We'll use the pipeline API from the Transformers library, which simplifies the process of using pre-trained models for various tasks, including text generation.
#
# from transformers import pipeline
# # Initialize the text generation pipeline with the GPT-2 model
# generator = pipeline('text-generation', model='gpt2')
#
# # Define a prompt for the model to generate text from
# prompt = "Once upon a time in a land far, far away"
#
# # Generate text using the model
# output = generator(prompt, max_length=50, num_return_sequences=1)
#
# # Print the generated text
# print(output[0]['generated_text'])
#
# Result of code execution:
# Once upon a time in a land far, far away, and still inhabited even after all the human race, there would be one God: a perfect universal God who has always been and will ever be worshipped. All His acts and deeds are immutable,
# ```


=== GITHUB: 13_sandboxes/codelangchain/langserve.py ===
# ---
# pytest: false
# cmd: ["modal", "serve", "-m", "13_sandboxes.codelangchain.langserve"]
# ---

# # Deploy LangChain and LangGraph applications with LangServe

# This code demonstrates how to deploy a
# [LangServe](https://python.langchain.com/docs/langserve/) application on Modal.
# LangServe makes it easy to wrap LangChain and LangGraph applications in a FastAPI server,
# and Modal makes it easy to deploy FastAPI servers.

# The LangGraph application that it serves is from our [sandboxed LLM coding agent example](https://modal.com/docs/examples/agent).

# You can find the code for the agent and several other code files associated with this example in the
# [`codelangchain` directory of our examples repo](https://github.com/modal-labs/modal-examples/tree/main/13_sandboxes/codelangchain).

import modal

from .agent import construct_graph, create_sandbox
from .src.common import image

app = modal.App("example-langserve")

image = image.pip_install("langserve[all]==0.3.0")


@app.function(
    image=image,
    secrets=[  # see the agent.py file for more information on Secrets
        modal.Secret.from_name("openai-secret", required_keys=["OPENAI_API_KEY"]),
        modal.Secret.from_name("langsmith-secret", required_keys=["LANGCHAIN_API_KEY"]),
    ],
)
@modal.asgi_app()
def serve():
    from fastapi import FastAPI, responses
    from fastapi.middleware.cors import CORSMiddleware
    from langchain_core.runnables import RunnableLambda
    from langserve import add_routes

    # create a FastAPI app
    web_app = FastAPI(
        title="CodeLangChain Server",
        version="1.0",
        description="Writes code and checks if it runs.",
    )

    # set all CORS enabled origins
    web_app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
        expose_headers=["*"],
    )

    def inp(question: str) -> dict:
        return {"keys": {"question": question, "iterations": 0}}

    def out(state: dict) -> str:
        if "finish" in state:
            return state["finish"]["keys"]["response"]
        elif len(state) > 0 and "finish" in state[-1]:
            return state[-1]["finish"]["keys"]["response"]
        else:
            return str(state)

    graph = construct_graph(create_sandbox(app), debug=False).compile()

    chain = RunnableLambda(inp) | graph | RunnableLambda(out)

    add_routes(
        web_app,
        chain,
        path="/codelangchain",
    )

    # redirect the root to the interactive playground
    @web_app.get("/")
    def redirect():
        return responses.RedirectResponse(url="/codelangchain/playground")

    # return the FastAPI app and Modal will deploy it for us
    return web_app


=== GITHUB: 13_sandboxes/codelangchain/src/edges.py ===
"""Defines functions that transition our agent from one state to another."""

from typing import Callable

from .common import GraphState

EXPECTED_NODES = [
    "generate",
    "check_code_imports",
    "check_code_execution",
    "finish",
]


def enrich(graph):
    """Adds transition edges to the graph."""

    for node_name in set(EXPECTED_NODES):
        assert node_name in graph.nodes, f"Node {node_name} not found in graph"

    graph.add_edge("generate", "check_code_imports")
    graph.add_conditional_edges(
        "check_code_imports",
        EDGE_MAP["decide_to_check_code_exec"],
        {
            "check_code_execution": "check_code_execution",
            "generate": "generate",
        },
    )
    graph.add_edge("check_code_execution", "evaluate_execution")
    graph.add_conditional_edges(
        "evaluate_execution",
        EDGE_MAP["decide_to_finish"],
        {
            "finish": "finish",
            "generate": "generate",
        },
    )
    return graph


def decide_to_check_code_exec(state: GraphState) -> str:
    """
    Determines whether to test code execution, or re-try answer generation.

    Args:
    state (dict): The current graph state

    Returns:
        str: Next node to call
    """

    print("---DECIDE TO TEST CODE EXECUTION---")
    state_dict = state["keys"]
    error = state_dict["error"]

    if error == "None":
        # All documents have been filtered check_relevance
        # We will re-generate a new query
        print("---DECISION: TEST CODE EXECUTION---")
        return "check_code_execution"
    else:
        # We have relevant documents, so generate answer
        print("---DECISION: RE-TRY SOLUTION---")
        return "generate"


def decide_to_finish(state: GraphState) -> str:
    """
    Determines whether to finish (re-try code 3 times).

    Args:
        state (dict): The current graph state

    Returns:
        str: Next node to call
    """

    print("---DECIDE TO FINISH---")
    state_dict = state["keys"]
    evaluation = state_dict["evaluation"]
    iter = state_dict["iterations"]

    if evaluation.decision == "finish" or iter >= 3:
        print("---DECISION: FINISH---")
        return "finish"
    else:
        print("---DECISION: RE-TRY SOLUTION---")
        return "generate"


EDGE_MAP: dict[str, Callable] = {
    "decide_to_check_code_exec": decide_to_check_code_exec,
    "decide_to_finish": decide_to_finish,
}


=== GITHUB: 13_sandboxes/codelangchain/src/common.py ===
"""Shared information: image definitions and common utilities."""

import os
from typing import Any, Dict, TypedDict

import modal

PYTHON_VERSION = "3.11"

image = (
    modal.Image.debian_slim(python_version=PYTHON_VERSION)
    .pip_install(
        "beautifulsoup4~=4.12.3",
        "langchain==0.3.4",
        "langchain-core==0.3.12",
        "langgraph==0.2.39",
        "langchain-community==0.3.3",
        "langchain-openai==0.2.3",
        "pydantic==2.9.1",
    )
    .env({"LANGCHAIN_TRACING_V2": "true"})
)


class GraphState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        keys: A dictionary where each key is a string.
    """

    keys: Dict[str, Any]


os.environ["LANGCHAIN_PROJECT"] = "codelangchain"
os.environ["LANGCHAIN_TRACING"] = "true"

COLOR = {
    "HEADER": "\033[95m",
    "BLUE": "\033[94m",
    "GREEN": "\033[92m",
    "RED": "\033[91m",
    "ENDC": "\033[0m",
}


=== GITHUB: 13_sandboxes/codelangchain/src/retrieval.py ===
"""Just as a constant function is _technically_ a polynomial, so too is injecting the same information every time _technically_ RAG."""

from .common import COLOR

docs_url = "https://huggingface.co/docs/transformers/index"


def retrieve_docs(url: str = docs_url, debug=False):
    from bs4 import BeautifulSoup as Soup
    from langchain_community.document_loaders.recursive_url_loader import (
        RecursiveUrlLoader,
    )

    print(f"{COLOR['HEADER']}📜: Retrieving documents from {url}{COLOR['ENDC']}")
    loader = RecursiveUrlLoader(
        url=docs_url,
        max_depth=2 // (int(debug) + 1),  # retrieve fewer docs in debug mode
        extractor=lambda x: Soup(x, "html.parser").text,
    )
    docs = loader.load()

    # sort the list based on the URLs
    d_sorted = sorted(docs, key=lambda x: x.metadata["source"], reverse=True)

    # combine them all together
    concatenated_content = "\n\n\n --- \n\n\n".join(
        [
            "## " + doc.metadata["source"] + "\n\n" + doc.page_content.strip()
            for doc in d_sorted
        ]
    )

    print(
        f"{COLOR['HEADER']}📜: Retrieved {len(docs)} documents{COLOR['ENDC']}",
        f"{COLOR['GREEN']}{concatenated_content[:100].strip()}{COLOR['ENDC']}",
        sep="\n",
    )

    if debug:
        print(
            f"{COLOR['HEADER']}📜: Restricting to at most 30,000 characters{COLOR['ENDC']}"
        )
        concatenated_content = concatenated_content[:30_000]

    return concatenated_content


=== GITHUB: 13_sandboxes/codelangchain/src/nodes.py ===
import sys
from enum import Enum
from operator import itemgetter
from typing import Callable

import modal

from .common import GraphState, image

with image.imports():
    from langchain.output_parsers.openai_tools import PydanticToolsParser
    from langchain.prompts import PromptTemplate
    from langchain_core.utils.function_calling import convert_to_openai_tool
    from langchain_openai import ChatOpenAI
    from pydantic import BaseModel, Field


class Nodes:
    def __init__(
        self,
        context: str,
        sb: modal.Sandbox,
        run: Callable[[str, modal.Sandbox], tuple[str, str]],
        debug: bool = False,
    ):
        self.context = context
        self.debug = debug
        self.model = "gpt-4o-2024-08-06" if not self.debug else "gpt-4o-mini-2024-07-18"
        self.node_map = {
            "generate": self.generate,
            "check_code_imports": self.check_code_imports,
            "check_code_execution": self.check_code_execution,
            "evaluate_execution": self.evaluate_execution,  # New node
            "finish": self.finish,
        }

        self.sb = sb
        self.run = run

    def generate(self, state: GraphState) -> GraphState:
        """
        Generate a code solution based on docs and the input question
        with optional feedback from code execution tests

        Args:
            state (dict): The current graph state

        Returns:
            state (dict): New key added to state, documents, that contains retrieved documents
        """

        ## State
        state_dict = state["keys"]
        question = state_dict["question"]
        iter = state_dict["iterations"]

        ## Data model
        class Code(BaseModel):
            """Code output"""

            prefix: str = Field(description="Description of the problem and approach")
            imports: str = Field(description="Code block import statements")
            code: str = Field(description="Code block not including import statements")

        ## LLM
        llm = ChatOpenAI(temperature=0, model=self.model, streaming=True)

        # Tool
        code_tool_oai = convert_to_openai_tool(Code)

        # LLM with tool and enforce invocation
        llm_with_tool = llm.bind(
            tools=[code_tool_oai],
            tool_choice={"type": "function", "function": {"name": "Code"}},
        )

        # Parser
        parser_tool = PydanticToolsParser(tools=[Code])

        ## Prompt
        template = """
You are a coding assistant with expertise in Python.
You are able to execute Python code in a sandbox environment.
You are tasked with responding to the following user question: {question}
Your response will be shown to the user.
Here is a full set of documentation:

-------
{context}
-------

Answer the user question based on the above provided documentation.
Ensure any code you provide can be executed with all required imports and variables defined.
Structure your answer as a description of the code solution,
then a list of the imports, and then finally list the functioning code block.
Here is the user question again:

--- --- ---
{question}"""

        ## Generation
        if "error" in state_dict:
            print("---RE-GENERATE SOLUTION w/ ERROR FEEDBACK---")

            error = state_dict["error"]
            code_solution = state_dict["generation"]

            # Update prompt
            addendum = """You previously tried to solve this problem. Here is your solution:

{generation}

Here is the resulting error from code execution:

{error}

Please re-try to answer this. Structure your answer with a description of the code solution.
Then list the imports. And finally list the functioning code block. Structure your answer with a description of
the code solution. Then list the imports. And finally list the functioning code block.

Here is the user question:

{question}"""
            template = template + addendum

            # Prompt
            prompt = PromptTemplate(
                template=template,
                input_variables=["context", "question", "generation", "error"],
            )

            # Chain
            chain = (
                {
                    "context": lambda _: self.context,
                    "question": itemgetter("question"),
                    "generation": itemgetter("generation"),
                    "error": itemgetter("error"),
                }
                | prompt
                | llm_with_tool
                | parser_tool
            )

            code_solution = chain.invoke(
                {
                    "question": question,
                    "generation": str(code_solution[0]),
                    "error": error,
                }
            )

        else:
            print("---GENERATE SOLUTION---")

            # Prompt
            prompt = PromptTemplate(
                template=template,
                input_variables=["context", "question"],
            )

            # Chain
            chain = (
                {
                    "context": lambda _: self.context,
                    "question": itemgetter("question"),
                }
                | prompt
                | llm_with_tool
                | parser_tool
            )

            code_solution = chain.invoke({"question": question})

        iter = iter + 1
        return {
            "keys": {
                "generation": code_solution,
                "question": question,
                "iterations": iter,
            }
        }

    def check_code_imports(self, state: GraphState) -> GraphState:
        """
        Check imports

        Args:
            state (dict): The current graph state

        Returns:
            state (dict): New key added to state, error
        """

        ## State
        print("---CHECKING CODE IMPORTS---")
        state_dict = state["keys"]
        question = state_dict["question"]
        code_solution = state_dict["generation"]
        imports = code_solution[0].imports
        iter = state_dict["iterations"]

        # Attempt to execute the imports
        output, error = self.run(imports, self.sb)
        if error:
            print("---CODE IMPORT CHECK: FAILED---")
            # Catch any error during execution (e.g., ImportError, SyntaxError)
            error = f"Execution error: {error}"
            print(f"Error: {error}", file=sys.stderr)
            if "error" in state_dict:
                error_prev_runs = state_dict["error"]
                error = f"""
{error_prev_runs}

--- Most recent run output and error ---
------ output ------
{output}
------ error ------
{error}
"""
        else:
            print("---CODE IMPORT CHECK: SUCCESS---")
            # No errors occurred
            error = "None"

        return {
            "keys": {
                "generation": code_solution,
                "question": question,
                "error": error,
                "iterations": iter,
            }
        }

    def check_code_execution(self, state: GraphState) -> GraphState:
        """
        Check code block execution

        Args:
            state (dict): The current graph state

        Returns:
            state (dict): New key added to state, error
        """

        ## State
        print("---CHECKING CODE EXECUTION---")
        state_dict = state["keys"]
        question = state_dict["question"]
        code_solution = state_dict["generation"]
        imports = code_solution[0].imports
        code = code_solution[0].code
        code_block = imports + "\n" + code
        iter = state_dict["iterations"]

        output, error = self.run(code_block, self.sb)
        if error:
            print("---CODE BLOCK CHECK: FAILED---")
            error = f"Execution error: {error}"
            print(f"Error: {error}", file=sys.stderr)
            if "error" in state_dict:
                error_prev_runs = state_dict["error"]
                error = (
                    error_prev_runs + "\n --- Most recent run output and error --- \n"
                    " ------ output ------ \n"
                    + output
                    + "\n ------ error ------ \n"
                    + error
                )
        else:
            print("---CODE BLOCK CHECK: SUCCESS---")
            # No errors occurred
            error = "None"

        return {
            "keys": {
                "generation": code_solution,
                "question": question,
                "error": error,
                "output": output,
                "iterations": iter,
            }
        }

    def evaluate_execution(self, state: GraphState) -> GraphState:
        """
        Evaluate the code execution results and determine whether to finish or retry.

        Args:
            state (dict): The current graph state

        Returns:
            state (dict): Updated state with decision to finish or retry
        """
        print("---EVALUATING EXECUTION---")

        state_dict = state["keys"]
        output = state_dict["output"]
        error = state_dict["error"]

        code_solution = state_dict["generation"][0]
        code = code_solution.code

        class Decision(str, Enum):
            FINISH = "finish"
            RETRY = "retry"

        class ExecutionEvaluation(BaseModel):
            """Evaluation of code execution"""

            decision: Decision = Field(description="Decision to finish or retry")
            explanation: str = Field(description="Explanation for the decision")

        llm = ChatOpenAI(temperature=0, model=self.model)
        evaluation_tool = convert_to_openai_tool(ExecutionEvaluation)
        llm_with_tool = llm.bind(
            tools=[evaluation_tool],
            tool_choice={
                "type": "function",
                "function": {"name": "ExecutionEvaluation"},
            },
        )
        parser_tool = PydanticToolsParser(tools=[ExecutionEvaluation])

        template = """
You are an expert code evaluator. Analyze the following code execution results and determine if the execution was successful.

Code:
{code}

Output:
{output}

Error:
{error}

Decide whether to finish (if the execution was successful) or retry (if there were errors or unexpected results).
Provide a brief explanation for your decision.
        """.strip()

        prompt = PromptTemplate(
            template=template,
            input_variables=["code", "output", "error"],
        )

        chain = prompt | llm_with_tool | parser_tool

        evaluation = chain.invoke({"code": code, "output": output, "error": error})

        return {
            "keys": {
                **state_dict,
                "evaluation": evaluation[0],
            }
        }

    def finish(self, state: GraphState) -> dict:
        """
        Finish the graph

        Returns:
            dict: Final result
        """

        print("---FINISHING---")

        response = extract_response(state)

        self.sb.terminate()

        return {"keys": {"response": response}}


def extract_response(state: GraphState) -> str:
    """
    Extract the response from the graph state

    Args:
        state (dict): The current graph state

    Returns:
        str: The response
    """

    state_dict = state["keys"]
    code_solution = state_dict["generation"][0]

    prefix = code_solution.prefix
    imports = code_solution.imports
    code = code_solution.code

    code_output = state_dict["output"]

    return f"""{prefix}

{imports}
{code}

Result of code execution:
{code_output}
"""



=== CATEGORY: CLUSTERS ===

=== GITHUB: 14_clusters/simple_torch_cluster_script.py ===
# ---
# lambda-test: false  # auxiliary-file
# pytest: false
# ---
import argparse
import os
from contextlib import contextmanager

import torch
import torch.distributed as dist

# Environment variables set by torch.distributed.run.
LOCAL_RANK = int(os.environ["LOCAL_RANK"])
WORLD_SIZE = int(os.environ["WORLD_SIZE"])
WORLD_RANK = int(os.environ["RANK"])
# The master (or leader) rank is always 0 with torch.distributed.run.
MASTER_RANK = 0

# This `run` function performs a simple distributed data transfer between containers
# using the specified distributed communication backend.

# An example topology of the cluster when WORLD_SIZE=4 is shown below:
#
#        +---------+
#        | Master  |
#        | Rank 0  |
#        +----+----+
#             |
#             |
#    +--------+--------+
#    |        |        |
#    |        |        |
# +--+--+  +--+--+  +--+--+
# |Rank 1| |Rank 2| |Rank 3|
# +-----+  +-----+  +-----+

# A broadcast operation (https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/collectives.html#broadcast)
# is performed between the master container (rank 0) and all other containers.

# The master container (rank 0) sends a tensor to all other containers.
# Each container then receives that tensor from the master container.


def run(backend):
    # Helper function providing a vanity name for each container based on its world (i.e. global) rank.
    def container_name(wrld_rank: int) -> str:
        return (
            f"container-{wrld_rank} (main)"
            if wrld_rank == 0
            else f"container-{wrld_rank}"
        )

    tensor = torch.zeros(1)

    # Need to put tensor on a GPU device for NCCL backend.
    if backend == "nccl":
        device = torch.device("cuda:{}".format(LOCAL_RANK))
        tensor = tensor.to(device)

    if WORLD_RANK == MASTER_RANK:
        print(f"{container_name(WORLD_RANK)} sending data to all other containers...\n")
        for rank_recv in range(1, WORLD_SIZE):
            dist.send(tensor=tensor, dst=rank_recv)
            print(
                f"{container_name(WORLD_RANK)} sent data to {container_name(rank_recv)}\n"
            )
    else:
        dist.recv(tensor=tensor, src=MASTER_RANK)
        print(
            f"{container_name(WORLD_RANK)} has received data from {container_name(MASTER_RANK)}\n"
        )


# In order for the broadcast operation to happen across the cluster, we need to have the master container (rank 0)
# learn the network addresses of all other containers.

# This is done by calling `dist.init_process_group` with the specified backend.

# See https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group for more details.


@contextmanager
def init_processes(backend):
    try:
        dist.init_process_group(backend, rank=WORLD_RANK, world_size=WORLD_SIZE)
        yield
    finally:
        dist.barrier()  # ensure any async work is done before cleaning up
        # Remove this if it causes program to hang. ref: https://github.com/pytorch/pytorch/issues/75097.
        dist.destroy_process_group()


if __name__ == "__main__":
    # This is a minimal CLI interface adhering to the requirements of torch.distributed.run (torchrun).
    #
    # Our Modal Function will use torch.distributed.run to launch this script.
    #
    # See https://pytorch.org/docs/stable/elastic/run.html for more details on the CLI interface.
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--local-rank",
        "--local_rank",
        type=int,
        help="Local rank. Necessary for using the torch.distributed.launch utility.",
    )
    parser.add_argument("--backend", type=str, default="gloo", choices=["nccl", "gloo"])
    args = parser.parse_args()

    with init_processes(backend=args.backend):
        run(backend=args.backend)


=== GITHUB: 14_clusters/simple_torch_cluster.py ===
# # Simple PyTorch cluster

# This example shows how you can perform distributed computation with PyTorch.
# It is a kind of 'hello world' example for distributed ML training: setting up a cluster
# and executing a broadcast operation to share a single tensor.

# ## Basic setup: Imports, dependencies, and a script

# Let's get the imports out of the way first.
# We need to import `modal.experimental` to use this feature, since it's still under development.
# Let us know if you run into any issues!

import os
from pathlib import Path

import modal
import modal.experimental

# Communicating between nodes in a cluster requires communication libraries.
# We'll use `torch`, so we add it to our container's [Image](https://modal.com/docs/guide/images) here.

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "torch~=2.5.1", "numpy~=2.2.1"
)

# The approach we're going to take is to use a Modal [Function](https://modal.com/docs/reference/modal.Function)
# to launch the underlying script we want to distribute over the cluster nodes.
# The script is located in another file in the same directory
# of [our examples repo](https://github.com/modal-labs/modal-examples/).
# In order to use it in our remote Modal Function,
# we need to duplicate it remotely, which we do with `add_local_file`.

this_directory = Path(__file__).parent

image = image.add_local_file(
    this_directory / "simple_torch_cluster_script.py",
    remote_path="/root/script.py",
)

app = modal.App("example-simple-torch-cluster", image=image)

# ## Configuring a test cluster

# First, we set the size of the cluster in containers/nodes. This can be between 1 and 8.
# This is part of our Modal configuration, since Modal is responsible for spinning up our cluster.

n_nodes = 4

# Next, we set the number of processes we run per node.
# The usual practice is to run one process per GPU,
# so we set those two values to be equal.
# Note that `N_GPU` is Modal configuration ("how many GPUs should we spin up for you?")
# while `nproc_per_node` is `torch.distributed` configuration ("how many processes should we spawn for you?").

n_proc_per_node = N_GPU = 1
GPU_CONFIG = f"H100:{N_GPU}"

# Lastly, we need to select our communications library: the software that will handle
# sending messages between nodes in our cluster.
# Since we are running on GPUs, we use the
# [NVIDIA Collective Communications Library](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html)
# (`nccl`, pronounced "nickle").

# This is part of `torch.distributed` configuration --
# Modal handles the networking infrastructure but not the communication protocol.

backend = "nccl"  # or "gloo" on CPU, see https://pytorch.org/docs/stable/distributed.html#which-backend-to-use

# This cluster configurations is nice for testing, but typically
# you'll want to run a cluster with the maximum number of GPUs per container --
# 8 if you're running on H100s, the beefiest GPUs we offer on Modal.

# ## Launching the script

# Our Modal Function is merely a 'launcher' that sets up the distributed
# cluster environment and then calls `torch.distributed.run`,
# the underlying Python code exposed by the [`torchrun`](https://pytorch.org/docs/stable/elastic/run.html)
# command line tool.

# So executing this distributed job is easy! Just run

# ```bash
# modal run simple_torch_cluster.py
# ```

# in your terminal.

# In addition to the values set in code above, you can pass additional arguments to `torch.distributed.run`
# via the command line:

# ```bash
# modal run simple_torch_cluster.py --max-restarts=1
# ```


@app.function(gpu=GPU_CONFIG)
@modal.experimental.clustered(size=n_nodes)
def dist_run_script(*args):
    from torch.distributed.run import parse_args, run

    cluster_info = (  # we populate this data for you
        modal.experimental.get_cluster_info()
    )
    # which container am I?
    container_rank = cluster_info.rank
    # how many containers are in this cluster?
    world_size = len(cluster_info.container_ips)
    # what's the leader/master/main container's address?
    main_addr = cluster_info.container_ips[0]
    # what's the identifier of this cluster task in Modal?
    task_id = os.environ["MODAL_TASK_ID"]
    print(f"hello from {container_rank=}")
    if container_rank == 0:
        print(
            f"reporting cluster state from rank0/main: {main_addr=}, {world_size=}, {task_id=}"
        )

    run(
        parse_args(
            [
                f"--nnodes={n_nodes}",
                f"--node_rank={cluster_info.rank}",
                f"--master_addr={main_addr}",
                f"--nproc-per-node={n_proc_per_node}",
                "--master_port=1234",
            ]
            + list(args)
            + ["/root/script.py", "--backend", backend]
        )
    )



=== CATEGORY: MISC ===

=== GITHUB: misc/stable_lm.py ===
# # Run StableLM text completion model

# This example shows how you can run [`stabilityai/stablelm-tuned-alpha-7b`](https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b) on Modal

import os
import time
from pathlib import Path
from typing import Any, Dict, Generator, List, Union

import modal
from pydantic import BaseModel
from typing_extensions import Annotated, Literal


def build_models():
    import torch
    from huggingface_hub import snapshot_download
    from transformers import AutoModelForCausalLM, AutoTokenizer

    model_path = snapshot_download(
        "stabilityai/stablelm-tuned-alpha-7b",
        ignore_patterns=["*.md"],
    )
    m = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map="auto",
        local_files_only=True,
    )
    m.save_pretrained(model_path, safe_serialization=True, max_shard_size="24GB")
    tok = AutoTokenizer.from_pretrained(model_path)
    tok.save_pretrained(model_path)
    [p.unlink() for p in Path(model_path).rglob("*.bin")]  # type: ignore


image = (
    modal.Image.micromamba()
    .apt_install("git", "software-properties-common", "wget")
    .micromamba_install(
        "cudatoolkit-dev=11.7",
        "pytorch-cuda=11.7",
        "rust=1.69.0",
        channels=["nvidia", "pytorch", "conda-forge"],
    )
    .env(
        {
            "HF_HOME": "/root",
            "HF_HUB_ENABLE_HF_TRANSFER": "1",
            "SAFETENSORS_FAST_GPU": "1",
            "BITSANDBYTES_NOWELCOME": "1",
            "PIP_DISABLE_PIP_VERSION_CHECK": "1",
            "PIP_NO_CACHE_DIR": "1",
        }
    )
    .pip_install(
        "transformers~=4.28.1",
        "safetensors==0.3.0",
        "accelerate==0.18.0",
        "bitsandbytes==0.38.1",
        "msgspec==0.18.6",
        "sentencepiece==0.1.98",
        "hf-transfer==0.1.3",
        gpu="any",
    )
    .run_function(
        build_models,
        gpu=None,
        timeout=3600,
    )
)

app = modal.App(
    name="example-stability-lm",
    image=image,
    secrets=[
        modal.Secret.from_dict({"REPO_ID": "stabilityai/stablelm-tuned-alpha-7b"})
    ],
)


class CompletionRequest(BaseModel):
    prompt: Annotated[str, "The prompt for text completion"]
    model: Annotated[
        Literal["stabilityai/stablelm-tuned-alpha-7b"],
        "The model to use for text completion",
    ] = "stabilityai/stablelm-tuned-alpha-7b"
    temperature: Annotated[
        float,
        "Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic.",
    ] = 0.8
    max_tokens: Annotated[
        int, "Maximum number of new tokens to generate for text completion."
    ] = 16
    top_p: Annotated[
        float,
        "Probability threshold for the decoder to use in sampling next most likely token.",
    ] = 0.9
    stream: Annotated[
        bool, "Whether to stream the generated text or return it all at once."
    ] = False
    stop: Annotated[Union[str, List[str]], "Any additional stop words."] = []
    top_k: Annotated[
        int,
        "Limits the set of tokens to consider for next token generation to the top k.",
    ] = 40
    do_sample: Annotated[
        bool, "Whether to use sampling or greedy decoding for text completion."
    ] = True


@app.cls(gpu="A10G")
class StabilityLM:
    stop_tokens = [
        "<|USER|>",
        "<|ASSISTANT|>",
        "<|SYSTEM|>",
        "<|padding|>",
        "<|endoftext|>",
    ]
    model_url: str = modal.parameter(default="stabilityai/stablelm-tuned-alpha-7b")

    @modal.enter()
    def setup_model(self):
        """
        Container-lifeycle method for model setup.
        """
        os.environ["HF_HUB_OFFLINE"] = "1"
        os.environ["TRANSFORMERS_OFFLINE"] = "1"

        import torch
        from transformers import AutoTokenizer, TextIteratorStreamer, pipeline

        tokenizer = AutoTokenizer.from_pretrained(self.model_url, local_files_only=True)
        self.stop_ids = tokenizer.convert_tokens_to_ids(self.stop_tokens)
        self.streamer = TextIteratorStreamer(
            tokenizer,
            skip_prompt=True,
        )
        self.generator = pipeline(
            "text-generation",
            model=self.model_url,
            tokenizer=tokenizer,
            streamer=self.streamer,
            torch_dtype=torch.float16,
            device_map="auto",
            model_kwargs={"local_files_only": True},
        )
        self.generator.model = torch.compile(self.generator.model)

    def get_config(self, completion_request: CompletionRequest) -> Dict[str, Any]:
        return dict(
            pad_token_id=self.generator.tokenizer.eos_token_id,
            eos_token_id=list(
                set(
                    self.generator.tokenizer.convert_tokens_to_ids(
                        self.generator.tokenizer.tokenize(
                            "".join(completion_request.stop)
                        )
                    )
                    + self.stop_ids
                )
            ),
            max_new_tokens=completion_request.max_tokens,
            **completion_request.dict(
                exclude={"prompt", "model", "stop", "max_tokens", "stream"}
            ),
        )

    def generate_completion(
        self, completion_request: CompletionRequest
    ) -> Generator[str, None, None]:
        import re
        from threading import Thread

        from transformers import GenerationConfig

        text = format_prompt(completion_request.prompt)
        gen_config = GenerationConfig(**self.get_config(completion_request))
        stop_words = self.generator.tokenizer.convert_ids_to_tokens(
            gen_config.eos_token_id
        )
        stop_words_pattern = re.compile("|".join(map(re.escape, stop_words)))
        thread = Thread(
            target=self.generator.__call__,
            kwargs=dict(text_inputs=text, generation_config=gen_config),
        )
        thread.start()
        for new_text in self.streamer:
            if new_text.strip():
                new_text = stop_words_pattern.sub("", new_text)
                yield new_text
        thread.join()

    @modal.method()
    def generate(self, completion_request: CompletionRequest) -> str:
        return "".join(self.generate_completion(completion_request))

    @modal.method()
    def generate_stream(self, completion_request: CompletionRequest) -> Generator:
        for text in self.generate_completion(completion_request):
            yield text


def format_prompt(instruction: str) -> str:
    return f"<|USER|>{instruction}<|ASSISTANT|>"


with app.image.imports():
    import uuid

    import msgspec

    class Choice(msgspec.Struct):
        text: str
        index: Union[int, None] = 0
        logprobs: Union[int, None] = None
        finish_reason: Union[str, None] = None

    class CompletionResponse(msgspec.Struct, kw_only=True):  # type: ignore
        id: Union[str, None] = None
        object: str = "text_completion"
        created: Union[int, None] = None
        model: str
        choices: List[Choice]

        def __post_init__(self):
            if self.id is None:
                self.id = str(uuid.uuid4())
            if self.created is None:
                self.created = int(time.time())


@app.function()
@modal.fastapi_endpoint(method="POST", docs=True)  # Interactive docs at /docs
async def completions(completion_request: CompletionRequest):
    from fastapi import Response, status
    from fastapi.responses import StreamingResponse

    response_id = str(uuid.uuid4())
    response_utc = int(time.time())

    if not completion_request.stream:
        return Response(
            content=msgspec.json.encode(
                CompletionResponse(
                    id=response_id,
                    created=response_utc,
                    model=completion_request.model,
                    choices=[
                        Choice(
                            index=0,
                            text=StabilityLM().generate.remote(
                                completion_request=completion_request
                            ),
                        )
                    ],
                )
            ),
            status_code=status.HTTP_200_OK,
            media_type="application/json",
        )

    def wrapped_stream():
        for new_text in StabilityLM().generate_stream.remote(
            completion_request=completion_request
        ):
            yield (
                msgspec.json.encode(
                    CompletionResponse(
                        id=response_id,
                        created=response_utc,
                        model=completion_request.model,
                        choices=[Choice(index=0, text=new_text)],
                    )
                )
                + b"\n\n"
            )

    return StreamingResponse(
        content=wrapped_stream(),
        status_code=status.HTTP_200_OK,
        media_type="text/event-stream",
    )


@app.local_entrypoint()
def main():
    q_style, q_end = "\033[1m", "\033[0m"
    instructions = [
        "Generate a list of the 10 most beautiful cities in the world.",
        "How can I tell apart female and male red cardinals?",
    ]
    instruction_requests = [
        CompletionRequest(prompt=q, max_tokens=128) for q in instructions
    ]
    print("Running example non-streaming completions:\n")
    for q, a in zip(
        instructions, list(StabilityLM().generate.map(instruction_requests))
    ):
        print(f"{q_style}{q}{q_end}\n{a}\n\n")

    print("Running example streaming completion:\n")
    for part in StabilityLM().generate_stream.remote_gen(
        CompletionRequest(
            prompt="Generate a list of ten sure-to-be unicorn AI startup names.",
            max_tokens=128,
            stream=True,
        )
    ):
        print(part, end="", flush=True)


# ```bash
# curl $MODEL_APP_ENDPOINT \
#   -H "Content-Type: application/json" \
#   -d '{
#     "prompt": "Generate a list of 20 great names for sentient cheesecakes that teach SQL",
#     "stream": true,
#     "max_tokens": 64
#   }'
# ```


=== GITHUB: misc/lmdeploy_oai_compatible.py ===
# # Deploy a model with `lmdeploy`
#
# This script is used to deploy a model using [lmdeploy](https://github.com/InternLM/lmdeploy) with OpenAI compatible API.

import subprocess

import modal
from modal import App, Image, Secret, gpu

########## CONSTANTS ##########


# define model for serving and path to store in modal container
MODEL_NAME = "meta-llama/Llama-2-7b-hf"
MODEL_DIR = f"/models/{MODEL_NAME}"
SERVE_MODEL_NAME = "meta--llama-2-7b"
HF_SECRET = Secret.from_name("huggingface-secret")
SECONDS = 60  # for timeout


########## UTILS FUNCTIONS ##########


def download_hf_model(model_dir: str, model_name: str):
    """Retrieve model from HuggingFace Hub and save into
    specified path within the modal container.

    Args:
        model_dir (str): Path to save model weights in container.
        model_name (str): HuggingFace Model ID.
    """
    import os

    from huggingface_hub import snapshot_download  # type: ignore
    from transformers.utils import move_cache  # type: ignore

    os.makedirs(model_dir, exist_ok=True)

    snapshot_download(
        model_name,
        local_dir=model_dir,
        # consolidated.safetensors is prevent error here: https://github.com/vllm-project/vllm/pull/5005
        ignore_patterns=["*.pt", "*.bin", "consolidated.safetensors"],
        token=os.environ["HF_TOKEN"],
    )
    move_cache()


########## IMAGE DEFINITION ##########

# define image for modal environment
lmdeploy_image = (
    Image.from_registry(
        "openmmlab/lmdeploy:v0.4.2",
    )
    .pip_install(["lmdeploy[all]", "huggingface_hub", "hf-transfer"])
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        download_hf_model,
        timeout=60 * SECONDS,
        kwargs={"model_dir": MODEL_DIR, "model_name": MODEL_NAME},
        secrets=[HF_SECRET],
    )
)

########## APP SETUP ##########


app = App(f"lmdeploy-{SERVE_MODEL_NAME}")

NO_GPU = 1
TOKEN = "secret12345"


@app.function(
    image=lmdeploy_image,
    gpu=gpu.A10G(count=NO_GPU),
    scaledown_window=20 * SECONDS,
)
@modal.concurrent(max_inputs=256)  # https://modal.com/docs/guide/concurrent-inputs
@modal.web_server(port=23333, startup_timeout=60 * SECONDS)
def serve():
    cmd = f"""
    lmdeploy serve api_server {MODEL_DIR} \
        --model-name {SERVE_MODEL_NAME} \
        --server-port 23333 \
        --session-len 4092
    """
    subprocess.Popen(cmd, shell=True)


=== GITHUB: misc/tgi_oai_compatible.py ===
# # Run TGI on Modal

# This example shows how you can run LLMs with the [Text Generation Inference (TGI)](https://huggingface.co/docs/text-generation-inference/en/index) inference framework on Modal.

import subprocess

import modal
from modal import App, Image, Secret, gpu

# define model for serving and path to store in modal container
MODEL_NAME = "meta-llama/Llama-2-7b-hf"
MODEL_DIR = f"/models/{MODEL_NAME}"
SERVE_MODEL_NAME = "meta--llama-2-7b"
HF_SECRET = Secret.from_name("huggingface-secret")
SECONDS = 60  # for timeout

########## UTILS FUNCTIONS ##########


def download_hf_model(model_dir: str, model_name: str):
    """Retrieve model from HuggingFace Hub and save into
    specified path within the modal container.

    Args:
        model_dir (str): Path to save model weights in container.
        model_name (str): HuggingFace Model ID.
    """
    import os

    from huggingface_hub import snapshot_download  # type: ignore
    from transformers.utils import move_cache  # type: ignore

    os.makedirs(model_dir, exist_ok=True)

    snapshot_download(
        model_name,
        local_dir=model_dir,
        # consolidated.safetensors is prevent error here: https://github.com/vllm-project/vllm/pull/5005
        ignore_patterns=["*.pt", "*.bin", "consolidated.safetensors"],
        token=os.environ["HF_TOKEN"],
    )
    move_cache()


########## IMAGE DEFINITION ##########


# define image for modal environment
tgi_image = (
    Image.from_registry(
        "ghcr.io/huggingface/text-generation-inference", add_python="3.10"
    )
    .dockerfile_commands("ENTRYPOINT []")
    .pip_install(["huggingface_hub", "hf-transfer"])
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        download_hf_model,
        timeout=20 * SECONDS,
        kwargs={"model_dir": MODEL_DIR, "model_name": MODEL_NAME},
        secrets=[HF_SECRET],
    )
)


########## APP SETUP ##########


app = App(f"tgi-{SERVE_MODEL_NAME}")


NO_GPU = 1
TOKEN = "secret12345"


@app.function(
    image=tgi_image,
    gpu=gpu.A10G(count=NO_GPU),
    scaledown_window=20 * SECONDS,
)
@modal.concurrent(max_inputs=256)  # https://modal.com/docs/guide/concurrent-inputs
@modal.web_server(port=3000, startup_timeout=60 * SECONDS)
def serve():
    cmd = f"""
    text-generation-launcher --model-id {MODEL_DIR} \
        --hostname 0.0.0.0 \
        --port 3000
    """
    subprocess.Popen(cmd, shell=True)


=== GITHUB: misc/flux_endpoint.py ===
# ---
# lambda-test: false
# ---

# # Serve a fast FLUX.1 [dev] endpoint on Modal

# This example demonstrates how to run a high-performance FLUX.1 image generation endpoint
# on Modal GPUs. FLUX.1 is a state-of-the-art text-to-image model from Black Forest Labs
# that produces high-quality images from text prompts.

# The endpoint supports flexible image generation with various parameters
# and automatically uploads generated images to cloud storage (Cloudflare R2).

# ## Import dependencies and set up paths

# We start by importing the necessary libraries and defining our storage paths.
# We use Modal Volumes for caching model artifacts and Modal CloudBucketMounts for
# storing generated images.

from __future__ import annotations

from pathlib import Path

import modal

# Container mount directories
CONTAINER_CACHE_DIR = Path("/cache")
CONTAINER_CLOUD_MOUNT_DIR = Path("/outputs")

# Modal volume for caching compiled model artifacts and other caches across container restarts to reduce cold start times.
CONTAINER_CACHE_VOLUME = modal.Volume.from_name("flux_endpoint", create_if_missing=True)

# Configure your Cloudflare R2 bucket details here for image storage
CLOUD_BUCKET_ACCOUNT_ID = "CLOUDFLARE ACCOUNT ID"
CLOUD_BUCKET_NAME = "CLOUDFLARE R2 BUCKET NAME"

# ## Building the container image

# We start with an NVIDIA CUDA base image that includes the necessary GPU drivers
# and development tools.

# Image configuration and setup
cuda_version = "12.6.3"
flavor = "devel"
operating_system = "ubuntu24.04"
tag = f"{cuda_version}-{flavor}-{operating_system}"

nvidia_cuda_image = modal.Image.from_registry(
    f"nvidia/cuda:{tag}", add_python="3.12"
).entrypoint([])

# We then install all the Python dependencies needed for FLUX.1 inference.

flux_endpoint_image = nvidia_cuda_image.pip_install(
    "accelerate==1.6.0",
    "boto3==1.37.35",
    "diffusers==0.33.1",
    "fastapi[standard]==0.115.12",
    "huggingface-hub[hf_transfer]==0.30.2",
    "numpy==2.2.4",
    "opencv-python-headless==4.11.0.86",
    "para-attn==0.3.32",
    "pydantic==2.11.4",
    "safetensors==0.5.3",
    "sentencepiece==0.2.0",
    "torch==2.7.0",
    "transformers==4.51.3",
).env(
    {
        "HF_HUB_ENABLE_HF_TRANSFER": "1",
        "TORCHINDUCTOR_FX_GRAPH_CACHE": "1",
        "CUDA_CACHE_PATH": str(CONTAINER_CACHE_DIR / ".nv_cache"),
        "HF_HUB_CACHE": str(CONTAINER_CACHE_DIR / ".hf_hub_cache"),
        "TORCHINDUCTOR_CACHE_DIR": str(CONTAINER_CACHE_DIR / ".inductor_cache"),
        "TRITON_CACHE_DIR": str(CONTAINER_CACHE_DIR / ".triton_cache"),
    }
)

# ## Creating the Modal app

# We create a Modal App using the defined image and import necessary dependencies
# within the container's runtime environment.

app = modal.App("flux_endpoint", image=flux_endpoint_image)

with flux_endpoint_image.imports():
    import concurrent.futures
    import os
    import time
    import uuid
    from enum import Enum
    from typing import Optional

    import boto3
    import cv2
    import numpy as np
    import torch
    from diffusers import FluxPipeline
    from para_attn.first_block_cache.diffusers_adapters import apply_cache_on_pipe
    from pydantic import BaseModel, Field

    # Supported output formats for generated images
    class OutputFormat(Enum):
        PNG = "PNG"
        JPG = "JPG"
        WEBP = "WEBP"

    # ### Defining request/response model

    # We use Pydantic to define a strongly-typed request model. This gives us
    # automatic validation for our API endpoint.

    class InferenceRequest(BaseModel):
        prompt: str
        prompt2: Optional[str] = None
        negative_prompt: Optional[str] = None
        negative_prompt2: Optional[str] = None
        true_cfg_scale: float = Field(default=1.0, ge=0.0, le=20.0, multiple_of=0.1)
        height: int = Field(default=1024, ge=256, le=1024, multiple_of=16)
        width: int = Field(default=1024, ge=256, le=1024, multiple_of=16)
        steps: int = Field(default=28, ge=1, le=50)
        guidance_scale: float = Field(default=3.5, ge=0.0, le=20.0, multiple_of=0.1)
        num_images: int = Field(default=1, ge=1, le=4)
        seed: Optional[int] = None
        output_format: OutputFormat = Field(default=OutputFormat.PNG)
        output_quality: int = Field(default=90, ge=1, le=100)

# ## The FluxService class

# This class handles model loading, optimization, and inference. We use Modal's
# class decorator to control the lifecycle of our cloud container as well as to
# configure auto-scaling parameters, the GPU type, and necessary secrets.


@app.cls(
    secrets=[
        modal.Secret.from_name("huggingface-secret"),
        modal.Secret.from_name(
            "r2-secret", required_keys=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"]
        ),
    ],
    gpu="H100",
    volumes={
        CONTAINER_CACHE_DIR: CONTAINER_CACHE_VOLUME,
        CONTAINER_CLOUD_MOUNT_DIR: modal.CloudBucketMount(
            bucket_name=CLOUD_BUCKET_NAME,
            bucket_endpoint_url=f"https://{CLOUD_BUCKET_ACCOUNT_ID}.r2.cloudflarestorage.com",
            secret=modal.Secret.from_name(
                "r2-secret",
                required_keys=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"],
            ),
        ),
    },
    min_containers=1,
    buffer_containers=0,
    scaledown_window=300,  # 5 minutes
    timeout=3600,  # 1 hour
    enable_memory_snapshot=True,
)
class FluxService:
    # ## Model optimization methods

    # These methods apply various optimizations to make model inference faster.
    # The main optimizations are first block cache and torch compile.

    def _optimize(self):
        # apply first block cache, see: [ParaAttention](https://github.com/chengzeyi/ParaAttention)
        apply_cache_on_pipe(
            self.pipe,
            residual_diff_threshold=0.12,  # don't recommend going higher
        )

        # fuse qkv projections
        self.pipe.transformer.fuse_qkv_projections()
        self.pipe.vae.fuse_qkv_projections()

        # use channels last memory format
        self.pipe.transformer.to(memory_format=torch.channels_last)
        self.pipe.vae.to(memory_format=torch.channels_last)

        # torch compile configs
        config = torch._inductor.config
        config.conv_1x1_as_mm = True
        config.coordinate_descent_check_all_directions = True
        config.coordinate_descent_tuning = True
        config.disable_progress = False
        config.epilogue_fusion = False
        config.shape_padding = True

        # mark layers for compilation with dynamic shapes enabled
        self.pipe.transformer = torch.compile(
            self.pipe.transformer, mode="max-autotune-no-cudagraphs", dynamic=True
        )

        self.pipe.vae.decode = torch.compile(
            self.pipe.vae.decode, mode="max-autotune-no-cudagraphs", dynamic=True
        )

    def _compile(self):
        # monkey-patch torch inductor remove_noop_ops pass for para-attn dynamic compilation
        # swallow AttributeError: 'SymFloat' object has no attribute 'size' and return false
        from torch._inductor.fx_passes import post_grad

        if not hasattr(post_grad, "_orig_same_meta"):
            post_grad._orig_same_meta = post_grad.same_meta

            def _safe_same_meta(node1, node2):
                try:
                    return post_grad._orig_same_meta(node1, node2)
                except AttributeError as e:
                    if "SymFloat" in str(e) and "size" in str(e):
                        # return not the same, instead of crashing
                        return False
                    raise

            post_grad.same_meta = _safe_same_meta

        print("triggering torch compile")
        self.pipe("dummy prompt", height=1024, width=1024, num_images_per_prompt=1)

        # comment this out if you only need num_images_per_prompt=1
        print("recompiling for dynamic batch size")
        self.pipe("dummy prompt", height=1024, width=1024, num_images_per_prompt=2)

    # ## Mega-cache management

    # PyTorch "mega-cache" serializes compiled model artifacts into a blob that
    # can be easily transferred to another machine with the same GPU.

    def _load_mega_cache(self):
        print("loading torch mega-cache")
        try:
            if self.mega_cache_bin_path.exists():
                with open(self.mega_cache_bin_path, "rb") as f:
                    artifact_bytes = f.read()

                if artifact_bytes:
                    torch.compiler.load_cache_artifacts(artifact_bytes)
            else:
                print("torch mega cache not found, regenerating...")
        except Exception as e:
            print(f"error loading torch mega-cache: {e}")

    def _save_mega_cache(self):
        print("saving torch mega-cache")
        try:
            artifacts = torch.compiler.save_cache_artifacts()
            artifact_bytes, _ = artifacts

            with open(self.mega_cache_bin_path, "wb") as f:
                f.write(artifact_bytes)

            # persist changes to volume
            CONTAINER_CACHE_VOLUME.commit()
        except Exception as e:
            print(f"error saving torch mega-cache: {e}")

    # ## Memory Snapshotting

    # We utilize memory snapshotting to avoid reloading model weights into host memory
    # during subsequent container starts.

    @modal.enter(snap=True)
    def load(self):
        print("downloading (if necessary) and loading model")
        self.pipe = FluxPipeline.from_pretrained(
            "black-forest-labs/FLUX.1-dev",
            torch_dtype=torch.bfloat16,
            use_safetensors=True,
        ).to("cpu")

        # Set up mega cache paths
        mega_cache_dir = CONTAINER_CACHE_DIR / ".mega_cache"
        mega_cache_dir.mkdir(parents=True, exist_ok=True)
        self.mega_cache_bin_path = mega_cache_dir / "flux_torch_mega"

    @modal.enter(snap=False)
    def setup(self):
        self.pipe.to("cuda")

        self._load_mega_cache()
        self._optimize()
        self._compile()
        self._save_mega_cache()

        # Initialize S3 client for R2 storage
        try:
            self.s3_client = boto3.client(
                service_name="s3",
                endpoint_url=f"https://{CLOUD_BUCKET_ACCOUNT_ID}.r2.cloudflarestorage.com",
                aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"],
                aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"],
                region_name="auto",
            )
        except Exception as e:
            print(f"Error initiating s3 client: {e}")
            raise

    # ## The main inference endpoint

    # This method handles incoming requests, generates images, and uploads them
    # to cloud storage.

    @modal.fastapi_endpoint(method="POST")
    def inference(self, request: InferenceRequest):
        generator = (
            torch.Generator("cuda").manual_seed(request.seed)
            if request.seed is not None
            else None
        )

        # Time the inference
        torch.cuda.synchronize()
        t0 = time.perf_counter()

        # Generate images using the FLUX pipeline
        images = self.pipe(
            prompt=request.prompt,
            prompt_2=request.prompt2,
            negative_prompt=request.negative_prompt,
            negative_prompt_2=request.negative_prompt2,
            true_cfg_scale=request.true_cfg_scale,
            height=request.height,
            width=request.width,
            num_inference_steps=request.steps,
            guidance_scale=request.guidance_scale,
            num_images_per_prompt=request.num_images,
            generator=generator,
            output_type="np",
        ).images

        torch.cuda.synchronize()
        print(f"inference time: {time.perf_counter() - t0:.2f}s")
        t1 = time.perf_counter()

        # Process and upload images to cloud storage
        image_urls = []
        CONTAINER_CLOUD_MOUNT_DIR.mkdir(parents=True, exist_ok=True)

        # image processing
        def process_image(image):
            # Generate unique filename
            filename = str(uuid.uuid4())
            filename_with_ext = f"{filename}.{request.output_format.value.lower()}"
            output_path = CONTAINER_CLOUD_MOUNT_DIR / filename_with_ext

            # Convert to uint8 and BGR format for OpenCV
            image_np = (image * 255).astype(np.uint8)
            image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)

            # Set encoding parameters based on format
            match request.output_format:
                case OutputFormat.JPG:
                    params = [cv2.IMWRITE_JPEG_QUALITY, request.output_quality]
                case OutputFormat.WEBP:
                    params = [cv2.IMWRITE_WEBP_QUALITY, request.output_quality]
                case _:
                    params = []

            # Save image using OpenCV
            cv2.imwrite(str(output_path), image_bgr, params)

            # Generate a signed URL for the uploaded image
            # This allows clients to download the image directly from R2
            signed_url = self.s3_client.generate_presigned_url(
                "get_object",
                Params={"Bucket": CLOUD_BUCKET_NAME, "Key": filename_with_ext},
                ExpiresIn=86400,  # 24 hour expiry
            )
            return signed_url

        # process images in parallel
        with concurrent.futures.ThreadPoolExecutor() as executor:
            image_urls = list(executor.map(process_image, images))

        torch.cuda.synchronize()
        print(f"image processing and cloud save time: {time.perf_counter() - t1:.2f}s")
        return image_urls


=== GITHUB: misc/news_summarizer.py ===
# # News article summarizer
#
# In this example we scrape news articles from the [New York Times'
# Science section](https://www.nytimes.com/section/science) and summarize them
# using Google's deep learning summarization model [Pegasus](https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html).
# We log the resulting summaries to the terminal, but you can do whatever you want with the
# summaries afterwards: saving to a CSV file, sending to Slack, etc.

import os
import re
from dataclasses import dataclass
from typing import List

import modal

app = modal.App(name="example-news-summarizer")

# ## Building Images and Downloading Pre-trained Model
#
# We start by defining our images. In Modal, each function can use a different
# image. This is powerful because you add only the dependencies you need for
# each function.

# The first image contains dependencies for running our model. We also download the
# pre-trained model into the image using the `from_pretrained` method.
# This caches the model so that we don't have to download it on every function call.
# The model will be saved at `/cache` when this function is called at image build time;
# subsequent calls of this function at runtime will then load the model from `/cache`.


def fetch_model(local_files_only: bool = False):
    from transformers import PegasusForConditionalGeneration, PegasusTokenizer

    tokenizer = PegasusTokenizer.from_pretrained(
        "google/pegasus-xsum",
        cache_dir="/cache",
        local_files_only=local_files_only,
    )
    model = PegasusForConditionalGeneration.from_pretrained(
        "google/pegasus-xsum",
        cache_dir="/cache",
        local_files_only=local_files_only,
    )
    return model, tokenizer


deep_learning_image = (
    modal.Image.debian_slim()
    .pip_install("transformers==4.16.2", "torch", "sentencepiece")
    .run_function(fetch_model)
)

# Defining the scraping image is very similar. This image only contains the packages required
# to scrape the New York Times website, though; so it's much smaller.
scraping_image = modal.Image.debian_slim().pip_install(
    "requests", "beautifulsoup4", "lxml"
)


with scraping_image.imports():
    import requests
    from bs4 import BeautifulSoup


# ## Collect Data
#
# Collecting data happens in two stages: first a list of URL articles
# using the NYT API then scrape the NYT web page for each of those articles
# to collect article texts.


@dataclass
class NYArticle:
    title: str
    image_url: str = ""
    url: str = ""
    summary: str = ""
    text: str = ""


# In order to connect to the NYT API, you will need to sign up at [NYT Developer Portal](https://developer.nytimes.com/),
# create an App then grab an API key. Then head to Modal and create a [Secret](https://modal.com/docs/guide/secrets) called `nytimes`.
# Create an environment variable called `NYTIMES_API_KEY` with your API key.


@app.function(
    secrets=[modal.Secret.from_name("nytimes")],
    image=scraping_image,
)
def latest_science_stories(n_stories: int = 5) -> List[NYArticle]:
    # query api for latest science articles
    params = {
        "api-key": os.environ["NYTIMES_API_KEY"],
    }
    nyt_api_url = "https://api.nytimes.com/svc/topstories/v2/science.json"
    response = requests.get(nyt_api_url, params=params)

    # extract data from articles and return list of NYArticle objects
    results = response.json()
    reject_urls = {"null", "", None}
    articles = [
        NYArticle(
            title=u["title"],
            image_url=(u.get("multimedia")[0]["url"] if u.get("multimedia") else ""),
            url=u.get("url"),
        )
        for u in results["results"]
        if u.get("url") not in reject_urls
    ]

    # select only a handful of articles; this usually returns 25 articles
    articles = articles[:n_stories]
    print(f"Retrieved {len(articles)} from the NYT Top Stories API")
    return articles


# The NYT API only gives us article URLs but it doesn't include the article text. We'll get the article URLs
# from the API then scrape each URL for the article body. We'll be using
# [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for that.


@app.function(image=scraping_image)
def scrape_nyc_article(url: str) -> str:
    print(f"Scraping article => {url}")

    # fetch article; simulate desktop browser
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9"
    }
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "lxml")

    # get all text paragraphs & construct single string with article text
    article_text = ""
    article_section = soup.find_all(
        "div", {"class": re.compile(r"\bStoryBodyCompanionColumn\b")}
    )
    if article_section:
        paragraph_tags = article_section[0].find_all("p")
        article_text = " ".join([p.get_text() for p in paragraph_tags])

    # return article with scraped text
    return article_text


# Now the summarization function. We use `huggingface`'s Pegasus tokenizer and model implementation to
# generate a summary of the model. You can learn more about Pegasus does in the [HuggingFace
# documentation](https://huggingface.co/docs/transformers/model_doc/pegasus). Use `gpu="any"` to speed-up inference.


@app.function(
    image=deep_learning_image,
    gpu=False,
    memory=4096,
)
def summarize_article(text: str) -> str:
    print(f"Summarizing text with {len(text)} characters.")

    # `local_files_only` is set to `True` because we expect to read the model
    # files saved in the image.
    model, tokenizer = fetch_model(local_files_only=True)

    # summarize text
    batch = tokenizer(
        [text], truncation=True, padding="longest", return_tensors="pt"
    ).to("cpu")
    translated = model.generate(**batch)
    summary = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]

    return summary


# ## Create a Scheduled Function
#
# Put everything together and schedule it to run every day. You can also use `modal.Cron` for a
# more advanced scheduling interface.


@app.function(schedule=modal.Period(days=1))
def trigger():
    articles = latest_science_stories.remote()

    # parallelize article scraping
    for i, text in enumerate(scrape_nyc_article.map([a.url for a in articles])):
        articles[i].text = text

    # parallelize summarization
    for i, summary in enumerate(
        summarize_article.map([a.text for a in articles if len(a.text) > 0])
    ):
        articles[i].summary = summary

    # show all summaries in the terminal
    for article in articles:
        print(f'Summary of "{article.title}" => {article.summary}')


# Create a new Modal scheduled function with:
#
# ```shell
# modal deploy --name news_summarizer news_summarizer.py
# ```

# You can also run this entire Modal app in debugging mode before.
# call it with `modal run news_summarizer.py`


@app.local_entrypoint()
def main():
    trigger.remote()


# And that's it. You will now generate deep learning summaries from the latest
# NYT Science articles every day.


=== GITHUB: misc/ollama_deployment.py ===
# # Deploy Ollama service on Modal
#
# This example shows how to deploy Ollama (https://ollama.com/) as a Modal web service,
# allowing you to run and interact with open source large language models with GPU acceleration.
#
# ## Overview
#
# This script creates a Modal application that:
#
# 1. Sets up an Ollama server as a web service
# 2. Uses a persistent volume to store model weights
# 3. Provides a method to pull new models to the service
# 4. Automatically scales down when not in use
#
# ## Usage
#
# To run this example:
#
# ```bash
# modal deploy misc/ollama_deployment.py
# ```
#
# To pull a model (e.g., llama3):
#
# ```bash
# modal run misc/ollama_deployment.py::OllamaService.pull_model --model-name llama3
# ```
#
# You can then interact with the Ollama API using standard HTTP requests.

import subprocess
import time

import modal

# Define the base image with Ollama installed
image = (
    modal.Image.debian_slim(python_version="3.12")
    .apt_install("curl", "systemctl")
    .run_commands(
        "curl -fsSL https://ollama.com/install.sh | sh",
    )
    .pip_install("httpx", "loguru")
    .env(
        {
            "OLLAMA_HOST": "0.0.0.0:11434",  # Configure Ollama to listen on all interfaces
            "OLLAMA_MODELS": "/usr/share/ollama/.ollama/models",  # Set models directory
        }
    )
)

# Create a persistent volume to store model weights
volume = modal.Volume.from_name("ollama-model-weights", create_if_missing=True)

# Create the Modal application
app = modal.App(name="ollama-service", image=image)


def wait_for_ollama(timeout: int = 30, interval: int = 2) -> None:
    """Wait for Ollama service to be ready.

    :param timeout: Maximum time to wait in seconds
    :param interval: Time between checks in seconds
    :raises TimeoutError: If the service doesn't start within the timeout period
    """
    import httpx
    from loguru import logger

    start_time = time.time()
    while True:
        try:
            response = httpx.get("http://localhost:11434/api/version")
            if response.status_code == 200:
                logger.info("Ollama service is ready")
                return
        except httpx.ConnectError:
            if time.time() - start_time > timeout:
                raise TimeoutError("Ollama service failed to start")
            logger.info(
                f"Waiting for Ollama service... ({int(time.time() - start_time)}s)"
            )
            time.sleep(interval)


@app.cls(
    scaledown_window=10,  # Automatically scale down after 10 seconds of inactivity
    volumes={
        "/usr/share/ollama/.ollama/models": volume
    },  # Mount volume for model storage
    memory=1024 * 1,  # Allocate 1GB of memory
    gpu="A10G",  # Use A10G GPU for model inference
)
class OllamaService:
    """Main service class that runs Ollama within Modal."""

    @modal.enter()
    def enter(self):
        """Start the Ollama server when the container is created."""
        subprocess.Popen(["ollama", "serve"])

    @modal.method()
    def pull_model(self, model_name: str):
        """Pull a model from Ollama's model hub.

        :param model_name: Name of the model to pull (e.g., "llama3", "mistral")
        """
        subprocess.run(["echo", "pulling model", model_name])
        subprocess.run(["ollama", "pull", model_name])

    @modal.web_server(11434)
    def server(self):
        """Expose the Ollama API as a web server on port 11434."""
        pass


=== GITHUB: misc/xgboost_optuna_search.py ===
# # Distributed Hyperparameter Optimization with Optuna & XGBoost

# [Optuna](https://optuna.org) is an open-source Python framework designed to automate the process
# of finding the optimal hyperparameters for machine learning models.

# This example demonstrates how to parallelize your hyperparameter search with Optuna on Modal with XGBoost,
# [Hyperband pruning](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.HyperbandPruner.html),
# and access to the Optuna Dashboard. Pruning automatically stops unpromising trials at the early stages of training,
# saving on compute time.

# ## Defining the App

# We start by defining the image and Modal app.

from pathlib import Path

import modal

image = modal.Image.debian_slim(python_version="3.12").pip_install(
    "optuna==4.3.0",
    "scikit-learn==1.6.1",
    "numpy==2.2.5",
    "xgboost==3.0.0",
    "optuna-dashboard==0.18.0",
)
app = modal.App("xgboost-optuna-prune", image=image)

# We create a Modal Volume to hold Optuna's
# [JournalStorage](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.storages.JournalStorage.html)
# to track the trials and hyperparameters.

volume = modal.Volume.from_name("xgboost-optuna-logs-prune", create_if_missing=True)
DATA_DIR = Path("/data")
JOURNAL_STORAGE_LOG = DATA_DIR / ".log"

# ## Optuna Worker

# For this example, we restrict the number of containers to 20 and run 500 trials.

CONCURRENCY = 20
N_TRIALS = 500

# The Optuna worker is responsible for:
# 1. Evaluating a specific hyperparameter configuration.
# 2. Loading the dataset into memory during startup, so that the data stays warm for future trials.
# 3. For each XGBoost iteration, call back into the Optuna head to define if the current evaluation should be pruned


@app.cls(cpu=4, memory=1024, max_containers=CONCURRENCY)
class OptunaWorker:
    @modal.enter()
    def load_data(self):
        """Loads the data into memory during startup. Here we use a simple digits dataset. For large production
        datasets, we recommend saving your data into a modal Volume and loading the data from the Volume."""
        import xgboost as xgb
        from sklearn.datasets import load_digits
        from sklearn.model_selection import train_test_split

        X, y = load_digits(return_X_y=True)

        X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42)
        self.dtrain = xgb.DMatrix(X_train, label=y_train)
        self.dvalid = xgb.DMatrix(X_valid, label=y_valid)

    @modal.method()
    def evaluate(self, params: dict, trial_number: int) -> float:
        """Evaluates the XGBoost model for `params`."""
        import numpy as np
        import xgboost as xgb
        from sklearn.metrics import accuracy_score

        # An XGBoost callback that checks whether the run should be pruned
        class XGBoostPruningCallback(xgb.callback.TrainingCallback):
            def __init__(self, head, observation_key: str, trial_number: int):
                self.observation_key = observation_key
                self.head = head
                self.trial_number = trial_number

            def after_iteration(
                self, model: xgb.Booster, epoch: int, evals_log: dict
            ) -> bool:
                evaluation_results = {}
                for dataset, metrics in evals_log.items():
                    for metric, scores in metrics.items():
                        key = dataset + "-" + metric
                        assert isinstance(scores, list), scores
                        evaluation_results[key] = scores[-1]

                current_score = evaluation_results[self.observation_key]

                # The Optuna head defines a `should_prune` method that signals to the worker, if it should prune
                should_prune = self.head.should_prune.remote(
                    current_score, epoch, self.trial_number
                )
                return should_prune

        optuna_head = OptunaHead()
        pruning_callback = XGBoostPruningCallback(
            optuna_head,
            observation_key="validation-merror",
            trial_number=trial_number,
        )

        bst = xgb.train(
            params,
            self.dtrain,
            evals=[(self.dvalid, "validation")],
            callbacks=[pruning_callback],
        )
        preds = bst.predict(self.dvalid)
        pred_labels = np.rint(preds)
        return float(accuracy_score(self.dvalid.get_label(), pred_labels))


# ## Optuna Head

# The Optuna Head object is responsible for:
# 1. Keeping track of the results of the trials.
# 2. Decide when a trial should be pruned.
# 3. Run an optuna dashboard to visualize the progress and trials.
# 4. Concurrently, spawn Optuna workers with a concurrency limit of `CONCURRENCY`.

import asyncio
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import optuna


# The Optuna head requires a consistent state to manage the running trials, so we restrict the number of
# containers to one and allow it to take multiple inputs. With multiple inputs, this one container can handle
# all the requests from the optuna dashboard and the worker's can all `should_prune` at the same time.


@app.cls(cpu=2, memory=2048, volumes={"/data": volume}, max_containers=1)
@modal.concurrent(max_inputs=1000)
class OptunaHead:
    @modal.enter()
    def create_study(self):
        """Define the optuna study."""
        DATA_DIR.mkdir(exist_ok=True)
        JOURNAL_STORAGE_LOG.touch(exist_ok=True)
        import os

        import optuna
        from optuna.storages import JournalStorage
        from optuna.storages.journal import JournalFileBackend

        # Keeps track of the running trials
        self.trials: dict[int, optuna.Trial] = {}

        storage = JournalStorage(JournalFileBackend(os.fspath(JOURNAL_STORAGE_LOG)))
        pruner = optuna.pruners.HyperbandPruner()
        self.study = optuna.create_study(
            direction="maximize",
            study_name="xgboost-optuna",
            storage=storage,
            pruner=pruner,
            load_if_exists=True,
        )

    @modal.method()
    def should_prune(
        self, intermediate_value: float, step: int, trial_number: int
    ) -> bool:
        """Return True if a trial should be pruned."""
        try:
            trial = self.trials[trial_number]
            trial.report(intermediate_value, step)
            return trial.should_prune()
        except KeyError:
            return False

    async def spawn_worker(self, semaphore: asyncio.Semaphore):
        """Ask the study for a trial and spawn a Optuna worker to evaluate it. The semaphore is used to
        restrict the number of workers at the Python level. This enables the current workers to report back their
        results and inform the hyperparameters for future trials."""
        import optuna

        async with semaphore:
            trial = await asyncio.to_thread(self.study.ask)
            self.trials[trial.number] = trial
            params = await asyncio.to_thread(self.get_param_from_trial, trial)

            try:
                result = await OptunaWorker().evaluate.remote.aio(
                    params, trial_number=trial.number
                )
                await asyncio.to_thread(
                    self.study.tell,
                    trial,
                    result,
                    state=optuna.trial.TrialState.COMPLETE,
                )
                print(f"Completed with: {result}, {trial.params}")
            except Exception:
                await asyncio.to_thread(
                    self.study.tell, trial, state=optuna.trial.TrialState.FAIL
                )
                print(f"Failed with: {trial.params}")

            del self.trials[trial.number]

    @modal.method()
    async def run_trials(self):
        """Entry point for running `N_TRIALS` trials."""
        semaphore = asyncio.Semaphore(CONCURRENCY)
        trials = [self.spawn_worker(semaphore) for _ in range(N_TRIALS)]

        await asyncio.gather(*trials)

    @modal.web_server(port=8000, startup_timeout=30)
    def optuna_dashboard(self):
        """Entry point for the optuna dashboard."""
        volume.reload()
        import os
        import subprocess
        from shutil import which

        optuna_dashboard = which("optuna-dashboard")
        assert optuna_dashboard is not None

        cmd = [
            optuna_dashboard,
            os.fspath(JOURNAL_STORAGE_LOG),
            "--host",
            "0.0.0.0",
            "--port",
            "8000",
        ]

        subprocess.Popen(" ".join(cmd), shell=True)

    def get_param_from_trial(self, trial: "optuna.Trial") -> dict:
        """Helper method to get a hyperparameter configuration from a optuna Trial."""
        param = {
            "objective": "multi:softmax",
            "num_class": 10,
            "eval_metric": "merror",
            "booster": trial.suggest_categorical("booster", ["gbtree", "dart"]),
            "lambda": trial.suggest_float("lambda", 1e-8, 1.0, log=True),
            "alpha": trial.suggest_float("alpha", 1e-8, 1.0, log=True),
            "max_depth": trial.suggest_int("max_depth", 3, 9),
            "eta": trial.suggest_float("eta", 0.01, 0.3, log=True),
            "gamma": trial.suggest_float("gamma", 1e-8, 1.0, log=True),
            "grow_policy": trial.suggest_categorical(
                "grow_policy", ["depthwise", "lossguide"]
            ),
            "subsample": trial.suggest_float("subsample", 0.5, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
            "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
            "tree_method": "hist",
        }

        if param["booster"] == "dart":
            param["sample_type"] = trial.suggest_categorical(
                "sample_type", ["uniform", "weighted"]
            )
            param["normalize_type"] = trial.suggest_categorical(
                "normalize_type", ["tree", "forest"]
            )
            param["rate_drop"] = trial.suggest_float("rate_drop", 1e-8, 1.0, log=True)
            param["skip_drop"] = trial.suggest_float("skip_drop", 1e-8, 1.0, log=True)
        return param


# ## Deploying and Running the Hyperparameter search

# We deploy this Optuna App by running: `modal deploy xgboost_optuna_search.py`. This will give you access to
# the optuna dashboard. Finally, we trigger the hyperparameter search by running `python xgboost_optuna_search.py`.
# This runs the following code, which calls `run_trials` on the Optuna head node.

if __name__ == "__main__":
    head = modal.Cls.from_name("xgboost-optuna-prune", "OptunaHead")()
    fc = head.run_trials.spawn()
    print("Called with function id", fc.object_id)


=== GITHUB: misc/falcon_bitsandbytes.py ===
# ---
# args: ["--prompt", "How do planes work?"]
# ---
# # Run Falcon-40B with bitsandbytes
#
# In this example, we download the full-precision weights of the Falcon-40B LLM but load it in 4-bit using
# Tim Dettmers' [`bitsandbytes`](https://github.com/TimDettmers/bitsandbytes) library. This enables it to fit
# into a single GPU (A100 40GB).
#
# Due to the current limitations of the library, the inference speed is a little over 2 tokens/second and due
# to the sheer size of the model, the cold start time on Modal is around 2 minutes.
#
# For faster cold start at the expense of inference speed, check out
# [Running Falcon-40B with AutoGPTQ](https://modal.com/docs/examples/falcon_gptq).
#
# ## Setup
#
# First we import the components we need from `modal`.

from typing import Optional

import modal


# Spec for an image where falcon-40b-instruct is cached locally
def download_falcon_40b():
    from huggingface_hub import snapshot_download

    model_name = "tiiuae/falcon-40b-instruct"
    snapshot_download(model_name)


image = (
    modal.Image.micromamba()
    .micromamba_install(
        "cudatoolkit=11.7",
        "cudnn=8.1.0",
        "cuda-nvcc",
        "scipy",
        channels=["conda-forge", "nvidia"],
    )
    .apt_install("git")
    .pip_install(
        "bitsandbytes==0.39.0",
        "bitsandbytes-cuda117==0.26.0.post2",
        "peft==0.6.2",
        "transformers==4.31.0",
        "accelerate==0.26.1",
        "hf-transfer==0.1.5",
        "torch==2.0.0",
        "torchvision==0.15.1",
        "sentencepiece==0.1.97",
        "huggingface_hub==0.14.1",
        "einops==0.6.1",
    )
    # Use huggingface's hi-perf hf-transfer library to download this large model.
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(download_falcon_40b)
)

app = modal.App(image=image, name="example-falcon-bnb")


# ## The model class
#
# Next, we write the model code. We want Modal to load the model into memory just once every time a container starts up,
# so we use [class syntax](https://modal.com/docs/guide/lifecycle-functions) and the `@enter` decorator.
#
# Within the [@app.cls](https://modal.com/docs/reference/modal.App#cls) decorator, we use the [gpu parameter](/docs/guide/gpu)
# to specify that we want to run our function on an [A100 GPU](https://modal.com/docs/guide/gpu). We also allow each call 10 mintues to complete,
# and request the runner to stay live for 5 minutes after its last request.
#
# We load the model in 4-bit using the `bitsandbytes` library.
#
# The rest is just using the [`pipeline`](https://huggingface.co/docs/transformers/en/main_classes/pipelines)
# abstraction from the `transformers` library. Refer to the documentation for more parameters and tuning.
@app.cls(
    gpu="A100",
    timeout=60 * 10,  # 10 minute timeout on inputs
    scaledown_window=60 * 5,  # Keep runner alive for 5 minutes
)
class Falcon40B_4bit:
    @modal.enter()
    def load_model(self):
        import torch
        from transformers import (
            AutoModelForCausalLM,
            AutoTokenizer,
            BitsAndBytesConfig,
        )

        model_name = "tiiuae/falcon-40b-instruct"

        nf4_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_use_double_quant=False,
            bnb_4bit_compute_dtype=torch.bfloat16,
        )

        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            trust_remote_code=True,
            local_files_only=True,  # Model is downloaded to cache dir
            device_map="auto",
            quantization_config=nf4_config,
        )
        model.eval()

        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True,
            local_files_only=True,
            device_map="auto",
        )
        tokenizer.bos_token_id = 1

        self.model = torch.compile(model)
        self.tokenizer = tokenizer

    @modal.method()
    def generate(self, prompt: str):
        from threading import Thread

        from transformers import GenerationConfig, TextIteratorStreamer

        tokenized = self.tokenizer(prompt, return_tensors="pt")
        input_ids = tokenized.input_ids
        input_ids = input_ids.to(self.model.device)

        generation_config = GenerationConfig(
            do_sample=True,
            temperature=0.1,
            max_new_tokens=512,
        )

        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True)
        generate_kwargs = dict(
            input_ids=input_ids,
            generation_config=generation_config,
            return_dict_in_generate=True,
            eos_token_id=self.tokenizer.eos_token_id,
            pad_token_id=self.tokenizer.eos_token_id,
            bos_token_id=self.tokenizer.bos_token_id,
            attention_mask=tokenized.attention_mask,
            output_scores=True,
            streamer=streamer,
        )

        thread = Thread(target=self.model.generate, kwargs=generate_kwargs)
        thread.start()
        for new_text in streamer:
            print(new_text, end="")
            yield new_text

        thread.join()


# ## Run the model
# We define a [`local_entrypoint`](https:modal.com/docs/guide/apps#entrypoints-for-ephemeral-apps) to call our remote function
# sequentially for a list of inputs. You can run this locally with `modal run -q falcon_bitsandbytes.py`. The `-q` flag
# enables streaming to work in the terminal output.
prompt_template = (
    "A chat between a curious human user and an artificial intelligence assistant. The assistant give a helpful, detailed, and accurate answer to the user's question."
    "\n\nUser:\n{}\n\nAssistant:\n"
)


@app.local_entrypoint()
def cli(prompt: Optional[str] = None):
    question = (
        prompt
        or "What are the main differences between Python and JavaScript programming languages?"
    )
    model = Falcon40B_4bit()
    for text in model.generate.remote_gen(prompt_template.format(question)):
        print(text, end="", flush=True)


# ## Serve the model
# Finally, we can serve the model from a web endpoint with `modal deploy falcon_bitsandbytes.py`. If
# you visit the resulting URL with a question parameter in your URL, you can view the model's
# stream back a response.
# You can try our deployment [here](https://modal-labs--example-falcon-bnb-get.modal.run/?question=How%20do%20planes%20work?).
@app.function(timeout=60 * 10)
@modal.fastapi_endpoint()
def get(question: str):
    from itertools import chain

    from fastapi.responses import StreamingResponse

    model = Falcon40B_4bit()
    return StreamingResponse(
        chain(
            ("Loading model (100GB). This usually takes around 110s ...\n\n"),
            model.generate.remote(prompt_template.format(question)),
        ),
        media_type="text/event-stream",
    )


=== GITHUB: misc/say_hello_cron.py ===
# # Deploy a cron job with Modal

# This example shows how you can deploy a cron job with Modal.

import time
from datetime import datetime, timezone

import modal

app = modal.App("example-say-hello-cron")


@app.function(schedule=modal.Period(seconds=10))
def say_hello():
    start_time = datetime.now(timezone.utc)
    for i in range(10):
        print(f"Message #{i} from invocation at {start_time}")
        time.sleep(1.5)


=== GITHUB: misc/trellis3d.py ===
"This example originally contributed by @sandeeppatra96 and @patraxo on GitHub"

import logging
import tempfile
import traceback

import modal
import requests
from fastapi import HTTPException, Request, Response, status

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

REPO_URL = "https://github.com/microsoft/TRELLIS.git"
MODEL_NAME = "JeffreyXiang/TRELLIS-image-large"
TRELLIS_DIR = "/trellis"
MINUTES = 60
HOURS = 60 * MINUTES

cuda_version = "12.2.0"
flavor = "devel"
os_version = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{os_version}"


def clone_repository():
    import subprocess

    subprocess.run(
        ["git", "clone", "--recurse-submodules", REPO_URL, TRELLIS_DIR],
        check=True,
    )


# The specific version of torch==2.4.0 to circumvent the flash attention wheel build error

trellis_image = (
    modal.Image.from_registry(f"nvidia/cuda:{tag}", add_python="3.10")
    .apt_install(
        "git",
        "ffmpeg",
        "cmake",
        "clang",
        "build-essential",
        "libgl1-mesa-glx",
        "libglib2.0-0",
        "libgomp1",
        "libxrender1",
        "libxext6",
        "ninja-build",
    )
    .pip_install("packaging", "ninja", "torch==2.4.0", "wheel", "setuptools")
    .env(
        {
            # "MAX_JOBS": "16", # in case flash attention takes more time to build
            "HF_HUB_ENABLE_HF_TRANSFER": "1",
            "CC": "clang",
            "CXX": "clang++",
            "CUDAHOSTCXX": "clang++",
            "CUDA_HOME": "/usr/local/cuda-12.2",
            "CPATH": "/usr/local/cuda-12.2/targets/x86_64-linux/include",
            "LIBRARY_PATH": "/usr/local/cuda-12.2/targets/x86_64-linux/lib64",
            "LD_LIBRARY_PATH": "/usr/local/cuda-12.2/targets/x86_64-linux/lib64",
            "CFLAGS": "-Wno-narrowing",
            "CXXFLAGS": "-Wno-narrowing",
            "ATTN_BACKEND": "flash-attn",  # or 'xformers'
            "SPCONV_ALGO": "native",  # or 'auto'
        }
    )
    .pip_install("flash-attn==2.6.3", extra_options="--no-build-isolation")
    .pip_install(
        "git+https://github.com/EasternJournalist/utils3d.git@9a4eb15e4021b67b12c460c7057d642626897ec8",
        "numpy",
        "pillow",
        "imageio",
        "onnxruntime",
        "trimesh",
        "safetensors",
        "easydict",
        "scipy",
        "tqdm",
        "einops",
        "xformers",
        "hf_transfer",
        "opencv-python-headless",
        "largesteps",
        "spconv-cu118",
        "rembg",
        "torchvision",
        "imageio-ffmpeg",
        "xatlas",
        "pyvista",
        "pymeshfix",
        "igraph",
        "git+https://github.com/NVIDIAGameWorks/kaolin.git",
        "https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/nvdiffrast-0.3.3-cp310-cp310-linux_x86_64.whl",
        # "git+https://github.com/NVlabs/nvdiffrast.git", # build failed
        "huggingface-hub",
        "https://github.com/camenduru/wheels/releases/download/3090/diso-0.1.4-cp310-cp310-linux_x86_64.whl",
        "https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/diff_gaussian_rasterization-0.0.0-cp310-cp310-linux_x86_64.whl",
    )
    .pip_install("fastapi[standard]==0.115.6")
    .entrypoint([])
    .run_function(clone_repository)
)

app = modal.App(name="example-trellis-3d")

cache_dir = "/cache"
cache_vol = modal.Volume.from_name("hf-hub-cache")


@app.cls(
    image=trellis_image.env({"HF_HUB_CACHE": cache_dir}),
    gpu="L4",
    timeout=1 * HOURS,
    scaledown_window=1 * MINUTES,
    volumes={cache_dir: cache_vol},
)
class Model:
    @modal.enter()
    def initialize(self):
        import sys

        sys.path.append(TRELLIS_DIR)

        from trellis.pipelines import TrellisImageTo3DPipeline

        try:
            self.pipe = TrellisImageTo3DPipeline.from_pretrained(MODEL_NAME)
            self.pipe.cuda()
            logger.info("TRELLIS model initialized successfully")
        except Exception as e:
            error_msg = f"Error during model initialization: {str(e)}"
            logger.error(error_msg)
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    def process_image(
        self,
        image_url: str,
        simplify: float,
        texture_size: int,
        sparse_sampling_steps: int,
        sparse_sampling_cfg: float,
        slat_sampling_steps: int,
        slat_sampling_cfg: int,
        seed: int,
        output_format: str,
    ):
        import io
        import os

        from PIL import Image

        try:
            response = requests.get(image_url)
            if response.status_code != 200:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Failed to download image from provided URL",
                )

            image = Image.open(io.BytesIO(response.content))

            logger.info("Starting model inference...")
            outputs = self.pipe.run(
                image,
                seed=seed,
                sparse_structure_sampler_params={
                    "steps": sparse_sampling_steps,
                    "cfg_strength": sparse_sampling_cfg,
                },
                slat_sampler_params={
                    "steps": slat_sampling_steps,
                    "cfg_strength": slat_sampling_cfg,
                },
            )
            logger.info("Model inference completed successfully")

            if output_format == "glb":
                from trellis.utils import postprocessing_utils

                glb = postprocessing_utils.to_glb(
                    outputs["gaussian"][0],
                    outputs["mesh"][0],
                    simplify=simplify,
                    texture_size=texture_size,
                )

                temp_glb = tempfile.NamedTemporaryFile(suffix=".glb", delete=False)
                temp_path = temp_glb.name
                logger.info(f"Exporting mesh to: {temp_path}")
                glb.export(temp_path)
                temp_glb.close()

                try:
                    with open(temp_path, "rb") as file:
                        content = file.read()
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)
                            logger.info("Temp file cleaned up")
                        return Response(
                            content=content,
                            media_type="model/gltf-binary",
                            headers={
                                "Content-Disposition": "attachment; filename=output.glb",
                            },
                        )
                except Exception as e:
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
                    raise e

            else:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"Unsupported output format: {output_format}",
                )

        except Exception as e:
            error_msg = f"Error during processing: {str(e)}"
            logger.error(error_msg)
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=error_msg,
            )

    @modal.fastapi_endpoint(method="GET", docs=True)
    async def generate(
        self,
        request: Request,
        image_url: str,
        simplify: float = 0.95,
        texture_size: int = 1024,
        sparse_sampling_steps: int = 12,
        sparse_sampling_cfg: float = 7.5,
        slat_sampling_steps: int = 12,
        slat_sampling_cfg: int = 3,
        seed: int = 42,
        output_format: str = "glb",
    ):
        return self.process_image(
            image_url,
            simplify,
            texture_size,
            sparse_sampling_steps,
            sparse_sampling_cfg,
            slat_sampling_steps,
            slat_sampling_cfg,
            seed,
            output_format,
        )


=== GITHUB: misc/README.md ===
# Miscellaneous Examples

This directory contains a variety of examples of ways to use Modal.

Unlike the examples in the rest of this repository, these examples are not
continually monitored for correctness, so it is possible that they may become
out of date or incorrect over time.

If you find an error in one of these examples, please report it in the issues
tab or, even better, submit a pull request to fix it.


=== GITHUB: misc/run_fooocus.py ===
# # Generate: Fooocus
#
# This example demonstrates how to set up and run a web server using the Modal library with Fooocus as the frontend.
# Fooocus provides a beginner-friendly interface to work with the SDXL 1.0 model for image generation tasks.
# The script includes the setup of a Docker image, initialization of Fooocus, and launching a web server with GPU support.
#
# ## Basic setup

import modal

# To create an image that can run Fooocus, we start from an official NVIDIA base image and then add Python
# and a few system packages.
#
# We then download the Fooocus repository.

image = (
    modal.Image.from_registry("nvidia/cuda:12.3.1-base-ubuntu22.04", add_python="3.10")
    .apt_install(
        "software-properties-common",
        "git",
        "git-lfs",
        "coreutils",
        "aria2",
        "libgl1",
        "libglib2.0-0",
        "curl",
        "wget",
        "libsm6",
        "libxrender1",
        "libxext6",
        "ffmpeg",
    )
    .run_commands("git clone https://github.com/lllyasviel/Fooocus.git")
)

# ## Initialize Fooocus
#
# We are not limited to running shell commands and package installers in the image setup.
# We can also run Python functions by defining them in our code and passing them to the `run_function` method.
#
# This function installs Fooocus's dependencies and downloads the SDXL 1.0 model to the container image.
#
# This all happens at the time the container image is defined, so that the image is ready to run Fooocus when it is deployed.


def init_Fooocus():
    import os
    import subprocess

    # change the working directory to the Fooocus directory and install the required Python packages from the requirements file.
    os.chdir("/Fooocus")
    os.system("pip install -r requirements_versions.txt")

    # change the directory to the models' checkpoints and download the SDXL 1.0 model using wget.
    os.chdir("./models/checkpoints")
    subprocess.run(
        "wget -O juggernautXL_v8Rundiffusion.safetensors 'https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors'",
        shell=True,
    )


GPU_CONFIG = "T4"
image = image.run_function(init_Fooocus, gpu=GPU_CONFIG)

# ## Run Fooocus
#
# The `run` function is decorated with `app.function` to define it as a Modal function.
# The `web_server` decorator indicates that this function will serve a web application on the specified port.
# We increase the startup timeout to three minutes to account for the time it takes to load the model and start the server.

app = modal.App("Fooocus", image=image)

PORT = 8000
MINUTES = 60


@app.function(gpu=GPU_CONFIG, timeout=10 * MINUTES)
@modal.web_server(port=PORT, startup_timeout=3 * MINUTES)
def run():
    import os
    import subprocess

    # change the working directory to the Fooocus directory.
    os.chdir("/Fooocus")

    # launch the Fooocus application using a subprocess that listens on the specified port
    subprocess.Popen(
        [
            "python",
            "launch.py",
            "--listen",
            "0.0.0.0",
            "--port",
            str(PORT),
            "--always-high-vram",
        ]
    )


=== GITHUB: misc/hello_shebang.py ===
#!/usr/bin/env python
# # Syntax for making modal scripts executable

# This example shows how you can add a shebang to a script that is meant to be invoked with `modal run`.

import sys

import modal

app = modal.App("example-hello-world")


@app.function()
def f(i):
    if i % 2 == 0:
        print("hello", i)
    else:
        print("world", i, file=sys.stderr)

    return i * i


@app.local_entrypoint()
def main():
    # run the function locally
    print(f.local(1000))

    # run the function remotely on Modal
    print(f.remote(1002))

    # run the function in parallel and remotely on Modal
    total = 0
    for ret in f.map(range(200)):
        total += ret

    print(total)


if __name__ == "__main__":
    # Use `modal.enable_output()` to print the Sandbox's image build logs to the console, just like `modal run` does.
    # Use `app.run()` to substitute the `modal run` CLI invocation.
    with modal.enable_output(), app.run():
        main()


=== GITHUB: misc/queue_simple.py ===
# ---
# cmd: ["python", "misc/queue_simple.py"]
# runtimes: ["runc", "gvisor"]
# ---
#
# # Using a queue to send/receive data
#
# This is an example of how to use queues to send/receive data.
# We don't do it here, but you could imagine doing this _between_ two functions.


import asyncio

import modal
import modal.queue


async def run_async(q: modal.Queue) -> None:
    await q.put.aio(42)
    r = await q.get.aio()
    assert r == 42
    await q.put_many.aio([42, 43, 44, 45, 46])
    await q.put_many.aio([47, 48, 49, 50, 51])
    r = await q.get_many.aio(3)
    assert r == [42, 43, 44]
    r = await q.get_many.aio(99)
    assert r == [45, 46, 47, 48, 49, 50, 51]


async def many_consumers(q: modal.Queue) -> None:
    print("Creating getters")
    tasks = [asyncio.create_task(q.get.aio()) for i in range(20)]
    print("Putting values")
    await q.put_many.aio(list(range(10)))
    await asyncio.sleep(1)
    # About 10 tasks should now be done
    n_done_tasks = sum(1 for t in tasks if t.done())
    assert n_done_tasks == 10
    # Finish remaining ones
    await q.put_many.aio(list(range(10)))
    await asyncio.sleep(1)
    assert all(t.done() for t in tasks)


async def main():
    with modal.Queue.ephemeral() as q:
        await run_async(q)
        await many_consumers(q)


if __name__ == "__main__":
    asyncio.run(main())


=== GITHUB: misc/google_search_generator.py ===
# ---
# runtimes: ["runc", "gvisor"]
# ---
#
# # Use a generator to fetch search results
#
# This is a simple example which
#
# 1. Installs a custom Python package.
# 2. Uses a _generator_ to return results back to the launcher process.

import modal

# We build a custom image by adding the `google` package to the base image.
app = modal.App(
    "example-google-search-generator",
    image=modal.Image.debian_slim().pip_install("google"),
)

# Next, let's define a _generator_ function that uses our custom image.


@app.function()
def scrape(query):
    from googlesearch import search

    for url in search(query.encode(), stop=100):
        yield url


# Finally, let's launch it from the command line with `modal run`:


@app.local_entrypoint()
def main(query: str = "modal"):
    for url in scrape.remote_gen(query):
        print(url)


=== GITHUB: misc/deepseek_openai_server.py ===
# DeepSeek LLM Server with llama.cpp
#
# This implementation provides a FastAPI server running DeepSeek-R1 language model
# using llama.cpp backend. It features:
#
# - GPU-accelerated inference using CUDA
# - API key authentication
# - Automatic model downloading and caching
# - GGUF model file merging
# - Swagger UI documentation
#
# Key Components:
#
# 1. Infrastructure Setup:
#    - Uses Modal for serverless deployment
#    - CUDA 12.4.0 with development toolkit
#    - Python 3.12 environment
#
# 2. Model Configuration:
#    - DeepSeek-R1 model with UD-IQ1_S quantization
#    - Persistent model storage using Modal Volumes
#    - Automatic GGUF file merging for split models
#
# 3. Server Features:
#    - FastAPI-based REST API
#    - API key authentication (X-API-Key header)
#    - Interactive documentation at /docs endpoint
#    - Configurable context length and batch size
#    - Flash attention support
#
# Hardware Requirements:
#    - 5x NVIDIA L40S GPUs
#    - Supports concurrent requests
#
# Usage:
# 1. Set your API key by modifying the TOKEN variable
# 2. Deploy using Modal
# 3. Access the API at http://localhost:8000
# 4. View API documentation at http://localhost:8000/docs
#
# Authentication:
# All API endpoints (except documentation) require the X-API-Key header
# Example:
# curl -H "X-API-Key: your-token" http://localhost:8000/v1/completions
#
# Model Settings:
# - Context length (n_ctx): 8096
# - Batch size (n_batch): 512
# - Thread count (n_threads): 12
# - GPU Layers: All (-1)
# - Flash Attention: Enabled
#
# Note: The server includes automatic redirection from root (/) to documentation (/docs)
# for easier API exploration.

from __future__ import annotations

import glob
import subprocess

# Standard library imports
from pathlib import Path
from typing import Optional

# Third-party imports
import modal

# ## Calling a Modal Function from the command line

# To start, we define our `main` function --
# the Python function that we'll run locally to
# trigger our inference to run on Modal's cloud infrastructure.

# This function, like the others that form our inference service
# running on Modal, is part of a Modal [App](https://modal.com/docs/guide/apps).
# Specifically, it is a `local_entrypoint`.
# Any Python code can call Modal Functions remotely,
# but local entrypoints get a command-line interface for free.

app = modal.App("deepseek-openai-server")

MINUTES = 60

HOURS = 60 * MINUTES

TOKEN = "super-secret-token"
cuda_version = "12.4.0"  # should be no greater than host CUDA version
flavor = "devel"  #  includes full CUDA toolkit
operating_sys = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{operating_sys}"

# Combine all apt installations and system dependencies
vllm_image = (
    modal.Image.from_registry(f"nvidia/cuda:{tag}", add_python="3.12")
    .apt_install(
        "git",
        "build-essential",
        "cmake",
        "curl",
        "libcurl4-openssl-dev",
        "libopenblas-dev",
        "libomp-dev",
        "clang",
    )
    # Set compiler environment variables
    .run_commands(
        "export CC=clang && export CXX=clang++",
        # Build llama.cpp with CUDA support
        "git clone https://github.com/ggerganov/llama.cpp && "
        "cmake llama.cpp -B llama.cpp/build -DBUILD_SHARED_LIBS=OFF -DGGML_CUDA=ON -DLLAMA_CURL=ON && "
        "cmake --build llama.cpp/build --config Release -j --clean-first --target llama-quantize llama-cli llama-gguf-split && "
        "cp llama.cpp/build/bin/llama-* llama.cpp",
    )
    # Install all Python dependencies at once
    .pip_install(
        [
            "fastapi==0.115.8",
            "sse_starlette==2.2.1",
            "pydantic==2.10.6",
            "uvicorn[standard]==0.34.0",
            "python-multipart==0.0.20",
            "starlette-context==0.3.6",
            "pydantic-settings==2.7.1",
            "ninja==1.11.1.3",
            "packaging==24.2",
            "wheel",
            "torch==2.6.0",
        ],
    )
    .run_commands(
        'CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python',
        gpu=modal.gpu.L40S(count=1),
    )
    .entrypoint([])  # remove NVIDIA base container entrypoint
)

# To make the model weights available on Modal,
# we download them from Hugging Face.

# Modal is serverless, so disks are by default ephemeral.
# To make sure our weights don't disappear between runs
# and require a long download step, we store them in a
# Modal [Volume](https://modal.com/docs/guide/volumes).
model_cache = modal.Volume.from_name("deepseek", create_if_missing=True)
cache_dir = "/root/.cache/deepseek"

download_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("huggingface_hub[hf_transfer]==0.26.2")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
)


@app.function(
    image=download_image, volumes={cache_dir: model_cache}, timeout=30 * MINUTES
)
def download_model(repo_id, allow_patterns, revision: Optional[str] = None):
    from huggingface_hub import snapshot_download

    print(f"🦙 downloading model from {repo_id} if not present")

    snapshot_download(
        repo_id=repo_id,
        revision=revision,
        local_dir=cache_dir,
        allow_patterns=allow_patterns,
    )

    model_cache.commit()  # ensure other Modal Functions can see our writes before we quit

    print("🦙 model loaded")


# For more on how to use Modal Volumes to store model weights,
# see [this guide](https://modal.com/docs/guide/model-weights).
N_GPU = 5
MODELS_DIR = "/deepseek"


@app.function(
    image=vllm_image,
    gpu=modal.gpu.L40S(count=N_GPU),
    scaledown_window=5 * MINUTES,
    timeout=15 * MINUTES,
    volumes={MODELS_DIR: model_cache},
    max_containers=1,
)
@modal.asgi_app()
def serve():
    from llama_cpp.server.app import create_app
    from llama_cpp.server.settings import ModelSettings, ServerSettings

    org_name = "unsloth"
    model_name = "DeepSeek-R1"
    quant = "UD-IQ1_S"
    repo_id = f"{org_name}/{model_name}-GGUF"
    model_pattern = f"*{quant}*"
    download_model.remote(repo_id, [model_pattern])
    model_cache.reload()  # ensure we have the latest version of the weights

    model_entrypoint_file = (
        f"{model_name}-{quant}/DeepSeek-R1-{quant}-00001-of-00003.gguf"
    )
    model_path = MODELS_DIR + "/" + model_entrypoint_file
    # Find and merge GGUF files
    model_dir = f"{MODELS_DIR}/{model_name}-{quant}"
    gguf_files = sorted(glob.glob(f"{model_dir}/*.gguf"))
    if len(gguf_files) > 1:
        print(f"Found {len(gguf_files)} GGUF files to merge")
        output_file = f"{model_dir}/{model_name}-{quant}-merged.gguf"
        if not Path(output_file).exists():
            print(f"🔄 Merging GGUF files to {output_file}")
            merge_command = (
                ["/llama.cpp/llama-gguf-split", "--merge"]
                + [gguf_files[0]]
                + [output_file]
            )
            print(f"Merging files with command: {' '.join(merge_command)}")
            subprocess.run(merge_command, check=True)
            print("🔄 GGUF files merged successfully")
        model_path = output_file
    else:
        model_path = (
            gguf_files[0]
            if gguf_files
            else f"{model_dir}/DeepSeek-R1-{quant}-00001-of-00003.gguf"
        )
    model_cache.reload()  # ensure we have the latest version of the weights
    print(f"🔄 Using model path: {model_path}")
    # Create model settings directly
    model_settings = [
        ModelSettings(
            model=model_path,  # Replace with your model path
            n_gpu_layers=-1,  # Use all GPU layers
            n_ctx=8096,
            n_batch=512,
            n_threads=12,
            verbose=True,
            flash_attn=True,
        )
    ]

    # Create server settings
    server_settings = ServerSettings(host="0.0.0.0", port=8000, api_key=TOKEN)

    # Create the llama.cpp app
    app = create_app(
        server_settings=server_settings,
        model_settings=model_settings,
    )

    return app


=== GITHUB: misc/tqdm_progress_bar.py ===
# # Show a progress bar with tqdm on Modal

# This example shows how you can show a progress bar with [tqdm](https://github.com/tqdm/tqdm) on Modal.

import time

import modal

app = modal.App(
    "example-tqdm",
    image=modal.Image.debian_slim().pip_install("tqdm"),
)


@app.function()
def f():
    from tqdm import tqdm

    for i in tqdm(range(100)):
        time.sleep(0.1)


if __name__ == "__main__":
    with app.run():
        f.remote()


=== GITHUB: misc/falcon_gptq.py ===
# # Run Falcon-40B with AutoGPTQ
#
# In this example, we run a quantized 4-bit version of Falcon-40B, the first open-source large language
# model of its size, using HuggingFace's [transformers](https://huggingface.co/docs/transformers/index)
# library and [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ).
#
# Due to the current limitations of the library, the inference speed is a little under 1 token/second and the
# cold start time on Modal is around 25s.
#
# For faster inference at the expense of a slower cold start, check out
# [Running Falcon-40B with `bitsandbytes` quantization](https://modal.com/docs/examples/falcon_bitsandbytes). You can also
# run a smaller model via the [Gemma 7B example](https://modal.com/docs/examples/vllm_gemma).
#
# ## Setup
#
# First we import the components we need from `modal`.

import modal

# ## Define a container image
#
# To take advantage of Modal's blazing fast cold-start times, we download model weights
# into a folder inside our container image. These weights come from a quantized model
# found on Huggingface.
IMAGE_MODEL_DIR = "/model"


def download_model():
    from huggingface_hub import snapshot_download

    model_name = "TheBloke/falcon-40b-instruct-GPTQ"
    snapshot_download(model_name, local_dir=IMAGE_MODEL_DIR)


# Now, we define our image. We'll use the `debian-slim` base image, and install the dependencies we need
# using [`pip_install`](https://modal.com/docs/reference/modal.Image#pip_install). At the end, we'll use
# [`run_function`](https://modal.com/docs/guide/custom-container#run-a-modal-function-during-your-build-with-run_function-beta) to run the
# function defined above as part of the image build.

image = (
    modal.Image.debian_slim(python_version="3.10")
    .apt_install("git")
    .pip_install(
        "auto-gptq==0.7.0",
        "einops==0.6.1",
        "hf-transfer==0.1.5",
        "huggingface_hub==0.14.1",
        "transformers==4.31.0",
    )
    # Use huggingface's hi-perf hf-transfer library to download this large model.
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(download_model)
)

# Let's instantiate and name our [`App`](https://modal.com/docs/guide/apps).
app = modal.App(name="example-falcon-gptq", image=image)


# ## The model class
#
# Next, we write the model code. We want Modal to load the model into memory just once every time a container starts up,
# so we use [class syntax](https://modal.com/docs/guide/lifecycle-functions) and the `@enter` decorator.
#
# Within the [`@app.cls`](https://modal.com/docs/reference/modal.App#cls) decorator, we use the [`gpu` parameter](https://modal.com/docs/guide/gpu)
# to specify that we want to run our function on an [A100 GPU](https://modal.com/docs/guide/gpu#a100-gpus). We also allow each call 10 mintues to complete,
# and request the runner to stay live for 5 minutes after its last request.
#
# The rest is just using the `transformers` library to run the model. Refer to the
# [documentation](https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/text_generation#transformers.GenerationMixin.generate)
# for more parameters and tuning.
#
# Note that we need to create a separate thread to call the `generate` function because we need to
# yield the text back from the streamer in the main thread. This is an idiosyncrasy with streaming in `transformers`.
@app.cls(gpu="A100", timeout=60 * 10, scaledown_window=60 * 5)
class Falcon40BGPTQ:
    @modal.enter()
    def load_model(self):
        from auto_gptq import AutoGPTQForCausalLM
        from transformers import AutoTokenizer

        self.tokenizer = AutoTokenizer.from_pretrained(IMAGE_MODEL_DIR, use_fast=True)
        print("Loaded tokenizer.")

        self.model = AutoGPTQForCausalLM.from_quantized(
            IMAGE_MODEL_DIR,
            trust_remote_code=True,
            use_safetensors=True,
            device_map="auto",
            use_triton=False,
            strict=False,
        )
        print("Loaded model.")

    @modal.method()
    def generate(self, prompt: str):
        from threading import Thread

        from transformers import TextIteratorStreamer

        inputs = self.tokenizer(prompt, return_tensors="pt")
        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True)
        generation_kwargs = dict(
            inputs=inputs.input_ids.cuda(),
            attention_mask=inputs.attention_mask,
            temperature=0.1,
            max_new_tokens=512,
            streamer=streamer,
        )

        # Run generation on separate thread to enable response streaming.
        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)
        thread.start()
        for new_text in streamer:
            yield new_text

        thread.join()


# ## Run the model
# We define a [`local_entrypoint`](https://modal.com/docs/guide/apps#entrypoints-for-ephemeral-apps) to call our remote function
# sequentially for a list of inputs. You can run this locally with `modal run -q falcon_gptq.py`. The `-q` flag
# enables streaming to work in the terminal output.
prompt_template = (
    "A chat between a curious human user and an artificial intelligence assistant. The assistant give a helpful, detailed, and accurate answer to the user's question."
    "\n\nUser:\n{}\n\nAssistant:\n"
)


@app.local_entrypoint()
def cli():
    question = "What are the main differences between Python and JavaScript programming languages?"
    model = Falcon40BGPTQ()
    for text in model.generate.remote_gen(prompt_template.format(question)):
        print(text, end="", flush=True)


# ## Serve the model
# Finally, we can serve the model from a web endpoint with `modal deploy falcon_gptq.py`. If
# you visit the resulting URL with a question parameter in your URL, you can view the model's
# stream back a response.
# You can try our deployment [here](https://modal-labs--example-falcon-gptq-get.modal.run/?question=Why%20are%20manhole%20covers%20round?).
@app.function(timeout=60 * 10)
@modal.fastapi_endpoint()
def get(question: str):
    from itertools import chain

    from fastapi.responses import StreamingResponse

    model = Falcon40BGPTQ()
    return StreamingResponse(
        chain(
            ("Loading model. This usually takes around 20s ...\n\n"),
            model.generate.remote_gen(prompt_template.format(question)),
        ),
        media_type="text/event-stream",
    )


=== GITHUB: misc/batch_inference/batch_inference_using_huggingface.py ===
# ---
# runtimes: ["runc", "gvisor"]
# ---
# # Batch inference using a model from Huggingface
#
# <center>
#   <img src="./batch_inference_huggingface.png" alt="Huggingface company logo" />
# </center>
#
# This example shows how to use a sentiment analysis model from Huggingface to classify
# 25,000 movie reviews in a couple of minutes.
#
# Some Modal features it uses:
# * Container lifecycle hook: this lets us load the model only once in each container
# * CPU requests: the prediction function is very CPU-hungry, so we reserve 8 cores
# * Mapping: we map over 25,000 sentences and Modal manages the pool of containers for us
#
# ## Basic setup
#
# Let's get started writing code.
# For the Modal container image, we need a few Python packages,
# including `transformers`, which is the main Huggingface package.

import io

import modal

app = modal.App(
    "example-batch-inference-using-huggingface",
    image=modal.Image.debian_slim().pip_install(
        "datasets",
        "matplotlib",
        "scikit-learn",
        "torch",
        "transformers",
    ),
)

# ## Defining the prediction function
#
# Instead of a using `@app.function()` in the global scope,
# we put the method on a class, and define a setup method that we
# decorate with `@modal.enter()`.
#
# Modal reuses containers for successive calls to the same function, so
# we want to take advantage of this and avoid setting up the same model
# for every function call.
#
# Since the transformer model is very CPU-hungry, we allocate 8 CPUs
# to the model. Every container that runs will have 8 CPUs set aside for it.


@app.cls(cpu=8, retries=3)
class SentimentAnalysis:
    @modal.enter()
    def setup_pipeline(self):
        from transformers import pipeline

        self.sentiment_pipeline = pipeline(
            model="distilbert-base-uncased-finetuned-sst-2-english"
        )

    @modal.method()
    def predict(self, phrase: str):
        pred = self.sentiment_pipeline(phrase, truncation=True, max_length=512, top_k=2)
        # pred will look like: [{'label': 'NEGATIVE', 'score': 0.99}, {'label': 'POSITIVE', 'score': 0.01}]
        probs = {p["label"]: p["score"] for p in pred}
        return probs["POSITIVE"]


# ## Getting data
#
# We need some data to run the batch inference on.
# We use this [dataset of IMDB reviews](https://ai.stanford.edu/~amaas/data/sentiment/) for this purpose.
# Huggingface actually offers this data [as a preprocessed dataaset](https://huggingface.co/datasets/imdb),
# which we can download using the `datasets` package:


@app.function()
def get_data():
    from datasets import load_dataset

    imdb = load_dataset("imdb")
    data = [(row["text"], row["label"]) for row in imdb["test"]]
    return data


# ## Plotting the ROC curve
#
# In order to evaluate the classifier, let's plot an
# [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic).
# This is a common way to evaluate classifiers on binary data.


@app.function()
def roc_plot(labels, predictions):
    from matplotlib import pyplot
    from sklearn.metrics import RocCurveDisplay

    pyplot.style.use("ggplot")
    RocCurveDisplay.from_predictions(labels, predictions)
    with io.BytesIO() as buf:
        pyplot.savefig(buf, format="png")
        return buf.getvalue()


# A bit of a spoiler warning, but if you run this script, the ROC curve will look like this:
#
# ![roc](./batch_inference_roc.png)
#
# The AUC of this classifier is 0.96, which means it's very good!

# ## Putting it together
#
# The main flow of the code downloads the data, then runs the batch inference,
# then plots the results.
# Each prediction takes roughly 0.1-1s, so if we ran everything sequentially it would take 2,500-25,000 seconds.
# That's a lot! Luckily because of Modal's `.map` method, we can process everything in a couple of minutes at most.
# Modal will automatically spin up more and more workers until all inputs are processed.


@app.local_entrypoint()
def main():
    print("Downloading data...")
    data = get_data.remote()
    print("Got", len(data), "reviews")
    reviews = [review for review, label in data]
    labels = [label for review, label in data]

    # Let's check that the model works by classifying the first 5 entries
    predictor = SentimentAnalysis()
    for review, label in data[:5]:
        prediction = predictor.predict.remote(review)
        print(f"Sample prediction with positivity score {prediction}:\n{review}\n\n")

    # Now, let's run batch inference over it
    print("Running batch prediction...")
    predictions = list(predictor.predict.map(reviews))

    # Generate a ROC plot
    print("Creating ROC plot...")
    png_data = roc_plot.remote(labels, predictions)
    fn = "/tmp/roc.png"
    with open(fn, "wb") as f:
        f.write(png_data)
    print(f"Wrote ROC curve to {fn}")


# ## Running this
#
# When you run this, it will download the dataset and load the model, then output some
# sample predictions:
#
# ```
# Sample prediction with positivity score 0.0003837468393612653:
# I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say "Gene Roddenberry's Earth..." otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.
#
# Sample prediction with positivity score 0.38294079899787903:
# Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.
#
# Sample prediction with positivity score 0.0002899310493376106:
# its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality
#
# Sample prediction with positivity score 0.004243704490363598:
# STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />Former New Orleans homicide cop Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. The culprits turn out to be ex-military, lead by former commander Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special method he learned in Afghanistan to fight off his opponents. But Jack has a more personal reason for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive.<br /><br />After Until Death, Van Damme appeared to be on a high, showing he could make the best straight to video films in the action market. While that was a far more drama oriented film, with The Shepherd he has returned to the high-kicking, no brainer action that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as bad as that film, but what I said still stands.<br /><br />A dull, predictable film, with very little in the way of any exciting action. What little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. Being a Mexican set film, director Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />VD gives a particularly uninspired performance and given he's never been a Robert De Niro sort of actor, that can't be good. As the villain, Lord shouldn't expect to leave the beeb anytime soon. He gets little dialogue at the beginning as he struggles to muster an American accent but gets mysteriously better towards the end. All the supporting cast are equally bland, and do nothing to raise the films spirits at all.<br /><br />This is one shepherd that's strayed right from the flock. *
#
# Sample prediction with positivity score 0.996307373046875:
# First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!
# ```
#
# After that, it kicks off the actual batch inference.
# It should look something like the screenshot below (we are very proud of the progress bar):
#
# ![progress](./batch_inference_progress.png)
#
# The whole thing should take a few minutes to run.
#
# ## Further optimization notes
#
# Every container downloads the model when it starts, which is a bit inefficient.
# In order to improve this, what you could do is store the model in the image that
# backs each container.
# See [`Image.run_function`](/docs/guide/custom-container#run-a-modal-function-during-your-build-with-run_function-beta).
#


=== GITHUB: misc/quic/quic_yolo_modal.py ===
"""
This script implements a GPU-powered YOLO inference server that communicates
with a client over QUIC. It uses NAT hole punching to establish a
direct connection through firewalls.
Networking code adapted from:
https://gist.github.com/aksh-at/e85a5517610a1a2bff35fac41d4c982f
YOLO model code from:
https://github.com/modal-labs/modal-examples/tree/main/07_web_endpoints/webrtc
Usage:
# Start server (rendezvous + YOLO on GPU)
> uvx modal serve quic_yolo_modal.py
# Run client locally
> uv run client.py --url <rendezvous_url> [--fake]  # --fake if no webcam available
"""

import asyncio
import socket
import ssl
import uuid
from pathlib import Path
from typing import Literal

import modal

server_id = str(uuid.uuid4())

# Modal setup
app_name = "modal-quic-yolo"
py_version = "3.12"
tensorrt_ld_path = f"/usr/local/lib/python{py_version}/site-packages/tensorrt_libs"

image = (
    modal.Image.debian_slim(python_version=py_version)  # matching ld path
    # update locale as required by onnx
    .apt_install("locales")
    .run_commands(
        "sed -i '/^#\\s*en_US.UTF-8 UTF-8/ s/^#//' /etc/locale.gen",  # use sed to uncomment
        "locale-gen en_US.UTF-8",  # set locale
        "update-locale LANG=en_US.UTF-8",
    )
    .env({"LD_LIBRARY_PATH": tensorrt_ld_path, "LANG": "en_US.UTF-8"})
    # install system dependencies
    .apt_install("python3-opencv", "ffmpeg")
    # install Python dependencies
    .pip_install(
        "aioquic==1.2.0",
        "cryptography==45.0.4",
        "huggingface-hub[hf_xet]==0.33.0",
        "onnxruntime-gpu==1.21.0",
        "opencv-python==4.11.0.86",
        "tensorrt==10.9.0.34",
        "pynat==0.6.0",
    )
)

cache_vol = modal.Volume.from_name(f"{app_name}-cache", create_if_missing=True)
cache_dir = Path("/cache")
cache = {cache_dir: cache_vol}

app = modal.App(app_name)


with image.imports():
    import cv2
    import numpy as np
    import onnxruntime
    from cryptography import x509
    from cryptography.hazmat.primitives.asymmetric.dsa import DSAPrivateKey

    async def get_ext_addr(sock: socket.socket) -> tuple[str, int]:
        from pynat import get_stun_response

        response = get_stun_response(sock, ("stun.ekiga.net", 3478))
        return response["ext_ip"], response["ext_port"]

    def create_cert(key: DSAPrivateKey) -> x509.Certificate:
        import datetime

        from cryptography.hazmat.primitives import hashes
        from cryptography.x509.oid import NameOID

        return (
            x509.CertificateBuilder()
            .subject_name(
                x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, app_name)])
            )
            .issuer_name(x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, app_name)]))
            .public_key(key.public_key())
            .serial_number(x509.random_serial_number())
            .not_valid_before(datetime.datetime.utcnow())
            .not_valid_after(datetime.datetime.utcnow() + datetime.timedelta(days=1))
            .sign(key, hashes.SHA256())
        )

    class YOLOv10:
        def __init__(self, cache_dir: Path):
            from huggingface_hub import hf_hub_download

            # initialize model
            self.cache_dir = cache_dir
            model_file = hf_hub_download(
                repo_id="onnx-community/yolov10n",
                filename="onnx/model.onnx",
                cache_dir=self.cache_dir,
            )
            self.initialize_model(model_file)

        def initialize_model(self, model_file: Path):
            self.session = onnxruntime.InferenceSession(
                model_file,
                providers=[
                    (
                        "TensorrtExecutionProvider",
                        {
                            "trt_engine_cache_enable": True,
                            "trt_engine_cache_path": self.cache_dir / "onnx.cache",
                        },
                    ),
                    "CUDAExecutionProvider",
                ],
            )
            # get model info
            self.get_input_details()
            self.get_output_details()

            # class names
            self.class_names = [
                "person",
                "bicycle",
                "car",
                "motorcycle",
                "airplane",
                "bus",
                "train",
                "truck",
                "boat",
                "traffic light",
                "fire hydrant",
                "stop sign",
                "parking meter",
                "bench",
                "bird",
                "cat",
                "dog",
                "horse",
                "sheep",
                "cow",
                "elephant",
                "bear",
                "zebra",
                "giraffe",
                "backpack",
                "umbrella",
                "handbag",
                "tie",
                "suitcase",
                "frisbee",
                "skis",
                "snowboard",
                "sports ball",
                "kite",
                "baseball bat",
                "baseball glove",
                "skateboard",
                "surfboard",
                "tennis racket",
                "bottle",
                "wine glass",
                "cup",
                "fork",
                "knife",
                "spoon",
                "bowl",
                "banana",
                "apple",
                "sandwich",
                "orange",
                "broccoli",
                "carrot",
                "hot dog",
                "pizza",
                "donut",
                "cake",
                "chair",
                "couch",
                "potted plant",
                "bed",
                "dining table",
                "toilet",
                "tv",
                "laptop",
                "mouse",
                "remote",
                "keyboard",
                "cell phone",
                "microwave",
                "oven",
                "toaster",
                "sink",
                "refrigerator",
                "book",
                "clock",
                "vase",
                "scissors",
                "teddy bear",
                "hair drier",
                "toothbrush",
            ]
            self.colors = np.random.default_rng(3).uniform(
                0, 255, size=(len(self.class_names), 3)
            )

        def detect_objects(
            self, image: np.ndarray, conf_threshold: float = 0.3
        ) -> np.ndarray:
            input_tensor = self.prepare_input(image)
            new_image = self.inference(image, input_tensor, conf_threshold)
            return new_image

        def prepare_input(self, image: np.ndarray) -> np.ndarray:
            self.img_height, self.img_width = image.shape[:2]

            input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # resize input image to model input size
            input_img = cv2.resize(input_img, (self.input_width, self.input_height))

            # scale input pixel values to 0 to 1
            input_img = input_img / 255.0
            input_img = input_img.transpose(2, 0, 1)
            input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)

            return input_tensor

        def inference(
            self,
            image: np.ndarray,
            input_tensor: np.ndarray,
            conf_threshold: float = 0.3,
        ) -> np.ndarray:
            # set seed to potentially create smoother output in RT setting
            onnxruntime.set_seed(42)
            # start = time.perf_counter()
            outputs = self.session.run(
                self.output_names, {self.input_names[0]: input_tensor}
            )

            # print(f"Inference time: {(time.perf_counter() - start) * 1000:.2f} ms")
            (
                boxes,
                scores,
                class_ids,
            ) = self.process_output(outputs, conf_threshold)
            return self.draw_detections(image, boxes, scores, class_ids)

        def process_output(
            self, output: np.ndarray, conf_threshold: float = 0.3
        ) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
            predictions = np.squeeze(output[0])

            # filter out object confidence scores below threshold
            scores = predictions[:, 4]
            predictions = predictions[scores > conf_threshold, :]
            scores = scores[scores > conf_threshold]

            if len(scores) == 0:
                return [], [], []

            # get the class with the highest confidence
            class_ids = predictions[:, 5].astype(int)

            # get bounding boxes for each object
            boxes = self.extract_boxes(predictions)

            return boxes, scores, class_ids

        def extract_boxes(self, predictions: np.ndarray) -> np.ndarray:
            # extract boxes from predictions
            boxes = predictions[:, :4]

            # scale boxes to original image dimensions
            boxes = self.rescale_boxes(boxes)

            # convert boxes to xyxy format
            # boxes = xywh2xyxy(boxes)

            return boxes

        def rescale_boxes(self, boxes: np.ndarray) -> np.ndarray:
            # rescale boxes to original image dimensions
            input_shape = np.array(
                [
                    self.input_width,
                    self.input_height,
                    self.input_width,
                    self.input_height,
                ]
            )
            boxes = np.divide(boxes, input_shape, dtype=np.float32)
            boxes *= np.array(
                [self.img_width, self.img_height, self.img_width, self.img_height]
            )
            return boxes

        def draw_detections(
            self,
            image: np.ndarray,
            boxes: np.ndarray,
            scores: np.ndarray,
            class_ids: np.ndarray,
        ) -> np.ndarray:
            det_img = image.copy()

            img_height, img_width = image.shape[:2]
            font_size = min([img_height, img_width]) * 0.0012
            text_thickness = int(min([img_height, img_width]) * 0.004)

            # draw bounding boxes and labels of detections
            for class_id, box, score in zip(class_ids, boxes, scores):
                color = self.colors[class_id]

                self.draw_box(det_img, box, color)  # type: ignore

                label = self.class_names[class_id]
                caption = f"{label} {int(score * 100)}%"
                self.draw_text(det_img, caption, box, color, font_size, text_thickness)  # type: ignore

            return det_img

        def get_input_details(self):
            model_inputs = self.session.get_inputs()
            self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]

            self.input_shape = model_inputs[0].shape
            self.input_height = self.input_shape[2]
            self.input_width = self.input_shape[3]

        def get_output_details(self):
            model_outputs = self.session.get_outputs()
            self.output_names = [
                model_outputs[i].name for i in range(len(model_outputs))
            ]

        def draw_box(
            self,
            image: np.ndarray,
            box: np.ndarray,
            color: tuple[int, int, int] = (0, 0, 255),
            thickness: int = 5,
        ) -> np.ndarray:
            x1, y1, x2, y2 = box.astype(int)
            return cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

        def draw_text(
            self,
            image: np.ndarray,
            text: str,
            box: np.ndarray,
            color: tuple[int, int, int] = (0, 0, 255),
            font_size: float = 0.100,
            text_thickness: int = 5,
            box_thickness: int = 5,
        ) -> np.ndarray:
            x1, y1, _, _ = box.astype(int)
            (tw, th), _ = cv2.getTextSize(
                text=text,
                fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=font_size,
                thickness=text_thickness,
            )
            x1 = x1 - box_thickness
            th = int(th * 1.2)

            cv2.rectangle(image, (x1, y1), (x1 + tw, y1 - th), color, -1)

            return cv2.putText(
                image,
                text,
                (x1, y1),
                cv2.FONT_HERSHEY_SIMPLEX,
                font_size,
                (255, 255, 255),
                text_thickness,
                cv2.LINE_AA,
            )

    def get_yolo_model(cache_path: Path) -> YOLOv10:
        import onnxruntime

        onnxruntime.preload_dlls()
        return YOLOv10(cache_path)


@app.function(
    image=image,
    gpu="A100-40GB",
    volumes=cache,
    region="us-west-1",
    max_inputs=1,
)
async def yolo_quic_server(
    *,
    rendezvous_url: str,
    target_id: str,
    local_port: int = 5555,
):
    import aiohttp
    import cv2
    import numpy as np
    from aioquic.asyncio import serve
    from aioquic.quic.configuration import QuicConfiguration
    from cryptography.hazmat.primitives.asymmetric import ec

    # discover public mapping via STUN
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.bind(("0.0.0.0", local_port))
    sock.setblocking(False)

    pub_ip, pub_port = await get_ext_addr(sock)
    print(f"[{target_id}] Public tuple: {pub_ip}:{pub_port}")

    # register & wait for the peer's tuple
    async with aiohttp.ClientSession() as session:
        while True:
            resp = await session.post(
                f"{rendezvous_url}/register",
                json={
                    "role": "server",
                    "peer_id": server_id,
                    "target_id": target_id,
                    "ip": pub_ip,
                    "port": pub_port,
                },
            )
            if peer := (await resp.json()).get("peer"):
                peer_ip, peer_port = peer
                break
            await asyncio.sleep(1)
    print(f"[{target_id}] Peer tuple: {peer_ip}:{peer_port}")

    for _ in range(150):  # 15s total
        sock.sendto(b"punch", (peer_ip, peer_port))
        try:
            await asyncio.wait_for(asyncio.get_event_loop().sock_recv(sock, 16), 0.1)
            break
        except asyncio.TimeoutError:
            continue
    else:
        raise RuntimeError(
            f"[{target_id}] NAT hole punching failed – no response from peer"
        )
    print(f"[{target_id}] Punched {pub_ip}:{pub_port} -> {peer_ip}:{peer_port}")

    sock.close()  # close socket, mapping should stay alive

    cfg = QuicConfiguration(
        is_client=False,
        alpn_protocols=["hq-29"],
        verify_mode=ssl.CERT_NONE,
    )
    cfg.private_key = ec.generate_private_key(ec.SECP256R1())
    cfg.certificate = create_cert(cfg.private_key)

    yolo = get_yolo_model(cache_dir)

    all_done = asyncio.Event()

    async def handle_stream(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):
        frame_idx = 0

        try:
            while True:
                try:
                    header = await reader.readexactly(4)  # 4-byte length header
                except asyncio.IncompleteReadError:
                    # Client disconnected abruptly
                    break
                frame_len = int.from_bytes(header, "big")
                if frame_len == 0:  # client finished, stop loop
                    break
                try:
                    data = await reader.readexactly(frame_len)
                except asyncio.IncompleteReadError:
                    break

                # decode JPEG bytes → ndarray
                np_arr = np.frombuffer(data, dtype=np.uint8)
                frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                if frame is None:
                    print("Failed to decode frame; skipping")
                    continue

                # run inference
                annotated = yolo.detect_objects(frame)

                # re-encode as JPEG
                ok, buf = cv2.imencode(
                    ".jpg", annotated, [cv2.IMWRITE_JPEG_QUALITY, 80]
                )
                if not ok:
                    print("JPEG encode failed; skipping frame")
                    continue
                out_bytes = buf.tobytes()

                writer.write(len(out_bytes).to_bytes(4, "big") + out_bytes)
                await writer.drain()

                frame_idx += 1
        finally:
            writer.close()
            all_done.set()
            try:
                await asyncio.wait_for(writer.wait_closed(), timeout=2.0)
            except (asyncio.TimeoutError, Exception):
                pass

    def stream_handler(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):
        asyncio.create_task(handle_stream(reader, writer))  # run in the background

    server = await serve(
        host="0.0.0.0",
        port=local_port,  # Use the punched port.
        configuration=cfg,
        stream_handler=stream_handler,
    )

    await all_done.wait()
    server.close()
    print(f"[{target_id}] Shutting down server")


@app.cls(image=image, max_containers=1)
class Rendezvous:
    peers: dict[str, tuple[str, str, int]]
    spawned_clients: set[str]

    @modal.enter()
    def _enter(self):
        self.peers = {}
        self.spawned_clients = set()

    @modal.asgi_app()
    def app(self):
        from fastapi import FastAPI, Request
        from pydantic import BaseModel

        api = FastAPI()

        class RegisterRequest(BaseModel):
            role: Literal["server", "client"]
            peer_id: str
            target_id: str | None
            ip: str
            port: int

        @api.post("/register")
        async def register(req: RegisterRequest, request: Request):
            self.peers[req.peer_id] = (req.role, req.ip, req.port)

            if req.role == "client" and req.peer_id not in self.spawned_clients:
                base_url = str(request.base_url).rstrip("/")
                yolo_quic_server.spawn(rendezvous_url=base_url, target_id=req.peer_id)
                self.spawned_clients.add(req.peer_id)

            if req.role == "server":
                for peer_id, (role, ip, port) in self.peers.items():
                    if role == "client" and peer_id == req.target_id:
                        return {"peer": (ip, port)}
            else:
                for peer_id, (role, ip, port) in self.peers.items():
                    if role == "server":
                        return {"peer": (ip, port)}
            return {"peer": None}

        return api


=== GITHUB: misc/quic/client.py ===
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "aioquic==1.2.0",
#     "aiohttp==3.12.13",
#     "opencv-python==4.11.0.86",
#     "pynat==0.6.0",
# ]
# ///

import argparse
import asyncio
import socket
import ssl
import time
import uuid

import aiohttp
import cv2
import numpy as np
from aioquic.asyncio import connect
from aioquic.quic.configuration import QuicConfiguration
from pynat import get_stun_response


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="QUIC-YOLO webcam client")
    p.add_argument("--url", type=str, required=True, help="Rendezvous URL")
    p.add_argument(
        "--local-port", type=int, default=5555, help="Local UDP port to bind."
    )
    p.add_argument(
        "--max-fps",
        type=float,
        default=30.0,
        help="Maximum FPS for real-time video streaming (higher = smoother but more bandwidth)",
    )
    p.add_argument(
        "--fake", action="store_true", help="Send synthetic video instead of webcam"
    )
    return p.parse_args()


async def get_ext_addr(sock: socket.socket) -> tuple[str, int]:
    resp = get_stun_response(sock, ("stun.ekiga.net", 3478))
    return resp["ext_ip"], resp["ext_port"]


async def run(args):
    client_id = str(uuid.uuid4())

    # discover public mapping via STUN
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.bind(("0.0.0.0", args.local_port))
    sock.setblocking(False)

    pub_ip, pub_port = await get_ext_addr(sock)
    print(f"Public tuple: {pub_ip}:{pub_port}")

    # register & wait for the peer's tuple
    async with aiohttp.ClientSession() as session:
        while True:
            resp = await session.post(
                f"{args.url}/register",
                json={
                    "role": "client",
                    "peer_id": client_id,
                    "ip": pub_ip,
                    "port": pub_port,
                },
            )
            peer = (await resp.json()).get("peer")
            if peer:
                peer_ip, peer_port = peer
                break
            await asyncio.sleep(1)
    print(f"Peer tuple: {peer_ip}:{peer_port}")

    for _ in range(150):  # 15s total (for cold-start latency)
        sock.sendto(b"punch", (peer_ip, peer_port))
        try:
            await asyncio.wait_for(asyncio.get_event_loop().sock_recv(sock, 16), 0.05)
            break
        except asyncio.TimeoutError:
            continue
    else:
        raise RuntimeError("NAT hole punching failed – no response from server")
    print(f"Punched {pub_ip}:{pub_port} -> {peer_ip}:{peer_port}")

    sock.close()  # close socket, mapping should stay alive

    cfg = QuicConfiguration(
        is_client=True,
        alpn_protocols=["hq-29"],
        verify_mode=ssl.CERT_NONE,
    )

    async with connect(
        peer_ip,
        peer_port,
        configuration=cfg,
        local_port=args.local_port,
    ) as quic:
        reader, writer = await quic.create_stream()

        cap = None
        if not args.fake:
            cap = cv2.VideoCapture(0)

            if not cap.isOpened():
                print("[WARN] Webcam not available. Falling back to synthetic frames.")
                cap.release()
                cap = None

        frame_h, frame_w = 480, 640

        def gen_fake_frame(
            idx: int,
        ) -> np.ndarray:  # generate a simple synthetic BGR frame with moving rectangle
            img = np.zeros((frame_h, frame_w, 3), dtype=np.uint8)
            size = 80
            x = (idx * 5) % (frame_w - size)
            y = (idx * 3) % (frame_h - size)
            color = (0, 255, 0)
            cv2.rectangle(img, (x, y), (x + size, y + size), color, -1)
            cv2.putText(
                img,
                "SYNTH",
                (10, frame_h - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (255, 255, 255),
                2,
            )
            return img

        min_frame_interval = 1.0 / args.max_fps
        last_frame_ts = 0.0
        frame_idx = 0

        try:
            while True:
                ts = time.time()
                if ts - last_frame_ts < min_frame_interval:
                    await asyncio.sleep(min_frame_interval - (ts - last_frame_ts))
                last_frame_ts = time.time()

                if cap is not None:
                    ret, frame = cap.read()
                    if not ret:
                        print(
                            "Failed to read frame from webcam; switching to synthetic."
                        )
                        cap.release()
                        cap = None
                        frame = gen_fake_frame(frame_idx)
                else:
                    frame = gen_fake_frame(frame_idx)

                ok, buf = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                if not ok:
                    print("JPEG encode failed")
                    continue
                data = buf.tobytes()

                # send frame
                writer.write(len(data).to_bytes(4, "big") + data)
                await writer.drain()

                # receive annotated frame
                hdr = await reader.readexactly(4)
                resp_len = int.from_bytes(hdr, "big")
                if resp_len == 0:
                    print("Server closed stream")
                    break
                resp_bytes = await reader.readexactly(resp_len)
                img_np = np.frombuffer(resp_bytes, dtype=np.uint8)
                annotated = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
                if annotated is None:
                    continue

                frame_idx += 1

                cv2.imshow("YOLO (Remote)", annotated)
                if cv2.waitKey(1) & 0xFF == ord("q"):
                    break
        finally:
            writer.write((0).to_bytes(4, "big"))
            await writer.drain()
            if cap is not None:
                cap.release()
            cv2.destroyAllWindows()


if __name__ == "__main__":
    asyncio.run(run(parse_args()))



=== CATEGORY: INTERNAL ===

=== GITHUB: internal/test_generate_diff_matrix.py ===
import json
import subprocess

import generate_diff_matrix as gdm
import pytest


def test_determine_diff_range_push():
    event = {"before": "commit1", "after": "commit2"}
    base, head = gdm.determine_diff_range(event, "push")
    assert base == "commit1"
    assert head == "commit2"


def test_determine_diff_range_pull():
    event = {
        "pull_request": {
            "base": {"sha": "base_sha"},
            "head": {"sha": "head_sha"},
        }
    }
    base, head = gdm.determine_diff_range(event, "pull_request")
    assert base == "base_sha"
    assert head == "head_sha"


def test_determine_diff_range_invalid_event():
    event = {}
    with pytest.raises(SystemExit):
        gdm.determine_diff_range(event, "unsupported_event")


def test_filter_files():
    files = [
        "example.py",
        "internal/test.py",
        "misc/skip.py",
        "script.js",
        "dir/another.py",
    ]
    filtered = gdm.filter_files(files)
    assert filtered == ["example.py", "dir/another.py"]


def test_get_changed_files(monkeypatch):
    class DummyCompletedProcess:
        def __init__(self, stdout):
            self.stdout = stdout

    def fake_run(args, capture_output, text, check):
        return DummyCompletedProcess("file1.py\nfile2.py\n")

    monkeypatch.setattr(subprocess, "run", fake_run)
    files = gdm.get_changed_files("base", "head")
    assert files == ["file1.py", "file2.py"]


def test_write_output(tmp_path, monkeypatch):
    temp_output = tmp_path / "github_output.txt"
    monkeypatch.setenv("GITHUB_OUTPUT", str(temp_output))

    gdm.write_output("test_key", "test_value")

    with open(temp_output, "r") as f:
        content = f.read()
    assert "test_key=test_value" in content


def test_main_push(monkeypatch, tmp_path):
    # simulate a push event by creating a temporary event JSON
    event_data = {"before": "commit1", "after": "commit2"}
    event_file = tmp_path / "event.json"
    event_file.write_text(json.dumps(event_data))

    monkeypatch.setenv("GITHUB_EVENT_PATH", str(event_file))
    monkeypatch.setenv("GITHUB_EVENT_NAME", "push")

    output_file = tmp_path / "output.txt"
    monkeypatch.setenv("GITHUB_OUTPUT", str(output_file))

    # override get_changed_files to simulate a git diff call
    def fake_get_changed_files(base, head):
        return ["file1.py", "internal/ignore.py", "misc/skip.py", "dir/keep.py"]

    monkeypatch.setattr(gdm, "get_changed_files", fake_get_changed_files)

    gdm.main()

    with open(output_file, "r") as f:
        output_content = f.read().strip()
    expected = json.dumps(["file1.py", "dir/keep.py"])
    assert f"all_changed_files={expected}" in output_content


def test_main_pull(monkeypatch, tmp_path):
    # simulate a pull_request event
    event_data = {
        "pull_request": {
            "base": {"sha": "base_commit"},
            "head": {"sha": "head_commit"},
        }
    }
    event_file = tmp_path / "event.json"
    event_file.write_text(json.dumps(event_data))

    monkeypatch.setenv("GITHUB_EVENT_PATH", str(event_file))
    monkeypatch.setenv("GITHUB_EVENT_NAME", "pull_request")

    output_file = tmp_path / "output.txt"
    monkeypatch.setenv("GITHUB_OUTPUT", str(output_file))

    def fake_get_changed_files(base, head):
        return [
            "pull_file.py",
            "internal/not_this.py",
            "misc/also_not.py",
            "folder/keep_this.py",
        ]

    monkeypatch.setattr(gdm, "get_changed_files", fake_get_changed_files)

    gdm.main()

    with open(output_file, "r") as f:
        output_content = f.read().strip()
    expected = json.dumps(["pull_file.py", "folder/keep_this.py"])
    assert f"all_changed_files={expected}" in output_content


=== GITHUB: internal/examples_test.py ===
import importlib
import json
import pathlib
import sys

import pytest
from utils import (
    EXAMPLES_ROOT,
    ExampleType,
    get_examples,
    get_examples_json,
    render_example_md,
)

examples = [ex for ex in get_examples() if ex.type == ExampleType.MODULE]
examples = [ex for ex in examples if ex.metadata.get("pytest", True)]
example_ids = [ex.module for ex in examples]


@pytest.fixture(autouse=True)
def disable_auto_mount(monkeypatch):
    monkeypatch.setenv("MODAL_AUTOMOUNT", "0")
    yield


@pytest.fixture(autouse=False)
def add_root_to_syspath(monkeypatch):
    sys.path.append(str(EXAMPLES_ROOT))
    yield
    sys.path.pop()


@pytest.mark.parametrize("example", examples, ids=example_ids)
def test_filename(example):
    assert not example.repo_filename.startswith("/")
    assert pathlib.Path(example.repo_filename).exists()


@pytest.mark.parametrize("example", examples, ids=example_ids)
def test_import(example, add_root_to_syspath):
    importlib.import_module(example.module)


@pytest.mark.parametrize("example", examples, ids=example_ids)
def test_render(example):
    md = render_example_md(example)
    assert isinstance(md, str)
    assert len(md) > 0


def test_json():
    data = get_examples_json()
    examples = json.loads(data)
    assert isinstance(examples, list)
    assert len(examples) > 0


=== GITHUB: internal/conftest.py ===
import pytest


@pytest.fixture(autouse=True)
def disable_auto_mount(monkeypatch):
    monkeypatch.setenv("MODAL_AUTOMOUNT", "0")
    yield


=== GITHUB: internal/deploy.py ===
import argparse
import os
import re
import shlex
import subprocess
import sys
from pathlib import Path
from typing import NamedTuple, Optional

from utils import ExampleType, get_examples


class DeployError(NamedTuple):
    stdout: str
    stderr: str
    code: int


def deploy(
    deployable: bool,
    module_with_app: Path,
    dry_run: bool,
    filter_pttrn: Optional[str],
    env: Optional[dict[str, str]],
) -> Optional[DeployError]:
    if filter_pttrn and not re.match(filter_pttrn, module_with_app.name):
        return None

    if not deployable:
        print(f"⏩ skipping: '{module_with_app.name}' is not marked for deploy")
        return None

    deploy_command = f"modal deploy {module_with_app.name}"
    if dry_run:
        print(f"🌵  dry-run: '{module_with_app.name}' would have deployed")
    else:
        print(f"⛴ deploying: '{module_with_app.name}' ...")
        r = subprocess.run(
            shlex.split(deploy_command),
            cwd=module_with_app.parent,
            capture_output=True,
            env=os.environ | (env or {}),
        )
        if r.returncode != 0:
            print(
                f"⚠️ deployment failed: '{module_with_app.name}'",
                file=sys.stderr,
            )
            print(r.stderr)
            return DeployError(stdout=r.stdout, stderr=r.stderr, code=r.returncode)
        else:
            print(f"✔️ deployed '{module_with_app.name}")
    return None


def main(argv: Optional[list[str]] = None) -> int:
    parser = argparse.ArgumentParser(
        description="Deploy Modal example programs to our Modal organization.",
        add_help=True,
    )
    parser.add_argument(
        "--dry-run",
        default=True,
        action="store_true",
        help="show what apps be deployed without deploying them.",
    )
    parser.add_argument("--no-dry-run", dest="dry_run", action="store_false")
    parser.add_argument(
        "--filter",
        default=None,
        help="Filter which apps are deployed with basic pattern matching. eg. 'cron' matches 'say_hello_cron.py'.",
    )
    arguments = parser.parse_args()

    if arguments.dry_run:
        print(
            "INFO: dry-run is active. Intended deployments will be displayed to console."
        )

    example_modules = (ex for ex in get_examples() if ex.type == ExampleType.MODULE)
    filter_pttrn = (r".*" + arguments.filter + r".*") if arguments.filter else None
    results = [
        deploy(
            deployable=bool(ex_mod.metadata.get("deploy")),
            module_with_app=Path(ex_mod.module),
            dry_run=arguments.dry_run,
            filter_pttrn=filter_pttrn,
            env=ex_mod.metadata.get("env"),
        )
        for ex_mod in example_modules
    ]

    failures = [r for r in results if r]
    if any(failures):
        print(f"ERROR: {len(failures)} deployment failures.")
        return 1
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


=== GITHUB: internal/requirements.txt ===
pytest
jupyter
ipython
nbconvert
jupytext~=1.16.1
pydantic~=1.10.14
mypy==1.2.0
ruff==0.9.6
fastapi


=== GITHUB: internal/typecheck.py ===
"""
MyPy type-checking script.
Unvalidated, incorrect type-hints are worse than no type-hints!
"""

import concurrent
import os
import pathlib
import subprocess
import sys
from concurrent.futures import ProcessPoolExecutor

import mypy.api


def fetch_git_repo_root() -> pathlib.Path:
    return pathlib.Path(
        subprocess.check_output(["git", "rev-parse", "--show-toplevel"])
        .decode("ascii")
        .strip()
    )


def run_mypy(pkg: str, config_file: pathlib.Path) -> list[str]:
    args = [
        pkg,
        "--no-incremental",
        "--namespace-packages",
        "--config-file",
        str(config_file),
    ]
    result = mypy.api.run(args)
    return result[0].splitlines()


def extract_errors(output: list[str]) -> list[str]:
    if len(output) > 0 and "success" in output[0].lower():
        print(output[0], file=sys.stderr)
        return []
    return [l for l in output if "error" in l]


def main() -> int:
    repo_root = fetch_git_repo_root()
    config_file = repo_root / "pyproject.toml"
    errors = []

    # Type-check scripts
    topic_dirs = sorted([d for d in repo_root.iterdir() if d.name[:2].isdigit()])

    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
        future_to_path = {}
        for topic_dir in topic_dirs:
            for pth in topic_dir.iterdir():
                if not (pth.is_file() and pth.name.endswith(".py")):
                    continue
                elif "__pycache__" in pth.parts:
                    continue
                else:
                    print(f"⌛️ spawning mypy on '{pth}'", file=sys.stderr)
                    future = executor.submit(
                        run_mypy, pkg=str(pth), config_file=config_file
                    )
                    future_to_path[future] = pth

        for future in concurrent.futures.as_completed(future_to_path, timeout=60):
            pth = future_to_path[future]
            try:
                output = future.result()
                topic_errors = extract_errors(output)
                if topic_errors:
                    print(f"\nfound {len(topic_errors)} errors in '{pth}'")
                    print("\n".join(topic_errors))
                    errors.extend(topic_errors)
            except Exception as exc:
                print(f"Error on file {pth}: {exc}")
                errors.append(exc)

    # Type-check packages
    # Getting mypy running successfully with a monorepo of heterogenous packaging structures
    # is a bit fiddly, so we expect top-level packages to opt-in to type-checking by placing a
    # `py.typed` file inside themselves. https://peps.python.org/pep-0561/
    for py_typed in repo_root.glob("**/py.typed"):
        if "site-packages" in py_typed.parts:
            continue
        toplevel_pkg = py_typed.parent
        print(f"⌛️ running mypy on '{toplevel_pkg}'", file=sys.stderr)
        package_errors = extract_errors(
            run_mypy(
                pkg=str(toplevel_pkg),
                config_file=config_file,
            )
        )
        if package_errors:
            print(
                f"found {len(package_errors)} errors in '{toplevel_pkg}'",
                file=sys.stderr,
            )
            print("\n".join(package_errors))
            errors.extend(package_errors)

    if errors:
        return 1
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


=== GITHUB: internal/readme.md ===
## `Internal/`

This folder contains internal repository and documentation management code.
It does not contain examples.

### Continuous Integration and Continuous Deployment

Modal cares deeply about the correctness of our examples -- we have also
suffered from janky, poorly-maintained documentation and we do our best to
ensure that our examples don't pay that forward.

This document explains the CI/CD process we use. It is primarily intended for
Modal engineers, but if you're contributing an example and have the bandwidth to
set up the testing as well, we appreciate it!

#### Frontmatter

Examples can include a small frontmatter block in YAML format that controls
testing and deployment behavior.

Fields include:

- `deploy`: If `true`, the example is deployed as a Modal application with
  `modal deploy`. If `false`, it is not. Default is `false`. Examples should be
  deployed only if they are a live demo or they are consumed as a service by
  other examples.
- `cmd`: The command to run the example for testing. Default is
  `["modal", "run", "<path>"]`. All `path`s should be relative to the
  root directory of the repository.
- `args`: Arguments to pass to the command. Default is `[]`.
- `lambda-test`: If `true`, the example is tested with the cli command provided
  in `cmd`. If `false`, it is not. Default is `true`. Note that this controls
  execution in the CI/CD of this repo _and_ in the internal AWS Lambda monitor
  as part of `synthetic_monitoring`.
- `env`: A dictionary of environment variables to include when testing.
  Default is `{}`, but note that the environment can be modified in the CI/CD of
  this repo or in the monitor-based testing.

Below is an example frontmatter for deploying a web app. Note that here we
`modal serve` in the test so as to not deploy to prod when testing. Note that in
testing environments, the `MODAL_SERVE_TIMEOUT` environment variable is set so
that the command terminates.

```yaml
---
deploy: true
cmd: ["modal", "serve", "10_integrations/pushgateway.py"]
---
# example prose and code begins here
```

#### Testing in GitHub Actions

When a PR is opened or updated, any changed examples are run via GitHub Actions.
We also create a preview of the documentation site and share the URL in the PR.

You can find the commands used to execute tests in the `.github/workflows`
directory. These can be used to run the tests locally. You may need to install
the `requirements.txt` in this folder to do so.

This workflow is intended to catch errors at the time a PR is made -- including
both errors in the example and issues with the execution of the example in the
monitoring system, like file imports.

#### Continual Monitoring

Examples are executed regularly and at random to check for regressions. The
results are monitored.

Modal engineers, see `synthetic_monitoring` in the `modal` repo for details.

### Previewing the Documentation Site

Modal engineers can preview the documentation site with a fast-reloading
development server (`inv just-frontend`) when iterating or with a shareable
Web deployment with one week TTL (`inv frontend-preview`). See the `modal`
repo for details.

You can find the process for creating a preview in the GitHub Action.


=== GITHUB: internal/run_example.py ===
import os
import random
import subprocess
import sys
import time

from . import utils

MINUTES = 60
TIMEOUT = 12 * MINUTES


def run_script(example):
    t0 = time.time()

    try:
        print(f"cli args: {example.cli_args}")
        process = subprocess.run(
            [str(x) for x in example.cli_args],
            env=os.environ | example.env | {"MODAL_SERVE_TIMEOUT": "5.0"},
            timeout=TIMEOUT,
        )
        total_time = time.time() - t0
        if process.returncode == 0:
            print(f"Success after {total_time:.2f}s :)")
        else:
            print(
                f"Failed after {total_time:.2f}s with return code {process.returncode} :("
            )

        returncode = process.returncode

    except subprocess.TimeoutExpired:
        print(f"Past timeout of {TIMEOUT}s :(")
        returncode = 999

    return returncode


def run_single_example(stem):
    examples = utils.get_examples()
    for example in examples:
        if stem == example.stem and example.metadata.get("lambda-test", True):
            return run_script(example)
    else:
        print(f"Could not find example name {stem}")
        return 0


def run_random_example():
    examples = filter(
        lambda ex: ex.metadata and ex.metadata.get("lambda-test", True),
        utils.get_examples(),
    )
    return run_script(random.choice(list(examples)))


if __name__ == "__main__":
    if len(sys.argv) > 1:
        sys.exit(run_single_example(sys.argv[1]))
    else:
        sys.exit(run_random_example())


=== GITHUB: internal/utils.py ===
import json
import re
import warnings
from enum import Enum
from pathlib import Path
from typing import Iterator, Optional

from pydantic import BaseModel

EXAMPLES_ROOT = Path(__file__).parent.parent


with warnings.catch_warnings():
    # This triggers some dumb warning in jupyter_core
    warnings.simplefilter("ignore")
    import jupytext
    import jupytext.config


class ExampleType(int, Enum):
    MODULE = 1
    ASSET = 2


class Example(BaseModel):
    type: ExampleType
    filename: str  # absolute filepath to example file
    module: Optional[str] = (
        None  # python import path, or none if file is not a py module.
    )
    # TODO(erikbern): don't think the module is used (by docs or monitors)?
    metadata: Optional[dict] = None
    repo_filename: str  # git repo relative filepath
    cli_args: Optional[list] = None  # Full command line args to run it
    stem: Optional[str] = None  # stem of path
    tags: Optional[list[str]] = None  # metadata tags for the example
    env: Optional[dict[str, str]] = None  # environment variables for the example


_RE_NEWLINE = re.compile(r"\r?\n")
_RE_FRONTMATTER = re.compile(r"^---$", re.MULTILINE)
_RE_CODEBLOCK = re.compile(r"\s*```[^`]+```\s*", re.MULTILINE)


def render_example_md(example: Example) -> str:
    """Render a Python code example to Markdown documentation format."""

    with open(example.filename) as f:
        content = f.read()

    lines = _RE_NEWLINE.split(content)
    markdown: list[str] = []
    code: list[str] = []
    for line in lines:
        if line == "#" or line.startswith("# "):
            if code:
                markdown.extend(["```python", *code, "```", ""])
                code = []
            markdown.append(line[2:])
        else:
            if markdown and markdown[-1]:
                markdown.append("")
            if code or line:
                code.append(line)

    if code:
        markdown.extend(["```python", *code, "```", ""])

    text = "\n".join(markdown)
    if _RE_FRONTMATTER.match(text):
        # Strip out frontmatter from text.
        if match := _RE_FRONTMATTER.search(text, 4):
            text = text[match.end() + 1 :]

    if match := _RE_CODEBLOCK.match(text):
        filename = Path(example.filename).name
        if match.end() == len(text):
            # Special case: The entire page is a single big code block.
            text = f"""# Example ({filename})

This is the source code for **{example.module}**.
{text}"""

    return text


def gather_example_files(
    parents: list[str], subdir: Path, ignored: list[str], recurse: bool
) -> Iterator[Example]:
    config = jupytext.config.JupytextConfiguration(
        root_level_metadata_as_raw_cell=False
    )

    for filename in sorted(list(subdir.iterdir())):
        if filename.is_dir() and recurse:
            # Gather two-subdirectories deep, but no further.
            yield from gather_example_files(
                parents + [str(subdir.stem)], filename, ignored, recurse=False
            )
        else:
            filename_abs: str = str(filename.resolve())
            ext: str = filename.suffix
            if parents:
                repo_filename: str = (
                    f"{'/'.join(parents)}/{subdir.name}/{filename.name}"
                )
            else:
                repo_filename: str = f"{subdir.name}/{filename.name}"

            if ext == ".py" and filename.stem != "__init__":
                if parents:
                    parent_mods = ".".join(parents)
                    module = f"{parent_mods}.{subdir.stem}.{filename.stem}"
                else:
                    module = f"{subdir.stem}.{filename.stem}"
                data = jupytext.read(open(filename_abs), config=config)
                metadata = data["metadata"]["jupytext"].get("root_level_metadata", {})
                cmd = metadata.get("cmd", ["modal", "run", repo_filename])
                args = metadata.get("args", [])
                tags = metadata.get("tags", [])
                env = metadata.get("env", dict())
                yield Example(
                    type=ExampleType.MODULE,
                    filename=filename_abs,
                    metadata=metadata,
                    module=module,
                    repo_filename=repo_filename,
                    cli_args=(cmd + args),
                    stem=Path(filename_abs).stem,
                    tags=tags,
                    env=env,
                )
            elif ext in [".png", ".jpeg", ".jpg", ".gif", ".mp4"]:
                yield Example(
                    type=ExampleType.ASSET,
                    filename=filename_abs,
                    repo_filename=repo_filename,
                )
            else:
                ignored.append(str(filename))


def get_examples() -> Iterator[Example]:
    """Yield all Python module files and asset files relevant to building modal.com/docs."""
    if not EXAMPLES_ROOT.exists():
        raise Exception(
            f"Can't find directory {EXAMPLES_ROOT}. You might need to clone the modal-examples repo there."
        )

    ignored = []
    for subdir in sorted(
        p
        for p in EXAMPLES_ROOT.iterdir()
        if p.is_dir()
        and not p.name.startswith(".")
        and not p.name.startswith("internal")
        and not p.name.startswith("misc")
    ):
        yield from gather_example_files(
            parents=[], subdir=subdir, ignored=ignored, recurse=True
        )


def get_examples_json():
    examples = list(ex.dict() for ex in get_examples())
    return json.dumps(examples)


if __name__ == "__main__":
    for example in get_examples():
        print(example.model_dump_json())


=== GITHUB: internal/generate_diff_matrix.py ===
import json
import os
import subprocess
import sys


def load_event():
    event_path = os.environ.get("GITHUB_EVENT_PATH")
    if not event_path:
        print("GITHUB_EVENT_PATH not set", file=sys.stderr)
        sys.exit(1)
    try:
        with open(event_path, "r") as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading event JSON: {e}", file=sys.stderr)
        sys.exit(1)


def determine_diff_range(event, event_name):
    if event_name == "pull_request":
        try:
            base = event["pull_request"]["base"]["sha"]
            head = event["pull_request"]["head"]["sha"]
        except KeyError as e:
            print(f"Missing key in pull_request event: {e}", file=sys.stderr)
            sys.exit(1)
    elif event_name == "push":
        base = event.get("before")
        head = event.get("after")
    else:
        print(f"Unsupported event type: {event_name}", file=sys.stderr)
        sys.exit(1)

    if not base or not head:
        print("Could not determine base and head commits", file=sys.stderr)
        sys.exit(1)
    return base, head


def get_changed_files(base, head):
    try:
        result = subprocess.run(
            ["git", "diff", "--name-only", base, head],
            capture_output=True,
            text=True,
            check=True,
        )
        return result.stdout.splitlines()
    except subprocess.CalledProcessError as e:
        print(f"Error running git diff: {e}", file=sys.stderr)
        sys.exit(1)


def filter_files(files):
    return [
        f
        for f in files
        if f.endswith(".py")
        and not (f.startswith("internal/") or f.startswith("misc/"))
    ]


def write_output(key, value):
    github_output = os.environ.get("GITHUB_OUTPUT")
    if github_output:
        try:
            with open(github_output, "a") as out:
                out.write(f"{key}={value}\n")
        except Exception as e:
            print(f"Error writing to GITHUB_OUTPUT: {e}", file=sys.stderr)


def main():
    event = load_event()
    event_name = event.get("event_name") or os.environ.get("GITHUB_EVENT_NAME")
    base, head = determine_diff_range(event, event_name)
    changed_files = get_changed_files(base, head)
    filtered_files = filter_files(changed_files)
    json_output = json.dumps(filtered_files)
    write_output("all_changed_files", json_output)
    print(json_output)


if __name__ == "__main__":
    main()



====================================================================================================
DOCUMENTATION SITE: BOOTSTRAP
Size: 0.9 MB
====================================================================================================

=== BOOTSTRAP 5.3 COMPLETE DOCUMENTATION COLLECTION ===
Ultra-comprehensive Bootstrap documentation scraped with 80%+ coverage
Source: https://getbootstrap.com/docs/5.3/
Scraped with: Ultra-aggressive parallel scraper
Content: Getting Started, Layout, Content, Forms, Components, Helpers, Utilities, Customization, and More
================================================================================


========================= GETTING STARTED =========================
Section: Getting Started
Files: 18
======================================================================

--- 002_getting-started_browsers-devices.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/browsers-devices
--------------------------------------------------
Supported browsers
latest, stable releases
of all major browsers and platforms.
Alternative browsers which use the latest version of WebKit, Blink, or Gecko, whether directly or via the platform’s web view API, are not explicitly supported. However, Bootstrap should (in most cases) display and function correctly in these browsers as well. More specific support information is provided below.
You can find our supported range of browsers and their versions
in our
.browserslistrc file
# https://github.com/browserslist/browserslist#readme
>= 0.5%
last 2 major versions
not dead
Chrome >= 60
Firefox >= 60
Firefox ESR
iOS >= 12
Safari >= 12
not Explorer <= 11
not kaios <= 2.5 # fix floating label issues in Firefox (see https://github.com/postcss/autoprefixer/issues/1533)
We use
Autoprefixer
to handle intended browser support via CSS prefixes, which uses
Browserslist
to manage these browser versions. Consult their documentation for how to integrate these tools into your projects.
Mobile devices
Generally speaking, Bootstrap supports the latest versions of each major platform’s default browsers. Note that proxy browsers (such as Opera Mini, Opera Mobile’s Turbo mode, UC Browser Mini, Amazon Silk) are not supported.
Chrome
Firefox
Safari
Android Browser & WebView
Android
Supported
Supported
Supported
Supported
Supported
Desktop browsers
Similarly, the latest versions of most desktop browsers are supported.
Chrome
Firefox
Microsoft Edge
Opera
Safari
Supported
Supported
Supported
Supported
Supported
Windows
Supported
Supported
Supported
Supported
For Firefox, in addition to the latest normal stable release, we also support the latest
Extended Support Release (ESR)
version of Firefox.
Unofficially, Bootstrap should look and behave well enough in Chromium and Chrome for Linux, and Firefox for Linux, though they are not officially supported.
Internet Explorer
Internet Explorer is not supported.
If you require Internet Explorer support, please use Bootstrap v4.
Modals and dropdowns on mobile
Overflow and scrolling
Support for
overflow: hidden;
on the
<body>
element is quite limited in iOS and Android. To that end, when you scroll past the top or bottom of a modal in either of those devices’ browsers, the
<body>
content will begin to scroll. See
Chrome bug #175502
(fixed in Chrome v40) and
WebKit bug #153852
iOS text fields and scrolling
As of iOS 9.2, while a modal is open, if the initial touch of a scroll gesture is within the boundary of a textual
<input>
or a
<textarea>
, the
<body>
content underneath the modal will be scrolled instead of the modal itself. See
WebKit bug #153856
Navbar Dropdowns
.dropdown-backdrop
element isn’t used on iOS in the nav because of the complexity of z-indexing. Thus, to close dropdowns in navbars, you must directly click the dropdown element (or
any other element which will fire a click event in iOS
Browser zooming
Page zooming inevitably presents rendering artifacts in some components, both in Bootstrap and the rest of the web. Depending on the issue, we may be able to fix it (search first and then open an issue if need be). However, we tend to ignore these as they often have no direct solution other than hacky workarounds.
Validators
In order to provide the best possible experience to old and buggy browsers, Bootstrap uses
CSS browser hacks
in several places to target special CSS to certain browser versions in order to work around bugs in the browsers themselves. These hacks understandably cause CSS validators to complain that they are invalid. In a couple places, we also use bleeding-edge CSS features that aren’t yet fully standardized, but these are used purely for progressive enhancement.
These validation warnings don’t matter in practice since the non-hacky portion of our CSS does fully validate and the hacky portions don’t interfere with the proper functioning of the non-hacky portion, hence why we deliberately ignore these particular warnings.
Our HTML docs likewise have some trivial and inconsequential HTML validation warnings due to our inclusion of a workaround for
a certain Firefox bug


--- 008_getting-started_accessibility.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/accessibility
--------------------------------------------------
Overview and limitations
The overall accessibility of any project built with Bootstrap depends in large part on the author’s markup, additional styling, and scripting they’ve included. However, provided that these have been implemented correctly, it should be perfectly possible to create websites and applications with Bootstrap that fulfill
WCAG
(A/AA/AAA),
Section 508
, and similar accessibility standards and requirements.
Structural markup
Interactive components
ARIA
roles and attributes, these components should also be understandable and operable using assistive technologies (such as screen readers).
Because Bootstrap’s components are purposely designed to be fairly generic, authors may need to include further
ARIA
roles and attributes, as well as JavaScript behavior, to more accurately convey the precise nature and functionality of their component. This is usually noted in the documentation.
Color contrast
Some combinations of colors that currently make up Bootstrap’s default palette—used throughout the framework for things such as button variations, alert variations, form validation indicators—may lead to
insufficient
color contrast (below the recommended
WCAG 2.2 text color contrast ratio of 4.5:1
and the
WCAG 2.2 non-text color contrast ratio of 3:1
), particularly when used against a light background. Authors are encouraged to test their specific uses of color and, where necessary, manually modify/extend these default colors to ensure adequate color contrast ratios.
Visually hidden content
Content which should be visually hidden, but remain accessible to assistive technologies such as screen readers, can be styled using the
.visually-hidden
class. This can be useful in situations where additional visual information or cues (such as meaning denoted through the use of color) need to also be conveyed to non-visual users.
class
text-danger
span
class
visually-hidden
Danger:
span
This action is not reversible
For visually hidden interactive controls, such as traditional “skip” links, use the
.visually-hidden-focusable
class. This will ensure that the control becomes visible once focused (for sighted keyboard users).
Watch out, compared to the equivalent
.sr-only
.sr-only-focusable
classes in past versions, Bootstrap 5’s
.visually-hidden-focusable
is a standalone class, and must not be used in combination with the
.visually-hidden
class.
class
visually-hidden-focusable
href
#content
Reduced motion
prefers-reduced-motion
media feature
. In browsers/environments that allow the user to specify their preference for reduced motion, most CSS transition effects in Bootstrap (for instance, when a modal dialog is opened or closed, or the sliding animation in carousels) will be disabled, and meaningful animations (such as spinners) will be slowed down.
On browsers that support
prefers-reduced-motion
, and where the user has
explicitly signaled that they’d prefer reduced motion (i.e. where
prefers-reduced-motion: no-preference
), Bootstrap enables smooth scrolling using the
scroll-behavior
property.
Additional resources
Web Content Accessibility Guidelines (WCAG) 2.2
The A11Y Project
MDN accessibility documentation
Color Contrast Analyser (CCA)
"HTML Codesniffer" bookmarklet for identifying accessibility issues
Microsoft Accessibility Insights
Deque Axe testing tools
Introduction to Web Accessibility


--- 009_examples_checkout-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/checkout-rtl
--------------------------------------------------
نموذج إتمام الشراء
فيما يلي مثال على نموذج تم إنشاؤه بالكامل باستخدام عناصر تحكم النموذج في Bootstrap. لكل مجموعة نماذج مطلوبة حالة تحقق يمكن تشغيلها بمحاولة إرسال النموذج دون استكماله.
عربة التسوق
اسم المنتج
وصف مختصر
المنتج الثاني
وصف مختصر
البند الثالث
وصف مختصر
رمز ترويجي
EXAMPLECODE
مجموع (USD)
تحقق
عنوان الفوترة
الاسم الأول
يرجى إدخال اسم أول صحيح.
اسم العائلة
يرجى إدخال اسم عائلة صحيح.
اسم المستخدم
اسم المستخدم الخاص بك مطلوب.
البريد الإلكتروني
(اختياري)
يرجى إدخال عنوان بريد إلكتروني صحيح لتصلكم تحديثات الشحن.
العنوان
يرجى إدخال عنوان الشحن الخاص بك.
عنوان 2
(اختياري)
البلد
اختر...
الولايات المتحدة الأمريكية
يرجى اختيار بلد صحيح.
المنطقة
اختر...
كاليفورنيا
يرجى اختيار اسم منطقة صحيح.
الرمز البريدي
الرمز البريدي مطلوب.
عنوان الشحن هو نفس عنوان الفوترة الخاص بي
احفظ هذه المعلومات في المرة القادمة
طريقة الدفع
بطاقة ائتمان
PayPal
الاسم على البطاقة
الاسم الكامل كما هو معروض على البطاقة
الاسم على البطاقة مطلوب
رقم البطاقة
رقم بطاقة الائتمان مطلوب
تاريخ انتهاء الصلاحية
تاريخ انتهاء الصلاحية مطلوب
الرمز الثلاثي (CVV)
رمز الحماية مطلوب
الاستمرار بالدفع


--- 016_getting-started_introduction.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/introduction
--------------------------------------------------
Quick start
Get started by including Bootstrap’s production-ready CSS and JavaScript via CDN without the need for any build steps. See it in practice with this
Create a new
index.html
file in your project root.
Include the
<meta name="viewport">
tag as well for
proper responsive behavior
in mobile devices.
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
head
body
Hello, world!
body
html
Include Bootstrap’s CSS and JS.
Place the
<link>
tag in the
<head>
for our CSS, and the
<script>
tag for our JavaScript bundle (including Popper for positioning dropdowns, popovers, and tooltips) before the closing
</body>
. Learn more about our
CDN links
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
link
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.min.css
stylesheet
integrity
sha384-LN+7fdVzj6u52u30Kp6M/trliBMCMKTyK833zpbD+pXdCLuTusPj697FH4R/5mcr
crossorigin
anonymous
head
body
Hello, world!
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.bundle.min.js
integrity
sha384-ndDqU0Gzau9qJ1lfW4pNLlhNTkCfHzAVBReH9diLvGRem5+R9g2FzA8ZGN954O5Q
crossorigin
anonymous
script
body
html
You can also include
Popper
and our JS separately. If you don’t plan to use dropdowns, popovers, or tooltips, save some kilobytes by not including Popper.
script
https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js
integrity
sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r
crossorigin
anonymous
script
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.min.js
integrity
sha384-7qAoOXltbVP82dhxHAUje59V5r2YsVfBafyUDxEdApLPmcdhBPg1DKg1ERo0BZlK
crossorigin
anonymous
script
Hello, world!
Open the page in your browser of choice to see your Bootstrapped page. Now you can start building with Bootstrap by creating your own
layout
, adding dozens of
components
, and utilizing
our official examples
CDN links
As reference, here are our primary CDN links.
Description
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.min.css
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.bundle.min.js
You can also use the CDN to fetch any of our
additional builds listed in the Contents page
When using CDN links, be sure to use the
integrity
attribute to verify the correct files and versions. These hashes are unique to each file and version of Bootstrap, so when you update to a new version, be sure the
integrity
attribute is also updated.
We also include a
crossorigin="anonymous"
attribute to prevent
CORS
errors.
Next steps
Read a bit more about some
important global environment settings
that Bootstrap utilizes.
Read about what’s included in Bootstrap in our
contents section
and the list of
components that require JavaScript
below.
Need a little more power? Consider building with Bootstrap by
including the source files via package manager
Looking to use Bootstrap as a module with
<script type="module">
? Please refer to our
using Bootstrap as a module
section.
JS components
Curious which components explicitly require our JavaScript and Popper? If you’re at all unsure about the general page structure, keep reading for an example page template.
Accordions for extending our Collapse plugin
Alerts for dismissing
Buttons for toggling states and checkbox/radio functionality
Carousel for all slide behaviors, controls, and indicators
Collapse for toggling visibility of content
Dropdowns for displaying and positioning (also requires
Popper
Modals for displaying, positioning, and scroll behavior
Navbar for extending our Collapse and Offcanvas plugins to implement responsive behaviors
Navs with the Tab plugin for toggling content panes
Offcanvases for displaying, positioning, and scroll behavior
Scrollspy for scroll behavior and navigation updates
Toasts for displaying and dismissing
Tooltips and popovers for displaying and positioning (also requires
Popper
Important globals
normalization
of cross browser styles. Let’s dive in.
HTML5 doctype
doctype
html
html
lang
html
Viewport meta
mobile first
, a strategy in which we optimize code for mobile devices first and then scale up components as necessary using CSS media queries. To ensure proper rendering and touch zooming for all devices, add the responsive viewport meta tag to your
<head>
meta
name
viewport
content
width=device-width, initial-scale=1
You can see an example of this in action in the
quick start
Box-sizing
For more straightforward sizing in CSS, we switch the global
box-sizing
value from
content-box
border-box
. This ensures
padding
does not affect the final computed width of an element, but it can cause problems with some third-party software like Google Maps and Google Custom Search Engine.
On the rare occasion you need to override it, use something like the following:
.selector-for-some-widget
box-sizing
content-box
With the above snippet, nested elements—including generated content via
::before
::after
—will all inherit the specified
box-sizing
for that
.selector-for-some-widget
Learn more about
box model and sizing at CSS Tricks
Reboot
For improved cross-browser rendering, we use
Reboot
to correct inconsistencies across browsers and devices while providing slightly more opinionated resets to common HTML elements.
Community
Stay up-to-date on the development of Bootstrap and reach out to the community with these helpful resources.
Read and subscribe to
The Official Bootstrap Blog
Ask questions and explore
our GitHub Discussions
Discuss, ask questions, and more on
the community Discord
Chat with fellow Bootstrappers in IRC. On the
irc.libera.chat
server, in the
#bootstrap
channel.
Implementation help may be found at Stack Overflow (tagged
Developers should use the keyword
on packages that modify or add to the functionality of Bootstrap when distributing through
or similar delivery mechanisms for maximum discoverability.
You can also follow
@getbootstrap on X
for the latest gossip and awesome music videos.


--- 017_examples_cheatsheet-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/cheatsheet-rtl
--------------------------------------------------
المحتوى
النصوص
دليل الإستخدام
العرض 1
العرض 2
العرض 3
العرض 4
العرض 5
العرض 6
عنوان 1
عنوان 2
عنوان 3
عنوان 4
عنوان 5
عنوان 6
هذه قطعة إملائية متميزة، فهي مصممة لتكون بارزة من بين القطع الإملائية الأخرى.
يمكنك استخدام تصنيف mark
لتحديد
من المفترض أن يتم التعامل مع هذا السطر كنص محذوف.
من المفترض أن يتم التعامل مع هذا السطر على أنه لم يعد دقيقًا.
من المفترض أن يتم التعامل مع هذا السطر كإضافة إلى المستند.
سيتم عرض النص في هذا السطر كما وتحته خط.
من المفترض أن يتم التعامل مع هذا السطر على أنه يحوي تفاصيل صغيرة.
هذا السطر يحوي نص عريض.
هذا السطر يحوي نص مائل.
إقتباس مبهر، موضوع في عنصر blockquote
هذه قائمة عناصر.
بالرغم من أنها مصممة كي لا تظهر كذلك.
إلا أنها مجهزة كـ قائمة خلف الكواليس
هذا التصميم ينطبق فقد على القائمة الرئيسية
القوائم الفرعية
لا تتأثر بهذا التصميم
فهي تظهر عليها علامات الترقيم
وتحتوي على مساحة فارغة بجوارها
قد يكون هذا التصميم مفيدًا في بعض الأحيان.
هذا عنصر في قائمة.
وهذا أيضًا.
لكنهم يظهرون متجاورين.
الصور
دليل الإستخدام
Placeholder
صورة مستجيبة
صورة عنصر نائب مربع عام مع حدود بيضاء حولها ، مما يجعلها تشبه صورة تم التقاطها بكاميرا فورية قديمة
200x200
الجداول
دليل الإستخدام
الاسم الاول
الكنية
الاسم المستعار
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
الاسم الاول
الكنية
الاسم المستعار
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
Class
عنوان
عنوان
Default
خلية
خلية
Primary
خلية
خلية
Secondary
خلية
خلية
Success
خلية
خلية
Danger
خلية
خلية
Warning
خلية
خلية
Info
خلية
خلية
Light
خلية
خلية
Dark
خلية
خلية
الاسم الاول
الكنية
الاسم المستعار
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
النماذج البيانية
دليل الإستخدام
Placeholder
400x300
شرح للصورة أعلاه.
النماذج
نظرة عامة
دليل الإستخدام
البريد الإلكتروني
لن نقوم بمشاركة بريدك الإلكتروني مع أي شخص آخر.
كلمة السر
قائمة اختيار
افتح قائمة الاختيار هذه
واحد
اثنان
ثلاثة
اخترني
أزرار الاختيار الأحادي
الخيار الافتراضي
خيار آخر
زر على شكل مفتاح اختيار.
مثال على حقل اختيار نطاقي
إرسال
الحقول المعطلة
دليل الإستخدام
حقل إدخال معطل
قائمة اختيار معطلة
خيار معطل
زر اختيار معطل
أزرار اختيار أحادي معطلين
خيار معطل
خيار آخر معطل
رفع معطل
زر معطل على شكل مفتاح اختيار.
حقل اختيار نطاقي معطل
إرسال
الأحجام
دليل الإستخدام
افتح قائمة الاختيار هذه
واحد
اثنان
ثلاثة
افتح قائمة الاختيار هذه
واحد
اثنان
ثلاثة
مجموعة الإدخال
دليل الإستخدام
أنا اسمي
وغيرها
عنوان حسابك الشخصي
https://example.com/users/
مع textarea
الحقول ذوي العناوين العائمة
دليل الإستخدام
البريد الالكتروني
كلمة السر
التحقق
دليل الإستخدام
الاسم الاول
يبدو صحيحًا!
الكنية
يبدو صحيحًا!
اسم المستخدم
يرجى اختيار اسم مستخدم.
مدينة
يرجى إدخال مدينة صحيحة.
حالة
اختر...
يرجى اختيار ولاية صحيحة.
الرمز البريدي
يرجى إدخال رمز بريدي صحيح.
أوافق على الشروط والأحكام
تجب الموافقة قبل إرسال النموذج.
إرسال النموذج
العناصر
المطوية
دليل الإستخدام
عنصر المطوية الأول
هذا هو محتوى عنصر المطوية الأول.
سيكون المحتوى مخفيًا بشكل إفتراضي حتى يقوم Bootstrap بإضافة الكلاسات اللازمة لكل عنصر في المطوية. هذه الكلاسات تتحكم بالمظهر العام ووتتحكم أيضا بإظهار وإخفاء أقسام المطوية عبر حركات CSS الإنتقالية. يمكنك تعديل أي من هذه عبر كلاسات CSS خاصة بك، او عبر تغيير القيم الإفتراضية المقدمة من Bootstrap. من الجدير بالذكر أنه يمكن وضع أي كود HTML هنا، ولكن الحركة الإنتقالية قد تحد من الoverflow.
عنصر المطوية الثاني
هذا هو محتوى عنصر المطوية الثاني.
سيكون المحتوى مخفيًا بشكل إفتراضي حتى يقوم Bootstrap بإضافة الكلاسات اللازمة لكل عنصر في المطوية. هذه الكلاسات تتحكم بالمظهر العام ووتتحكم أيضا بإظهار وإخفاء أقسام المطوية عبر حركات CSS الإنتقالية. يمكنك تعديل أي من هذه عبر كلاسات CSS خاصة بك، او عبر تغيير القيم الإفتراضية المقدمة من Bootstrap. من الجدير بالذكر أنه يمكن وضع أي كود HTML هنا، ولكن الحركة الإنتقالية قد تحد من الoverflow.
عنصر المطوية الثالث
هذا هو محتوى عنصر المطوية الثالث.
سيكون المحتوى مخفيًا بشكل إفتراضي حتى يقوم Bootstrap بإضافة الكلاسات اللازمة لكل عنصر في المطوية. هذه الكلاسات تتحكم بالمظهر العام ووتتحكم أيضا بإظهار وإخفاء أقسام المطوية عبر حركات CSS الإنتقالية. يمكنك تعديل أي من هذه عبر كلاسات CSS خاصة بك، او عبر تغيير القيم الإفتراضية المقدمة من Bootstrap. من الجدير بالذكر أنه يمكن وضع أي كود HTML هنا، ولكن الحركة الإنتقالية قد تحد من الoverflow.
الإنذارات
دليل الإستخدام
تنبيه primary بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه secondary بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه success بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه danger بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه warning بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه info بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه light بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
تنبيه dark بسيط مع
رابط مثال
. أعطها نقرة إذا أردت.
أحسنت!
لقد نجحت في قراءة رسالة التنبيه المهمة هذه. سيتم تشغيل نص المثال هذا لفترة أطول قليلاً حتى تتمكن من رؤية كيفية عمل التباعد داخل التنبيه مع هذا النوع من المحتوى.
كلما احتجت إلى ذلك ، تأكد من استخدام أدوات الهامش للحفاظ على الأشياء لطيفة ومرتبة.
الشارة
دليل الإستخدام
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
مثال على عنوان
جديد
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
مسار التنقل التفصيلي (فتات الخبز)
دليل الإستخدام
الأزرار
دليل الإستخدام
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
رابط
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
زر صغير
زر قياسي
زر كبير
مجموعة الأزرار
دليل الإستخدام
البطاقة
دليل الإستخدام
Placeholder
غطاء الصورة
عنوان البطاقة
بعض الأمثلة السريعة للنصوص للبناء على عنوان البطاقة وتشكيل الجزء الأكبر من محتوى البطاقة.
اذهب لمكان ما
متميز
عنوان البطاقة
بعض الأمثلة السريعة للنصوص للبناء على عنوان البطاقة وتشكيل الجزء الأكبر من محتوى البطاقة.
اذهب لمكان ما
منذ يومان
عنوان البطاقة
بعض الأمثلة السريعة للنصوص للبناء على عنوان البطاقة وتشكيل الجزء الأكبر من محتوى البطاقة.
عنصر
عنصر آخر
عنصر ثالث
رابط البطاقة
رابط آخر
Placeholder
صورة
عنوان البطاقة
هذه بطاقة أعرض مع نص داعم تحتها كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
آخر تحديث منذ 3 دقائق
شرائح العرض
دليل الإستخدام
Placeholder
الشريحة الأولى
عنوان الشريحة الأولى
محتوى وصفي يعبئ فراغ الشريحة الأولى.
Placeholder
الشريحة الثانية
عنوان الشريحة الثانية
محتوى وصفي يعبئ فراغ الشريحة الأولى.
Placeholder
الشريحة الثالثة
عنوان الشريحة الثالثة
محتوى وصفي يعبئ فراغ الشريحة الأولى.
السابق
التالي
القوائم المنسدلة
دليل الإستخدام
زر القائمة المنسدلة
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
زر القائمة المنسدلة
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
زر القائمة المنسدلة
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
Primary
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
Secondary
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
Success
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
Info
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
Warning
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
Danger
تبديل القائمة المنسدلة
عمل آخر
شيء آخر هنا
زر القائمة المنسدلة لليسار
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
زر القائمة المنسدلة للأعلى
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
زر القائمة المنسدلة لليمين
عنوان القائمة المنسدلة
عمل آخر
شيء آخر هنا
رابط منفصل
قائمة منسدلة بمحاذاة نهاية الزر
عنوان القائمة المنسدلة
عمل آخر
رابط منفصل
مجموعة العناصر
دليل الإستخدام
عنصر معطل
عنصر ثاني
عنصر ثالث
عنصر رابع
وعنصر خامس أيضًا
عنصر
عنصر ثاني
عنصر ثالث
عنصر رابع
وعنصر خامس أيضًا
عنصر مجموعة قائمة default بسيط
عنصر مجموعة قائمة primary بسيط
عنصر مجموعة قائمة secondary بسيط
عنصر مجموعة قائمة success بسيط
عنصر مجموعة قائمة danger بسيط
عنصر مجموعة قائمة warning بسيط
عنصر مجموعة قائمة info بسيط
عنصر مجموعة قائمة light بسيط
عنصر مجموعة قائمة dark بسيط
الصندوق العائم
دليل الإستخدام
إطلاق صندوق عائم تجريبي
إطلاق صندوق عائم عالق
صندوق عائم متنصف عاموديًا وقابل للتمرير
صندوق عائم يملأ الشاشة
التنقل
دليل الإستخدام
محتوى لتوضيح كيف يعمل التبويب. هذا المحتوى مرتبط بتبويب الصفحة الرئيسية. إذن، أمامنا بعض التحدّيات الصعبة. لكن لا يمكننا أن نعتمد على التطورات التكنولوجية وحدها في ميدان قوى السوق الحرة، لإخراجنا من هذه الورطة، لا سيّما أنها نفسها، مقرونة بالافتقار إلى البصيرة، هي التي أودت بنا إلى هذا التبدُّل المناخي في الدرجة الأولى.
محتوى لتوضيح كيف يعمل التبويب. هذا المحتوى مرتبط بتبويب الملف الشخصي. معظم البشر في بلدان العالَم النامي، لم يقتنوا بعد مكيّفهم الأول، والمشكلة إلى ازدياد. فمعظم البلدان النامية هي من البلدان الأشد حرارة والأكثر اكتظاظًا بالسكان في العالم.
محتوى لتوضيح كيف يعمل التبويب. هذا المحتوى مرتبط بتبويب الاتصال بنا. أمامنا بعض التحدّيات الصعبة. لكن لا يمكننا أن نعتمد على التطورات التكنولوجية وحدها في ميدان قوى السوق الحرة، بل يجب وضع معايير جدوى جديدة لشركات البناء ومعايير أعلى لجدوى التكييف من أجل تحفيز الحلول المستدامة قانونيًا.
رابط
رابط
معطل
شريط التنقل
دليل الإستخدام
ترقيم الصفحات
دليل الإستخدام
الصناديق المنبثقة
دليل الإستخدام
انقر لعرض/إخفاء الصندوق المنبثق
انبثاق إلى الأعلى
انبثاق إلى اليسار
انبثاق إلى الأسفل
انبثاق إلى اليمين
شريط التقدم
دليل الإستخدام
100%
المخطوطة
دليل الإستخدام
@fat
محتوى لتوضيح كيف تعمل المخطوطة. ببساطة، المخطوطة عبارة عن منشور طويل يحتوي على عدة أقسام، ولديه شريط تنقل يسهل الوصول إلى هذه الأقسام الفرعية.
@mdo
بصرف النظر عن تحسيننا جدوى المكيّفات أو عدم تحسينها، فإن الطلب على الطاقة سيزداد. وطبقاً لما جاء في مقالة معهد ماساشوستس للتكنولوجيا، السالف ذكره، ثمَّة أمر يجب عدم إغفاله، وهو كيف أن هذا الطلب سيضغط على نظم توفير الطاقة الحالية. إذ لا بد من إعادة تأهيل كل شبكات الكهرباء، وتوسيعها لتلبية طلب الطاقة في زمن الذروة، خلال موجات الحرارة المتزايدة. فحين يكون الحر شديداً يجنح الناس إلى البقاء في الداخل، وإلى زيادة تشغيل المكيّفات، سعياً إلى جو لطيف وهم يستخدمون أدوات وأجهزة مختلفة أخرى.
واحد
وكل هذه الأمور المتزامنة من تشغيل الأجهزة، يزيد الضغط على شبكات الطاقة، كما أسلفنا. لكن مجرد زيادة سعة الشبكة ليس كافياً. إذ لا بد من تطوير الشبكات الذكية التي تستخدم الجسّاسات، ونظم المراقبة، والبرامج الإلكترونية، لتحديد متى يكون الشاغلون في المبنى، ومتى يكون ثمَّة حاجة إلى الطاقة، ومتى تكون الحرارة منخفضة، وبذلك يخرج الناس، فلا يستخدمون كثيراً من الكهرباء.
اثنان
مع الأسف، كل هذه الحلول المبتكرة مكلِّفة، وهذا ما يجعلها عديمة الجدوى في نظر بعض الشركات الخاصة والمواطن المتقشّف. إن بعض الأفراد الواعين بيئياً يبذلون قصارى جهدهم في تقليص استهلاكهم من الطاقة، ويعون جيداً أهمية أجهزة التكييف المجدية والأرفق بالبيئة. ولكن جهات كثيرة لن تتحرّك لمجرد حافز سلامة المناخ ووقف هدر الطاقة، ما دامت لا تحركها حوافز قانونية. وعلى الحكومات أن تُقدِم عند الاهتمام بالتغيّر المناخي، على وضع التشريعات المناسبة. فبالنظم والحوافز والدعم، يمكن دفع الشركات إلى اعتماد الحلول الأجدى في مكاتبها.
ثلاثة
وكما يتبيّن لنا، من عدد الحلول الملطِّفة للمشكلة، ومن تنوّعها، وهي الحلول التي أسلفنا الحديث عنها، فإن التكنولوجيا التي نحتاج إليها من أجل معالجة هذه التحديات، هي في مدى قدرتنا، لكنها ربما تتطلّب بعض التحسين، ودعماً استثمارياً أكبر!
ولا مانع من إضافة محتوى آخر ليس تحت أي قسم معين.
الدوائر المتحركة
دليل الإستخدام
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
جار التحميل...
الإشعارات
دليل الإستخدام
قبل 11 دقيقة
مرحبًا بالعالم! هذه رسالة إشعار.
التلميحات
دليل الإستخدام
تلميح يظهر في الأعلى
تلميح يظهر على اليسار
تلميح يظهر في الأسفل
تلميح يظهر على اليمين
تلميح مع HTML


--- 018_getting-started_parcel.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/parcel
--------------------------------------------------
Want to skip to the end?
Download the source code and working demo for this guide from the
twbs/examples repository
. You can also
open the example in StackBlitz
but not run it because Parcel isn’t currently supported there.
What is Parcel?
Parcel
is a web application bundler designed to simplify the development process with a zero-configuration setup out of the box. It offers features found in more advanced bundlers while focusing on ease of use, making it ideal for developers seeking a quick start.
Setup
We’re building a Parcel project with Bootstrap from scratch, so there are some prerequisites and upfront steps before we can really get started. This guide requires you to have Node.js installed and some familiarity with the terminal.
Create a project folder and set up npm.
We'll create the
my-project
folder and initialize npm with the
argument to avoid it asking us all the interactive questions.
mkdir
my-project
my-project
init
Install Parcel.
Unlike our Webpack guide, there’s only a single build tool dependency here. Parcel will automatically install language transformers (like Sass) as it detects them. We use
--save-dev
to signal that this dependency is only for development use and not for production.
i --save-dev parcel
Install Bootstrap.
Now we can install Bootstrap. We'll also install Popper since our dropdowns, popovers, and tooltips depend on it for their positioning. If you don’t plan on using those components, you can omit Popper here.
--save
Now that we have all the necessary dependencies installed, we can get to work creating the project files and importing Bootstrap.
Project structure
We’ve already created the
my-project
folder and initialized npm. Now we'll also create our
folder, stylesheet, and JavaScript file to round out the project structure. Run the following from
my-project
, or manually create the folder and file structure shown below.
mkdir
src,src/js,src/scss
touch
src/index.html src/js/main.js src/scss/styles.scss
When you’re done, your complete project should look like this:
my-project/
├── src/
│   ├── js/
│   │   └── main.js
│   ├── scss/
│   │   └── styles.scss
│   └── index.html
├── package-lock.json
└── package.json
At this point, everything is in the right place, but Parcel needs an HTML page and npm script to start our server.
Configure Parcel
With dependencies installed and our project folder ready for us to start coding, we can now configure Parcel and run our project locally. Parcel itself requires no configuration file by design, but we do need an npm script and an HTML file to start our server.
Fill in the
src/index.html
file.
Parcel needs a page to render, so we use our
index.html
page to set up some basic HTML, including our CSS and JavaScript files.
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
link
stylesheet
href
scss/styles.scss
script
type
module
js/main.js
script
head
body
class
container py-4 px-3 mx-auto
Hello, Bootstrap and Parcel!
button
class
btn btn-primary
Primary button
button
body
html
We’re including a little bit of Bootstrap styling here with the
div class="container"
<button>
so that we see when Bootstrap’s CSS is loaded by Parcel.
Parcel will automatically detect we’re using Sass and install the
Sass Parcel plugin
to support it. However, if you wish, you can also manually run
npm i --save-dev @parcel/transformer-sass
Add the Parcel npm scripts.
Open the
package.json
and add the following
start
script to the
scripts
object. We'll use this script to start our Parcel development server and render the HTML file we created after it’s compiled into the
dist
directory.
// ...
"scripts"
"start"
"parcel serve src/index.html --public-url / --dist-dir dist"
"test"
"echo \"Error: no test specified\" && exit 1"
// ...
And finally, we can start Parcel.
From the
my-project
folder in your terminal, run that newly added npm script:
start
In the next and final section to this guide, we'll import all of Bootstrap’s CSS and JavaScript.
Import Bootstrap
Importing Bootstrap into Parcel requires two imports, one into our
styles.scss
and one into our
main.js
Import Bootstrap’s CSS.
Add the following to
src/scss/styles.scss
to import all of Bootstrap’s source Sass.
// Import all of Bootstrap’s CSS
@import
"bootstrap/scss/bootstrap"
You can also import our stylesheets individually if you want.
Read our Sass import docs
for details.
Optional:
You may see Sass deprecation warnings with the latest versions of Dart Sass. These can silenced by adding the following configuration in a
.sassrc.js
file in the root folder with the following:
module
exports
silenceDeprecations
'import'
'mixed-decls'
'color-functions'
'global-builtin'
Import Bootstrap’s JS.
Add the following to
src/js/main.js
to import all of Bootstrap’s JS. Popper will be imported automatically through Bootstrap.
// Import all of Bootstrap’s JS
import
from
'bootstrap'
You can also import JavaScript plugins individually as needed to keep bundle sizes down:
import
Alert
from
'bootstrap/js/dist/alert'
// or, specify which plugins you need:
import
Tooltip
Toast
Popover
from
'bootstrap'
Read our JavaScript docs
for more information on how to use Bootstrap’s plugins.
And you’re done! 🎉
With Bootstrap’s source Sass and JS fully loaded, your local development server should now look like this:
Now you can start adding any Bootstrap components you want to use. Be sure to
check out the complete Parcel example project
for how to include additional custom Sass and optimize your build by importing only the parts of Bootstrap’s CSS and JS that you need.
See something wrong or out of date here? Please
open an issue on GitHub
. Need help troubleshooting?
Search or start a discussion
on GitHub.


--- 019_examples_album-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/album-rtl
--------------------------------------------------
مثال الألبوم
وصف قصير حول الألبوم أدناه (محتوياته ، ومنشؤه ، وما إلى ذلك). اجعله قصير ولطيف، ولكن ليست قصير جدًا حتى لا يتخطى الناس هذا الألبوم تمامًا.
الدعوة الرئيسية للعمل
عمل ثانوي
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق
Placeholder
صورة مصغرة
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي. هذا المحتوى أطول قليلاً.
تعديل
9 دقائق


--- 021_examples_blog-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/blog-rtl
--------------------------------------------------
عنوان تدوينة مميزة أطول
عدة أسطر نصية متعددة تعبر عن التدوية، وذلك لإعلام القراء الجدد بسرعة وكفاءة حول أكثر الأشياء إثارة للاهتمام في محتويات هذه التدوينة.
أكمل القراءة...
العالم
مشاركة مميزة
نوفمبر 12
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي.
أكمل القراءة
Placeholder
صورة مصغرة
التصميم
عنوان الوظيفة
نوفمبر 11
هذه بطاقة أوسع مع نص داعم أدناه كمقدمة طبيعية لمحتوى إضافي.
أكمل القراءة
Placeholder
صورة مصغرة
من Firehose
مثال على تدوينة
1 يناير 2021 بواسطة
Mark
تعرض مشاركة المدونة هذه بضعة أنواع مختلفة من المحتوى الذي يتم دعمه وتصميمه باستخدام Bootstrap. النصوص الأساسية، الصور، والأكواد مدعومة بشكل كامل.
يشكِّل تأمين الغذاء في المستقبل قضية تؤرِّق حكومات العالَم والعلماء على حدٍّ سواء. فخلال القرن العشرين ازداد عدد سكان الأرض أربعة أضعاف، وتشير التقديرات إلى أن العدد سوف يصل إلى عشرة مليارات إنسان بحلول عام 2050م. وسوف تمثل هذه الزيادة الهائلة تحدياً كبيراً وضغطاً متصاعداً على قدرة الإنتاج الزراعي. الأمر الذي كان ولا بد من أن يدفع إلى تطوير تقنيات مبتكرة في تصنيع الغذاء غير الزراعة، منها تقنية مستقبلية تقوم على تصنيع الغذاء من الهواء.
تشغل الزراعة مساحات كبيرة من اليابسة، وتستهلك كميات هائلة من المياه، كما أن إنتاج الغذاء بواسطة الزراعة يسهم بنسبة عالية من انبعاثات غازات الاحتباس الحراري العالمية
تشغل الزراعة مساحات كبيرة من اليابسة، وتستهلك كميات هائلة من المياه. كما أن إنتاج الغذاء بواسطة الزراعة يسهم بنسبة عالية من انبعاثات غازات الاحتباس الحراري العالمية، وللمقارنة فإن هذه النسبة من الانبعاثات هي أكبر مما ينتجه قطاع النقل بكل ما فيه من سيارات وشاحنات وطائرات وقطارات.
عنوان
تحصل النباتات على غذائها بواسطة عملية تسمى البناء الضوئي، حيث تقوم النباتات بتحويل ضوء الشمس والماء وثاني أكسيد الكربون الموجود في الغلاف الجوي إلى غذاء وتطلق الأكسجين كمنتج ثانوي لهذا التفاعل الكيميائي. وتحدث هذه العملية في "البلاستيدات الخضراء". فالنباتات تستفيد من طاقة ضوء الشمس في تقسيم الماء إلى هيدروجين وأكسجين، وتحدث تفاعلات كيميائية أخرى ينتج عنها سكر الجلكوز الذي تستخدمه كمصدر للغذاء وينطلق الأكسجين من النباتات إلى الغلاف الجوي. وهذا يعني أن النباتات تحوِّل ثاني أكسيد الكربون إلى غذاء من خلال تفاعلات كيميائية معقَّدة. ويُعد البناء الضوئي من أهم التفاعلات الكيميائية على كوكب الأرض، فقد ساعد في الماضي على تطوُّر كوكبنا وظهور الحياة عليه. فالنباتات تستخدم ثاني أكسيد الكربون لصنع غذائها، وتطلق الأكسجين لتساعد الكائنات الأخرى على التنفس!
عنوان فرعي
ألهمت هذه العملية علماء وكالة الفضاء الأمريكية (ناسا) خلال الستينيات من القرن الماضي، لبحث فكرة إطعام روَّاد الفضاء في مهمات الفضاء الطويلة مثل السفر إلى المريخ. وكانت واحدة من الأفكار الواعدة تصنيع الغذاء عن طريق ثاني أكسيد الكربون الذي ينتجه روَّاد الفضاء، لكن ليس بواسطة النباتات بل عن طريق ميكروبات صغيرة وحيدة الخلية قادرة على حصد ثاني أكسيد الكربون لإنتاج كميات وفيرة من البروتين المغذي على شكل مسحوق عديم النكهة، كما يمكن استخدام المادة في صنع الأطعمة المألوفة لدينا.
Example code block
وخلافاً لما هو الحال في عالم النبات، فإن هذه الميكروبات لا تستخدم الضوء كما يحدث في عملية البناء الضوئي التي تستخدمها النباتات للحصول على الغذاء، أي لأنها قادرة على النمو في الظلام. تسمى هذه البكتريا "هيدروجينوتروف" (Hydrogenotrophs)، وهي تستخدم الهيدروجين كوقود لإنتاج الغذاء من ثاني أكسيد الكربون. فعندما يُنتج روَّاد الفضاء ثاني أكسيد الكربون، تلتقطه الميكروبات، ويتحوَّل مع مدخلات أخرى إلى غذاء غني بالكربون. وبهذه الطريقة سوف نحصل على دورة كربون مغلقة الحلقة.
عنوان فرعي
بعد مرور أكثر من نصف قرن على أبحاث ناسا، تعمل حالياً عدة شركات في قطاع البيولوجيا التركيبية من ضمنها إير بروتين (Air Protein) وسولار فودز (Solar Foods) على تطوير جيل جديد من المنتجات الغذائية المستدامة، من دون وجود بصمة كربونية. ولن تقتصر هذه المنتجات الغذائية على روَّاد الفضاء فحسب، بل سوف تمتد لتشمل جميع سكان الأرض، وسوف تُنتَج في فترة زمنية قصيرة، بدلاً من الشهور، ومن دون الاعتماد على الأراضي الزراعية. وهذا يعني الحصول على منتجات غذائية بشكل سريع جداً. كما سيصبح من الممكن تصنيع الغذاء بطريقة عمودية من خلال هذه الميكروبات، بدلاً من الطريقة الأفقية التقليدية الشبيهة بتقنية الزراعة العمودية الحديثة. وهذا يعني توفير منتجات غذائية أكبر من المساحة نفسها.
يتكوَّن الغذاء البشري من ثلاثة أنواع رئيسة، هي:
البروتينات
الكربوهيدرات
الدهون
وتتكوَّن البروتينات من الأحماض الأمينية، وهي مجموعة من المركبات العضوية يبلغ عددها في جسم الإنسان عشرين حمضاً أمينياً، من بينها تسعة أساسية يحصل عليها الجسم من الغذاء. وتتكوَّن الأحماض الأمينية بشكل أساس من:
الكربون
الهيدروجين
الأكسجين
النيتروجين
ومن الملاحظ أن النيتروجين يشكِّل نسبة %78 من الهواء، كما أن الهيدروجين نحصل عليه من خلال التحليل الكهربائي للماء، ومن الممكن نظرياً سحب الكربون من الهواء لتشكيل هذه الأحماض، ذلك أن الكربون هو العمود الفقري للأحماض الأمينية، كما أن الحياة على كوكب الأرض قائمة على الكربون لقدرته على تكوين سلاسل كربونية طويلة، وهذا ما تفعله الميكروبات بتصنيع أحماض أمينية من ثاني أكسيد الكربون من خلال مجموعة من التفاعلات الكيميائية المعقَّدة. وإضافة إلى صنع وجبات غنية بالبروتين، فهذه الميكروبات تنتج منتجات أخرى مثل الزيوت التي لها عديد من الاستخدامات.
تدوينة أخرى
23 ديسمبر 2020 بواسطة
Jacob
في الوقت الحالي، تدرس عدَّة شركات هذه الميكروبات بشكل أعمق، وتستزرعها من أجل الحصول على الغذاء. ففي عام 2019م، أعلن باحثون في شركة (Air Protein) الأمريكية نجاحهم في تحويل ثاني أكسيد الكربون الموجود في الهواء إلى لحوم صناعية مصنوعة من البروتين، التي لا تتطلَّب أي أرض زراعية، بل هي معتمدة بشكل أساسي على الهواء.
تم تصنيع اللحوم بأنواع عديدة
إذ استخدم هؤلاء الباحثون الهواء والطاقة المتجدِّدة كمدخلات في عملية مشابهة للتخمير، لإنتاج بروتين يحتوي على الأحماض الأمينية التسعة الأساسية وغني بالفيتامينات والمعادن، كما أنه خالٍ من الهرمونات والمضادات الحيوية والمبيدات الحشرية ومبيدات الأعشاب.
وتم تصنيع اللحوم بأنواع عديدة بما فيها الدواجن والأبقار والمأكولات البحرية، من دون حصول انبعاثات كربونية، على عكس تربية الأبقار التي تسهم في انبعاث غاز الميثان أحد غازات الاحتباس الحراري.
ميزة جديدة
14 ديسمبر 2020 بواسطة
Jacob
كما أن الشركة الفنلندية (Solar Foods) طوَّرت تقنية لإنتاج البروتين من الهواء، حيث تبدأ العملية بتقسيم الماء إلى مكوناته الهيدروجين والأكسجين عن طريق الكهرباء. فالهيدروجين يوفِّر الطاقة للبكتريا لتحويل ثاني أكسيد الكربون والنيتروجين الموجودين في الهواء إلى مادة عضوية غنية بالبروتين بشكل أكفأ من نمو النباتات باستخدام البناء الضوئي. وهذا البروتين يشبه دقيق القمح وقد أطلق عليه اسم "سولين" (Solein).
وتقوم الشركة حالياً بجمع البيانات حول المنتج الغذائي لتقديمه إلى الاتحاد الأوروبي بهدف الحصول على ترخيص غذائي، كما أنها تخطط لبدء الإنتاج التجاري في العام المقبل 2021م. وقد أوضحت الشركة أنها مهتمة بإنتاج أطعمة صديقة للبيئة من خلال استخدام المواد الأساسية: الكهرباء وثاني أكسيد الكربون، وهذه الأطعمة سوف تجنبنا الأثر السلبي البيئي للزراعة التقليدية الذي يشمل كل شيء من استخدام الأرض والمياه إلى الانبعاثات الناتجة من تسميد المحاصيل أو تربية الحيوانات.
وعلى هذا، فإن البروتينات المشتقة من الميكروبات سوف:
توفر حلاً ممكناً في ظل زيادة الطلب العالمي المستقبلي على الغذاء
تتوسع مصانع الغذاء في المستقبل لتكون أكفأ وأكثر استدامة
تصبح قادرة على توفير الغذاء لروَّاد الفضاء في سفرهم إلى المريخ وجميع سكان كوكب الأرض في عام 2050م
فتخيّل أن الميكروبات ستكون مصانع المستقبل، وأن غذاء المستقبل سيكون مصنوعاً من الهواء! وأن عام 2050م سيكون مختلفاً تماماً عن عالمنا اليوم. فهو عالم من دون زراعة ولا تربية حيوانات من أجل الغذاء! قد يبدو ذلك خيالياً لكنه ليس مستحيلاً!
أقبلت، فأقبلت معك الحياة بجميع صنوفها وألوانها: فالنبات ينبت، والأشجار تورق وتزهر، والهرة تموء، والقمري يسجع، والغنم يثغو، والبقر يخور، وكل أليف يدعو أليفه. كل شيء يشعر بالحياة وينسي هموم الحياة، ولا يذكر إلا سعادة الحياة، فإن كان الزمان جسدا فأنت روحه، وإن كان عمرا فأنت شبابه.
المشاركات الاخيرة
مثال على عنوان منشور المدونة
15 يناير 2024
هذا عنوان آخر للمدونة
14 يناير 2024
أطول عنوان منشور للمدونة: يحتوي هذا الخط على عدة أسطر!
13 يناير 2024
الأرشيف
مارس 2021
شباط 2021
يناير 2021
ديسمبر 2020
نوفمبر 2020
أكتوبر 2020
سبتمبر 2020
اغسطس 2020
يوليو 2020
يونيو 2020
مايو 2020
ابريل 2020
في مكان آخر
GitHub
Social
Facebook


--- 023_getting-started_contents.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/contents
--------------------------------------------------
Compiled Bootstrap
Once downloaded, unzip the compressed folder and you’ll see something like this:
├── css/
│   ├── bootstrap-grid.css
│   ├── bootstrap-grid.css.map
│   ├── bootstrap-grid.min.css
│   ├── bootstrap-grid.min.css.map
│   ├── bootstrap-grid.rtl.css
│   ├── bootstrap-grid.rtl.css.map
│   ├── bootstrap-grid.rtl.min.css
│   ├── bootstrap-grid.rtl.min.css.map
│   ├── bootstrap-reboot.css
│   ├── bootstrap-reboot.css.map
│   ├── bootstrap-reboot.min.css
│   ├── bootstrap-reboot.min.css.map
│   ├── bootstrap-reboot.rtl.css
│   ├── bootstrap-reboot.rtl.css.map
│   ├── bootstrap-reboot.rtl.min.css
│   ├── bootstrap-reboot.rtl.min.css.map
│   ├── bootstrap-utilities.css
│   ├── bootstrap-utilities.css.map
│   ├── bootstrap-utilities.min.css
│   ├── bootstrap-utilities.min.css.map
│   ├── bootstrap-utilities.rtl.css
│   ├── bootstrap-utilities.rtl.css.map
│   ├── bootstrap-utilities.rtl.min.css
│   ├── bootstrap-utilities.rtl.min.css.map
│   ├── bootstrap.css
│   ├── bootstrap.css.map
│   ├── bootstrap.min.css
│   ├── bootstrap.min.css.map
│   ├── bootstrap.rtl.css
│   ├── bootstrap.rtl.css.map
│   ├── bootstrap.rtl.min.css
│   └── bootstrap.rtl.min.css.map
└── js/
├── bootstrap.bundle.js
├── bootstrap.bundle.js.map
├── bootstrap.bundle.min.js
├── bootstrap.bundle.min.js.map
├── bootstrap.esm.js
├── bootstrap.esm.js.map
├── bootstrap.esm.min.js
├── bootstrap.esm.min.js.map
├── bootstrap.js
├── bootstrap.js.map
├── bootstrap.min.js
└── bootstrap.min.js.map
This is the most basic form of Bootstrap: compiled files for quick drop-in usage in nearly any web project. We provide compiled CSS and JS (
), as well as compiled and minified CSS and JS (
Source maps
) are available for use with certain browsers’ developer tools. Bundled JS files (
and minified
) include
Popper
CSS files
CSS files
Layout
Content
Components
Utilities
Included
Included
Included
Included
Only grid system
Only flex utilities
Included
Only Reboot
JS files
Similarly, we have options for including some or all of our compiled JavaScript.
JS Files
Popper
Included
The Bootstrap source code download includes the compiled CSS and JavaScript assets, along with source Sass, JavaScript, and documentation. More specifically, it includes the following and more:
├── dist/
│   ├── css/
│   └── js/
├── site/
│   └──content/
│      └── docs/
│          └── 5.3/
│              └── examples/
├── js/
└── scss/
scss/
are the source code for our CSS and JavaScript. The
dist/
folder includes everything listed in the compiled download section above. The
site/content/docs/
folder includes the source code for our hosted documentation, including our live examples of Bootstrap usage.
Beyond that, any other included file provides support for packages, license information, and development.


--- 041_examples_dashboard-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/dashboard-rtl
--------------------------------------------------
لوحة القيادة
مشاركة
تصدير
هذا الأسبوع
عنوان القسم
عنوان
عنوان
عنوان
عنوان
1,001
بيانات
عشوائية
تثري
الجدول
1,002
تثري
مبهة
تصميم
تنسيق
1,003
عشوائية
غنية
قيمة
مفيدة
1,003
معلومات
تثري
توضيحية
عشوائية
1,004
الجدول
بيانات
تنسيق
قيمة
1,005
قيمة
مبهة
الجدول
تثري
1,006
قيمة
توضيحية
غنية
عشوائية
1,007
تثري
مفيدة
معلومات
مبهة
1,008
بيانات
عشوائية
تثري
الجدول
1,009
تثري
مبهة
تصميم
تنسيق
1,010
عشوائية
غنية
قيمة
مفيدة
1,011
معلومات
تثري
توضيحية
عشوائية
1,012
الجدول
تثري
تنسيق
قيمة
1,013
قيمة
مبهة
الجدول
تصميم
1,014
قيمة
توضيحية
غنية
عشوائية
1,015
بيانات
مفيدة
معلومات
الجدول


--- 044_getting-started_rfs.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/rfs
--------------------------------------------------
What is RFS?
is a unit resizing engine which was initially developed to resize font sizes (hence its abbreviation for Responsive Font Sizes). Nowadays RFS is capable of rescaling most CSS properties with unit values like
margin
padding
border-radius
, or even
box-shadow
The mechanism automatically calculates the appropriate values based on the dimensions of the browser viewport. It will be compiled into
calc()
functions with a mix of
and viewport units to enable the responsive scaling behavior.
Using RFS
The mixins are included in Bootstrap and are available once you include Bootstrap’s
scss
. RFS can also be
installed standalone
if needed.
Using the mixins
rfs()
mixin has shorthands for
font-size
margin
margin-top
margin-right
margin-bottom
margin-left
padding
padding-top
padding-right
padding-bottom
, and
padding-left
. See the example below for source Sass and compiled CSS.
.title
@include
font-size
4rem
.title
font-size
calc
1.525rem + 3.3vw
@media
min-width
1200px
.title
font-size
4rem
Any other property can be passed to the
rfs()
mixin like this:
.selector
@include
4rem
border-radius
!important
can also just be added to whatever value you want:
.selector
@include
padding
2.5rem
!important
Using the functions
When you don’t want to use the includes, there are also two functions:
rfs-value()
converts a value into a
value if a
value is passed, in other cases it returns the same result.
rfs-fluid-value()
returns the fluid version of a value if the property needs rescaling.
In this example, we use one of Bootstrap’s built-in
responsive breakpoint mixins
to only apply styling below the
breakpoint.
.selector
@include
media-breakpoint-down
padding
rfs-fluid-value
2rem
font-size
rfs-fluid-value
1.125rem
@media
max-width
991.98px
.selector
padding
calc
1.325rem + 0.9vw
font-size
1.125rem
/* 1.125rem is small enough, so RFS won’t rescale this */
Extended documentation
RFS is a separate project under the Bootstrap organization. More about RFS and its configuration can be found on its
GitHub repository


--- 067_getting-started_download.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/download
--------------------------------------------------
Compiled CSS and JS
Download ready-to-use compiled code for
to easily drop into your project, which includes:
Compiled and minified CSS bundles (see
CSS files comparison
Compiled and minified JavaScript plugins (see
JS files comparison
This doesn’t include documentation, source files, or any optional JavaScript dependencies like Popper.
Download
Source files
Compile Bootstrap with your own asset pipeline by downloading our source Sass, JavaScript, and documentation files. This option requires some additional tooling:
Sass compiler
for compiling Sass source files into CSS files
Autoprefixer
for CSS vendor prefixing
Should you require our full set of
build tools
, they are included for developing Bootstrap and its docs, but they’re likely unsuitable for your own purposes.
Download source
Examples
If you want to download and examine our
examples
, you can grab the already built examples:
Download Examples
CDN via jsDelivr
Skip the download with
jsDelivr
to deliver cached version of Bootstrap’s compiled CSS and JS to your project.
link
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.min.css
stylesheet
integrity
sha384-LN+7fdVzj6u52u30Kp6M/trliBMCMKTyK833zpbD+pXdCLuTusPj697FH4R/5mcr
crossorigin
anonymous
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.bundle.min.js
integrity
sha384-ndDqU0Gzau9qJ1lfW4pNLlhNTkCfHzAVBReH9diLvGRem5+R9g2FzA8ZGN954O5Q
crossorigin
anonymous
script
If you’re using our compiled JavaScript and prefer to include Popper separately, add Popper before our JS, via a CDN preferably.
script
https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js
integrity
sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r
crossorigin
anonymous
script
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.min.js
integrity
sha384-7qAoOXltbVP82dhxHAUje59V5r2YsVfBafyUDxEdApLPmcdhBPg1DKg1ERo0BZlK
crossorigin
anonymous
script
Alternative CDNs
We recommend
jsDelivr
and use it ourselves in our documentation. However, in some cases—like in some specific countries or environments—you may need to use other CDN providers like
cdnjs
unpkg
You’ll find the same files on these CDN providers, albeit with different URLs. With cdnjs, you can
use this direct Bootstrap package link
to copy and paste ready-to-use HTML snippets for each dist file from any version of Bootstrap.
If the SRI hashes differ for a given file, you shouldn’t use the files from that CDN, because it means that the file was modified by someone else.
Note that you should compare same length hashes, e.g.
sha384
with
sha384
, otherwise it’s expected for them to be different.
As such, you can use an online tool like
SRI Hash Generator
to make sure that the hashes are the same for a given file.
Alternatively, assuming you have OpenSSL installed, you can achieve the same from the CLI, for example:
openssl dgst
-sha384
-binary
openssl base64
Package managers
Pull in Bootstrap’s
source files
into nearly any project with some of the most popular package managers. No matter the package manager, Bootstrap will
require a
Sass compiler
Autoprefixer
for a setup that matches our official compiled versions.
Install Bootstrap in your Node.js powered apps with
the npm package
install
const bootstrap = require('bootstrap')
import bootstrap from 'bootstrap'
will load all of Bootstrap’s plugins onto a
object.
module itself exports all of our plugins. You can manually load Bootstrap’s plugins individually by loading the
/js/dist/*.js
files under the package’s top-level directory.
package.json
contains some additional metadata under the following keys:
sass
- path to Bootstrap’s main
Sass
source file
style
- path to Bootstrap’s non-minified CSS that’s been compiled using the default settings (no customization)
Get started with Bootstrap via npm with our starter project!
Head to the
Sass & JS example
template repository to see how to build and customize Bootstrap in your own npm project. Includes Sass compiler, Autoprefixer, Stylelint, PurgeCSS, and Bootstrap Icons.
yarn
Install Bootstrap in your Node.js powered apps with
the yarn package
yarn
Yarn 2+ (aka Yarn Berry) doesn’t support the
node_modules
directory by default
: using our
Sass & JS example
needs some adjustments:
yarn
config
nodeLinker node-modules
# Use the node_modules linker
touch
yarn.lock
# Create an empty yarn.lock file
yarn
install
# Install the dependencies
yarn
start
# Start the project
Install Bootstrap in your Bun or Node.js powered apps with
the Bun CLI
RubyGems
Install Bootstrap in your Ruby apps using
Bundler
recommended
) and
RubyGems
by adding the following line to your
Gemfile
'bootstrap'
'~> 5.3.7'
Alternatively, if you’re not using Bundler, you can install the gem by running this command:
install
See the gem’s README
for further details.
Composer
You can also install and manage Bootstrap’s Sass and JavaScript using
Composer
composer
require twbs/bootstrap:5.3.7
NuGet
If you develop in .NET Framework, you can also install and manage Bootstrap’s
Sass
and JavaScript using
NuGet
. Newer projects should use
libman
or another method as NuGet is designed for compiled code, not frontend assets.
Install-Package
Install-Package
sass
IntelliSense extension
Install the community-maintained
IntelliSense extension
for Visual Studio Code to get IntelliSense auto-completion for Bootstrap classes.
View in VS Code Marketplace


--- 086_examples_carousel-rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/carousel-rtl
--------------------------------------------------
عنوان المثال.
تشير الدراسات الإحصائية حسب الجمعية الأمريكية للغات بأن الإقبال على العربية زاد %126 في الولايات المتحدة الأمريكية وحدها بين عامي 2002 و2009م.
سجل اليوم
عنوان مثال آخر.
حسب المجلس الثقافي البريطاني فإن تعليم الإنجليزية داخل بريطانيا يسهم في تعزيز اقتصادها بما يتجاوز ملياري جنيه سنوياً، كما أنه وفر أكثر من 26 ألف وظيفة.
أعرف أكثر
واحد أكثر لقياس جيد.
الإحصاءات لحجم الاستثمار اللغوي خارج بريطانيا تتفاوت من سنة لأخرى إلا أن المدير التنفيذي للمجلس الثقافي البريطاني إدي بايرز يرى أن استثمار تعليم الإنجليزية في الخارج لا يحسب على المستوى المالي فحسب بل على المستوى السياسي أيضاً.
تصفح المعرض
السابق
التالي
Placeholder
عنوان
تذكر دائماً أن الحاسوب لا يمتلك ذكاءً، ولكنه يكتسب الذكاء الاصطناعي من خلال ثلاثة عناصر وظيفية رئيسة، هي: القدرة على التحليل، والقدرة على التأليف، والاستدلال المنطقي.
عرض التفاصيل
Placeholder
عنوان آخر
إذا أردنا استخدام الحاسوب الذكي في معالجة اللغة العربية فإننا نجد أنفسنا أمام تحدٍّ كبير، خاصة وأن لغتنا تمتاز بتماسك منظوماتها وتداخلها، ومع ذلك فإن الذكاء الاصطناعي يمكّننا من الحصول على أربعة أنواع من المعالجة، هي: المعالجة الصوتية، والمعالجة الصرفية، والمعالجة النحوية، والمعالجة الدلالية.
عرض التفاصيل
Placeholder
عنوان ثالث لتأكيد المعلومة
بفضل بحوث الذكاء الاصطناعي وتقنياته استطعنا الانتقال من مرحلة التعامل مع الفيزيائي إلى مرحلة التعامل مع المنطقي، وقد انعكس هذا الانتقال بصورة إيجابية على الكيفية التي تتعامل بها الشعوب مع لغاتها الحيَّة، وهذا يعني أنه يجب أن ينعكس بصورة إيجابية على كيفية تعاملنا مع لغتنا العربية.
عرض التفاصيل
العنوان الأول المميز.
سيذهل عقلك.
وجه الإنسان هو جزء معقَّد ومتميِّز للغاية من جسمه. وفي الواقع، إنه أحد أكثر أنظمة الإشارات المتاحة تعقيداً لدينا؛ فهو يتضمَّن أكثر من 40 عضلة مستقلة هيكلياً ووظيفياً، بحيث يمكن تشغيل كل منها بشكل مستقل عن البعض الآخر؛ وتشكِّل أحد أقوى مؤشرات العواطف.
Placeholder
500x500
أوه نعم، هذا جيد.
شاهد بنفسك.
عندما نضحك أو نبكي، فإننا نعرض عواطفنا، مما يسمح للآخرين بإلقاء نظرة خاطفة على أذهاننا أثناء "قراءة" وجوهنا بناءً على التغييرات في مكوّنات الوجه الرئيسة، مثل: العينين والحاجبين والجفنين والأنف والشفتين.
Placeholder
500x500
وأخيرًا، هذا.
كش ملك.
إن جميع العضلات في أجسامنا مدعمة بالأعصاب المتصلة من كافة أنحاء الجسم بالنخاع الشوكي والدماغ. وهذا الاتصال العصبي هو ثنائي الاتجاه، أي إن العصب يتسبَّب في تقلصات العضلات بناءً على إشارات الدماغ، ويقوم في الوقت نفسه بإرسال معلومات عن حالة العضلات إلى الدماغ
Placeholder
500x500


--- 103_getting-started_javascript.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/javascript
--------------------------------------------------
Individual or compiled
Plugins can be included individually (using Bootstrap’s individual
js/dist/*.js
), or all at once using
or the minified
(don’t include both).
If you use a bundler (Webpack, Parcel, Vite…), you can use
/js/dist/*.js
files which are UMD ready.
Usage with JavaScript frameworks
While the Bootstrap CSS can be used with any framework,
the Bootstrap JavaScript is not fully compatible with JavaScript frameworks like React, Vue, and Angular
which assume full knowledge of the DOM. Both Bootstrap and the framework may attempt to mutate the same DOM element, resulting in bugs like dropdowns that are stuck in the “open” position.
A better alternative for those using this type of frameworks is to use a framework-specific package
instead of
the Bootstrap JavaScript. Here are some of the most popular options:
React:
React Bootstrap
Try it yourself!
Download the source code and working demo for using Bootstrap with React, Next.js, and React Bootstrap from the
twbs/examples repository
. You can also
open the example in StackBlitz
Vue:
(Bootstrap 4)
Vue 3:
(Bootstrap 5, currently in alpha)
Angular:
ng-bootstrap
ngx-bootstrap
Using Bootstrap as a module
Try it yourself!
Download the source code and working demo for using Bootstrap as an ES module from the
twbs/examples repository
. You can also
open the example in StackBlitz
We provide a version of Bootstrap built as
) which allows you to use Bootstrap as a module in the browser, if your
targeted browsers support it
script
type
module
import
Toast
from
'bootstrap.esm.min.js'
Array
from
document
querySelectorAll
'.toast'
forEach
toastNode
Toast
toastNode
script
Compared to JS bundlers, using ESM in the browser requires you to use the full path and filename instead of the module name.
Read more about JS modules in the browser.
That’s why we use
'bootstrap.esm.min.js'
instead of
'bootstrap'
above. However, this is further complicated by our Popper dependency, which imports Popper into our JavaScript like so:
import
Popper
from
"@popperjs/core"
If you try this as-is, you’ll see an error in the console like the following:
Uncaught TypeError: Failed to resolve module specifier "@popperjs/core". Relative references must start with either "/", "./", or "../".
To fix this, you can use an
importmap
to resolve the arbitrary module names to complete paths. If your
targeted browsers
do not support
importmap
, you’ll need to use the
es-module-shims
project. Here’s how it works for Bootstrap and Popper:
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
link
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.min.css
stylesheet
integrity
sha384-LN+7fdVzj6u52u30Kp6M/trliBMCMKTyK833zpbD+pXdCLuTusPj697FH4R/5mcr
crossorigin
anonymous
title
Hello, modularity!
title
head
body
Hello, modularity!
button
popoverButton
type
button
class
btn btn-primary btn-lg
data-bs-toggle
popover
title
ESM in Browser
data-bs-content
Bang!
Custom popover
button
script
async
https://cdn.jsdelivr.net/npm/es-module-shims@1/dist/es-module-shims.min.js
crossorigin
anonymous
script
script
type
importmap
"imports"
"@popperjs/core"
"https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/esm/popper.min.js"
"bootstrap"
"https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.esm.min.js"
script
script
type
module
import
from
'bootstrap'
Popover
document
getElementById
'popoverButton'
script
body
html
Dependencies
Some plugins and CSS components depend on other plugins. If you include plugins individually, make sure to check for these dependencies in the docs.
Our dropdowns, popovers, and tooltips also depend on
Popper
Data attributes
Nearly all Bootstrap plugins can be enabled and configured through HTML alone with data attributes (our preferred way of using JavaScript functionality). Be sure to
only use one set of data attributes on a single element
(e.g., you cannot trigger a tooltip and modal from the same button.)
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Selectors
We use the native
querySelector
querySelectorAll
methods to query DOM elements for performance reasons, so you must use
valid selectors
. If you use special selectors like
collapse:Example
, be sure to escape them.
Events
show
) is triggered at the start of an event, and its past participle form (ex.
shown
) is triggered on the completion of an action.
All infinitive events provide
preventDefault()
functionality. This provides the ability to stop the execution of an action before it starts. Returning false from an event handler will also automatically call
preventDefault()
const
myModal
document
querySelector
'#myModal'
myModal
addEventListener
'show.bs.modal'
event
return
event
preventDefault
// stops modal from being shown
Programmatic API
All constructors accept an optional options object or nothing (which initiates a plugin with its default behavior):
const
myModalEl
document
querySelector
'#myModal'
const
modal
Modal
myModalEl
// initialized with defaults
const
configObject
keyboard
false
const
modal1
Modal
myModalEl
configObject
// initialized with no keyboard
If you’d like to get a particular plugin instance, each plugin exposes a
getInstance
method. For example, to retrieve an instance directly from an element:
Popover
getInstance
myPopoverEl
This method will return
null
if an instance is not initiated over the requested element.
Alternatively,
getOrCreateInstance
can be used to get the instance associated with a DOM element, or create a new one in case it wasn’t initialized.
Popover
getOrCreateInstance
myPopoverEl
configObject
In case an instance wasn’t initialized, it may accept and use an optional configuration object as second argument.
CSS selectors in constructors
In addition to the
getInstance
getOrCreateInstance
methods, all plugin constructors can accept a DOM element or a valid
CSS selector
as the first argument. Plugin elements are found with the
querySelector
method since our plugins only support a single element.
const
modal
Modal
'#myModal'
const
dropdown
Dropdown
'[data-bs-toggle="dropdown"]'
const
offcanvas
Offcanvas
getInstance
'#myOffcanvas'
const
alert
Alert
getOrCreateInstance
'#myAlert'
Asynchronous functions and transitions
All programmatic API methods are
asynchronous
and return to the caller once the transition is started, but
before it ends
. In order to execute an action once the transition is complete, you can listen to the corresponding event.
const
myCollapseEl
document
querySelector
'#myCollapse'
myCollapseEl
addEventListener
'shown.bs.collapse'
event
// Action to execute once the collapsible area is expanded
In addition, a method call on a
transitioning component will be ignored
const
myCarouselEl
document
querySelector
'#myCarousel'
const
carousel
Carousel
getInstance
myCarouselEl
// Retrieve a Carousel instance
myCarouselEl
addEventListener
'slid.bs.carousel'
event
carousel
// Will slide to the slide 2 as soon as the transition to slide 1 is finished
carousel
// Will start sliding to the slide 1 and returns to the caller
carousel
// !! Will be ignored, as the transition to the slide 1 is not finished !!
dispose
method
While it may seem correct to use the
dispose
method immediately after
hide()
, it will lead to incorrect results. Here’s an example of the problem use:
const
myModal
document
querySelector
'#myModal'
myModal
hide
// it is asynchronous
myModal
addEventListener
'shown.bs.hidden'
event
myModal
dispose
Default settings
You can change the default settings for a plugin by modifying the plugin’s
Constructor.Default
object:
// changes default for the modal plugin’s `keyboard` option to false
Modal
Default
keyboard
false
Methods and properties
Every Bootstrap plugin exposes the following methods and static properties.
Method
Description
dispose
Destroys an element’s modal. (Removes stored data on the DOM element)
getInstance
Static
method which allows you to get the modal instance associated with a DOM element.
getOrCreateInstance
Static
method which allows you to get the modal instance associated with a DOM element, or create a new one in case it wasn’t initialized.
Static property
Description
NAME
Returns the plugin name. (Example:
VERSION
The version of each of Bootstrap’s plugins can be accessed via the
VERSION
property of the plugin’s constructor (Example:
Sanitizer
Our tooltip and popover components are able to render arbitrary HTML to the page if configured to do so.
To prevent cross-site scripting (XSS) attacks, these components use our built-in content sanitizer to sanitize any options which accept HTML before they are rendered to the page. Content sanitization is enabled by default.
The tags and attributes allowed by default are as follows. Any tags or attributes not explicitly allowed will be removed during sanitization:
js/src/util/sanitizer.js
const
ARIA_ATTRIBUTE_PATTERN
^aria-[\w-]*$
export
const
DefaultAllowlist
// Global attributes allowed on any supplied element below.
'class'
'dir'
'id'
'lang'
'role'
ARIA_ATTRIBUTE_PATTERN
'target'
'href'
'title'
'rel'
area
code
'src'
'srcset'
'alt'
'title'
'width'
'height'
small
span
strong
Exercise caution when using these advanced options.
Refer to
OWASP’s Cross Site Scripting Prevention Cheat Sheet
for more information. Vulnerabilities caused solely by disabling or modifying content sanitization are not considered within scope for Bootstrap’s security model.
You can add new values to this default
allowList
const
myDefaultAllowList
Tooltip
Default
allowList
// To allow table elements
myDefaultAllowList
table
// To allow td elements and data-bs-option attributes on td elements
myDefaultAllowList
'data-bs-option'
// You can push your custom regex to validate your attributes.
// Be careful about your regular expressions being too lax
const
myCustomRegex
^data-my-app-[\w-]+
myDefaultAllowList
push
myCustomRegex
You can also replace our sanitizer with a dedicated library, for example
DOMPurify
const
yourTooltipEl
document
querySelector
'#yourTooltip'
const
tooltip
Tooltip
yourTooltipEl
sanitizeFn
content
return
DOMPurify
sanitize
content
Optionally using jQuery
You don’t need jQuery in Bootstrap 5
, but it’s still possible to use our components with jQuery. If Bootstrap detects
jQuery
in the
window
object, it'll add all of our components in jQuery’s plugin system. This allows you to do the following:
// to enable tooltips with the default configuration
'[data-bs-toggle="tooltip"]'
tooltip
// to initialize tooltips with given configuration
'[data-bs-toggle="tooltip"]'
tooltip
boundary
'clippingParents'
customClass
'myClass'
// to trigger the `show` method
'#myTooltip'
tooltip
'show'
The same goes for our other components.
No conflict
Sometimes it is necessary to use Bootstrap plugins with other UI frameworks. In these circumstances, namespace collisions can occasionally occur. If this happens, you may call
.noConflict
on the plugin you wish to revert the value of.
const
button
noConflict
// return $.fn.button to previously assigned value
// give $().bootstrapBtn the Bootstrap functionality
.noConflict
and namespaced events, there may be compatibility problems that you need to fix on your own.
jQuery events
jQuery
is present in the
window
object and there is no
data-bs-no-jquery
attribute set on
<body>
. If jQuery is found, Bootstrap will emit events thanks to jQuery’s event system. So if you want to listen to Bootstrap’s events, you’ll have to use the jQuery methods (
.one
) instead of
addEventListener
'#myTab a'
'shown.bs.tab'
// do something...
Disabled JavaScript
<noscript>
to explain the situation (and how to re-enable JavaScript) to your users, and/or add your own custom fallbacks.


--- 123_getting-started_webpack.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/webpack
--------------------------------------------------
Want to skip to the end?
Download the source code and working demo for this guide from the
twbs/examples repository
. You can also
open the example in StackBlitz
for live editing.
What is Webpack?
Webpack
is a JavaScript module bundler that processes modules and their dependencies to generate static assets. It simplifies managing complex web applications with multiple files and dependencies.
Setup
We’re building a Webpack project with Bootstrap from scratch, so there are some prerequisites and upfront steps before we can really get started. This guide requires you to have Node.js installed and some familiarity with the terminal.
Create a project folder and set up npm.
We'll create the
my-project
folder and initialize npm with the
argument to avoid it asking us all the interactive questions.
mkdir
my-project
my-project
init
Install Webpack.
Next we need to install our Webpack development dependencies:
webpack
for the core of Webpack,
webpack-cli
so we can run Webpack commands from the terminal, and
webpack-dev-server
so we can run a local development server. Additionally, we'll install
html-webpack-plugin
to be able to store our
index.html
directory instead of the default
dist
one. We use
--save-dev
to signal that these dependencies are only for development use and not for production.
i --save-dev webpack webpack-cli webpack-dev-server html-webpack-plugin
Install Bootstrap.
Now we can install Bootstrap. We'll also install Popper since our dropdowns, popovers, and tooltips depend on it for their positioning. If you don’t plan on using those components, you can omit Popper here.
--save
Install additional dependencies.
In addition to Webpack and Bootstrap, we need a few more dependencies to properly import and bundle Bootstrap’s CSS and JS with Webpack. These include Sass, some loaders, and Autoprefixer.
i --save-dev autoprefixer css-loader postcss-loader sass sass-loader style-loader
Now that we have all the necessary dependencies installed, we can get to work creating the project files and importing Bootstrap.
Project structure
We’ve already created the
my-project
folder and initialized npm. Now we'll also create our
dist
folders to round out the project structure. Run the following from
my-project
, or manually create the folder and file structure shown below.
mkdir
src,src/js,src/scss
touch
src/index.html src/js/main.js src/scss/styles.scss webpack.config.js
When you’re done, your complete project should look like this:
my-project/
├── src/
│   ├── js/
│   │   └── main.js
│   ├── scss/
│   │   └── styles.scss
│   └── index.html
├── package-lock.json
├── package.json
└── webpack.config.js
At this point, everything is in the right place, but Webpack won’t work because we haven’t filled in our
webpack.config.js
yet.
Configure Webpack
With dependencies installed and our project folder ready for us to start coding, we can now configure Webpack and run our project locally.
Open
webpack.config.js
in your editor.
Since it’s blank, we'll need to add some boilerplate config to it so we can start our server. This part of the config tells Webpack where to look for our project’s JavaScript, where to output the compiled code to (
dist
), and how the development server should behave (pulling from the
dist
folder with hot reload).
'use strict'
const
path
require
'path'
const
HtmlWebpackPlugin
require
'html-webpack-plugin'
module
exports
mode
'development'
entry
'./src/js/main.js'
output
filename
'main.js'
path
path
resolve
__dirname
'dist'
devServer
static
path
resolve
__dirname
'dist'
port
8080
true
plugins
HtmlWebpackPlugin
template
'./src/index.html'
Next we fill in our
src/index.html
This is the HTML page Webpack will load in the browser to utilize the bundled CSS and JS we'll add to it in later steps. Before we can do that, we have to give it something to render and include the
output
JS from the previous step.
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
head
body
class
container py-4 px-3 mx-auto
Hello, Bootstrap and Webpack!
button
class
btn btn-primary
Primary button
button
body
html
We’re including a little bit of Bootstrap styling here with the
div class="container"
<button>
so that we see when Bootstrap’s CSS is loaded by Webpack.
Now we need an npm script to run Webpack.
Open
package.json
and add the
start
script shown below (you should already have the test script). We'll use this script to start our local Webpack dev server. You can also add a
build
script shown below to build your project.
// ...
"scripts"
"start"
"webpack serve"
"build"
"webpack build --mode=production"
"test"
"echo \"Error: no test specified\" && exit 1"
// ...
And finally, we can start Webpack.
From the
my-project
folder in your terminal, run that newly added npm script:
start
In the next and final section to this guide, we'll set up the Webpack loaders and import all of Bootstrap’s CSS and JavaScript.
Import Bootstrap
Importing Bootstrap into Webpack requires the loaders we installed in the first section. We’ve installed them with npm, but now Webpack needs to be configured to use them.
Set up the loaders in
webpack.config.js
Your configuration file is now complete and should match the snippet below. The only new part here is the
module
section.
'use strict'
const
path
require
'path'
const
autoprefixer
require
'autoprefixer'
const
HtmlWebpackPlugin
require
'html-webpack-plugin'
module
exports
mode
'development'
entry
'./src/js/main.js'
output
filename
'main.js'
path
path
resolve
__dirname
'dist'
devServer
static
path
resolve
__dirname
'dist'
port
8080
true
plugins
HtmlWebpackPlugin
template
'./src/index.html'
module
rules
test
\.(scss)$
// Adds CSS to the DOM by injecting a `<style>` tag
loader
'style-loader'
// Interprets `@import` and `url()` like `import/require()` and will resolve them
loader
'css-loader'
// Loader for webpack to process CSS with PostCSS
loader
'postcss-loader'
options
postcssOptions
plugins
autoprefixer
// Loads a SASS/SCSS file and compiles it to CSS
loader
'sass-loader'
options
sassOptions
// Optional: Silence Sass deprecation warnings. See note below.
silenceDeprecations
'mixed-decls'
'color-functions'
'global-builtin'
'import'
Here’s a recap of why we need all these loaders.
style-loader
injects the CSS into a
<style>
element in the
<head>
of the HTML page,
css-loader
helps with using
@import
url()
postcss-loader
is required for Autoprefixer, and
sass-loader
allows us to use Sass.
Note:
Sass deprecation warnings are shown when compiling source Sass files with the latest versions of Dart Sass. This does not prevent compilation or usage of Bootstrap. We’re
working on a long-term fix
, but in the meantime these deprecation notices can be ignored.
Now, let’s import Bootstrap’s CSS.
Add the following to
src/scss/styles.scss
to import all of Bootstrap’s source Sass.
// Import all of Bootstrap’s CSS
@import
"bootstrap/scss/bootstrap"
You can also import our stylesheets individually if you want.
Read our Sass import docs
for details.
Next we load the CSS and import Bootstrap’s JavaScript.
Add the following to
src/js/main.js
to load the CSS and import all of Bootstrap’s JS. Popper will be imported automatically through Bootstrap.
// Import our custom CSS
import
'../scss/styles.scss'
// Import all of Bootstrap’s JS
import
from
'bootstrap'
You can also import JavaScript plugins individually as needed to keep bundle sizes down:
import
Alert
from
'bootstrap/js/dist/alert'
// or, specify which plugins you need:
import
Tooltip
Toast
Popover
from
'bootstrap'
Read our JavaScript docs
for more information on how to use Bootstrap’s plugins.
And you’re done! 🎉
With Bootstrap’s source Sass and JS fully loaded, your local development server should now look like this:
Now you can start adding any Bootstrap components you want to use. Be sure to
check out the complete Webpack example project
for how to include additional custom Sass and optimize your build by importing only the parts of Bootstrap’s CSS and JS that you need.
Production optimizations
Depending on your setup, you may want to implement some additional security and speed optimizations useful for running the project in production. Note that these optimizations are not applied on
the Webpack example project
and are up to you to implement.
Extracting CSS
style-loader
we configured above conveniently emits CSS into the bundle so that manually loading a CSS file in
dist/index.html
isn’t necessary. This approach may not work with a strict Content Security Policy, however, and it may become a bottleneck in your application due to the large bundle size.
To separate the CSS so that we can load it directly from
dist/index.html
, use the
mini-css-extract-loader
Webpack plugin.
First, install the plugin:
install
--save-dev mini-css-extract-plugin
Then instantiate and use the plugin in the Webpack configuration:
--- a/webpack.config.js
+++ b/webpack.config.js
@@ -3,6 +3,7 @@
const path = require('path')
const autoprefixer = require('autoprefixer')
const HtmlWebpackPlugin = require('html-webpack-plugin')
const miniCssExtractPlugin = require('mini-css-extract-plugin')
module.exports = {
mode: 'development',
@@ -17,7 +18,8 @@ module.exports = {
hot: true
plugins: [
new HtmlWebpackPlugin({ template: './src/index.html' })
new HtmlWebpackPlugin({ template: './src/index.html' }),
new miniCssExtractPlugin()
module: {
rules: [
@@ -25,8 +27,8 @@ module.exports = {
test: /\.(scss)$/,
use: [
// Adds CSS to the DOM by injecting a `<style>` tag
loader: 'style-loader'
// Extracts CSS for each JS file that includes CSS
loader: miniCssExtractPlugin.loader
After running
npm run build
again, there will be a new file
dist/main.css
, which will contain all of the CSS imported by
src/js/main.js
. If you view
dist/index.html
in your browser now, the style will be missing, as it is now in
dist/main.css
. You can include the generated CSS in
dist/index.html
like this:
--- a/dist/index.html
+++ b/dist/index.html
@@ -3,6 +3,7 @@
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="./main.css">
<title>Bootstrap w/ Webpack</title>
</head>
<body>
Extracting SVG files
data:
URIs. If you define a Content Security Policy for your project that blocks
data:
URIs for images, then these SVG files will not load. You can get around this problem by extracting the inline SVG files using Webpack’s asset modules feature.
Configure Webpack to extract inline SVG files like this:
--- a/webpack.config.js
+++ b/webpack.config.js
@@ -23,6 +23,14 @@ module.exports = {
module: {
rules: [
mimetype: 'image/svg+xml',
scheme: 'data',
type: 'asset/resource',
generator: {
filename: 'icons/[hash].svg'
test: /\.(scss)$/,
use: [
After running
npm run build
again, you’ll find the SVG files extracted into
dist/icons
and properly referenced from CSS.
See something wrong or out of date here? Please
open an issue on GitHub
. Need help troubleshooting?
Search or start a discussion
on GitHub.


--- 139_getting-started_rtl.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/rtl
--------------------------------------------------
Get familiar
We recommend getting familiar with Bootstrap first by reading through our
Getting Started Introduction page
. Once you’ve run through it, continue reading here for how to enable RTL.
You may also want to read up on
the RTLCSS project
, as it powers our approach to RTL.
and will evolve based on user feedback. Spotted something or have an improvement to suggest?
Open an issue
, we’d love to get your insights.
Required HTML
There are two strict requirements for enabling RTL in Bootstrap-powered pages.
dir="rtl"
on the
<html>
element.
Add an appropriate
lang
attribute, like
lang="ar"
, on the
<html>
element.
From there, you’ll need to include an RTL version of our CSS. For example, here’s the stylesheet for our compiled and minified CSS with RTL enabled:
link
stylesheet
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.rtl.min.css
integrity
sha384-Xbg45MqvDIk1e563NLpGEulpX6AvL404DP+/iCgW9eFa2BqztiwTexswJo2jLMue
crossorigin
anonymous
Starter template
You can see the above requirements reflected in this modified RTL starter template.
doctype
html
html
lang
head
<!-- Required meta tags -->
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
<!-- Bootstrap CSS -->
link
stylesheet
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.rtl.min.css
integrity
sha384-Xbg45MqvDIk1e563NLpGEulpX6AvL404DP+/iCgW9eFa2BqztiwTexswJo2jLMue
crossorigin
anonymous
title
مرحبًا بالعالم!
title
head
body
مرحبًا بالعالم!
<!-- Optional JavaScript; choose one of the two! -->
<!-- Option 1: Bootstrap Bundle with Popper -->
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.bundle.min.js
integrity
sha384-ndDqU0Gzau9qJ1lfW4pNLlhNTkCfHzAVBReH9diLvGRem5+R9g2FzA8ZGN954O5Q
crossorigin
anonymous
script
<!-- Option 2: Separate Popper and Bootstrap JS -->
<!--
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js" integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.min.js" integrity="sha384-7qAoOXltbVP82dhxHAUje59V5r2YsVfBafyUDxEdApLPmcdhBPg1DKg1ERo0BZlK" crossorigin="anonymous"></script>
body
html
RTL examples
Get started with one of our several
RTL examples
Approach
Our approach to building RTL support into Bootstrap comes with two important decisions that impact how we write and use our CSS:
First, we decided to build it with the
RTLCSS
project.
This gives us some powerful features for managing changes and overrides when moving from LTR to RTL. It also allows us to build two versions of Bootstrap from one codebase.
Second, we’ve renamed a handful of directional classes to adopt a logical properties approach.
Most of you have already interacted with logical properties thanks to our flex utilities—they replace direction properties like
left
right
in favor
start
. That makes the class names and values appropriate for LTR and RTL without any overhead.
For example, instead of
.ml-3
margin-left
, use
.ms-3
Working with RTL, through our source Sass or compiled CSS, shouldn’t be much different from our default LTR though.
Customize from source
When it comes to
customization
, the preferred way is to take advantage of variables, maps, and mixins. This approach works the same for RTL, even if it’s post-processed from the compiled files, thanks to
how RTLCSS works
Custom RTL values
Using
RTLCSS value directives
, you can make a variable output a different value for RTL. For example, to decrease the weight for
$font-weight-bold
throughout the codebase, you may use the
/*rtl: {value}*/
syntax:
$font-weight-bold
700 #
/* rtl:600 */
!default
Which would output to the following for our default CSS and RTL CSS:
/* bootstrap.css */
font-weight
/* rtl:600 */
/* bootstrap.rtl.css */
font-weight
Alternative font stack
In the case you’re using a custom font, be aware that not all fonts support the non-Latin alphabet. To switch from Pan-European to Arabic family, you may need to use
/*rtl:insert: {value}*/
in your font stack to modify the names of font families.
For example, to switch from
Helvetica Neue
font for LTR to
Helvetica Neue Arabic
for RTL, your Sass code could look like this:
$font-family-sans-serif
Helvetica Neue #
"/* rtl:insert:Arabic */"
// Cross-platform generic font family (default user interface font)
system-ui
// Safari for macOS and iOS (San Francisco)
-apple-system
// Chrome < 56 for macOS (San Francisco)
BlinkMacSystemFont
// Windows
"Segoe UI"
// Android
Roboto
// Basic web fallback
Arial
// Linux
"Noto Sans"
// Sans serif fallback
sans-serif
// Emoji fonts
"Apple Color Emoji"
"Segoe UI Emoji"
"Segoe UI Symbol"
"Noto Color Emoji"
!default
LTR and RTL at the same time
Need both LTR and RTL on the same page? Thanks to
RTLCSS String Maps
, this is pretty straightforward. Wrap your
@import
s with a class, and set a custom rename rule for RTLCSS:
/* rtl:begin:options: {
"autoRename": true,
"stringMap":[ {
"name": "ltr-rtl",
"priority": 100,
"search": ["ltr"],
"replace": ["rtl"],
"options": {
"scope": "*",
"ignoreCase": false
} */
.ltr
@import
"../node_modules/bootstrap/scss/bootstrap"
/*rtl:end:options*/
After running Sass then RTLCSS, each selector in your CSS files will be prepended by
.ltr
, and
.rtl
for RTL files. Now you’re able to use both files on the same page, and simply use
.ltr
.rtl
on your components wrappers to use one or the other direction.
Edge cases and known limitations
to consider when working with a combined LTR and RTL implementation:
When switching
.ltr
.rtl
, make sure you add
lang
attributes accordingly.
Loading both files can be a real performance bottleneck: consider some
optimization
, and maybe try to
load one of those files asynchronously
Nesting styles this way will prevent our
form-validation-state()
mixin from working as intended, thus require you tweak it a bit by yourself.
See #31223
Do you want to automate this process and address several edge cases involving both directions within a single stylesheet? Then, consider using
PostCSS RTLCSS
as a
PostCSS
plugin to process your source files. PostCSS RTLCSS uses
RTLCSS
behind the scenes to manage the direction flipping process, but it separates the flipped declarations into rules with a different prefix for LTR and RTL, something that allows you to have both directions within the same stylesheet file. By doing this, you can switch between LTR and RTL orientations by simply changing the
of the page (or even by modifying a specific class if you configure the plugin accordingly).
Important things to take into account
when using PostCSS RTLCSS to build a combined LTR and RTL implementation:
It is recommended that you add the
attribute to the
html
element. This way, the entire page will be affected when you change the direction. Also, make sure you add the
lang
attribute accordingly.
Having a single bundle with both directions will increase the size of the final stylesheet (on average, by 20%-30%): consider some
optimization
Take into account that PostCSS RTLCSS is not compatible with
/* rtl:remove */
directives because it doesn’t remove any CSS rule. You should replace your
/* rtl:remove */
/* rtl:begin:remove */
/* rtl:end:remove */
directives with
/* rtl:freeze */
/* rtl:begin:freeze */
/* rtl:end:freeze */
directives respectively. These directives will prefix the targeted rules or declarations with the current direction but will not create an RTL counterpart (same result as the
remove
ones in RTLCSS).
The breadcrumb case
breadcrumb separator
is the only case requiring its own brand-new variable— namely
$breadcrumb-divider-flipped
—defaulting to
$breadcrumb-divider
Additional resources
RTLCSS
RTL Styling 101


--- 140_getting-started_vite.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/vite
--------------------------------------------------
Want to skip to the end?
Download the source code and working demo for this guide from the
twbs/examples repository
. You can also
open the example in StackBlitz
for live editing.
What is Vite?
Vite
is a modern frontend build tool designed for speed and simplicity. It provides an efficient and streamlined development experience, especially for modern JavaScript frameworks.
Setup
We’re building a Vite project with Bootstrap from scratch, so there are some prerequisites and upfront steps before we can really get started. This guide requires you to have Node.js installed and some familiarity with the terminal.
Create a project folder and set up npm.
We'll create the
my-project
folder and initialize npm with the
argument to avoid it asking us all the interactive questions.
mkdir
my-project
my-project
init
Install Vite.
Unlike our Webpack guide, there’s only a single build tool dependency here. We use
--save-dev
to signal that this dependency is only for development use and not for production.
i --save-dev vite
Install Bootstrap.
Now we can install Bootstrap. We'll also install Popper since our dropdowns, popovers, and tooltips depend on it for their positioning. If you don’t plan on using those components, you can omit Popper here.
--save
Install additional dependency.
In addition to Vite and Bootstrap, we need another dependency (Sass) to properly import and bundle Bootstrap’s CSS.
i --save-dev sass
Now that we have all the necessary dependencies installed and set up, we can get to work creating the project files and importing Bootstrap.
Project structure
We’ve already created the
my-project
folder and initialized npm. Now we'll also create our
folder, stylesheet, and JavaScript file to round out the project structure. Run the following from
my-project
, or manually create the folder and file structure shown below.
mkdir
src,src/js,src/scss
touch
src/index.html src/js/main.js src/scss/styles.scss vite.config.js
When you’re done, your complete project should look like this:
my-project/
├── src/
│   ├── js/
│   │   └── main.js
│   └── scss/
│   |   └── styles.scss
|   └── index.html
├── package-lock.json
├── package.json
└── vite.config.js
At this point, everything is in the right place, but Vite won’t work because we haven’t filled in our
vite.config.js
yet.
Configure Vite
With dependencies installed and our project folder ready for us to start coding, we can now configure Vite and run our project locally.
Open
vite.config.js
in your editor.
Since it’s blank, we'll need to add some boilerplate config to it so we can start our server. This part of the config tells Vite where to look for our project’s JavaScript and how the development server should behave (pulling from the
folder with hot reload).
import
resolve
from
'path'
export
default
root
resolve
__dirname
'src'
build
outDir
'../dist'
server
port
8080
// Optional: Silence Sass deprecation warnings. See note below.
preprocessorOptions
scss
silenceDeprecations
'import'
'mixed-decls'
'color-functions'
'global-builtin'
Note:
Sass deprecation warnings are shown when compiling source Sass files with the latest versions of Dart Sass. This does not prevent compilation or usage of Bootstrap. We’re
working on a long-term fix
, but in the meantime these deprecation notices can be ignored.
Next we fill in
src/index.html
This is the HTML page Vite will load in the browser to utilize the bundled CSS and JS we'll add to it in later steps.
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
script
type
module
./js/main.js
script
head
body
class
container py-4 px-3 mx-auto
Hello, Bootstrap and Vite!
button
class
btn btn-primary
Primary button
button
body
html
We’re including a little bit of Bootstrap styling here with the
div class="container"
<button>
so that we see when Bootstrap’s CSS is loaded by Vite.
Now we need an npm script to run Vite.
Open
package.json
and add the
start
script shown below (you should already have the test script). We'll use this script to start our local Vite dev server.
// ...
"scripts"
"start"
"vite"
"test"
"echo \"Error: no test specified\" && exit 1"
// ...
And finally, we can start Vite.
From the
my-project
folder in your terminal, run that newly added npm script:
start
In the next and final section to this guide, we’ll import all of Bootstrap’s CSS and JavaScript.
Import Bootstrap
Import Bootstrap’s CSS.
Add the following to
src/scss/styles.scss
to import all of Bootstrap’s source Sass.
// Import all of Bootstrap’s CSS
@import
"bootstrap/scss/bootstrap"
You can also import our stylesheets individually if you want.
Read our Sass import docs
for details.
Next we load the CSS and import Bootstrap’s JavaScript.
Add the following to
src/js/main.js
to load the CSS and import all of Bootstrap’s JS. Popper will be imported automatically through Bootstrap.
// Import our custom CSS
import
'../scss/styles.scss'
// Import all of Bootstrap’s JS
import
from
'bootstrap'
You can also import JavaScript plugins individually as needed to keep bundle sizes down:
import
Alert
from
'bootstrap/js/dist/alert'
// or, specify which plugins you need:
import
Tooltip
Toast
Popover
from
'bootstrap'
Read our JavaScript docs
for more information on how to use Bootstrap’s plugins.
And you’re done! 🎉
With Bootstrap’s source Sass and JS fully loaded, your local development server should now look like this:
Now you can start adding any Bootstrap components you want to use. Be sure to
check out the complete Vite example project
for how to include additional custom Sass and optimize your build by importing only the parts of Bootstrap’s CSS and JS that you need.
See something wrong or out of date here? Please
open an issue on GitHub
. Need help troubleshooting?
Search or start a discussion
on GitHub.


--- 146_getting-started_contribute.txt ---
URL: https://getbootstrap.com/docs/5.3/getting-started/contribute
--------------------------------------------------
Tooling setup
npm scripts
to build the documentation and compile source files. Our
package.json
houses these scripts for compiling code, running tests, and more. These aren’t intended for use outside our repository and documentation.
To use our build system and run our documentation locally, you’ll need a copy of Bootstrap’s source files and Node. Follow these steps and you should be ready to rock:
Download and install Node.js
, which we use to manage our dependencies.
Either
download Bootstrap’s sources
or fork and clone
Navigate to the root
/bootstrap
directory and run
npm install
to install our local dependencies listed in
package.json
When completed, you’ll be able to run the various commands provided from the command line.
Using npm scripts
package.json
includes numerous tasks for developing the project. Run
npm run
to see all the npm scripts in your terminal.
Primary tasks include:
Task
Description
npm start
Compiles CSS and JavaScript, builds the documentation, and starts a local server.
npm run dist
Creates the
dist/
directory with compiled files. Uses
Sass
Autoprefixer
, and
terser
npm test
Runs tests locally after running
npm run dist
npm run docs-serve
Builds and runs the documentation locally.
Get started with Bootstrap via npm with our starter project!
Head to the
Sass & JS example
template repository to see how to build and customize Bootstrap in your own npm project. Includes Sass compiler, Autoprefixer, Stylelint, PurgeCSS, and Bootstrap Icons.
Sass
Dart Sass
for compiling our Sass source files into CSS files (included in our build process), and we recommend you do the same if you’re compiling Sass using your own asset pipeline. We previously used Node Sass for Bootstrap v4, but LibSass and packages built on top of it, including Node Sass, are now
deprecated
Dart Sass uses a rounding precision of 10 and for efficiency reasons does not allow adjustment of this value. We don’t lower this precision during further processing of our generated CSS, such as during minification, but if you chose to do so we recommend maintaining a precision of at least 6 to prevent issues with browser rounding.
Autoprefixer
Autoprefixer
(included in our build process) to automatically add vendor prefixes to some CSS properties at build time. Doing so saves us time and code by allowing us to write key parts of our CSS a single time while eliminating the need for vendor mixins like those found in v3.
We maintain the list of browsers supported through Autoprefixer in a separate file within our GitHub repository. See
.browserslistrc
for details.
RTLCSS
RTLCSS
to process compiled CSS and convert them to RTL – basically replacing horizontal direction aware properties (e.g.
padding-left
) with their opposite. It allows us only write our CSS a single time and make minor tweaks using RTLCSS
control
value
directives.
Local documentation
Running our documentation locally requires the use of Astro. Astro is a modern static site generator that allows us to build our documentation with a combination of Markdown and React components. Here’s how to get it started:
Run through the
tooling setup
above to install all dependencies.
From the root
/bootstrap
directory, run
npm run docs-serve
in the command line.
Open
http://localhost:4321/
in your browser, and voilà.
Learn more about using Astro by reading its
documentation
Troubleshooting
Should you encounter problems with installing dependencies, uninstall all previous dependency versions (global and local). Then, rerun
npm install


-------------------- End of Getting Started (18 pages) --------------------


========================= LAYOUT =========================
Section: Layout
Files: 11
======================================================================

--- 005_layout_gutters.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/gutters
--------------------------------------------------
How they work
Gutters are the gaps between column content, created by horizontal
padding
We set
padding-right
padding-left
on each column, and use negative
margin
to offset that at the start and end of each row to align content.
Gutters start at
1.5rem
24px
) wide.
This allows us to match our grid to the
padding and margin spacers
scale.
Gutters can be responsively adjusted.
Use breakpoint-specific gutter classes to modify horizontal gutters, vertical gutters, and all gutters.
Horizontal gutters
.gx-*
classes can be used to control the horizontal gutter widths. The
.container
.container-fluid
parent may need to be adjusted if larger gutters are used too to avoid unwanted overflow, using a matching padding utility. For example, in the following example we’ve increased the padding with
.px-4
Custom column padding
Custom column padding
html
class
container px-4 text-center
class
row gx-5
class
class
Custom column padding
class
class
Custom column padding
An alternative solution is to add a wrapper around the
.row
with the
.overflow-hidden
class:
Custom column padding
Custom column padding
html
class
container overflow-hidden text-center
class
row gx-5
class
class
Custom column padding
class
class
Custom column padding
Vertical gutters
.gy-*
classes can be used to control the vertical gutter widths within a row when columns wrap to new lines. Like the horizontal gutters, the vertical gutters can cause some overflow below the
.row
at the end of a page. If this occurs, you add a wrapper around
.row
with the
.overflow-hidden
class:
Custom column padding
Custom column padding
Custom column padding
Custom column padding
html
class
container overflow-hidden text-center
class
row gy-5
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
Horizontal & vertical gutters
.g-*
classes to control the horizontal and vertical grid gutters. In the example below, we use a smaller gutter width, so there isn’t a need for the
.overflow-hidden
wrapper class.
Custom column padding
Custom column padding
Custom column padding
Custom column padding
html
class
container text-center
class
row g-2
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
class
col-6
class
Custom column padding
Row columns gutters
Gutter classes can also be added to
row columns
. In the following example, we use responsive row columns and responsive gutter classes.
Row column
Row column
Row column
Row column
Row column
Row column
Row column
Row column
Row column
Row column
html
class
container text-center
class
row row-cols-2 row-cols-lg-5 g-2 g-lg-3
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
class
class
Row column
No gutters
The gutters between columns in our predefined grid classes can be removed with
.g-0
. This removes the negative
margin
s from
.row
and the horizontal
padding
from all immediate children columns.
Need an edge-to-edge design?
Drop the parent
.container
.container-fluid
and add
.mx-0
to the
.row
to prevent overflow.
In practice, here’s how it looks. Note that you can continue to use this with all other predefined grid classes (including column widths, responsive tiers, reorders, and more).
.col-sm-6 .col-md-8
.col-6 .col-md-4
html
class
row g-0 text-center
class
col-sm-6 col-md-8
.col-sm-6 .col-md-8
class
col-6 col-md-4
.col-6 .col-md-4
Change the gutters
Classes are built from the
$gutters
Sass map which is inherited from the
$spacers
Sass map.
$grid-gutter-width
1.5rem
$gutters
$spacer
$spacer
$spacer
$spacer
$spacer


--- 006_layout_columns.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/columns
--------------------------------------------------
Heads up!
Be sure to
read the Grid page
first before diving into how to modify and customize your grid columns.
How they work
Columns build on the grid’s flexbox architecture.
Flexbox means we have options for changing individual columns and
modifying groups of columns at the row level
. You choose how columns grow, shrink, or otherwise change.
When building grid layouts, all content goes in columns.
The hierarchy of Bootstrap’s grid goes from
container
to row to column to your content. On rare occasions, you may combine content and column, but be aware there can be unintended consequences.
With
six breakpoints
and a dozen columns at each grid tier, we have dozens of classes already built for you to create your desired layouts. This can be disabled via Sass if you wish.
Alignment
Use flexbox alignment utilities to vertically and horizontally align columns.
Vertical alignment
Change the vertical alignment with any of the responsive
align-items-*
classes.
One of three columns
One of three columns
One of three columns
html
class
container text-center
class
row align-items-start
class
One of three columns
class
One of three columns
class
One of three columns
One of three columns
One of three columns
One of three columns
html
class
container text-center
class
row align-items-center
class
One of three columns
class
One of three columns
class
One of three columns
One of three columns
One of three columns
One of three columns
html
class
container text-center
class
row align-items-end
class
One of three columns
class
One of three columns
class
One of three columns
Or, change the alignment of each column individually with any of the responsive
.align-self-*
classes.
One of three columns
One of three columns
One of three columns
html
class
container text-center
class
class
col align-self-start
One of three columns
class
col align-self-center
One of three columns
class
col align-self-end
One of three columns
Horizontal alignment
Change the horizontal alignment with any of the responsive
justify-content-*
classes.
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
One of two columns
html
class
container text-center
class
row justify-content-start
class
col-4
One of two columns
class
col-4
One of two columns
class
row justify-content-center
class
col-4
One of two columns
class
col-4
One of two columns
class
row justify-content-end
class
col-4
One of two columns
class
col-4
One of two columns
class
row justify-content-around
class
col-4
One of two columns
class
col-4
One of two columns
class
row justify-content-between
class
col-4
One of two columns
class
col-4
One of two columns
class
row justify-content-evenly
class
col-4
One of two columns
class
col-4
One of two columns
Column wrapping
If more than 12 columns are placed within a single row, each group of extra columns will, as one unit, wrap onto a new line.
.col-9
.col-4
Since 9 + 4 = 13 > 12, this 4-column-wide div gets wrapped onto a new line as one contiguous unit.
.col-6
Subsequent columns continue along the new line.
html
class
container
class
class
col-9
.col-9
class
col-4
.col-4
Since 9 + 4 = 13
&gt;
12, this 4-column-wide div gets wrapped onto a new line as one contiguous unit.
class
col-6
.col-6
Subsequent columns continue along the new line.
Column breaks
Breaking columns to a new line in flexbox requires a small hack: add an element with
width: 100%
wherever you want to wrap your columns to a new line. Normally this is accomplished with multiple
.row
s, but not every implementation method can account for this.
.col-6 .col-sm-3
.col-6 .col-sm-3
.col-6 .col-sm-3
.col-6 .col-sm-3
html
class
container text-center
class
class
col-6 col-sm-3
.col-6 .col-sm-3
class
col-6 col-sm-3
.col-6 .col-sm-3
<!-- Force next columns to break to new line -->
class
w-100
class
col-6 col-sm-3
.col-6 .col-sm-3
class
col-6 col-sm-3
.col-6 .col-sm-3
You may also apply this break at specific breakpoints with our
responsive display utilities
.col-6 .col-sm-4
.col-6 .col-sm-4
.col-6 .col-sm-4
.col-6 .col-sm-4
html
class
container text-center
class
class
col-6 col-sm-4
.col-6 .col-sm-4
class
col-6 col-sm-4
.col-6 .col-sm-4
<!-- Force next columns to break to new line at md breakpoint and up -->
class
w-100 d-none d-md-block
class
col-6 col-sm-4
.col-6 .col-sm-4
class
col-6 col-sm-4
.col-6 .col-sm-4
Reordering
Order classes
.order-
classes for controlling the
visual order
of your content. These classes are responsive, so you can set the
order
by breakpoint (e.g.,
.order-1.order-md-2
). Includes support for
through
across all six grid tiers.
First in DOM, no order applied
Second in DOM, with a larger order
Third in DOM, with an order of 1
html
class
container text-center
class
class
First in DOM, no order applied
class
col order-5
Second in DOM, with a larger order
class
col order-1
Third in DOM, with an order of 1
There are also responsive
.order-first
.order-last
classes that change the
order
of an element by applying
order: -1
order: 6
, respectively. These classes can also be intermixed with the numbered
.order-*
classes as needed.
First in DOM, ordered last
Second in DOM, unordered
Third in DOM, ordered first
html
class
container text-center
class
class
col order-last
First in DOM, ordered last
class
Second in DOM, unordered
class
col order-first
Third in DOM, ordered first
If you need more
.order-*
classes, you can add new ones by modifying our
$utilities
Sass map.
Read our Sass maps and loops docs
our Modify utilities docs
for details.
$utilities
map-merge
$utilities
"order"
map-merge
map-get
$utilities
"order"
values
map-merge
map-get
map-get
$utilities
"order"
"values"
// Add a new `.order-{breakpoint}-6` utility
last
// Change the `.order-{breakpoint}-last` utility to use the next number
Offsetting columns
You can offset grid columns in two ways: our responsive
.offset-
grid classes and our
margin utilities
. Grid classes are sized to match columns while margins are more useful for quick layouts where the width of the offset is variable.
Offset classes
Move columns to the right using
.offset-md-*
classes. These classes increase the left margin of a column by
columns. For example,
.offset-md-4
moves
.col-md-4
over four columns.
.col-md-4
.col-md-4 .offset-md-4
.col-md-3 .offset-md-3
.col-md-3 .offset-md-3
.col-md-6 .offset-md-3
html
class
container text-center
class
class
col-md-4
.col-md-4
class
col-md-4 offset-md-4
.col-md-4 .offset-md-4
class
class
col-md-3 offset-md-3
.col-md-3 .offset-md-3
class
col-md-3 offset-md-3
.col-md-3 .offset-md-3
class
class
col-md-6 offset-md-3
.col-md-6 .offset-md-3
In addition to column clearing at responsive breakpoints, you may need to reset offsets. See this in action in
the grid example
.col-sm-5 .col-md-6
.col-sm-5 .offset-sm-2 .col-md-6 .offset-md-0
.col-sm-6 .col-md-5 .col-lg-6
.col-sm-6 .col-md-5 .offset-md-2 .col-lg-6 .offset-lg-0
html
class
container text-center
class
class
col-sm-5 col-md-6
.col-sm-5 .col-md-6
class
col-sm-5 offset-sm-2 col-md-6 offset-md-0
.col-sm-5 .offset-sm-2 .col-md-6 .offset-md-0
class
class
col-sm-6 col-md-5 col-lg-6
.col-sm-6 .col-md-5 .col-lg-6
class
col-sm-6 col-md-5 offset-md-2 col-lg-6 offset-lg-0
.col-sm-6 .col-md-5 .offset-md-2 .col-lg-6 .offset-lg-0
Margin utilities
With the move to flexbox in v4, you can use margin utilities like
.me-auto
to force sibling columns away from one another.
.col-md-4
.col-md-4 .ms-auto
.col-md-3 .ms-md-auto
.col-md-3 .ms-md-auto
.col-auto .me-auto
.col-auto
html
class
container text-center
class
class
col-md-4
.col-md-4
class
col-md-4 ms-auto
.col-md-4 .ms-auto
class
class
col-md-3 ms-md-auto
.col-md-3 .ms-md-auto
class
col-md-3 ms-md-auto
.col-md-3 .ms-md-auto
class
class
col-auto me-auto
.col-auto .me-auto
class
col-auto
.col-auto
Standalone column classes
.col-*
classes can also be used outside a
.row
to give an element a specific width. Whenever column classes are used as non-direct children of a row, the paddings are omitted.
.col-3: width of 25%
.col-sm-9: width of 75% above sm breakpoint
html
class
col-3 p-3 mb-2
.col-3: width of 25%
class
col-sm-9 p-3
.col-sm-9: width of 75% above sm breakpoint
The classes can be used together with utilities to create responsive floated images. Make sure to wrap the content in a
.clearfix
wrapper to clear the float if the text is shorter.
Placeholder
Responsive floated image
A paragraph of placeholder text. We’re using it here to show the use of the clearfix class. We’re adding quite a few meaningless phrases here to demonstrate how the columns interact here with the floated image.
As you can see the paragraphs gracefully wrap around the floated image. Now imagine how this would look with some actual content in here, rather than just this boring placeholder text that goes on and on, but actually conveys no tangible information at. It simply takes up space and should not really be read.
And yet, here you are, still persevering in reading this placeholder text, hoping for some more insights, or some hidden easter egg of content. A joke, perhaps. Unfortunately, there’s none of that here.
html
class
clearfix
class
col-md-6 float-md-end mb-3 ms-md-3
A paragraph of placeholder text. We’re using it here to show the use of the clearfix class. We’re adding quite a few meaningless phrases here to demonstrate how the columns interact here with the floated image.
As you can see the paragraphs gracefully wrap around the floated image. Now imagine how this would look with some actual content in here, rather than just this boring placeholder text that goes on and on, but actually conveys no tangible information at. It simply takes up space and should not really be read.
And yet, here you are, still persevering in reading this placeholder text, hoping for some more insights, or some hidden easter egg of content. A joke, perhaps. Unfortunately, there’s none of that here.


--- 015_layout_css-grid.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/css-grid
--------------------------------------------------
Heads up—our CSS Grid system is experimental and opt-in as of v5.1.0!
We included it in our documentation’s CSS to demonstrate it for you, but it’s disabled by default. Keep reading to learn how to enable it in your projects.
How it works
With Bootstrap 5, we’ve added the option to enable a separate grid system that’s built on CSS Grid, but with a Bootstrap twist. You still get classes you can apply on a whim to build responsive layouts, but with a different approach under the hood.
CSS Grid is opt-in.
Disable the default grid system by setting
$enable-grid-classes: false
and enable the CSS Grid by setting
$enable-cssgrid: true
. Then, recompile your Sass.
Replace instances of
.row
with
.grid
.grid
class sets
display: grid
and creates a
grid-template
that you build on with your HTML.
Replace
.col-*
classes with
.g-col-*
classes.
This is because our CSS Grid columns use the
grid-column
property instead of
width
Columns and gutter sizes are set via CSS variables.
Set these on the parent
.grid
and customize however you want, inline or in a stylesheet, with
--bs-columns
--bs-gap
In the future, Bootstrap will likely shift to a hybrid solution as the
property has achieved nearly full browser support for flexbox.
Key differences
Compared to the default grid system:
Flex utilities don’t affect the CSS Grid columns in the same way.
Gaps replaces gutters. The
property replaces the horizontal
padding
from our default grid system and functions more like
margin
As such, unlike
.row
.grid
s have no negative margins and margin utilities cannot be used to change the grid gutters. Grid gaps are applied horizontally and vertically by default. See the
customizing section
for more details.
Inline and custom styles should be viewed as replacements for modifier classes (e.g.,
style="--bs-columns: 3;"
class="row-cols-3"
Nesting works similarly, but may require you to reset your column counts on each instance of a nested
.grid
. See the
nesting section
for details.
Examples
Three columns
Three equal-width columns across all viewports and devices can be created by using the
.g-col-4
classes. Add
responsive classes
to change the layout by viewport size.
.g-col-4
.g-col-4
.g-col-4
html
class
grid text-center
class
g-col-4
.g-col-4
class
g-col-4
.g-col-4
class
g-col-4
.g-col-4
Responsive
Use responsive classes to adjust your layout across viewports. Here we start with two columns on the narrowest viewports, and then grow to three columns on medium viewports and above.
.g-col-6 .g-col-md-4
.g-col-6 .g-col-md-4
.g-col-6 .g-col-md-4
html
class
grid text-center
class
g-col-6 g-col-md-4
.g-col-6 .g-col-md-4
class
g-col-6 g-col-md-4
.g-col-6 .g-col-md-4
class
g-col-6 g-col-md-4
.g-col-6 .g-col-md-4
Compare that to this two column layout at all viewports.
.g-col-6
.g-col-6
html
class
grid text-center
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
Wrapping
Grid items automatically wrap to the next line when there’s no more room horizontally. Note that the
applies to horizontal and vertical gaps between grid items.
.g-col-6
.g-col-6
.g-col-6
.g-col-6
html
class
grid text-center
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
Starts
Start classes aim to replace our default grid’s offset classes, but they’re not entirely the same. CSS Grid creates a grid template through styles that tell browsers to “start at this column” and “end at this column”. Those properties are
grid-column-start
grid-column-end
. Start classes are shorthand for the former. Pair them with the column classes to size and align your columns however you need. Start classes begin at
is an invalid value for these properties.
.g-col-3 .g-start-2
.g-col-4 .g-start-6
html
class
grid text-center
class
g-col-3 g-start-2
.g-col-3 .g-start-2
class
g-col-4 g-start-6
.g-col-4 .g-start-6
Auto columns
When there are no classes on the grid items (the immediate children of a
.grid
), each grid item will automatically be sized to one column.
html
class
grid text-center
This behavior can be mixed with grid column classes.
.g-col-6
html
class
grid text-center
class
g-col-6
.g-col-6
Nesting
Similar to our default grid system, our CSS Grid allows for easy nesting of
.grid
s. However, unlike the default, this grid inherits changes in the rows, columns, and gaps. Consider the example below:
We override the default number of columns with a local CSS variable:
--bs-columns: 3
In the first auto-column, the column count is inherited and each column is one-third of the available width.
In the second auto-column, we’ve reset the column count on the nested
.grid
to 12 (our default).
The third auto-column has no nested content.
In practice this allows for more complex and custom layouts when compared to our default grid system.
First auto-column
Auto-column
Auto-column
Second auto-column
6 of 12
4 of 12
2 of 12
Third auto-column
html
class
grid text-center overflow-x-auto
style
--bs-columns
First auto-column
class
grid
Auto-column
Auto-column
Second auto-column
class
grid
style
--bs-columns
class
g-col-6
6 of 12
class
g-col-4
4 of 12
class
g-col-2
2 of 12
Third auto-column
Customizing
Customize the number of columns, the number of rows, and the width of the gaps with local CSS variables.
Variable
Fallback value
Description
--bs-rows
The number of rows in your grid template
--bs-columns
The number of columns in your grid template
--bs-gap
1.5rem
The size of the gap between columns (vertical and horizontal)
These CSS variables have no default value; instead, they apply fallback values that are used
until
a local instance is provided. For example, we use
var(--bs-rows, 1)
for our CSS Grid rows, which ignores
--bs-rows
because that hasn’t been set anywhere yet. Once it is, the
.grid
instance will use that value instead of the fallback value of
No grid classes
Immediate children elements of
.grid
are grid items, so they’ll be sized without explicitly adding a
.g-col
class.
Auto-column
Auto-column
Auto-column
html
class
grid text-center
style
--bs-columns
Auto-column
Auto-column
Auto-column
Columns and gaps
Adjust the number of columns and the gap.
.g-col-2
.g-col-2
html
class
grid text-center
style
--bs-columns
--bs-gap
5rem
class
g-col-2
.g-col-2
class
g-col-2
.g-col-2
.g-col-6
.g-col-4
html
class
grid text-center
style
--bs-columns
--bs-gap
1rem
class
g-col-6
.g-col-6
class
g-col-4
.g-col-4
Adding rows
Adding more rows and changing the placement of columns:
Auto-column
Auto-column
Auto-column
html
class
grid text-center
style
--bs-rows
--bs-columns
Auto-column
class
g-start-2
style
grid-row
Auto-column
class
g-start-3
style
grid-row
Auto-column
Gaps
Change the vertical gaps only by modifying the
row-gap
. Note that we use
.grid
s, but
row-gap
column-gap
can be modified as needed.
.g-col-6
.g-col-6
.g-col-6
.g-col-6
html
class
grid text-center
style
row-gap
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
Because of that, you can have different vertical and horizontal
s, which can take a single value (all sides) or a pair of values (vertical and horizontal). This can be applied with an inline style for
, or with our
--bs-gap
CSS variable.
.g-col-6
.g-col-6
.g-col-6
.g-col-6
html
class
grid text-center
style
--bs-gap
.25rem 1rem
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
class
g-col-6
.g-col-6
Sass
One limitation of the CSS Grid is that our default classes are still generated by two Sass variables,
$grid-columns
$grid-gutter-width
. This effectively predetermines the number of classes generated in our compiled CSS. You have two options here:
Modify those default Sass variables and recompile your CSS.
Use inline or custom styles to augment the provided classes.
For example, you can increase the column count and change the gap size, and then size your “columns” with a mix of inline styles and predefined CSS Grid column classes (e.g.,
.g-col-4
14 columns
.g-col-4
html
class
grid text-center
style
--bs-columns
--bs-gap
.5rem
style
grid-column
span 14
14 columns
class
g-col-4
.g-col-4


--- 022_layout_utilities.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/utilities
--------------------------------------------------
Changing
display
Use our
display utilities
for responsively toggling common values of the
display
property. Mix it with our grid system, content, or components to show or hide them across specific viewports.
Flexbox options
display
has been changed to
display: flex
as this would add many unnecessary overrides and unexpectedly change key browser behaviors. Most of
our components
are built with flexbox enabled.
Should you need to add
display: flex
to an element, do so with
.d-flex
or one of the responsive variants (e.g.,
.d-sm-flex
). You’ll need this class or
display
value to allow the use of our extra
flexbox utilities
for sizing, alignment, spacing, and more.
Margin and padding
Use the
margin
padding
spacing utilities
to control how elements and components are spaced and sized. Bootstrap includes a six-level scale for spacing utilities, based on a
1rem
value default
$spacer
variable. Choose values for all viewports (e.g.,
.me-3
margin-right: 1rem
in LTR), or pick responsive variants to target specific viewports (e.g.,
.me-md-3
margin-right: 1rem
—in LTR— starting at the
breakpoint).
Toggle
visibility
When toggling
display
isn’t needed, you can toggle the
visibility
of an element with our
visibility utilities
. Invisible elements will still affect the layout of the page, but are visually hidden from visitors.


--- 034_layout_breakpoints.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/breakpoints
--------------------------------------------------
Core concepts
Breakpoints are the building blocks of responsive design.
Use them to control when your layout can be adapted at a particular viewport or device size.
Use media queries to architect your CSS by breakpoint.
Media queries are a feature of CSS that allow you to conditionally apply styles based on a set of browser and operating system parameters. We most commonly use
min-width
in our media queries.
Mobile first, responsive design is the goal.
Available breakpoints
grid tiers
, for building responsively. These breakpoints can be customized if you’re using our source Sass files.
Breakpoint
Class infix
Dimensions
Extra small
None
<576px
Small
≥576px
Medium
≥768px
Large
≥992px
Extra large
≥1200px
Extra extra large
≥1400px
Each breakpoint was chosen to comfortably hold containers whose widths are multiples of 12. Breakpoints are also representative of a subset of common device sizes and viewport dimensions—they don’t specifically target every use case or device. Instead, the ranges provide a strong and consistent foundation to build on for nearly any device.
These breakpoints are customizable via Sass—you’ll find them in a Sass map in our
_variables.scss
stylesheet.
scss/_variables.scss
$grid-breakpoints
576px
768px
992px
1200px
1400px
For more information and examples on how to modify our Sass maps and variables, please refer to
the CSS section of the Grid documentation
Media queries
Since Bootstrap is developed to be mobile first, we use a handful of
media queries
to create sensible breakpoints for our layouts and interfaces. These breakpoints are mostly based on minimum viewport widths and allow us to scale up elements as the viewport changes.
Min-width
// Source mixins
// No media query necessary for xs breakpoint as it’s effectively `@media (min-width: 0) { ... }`
@include
media-breakpoint-up
@include
media-breakpoint-up
@include
media-breakpoint-up
@include
media-breakpoint-up
@include
media-breakpoint-up
// Usage
// Example: Hide starting at `min-width: 0`, and then show at the `sm` breakpoint
.custom-class
display
none
@include
media-breakpoint-up
.custom-class
display
block
These Sass mixins translate in our compiled CSS using the values declared in our Sass variables. For example:
// X-Small devices (portrait phones, less than 576px)
// No media query for `xs` since this is the default in Bootstrap
// Small devices (landscape phones, 576px and up)
@media
min-width
576px
// Medium devices (tablets, 768px and up)
@media
min-width
768px
// Large devices (desktops, 992px and up)
@media
min-width
992px
// X-Large devices (large desktops, 1200px and up)
@media
min-width
1200px
// XX-Large devices (larger desktops, 1400px and up)
@media
min-width
1400px
Max-width
We occasionally use media queries that go in the other direction (the given screen size
or smaller
// No media query necessary for xs breakpoint as it’s effectively `@media (max-width: 0) { ... }`
@include
media-breakpoint-down
@include
media-breakpoint-down
@include
media-breakpoint-down
@include
media-breakpoint-down
@include
media-breakpoint-down
// Example: Style from medium breakpoint and down
@include
media-breakpoint-down
.custom-class
display
block
These mixins take those declared breakpoints, subtract
.02px
from them, and use them as our
max-width
values. For example:
// `xs` returns only a ruleset and no media query
// ... { ... }
// `sm` applies to x-small devices (portrait phones, less than 576px)
@media
max-width
575.98px
// `md` applies to small devices (landscape phones, less than 768px)
@media
max-width
767.98px
// `lg` applies to medium devices (tablets, less than 992px)
@media
max-width
991.98px
// `xl` applies to large devices (desktops, less than 1200px)
@media
max-width
1199.98px
// `xxl` applies to x-large devices (large desktops, less than 1400px)
@media
max-width
1399.98px
Why subtract .02px?
Browsers don’t currently support
range context queries
, so we work around the limitations of
min-
max-
prefixes
and viewports with fractional widths (which can occur under certain conditions on high-dpi devices, for instance) by using values with higher precision.
Single breakpoint
There are also media queries and mixins for targeting a single segment of screen sizes using the minimum and maximum breakpoint widths.
@include
media-breakpoint-only
@include
media-breakpoint-only
@include
media-breakpoint-only
@include
media-breakpoint-only
@include
media-breakpoint-only
@include
media-breakpoint-only
For example the
@include media-breakpoint-only(md) { ... }
will result in :
@media
min-width
768px
max-width
991.98px
Between breakpoints
Similarly, media queries may span multiple breakpoint widths:
@include
media-breakpoint-between
Which results in:
// Example
// Apply styles starting from medium devices and up to extra large devices
@media
min-width
768px
max-width
1199.98px


--- 054_layout_z-index.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/z-index
--------------------------------------------------
Several Bootstrap components utilize
z-index
, the CSS property that helps control layout by providing a third axis to arrange content. We utilize a default z-index scale in Bootstrap that’s been designed to properly layer navigation, tooltips and popovers, modals, and more.
These higher values start at an arbitrary number, high and specific enough to ideally avoid conflicts. We need a standard set of these across our layered components—tooltips, popovers, navbars, dropdowns, modals—so we can be reasonably consistent in the behaviors. There’s no reason we couldn’t have used
+ or
We don’t encourage customization of these individual values; should you change one, you likely need to change them all.
scss/_variables.scss
$zindex-dropdown
1000
$zindex-sticky
1020
$zindex-fixed
1030
$zindex-offcanvas-backdrop
1040
$zindex-offcanvas
1045
$zindex-modal-backdrop
1050
$zindex-modal
1055
$zindex-popover
1070
$zindex-tooltip
1080
$zindex-toast
1090
To handle overlapping borders within components (e.g., buttons and inputs in input groups), we use low single digit
z-index
values of
, and
for default, hover, and active states. On hover/focus/active, we bring a particular element to the forefront with a higher
z-index
value to show their border over the sibling elements.


--- 090_utilities_z-index.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/z-index
--------------------------------------------------
Example
z-index
utilities to stack elements on top of one another. Requires a
position
value other than
static
, which can be set with custom styles or using our
position utilities
We call these “low-level”
z-index
utilities because of their default values of
through
, which we use for the layout of overlapping components. High-level
z-index
values are used for overlay components like modals and tooltips.
z-n1
html
class
z-3 position-absolute p-5 rounded-3
span
span
class
z-2 position-absolute p-5 rounded-3
span
span
class
z-1 position-absolute p-5 rounded-3
span
span
class
z-0 position-absolute p-5 rounded-3
span
span
class
z-n1 position-absolute p-5 rounded-3
span
z-n1
span
Overlays
z-index
values to ensure a usable experience with competing “layers” of an interface.
Read about them in the
z-index
layout page
Component approach
On some components, we use our low-level
z-index
values to manage repeating elements that overlap one another (like buttons in a button group or items in a list group).
Learn about our
z-index
approach
Sass maps
Customize this Sass map to change the available values and generated utilities.
scss/_variables.scss
$zindex-levels
Sass utilities API
Position utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"z-index"
property
z-index
class
values
$zindex-levels


--- 095_forms_layout.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/layout
--------------------------------------------------
Forms
Every group of form fields should reside in a
<form>
element. Bootstrap provides no default styling for the
<form>
element, but there are some powerful browser features that are provided by default.
New to browser forms? Consider reviewing
the MDN form docs
for an overview and complete list of available attributes.
<button>
s within a
<form>
default to
type="submit"
, so strive to be specific and always include a
type
Since Bootstrap applies
display: block
width: 100%
to almost all our form controls, forms will by default stack vertically. Additional classes can be used to vary this layout on a per-form basis.
Utilities
Margin utilities
are the easiest way to add some structure to forms. They provide basic grouping of labels, controls, optional form text, and form validation messaging. We recommend sticking to
margin-bottom
utilities, and using a single direction throughout the form for consistency.
Feel free to build your forms however you like, with
<fieldset>
<div>
s, or nearly any other element.
Example label
Another label
html
class
mb-3
label
formGroupExampleInput
class
form-label
Example label
label
input
type
text
class
form-control
formGroupExampleInput
placeholder
Example input placeholder
class
mb-3
label
formGroupExampleInput2
class
form-label
Another label
label
input
type
text
class
form-control
formGroupExampleInput2
placeholder
Another input placeholder
Form grid
More complex forms can be built using our grid classes. Use these for form layouts that require multiple columns, varied widths, and additional alignment options.
Requires the
$enable-grid-classes
Sass variable to be enabled
(on by default).
html
class
class
input
type
text
class
form-control
placeholder
First name
aria-label
First name
class
input
type
text
class
form-control
placeholder
Last name
aria-label
Last name
Gutters
By adding
gutter modifier classes
, you can have control over the gutter width in as well the inline as block direction.
Also requires the
$enable-grid-classes
Sass variable to be enabled
(on by default).
html
class
row g-3
class
input
type
text
class
form-control
placeholder
First name
aria-label
First name
class
input
type
text
class
form-control
placeholder
Last name
aria-label
Last name
More complex layouts can also be created with the grid system.
Email
Password
Address
Address 2
City
State
Choose...
Check me out
Sign in
html
form
class
row g-3
class
col-md-6
label
inputEmail4
class
form-label
Email
label
input
type
email
class
form-control
inputEmail4
class
col-md-6
label
inputPassword4
class
form-label
Password
label
input
type
password
class
form-control
inputPassword4
class
col-12
label
inputAddress
class
form-label
Address
label
input
type
text
class
form-control
inputAddress
placeholder
1234 Main St
class
col-12
label
inputAddress2
class
form-label
Address 2
label
input
type
text
class
form-control
inputAddress2
placeholder
Apartment, studio, or floor
class
col-md-6
label
inputCity
class
form-label
City
label
input
type
text
class
form-control
inputCity
class
col-md-4
label
inputState
class
form-label
State
label
select
inputState
class
form-select
option
selected
Choose...
option
option
option
select
class
col-md-2
label
inputZip
class
form-label
label
input
type
text
class
form-control
inputZip
class
col-12
class
form-check
input
class
form-check-input
type
checkbox
gridCheck
label
class
form-check-label
gridCheck
Check me out
label
class
col-12
button
type
submit
class
btn btn-primary
Sign in
button
form
Horizontal form
Create horizontal forms with the grid by adding the
.row
class to form groups and using the
.col-*-*
classes to specify the width of your labels and controls. Be sure to add
.col-form-label
to your
<label>
s as well so they’re vertically centered with their associated form controls.
At times, you maybe need to use margin or padding utilities to create that perfect alignment you need. For example, we’ve removed the
padding-top
on our stacked radio inputs label to better align the text baseline.
Email
Password
Radios
First radio
Second radio
Third disabled radio
Example checkbox
Sign in
html
form
class
row mb-3
label
inputEmail3
class
col-sm-2 col-form-label
Email
label
class
col-sm-10
input
type
email
class
form-control
inputEmail3
class
row mb-3
label
inputPassword3
class
col-sm-2 col-form-label
Password
label
class
col-sm-10
input
type
password
class
form-control
inputPassword3
fieldset
class
row mb-3
legend
class
col-form-label col-sm-2 pt-0
Radios
legend
class
col-sm-10
class
form-check
input
class
form-check-input
type
radio
name
gridRadios
gridRadios1
value
option1
checked
label
class
form-check-label
gridRadios1
First radio
label
class
form-check
input
class
form-check-input
type
radio
name
gridRadios
gridRadios2
value
option2
label
class
form-check-label
gridRadios2
Second radio
label
class
form-check disabled
input
class
form-check-input
type
radio
name
gridRadios
gridRadios3
value
option3
disabled
label
class
form-check-label
gridRadios3
Third disabled radio
label
fieldset
class
row mb-3
class
col-sm-10 offset-sm-2
class
form-check
input
class
form-check-input
type
checkbox
gridCheck1
label
class
form-check-label
gridCheck1
Example checkbox
label
button
type
submit
class
btn btn-primary
Sign in
button
form
Horizontal form label sizing
Be sure to use
.col-form-label-sm
.col-form-label-lg
to your
<label>
s or
<legend>
s to correctly follow the size of
.form-control-lg
.form-control-sm
Email
Email
Email
html
class
row mb-3
label
colFormLabelSm
class
col-sm-2 col-form-label col-form-label-sm
Email
label
class
col-sm-10
input
type
email
class
form-control form-control-sm
colFormLabelSm
placeholder
col-form-label-sm
class
row mb-3
label
colFormLabel
class
col-sm-2 col-form-label
Email
label
class
col-sm-10
input
type
email
class
form-control
colFormLabel
placeholder
col-form-label
class
label
colFormLabelLg
class
col-sm-2 col-form-label col-form-label-lg
Email
label
class
col-sm-10
input
type
email
class
form-control form-control-lg
colFormLabelLg
placeholder
col-form-label-lg
Column sizing
As shown in the previous examples, our grid system allows you to place any number of
.col
s within a
.row
. They’ll split the available width equally between them. You may also pick a subset of your columns to take up more or less space, while the remaining
.col
s equally split the rest, with specific column classes like
.col-sm-7
html
class
row g-3
class
col-sm-7
input
type
text
class
form-control
placeholder
City
aria-label
City
class
col-sm
input
type
text
class
form-control
placeholder
State
aria-label
State
class
col-sm
input
type
text
class
form-control
placeholder
aria-label
Auto-sizing
The example below uses a flexbox utility to vertically center the contents and changes
.col
.col-auto
so that your columns only take up as much space as needed. Put another way, the column sizes itself based on the contents.
Name
Username
Preference
Choose...
Three
Remember me
Submit
html
form
class
row gy-2 gx-3 align-items-center
class
col-auto
label
class
visually-hidden
autoSizingInput
Name
label
input
type
text
class
form-control
autoSizingInput
placeholder
Jane Doe
class
col-auto
label
class
visually-hidden
autoSizingInputGroup
Username
label
class
input-group
class
input-group-text
input
type
text
class
form-control
autoSizingInputGroup
placeholder
Username
class
col-auto
label
class
visually-hidden
autoSizingSelect
Preference
label
select
class
form-select
autoSizingSelect
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
class
col-auto
class
form-check
input
class
form-check-input
type
checkbox
autoSizingCheck
label
class
form-check-label
autoSizingCheck
Remember me
label
class
col-auto
button
type
submit
class
btn btn-primary
Submit
button
form
You can then remix that once again with size-specific column classes.
Name
Username
Preference
Choose...
Three
Remember me
Submit
html
form
class
row gx-3 gy-2 align-items-center
class
col-sm-3
label
class
visually-hidden
specificSizeInputName
Name
label
input
type
text
class
form-control
specificSizeInputName
placeholder
Jane Doe
class
col-sm-3
label
class
visually-hidden
specificSizeInputGroupUsername
Username
label
class
input-group
class
input-group-text
input
type
text
class
form-control
specificSizeInputGroupUsername
placeholder
Username
class
col-sm-3
label
class
visually-hidden
specificSizeSelect
Preference
label
select
class
form-select
specificSizeSelect
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
class
col-auto
class
form-check
input
class
form-check-input
type
checkbox
autoSizingCheck2
label
class
form-check-label
autoSizingCheck2
Remember me
label
class
col-auto
button
type
submit
class
btn btn-primary
Submit
button
form
Inline forms
Use the
.row-cols-*
classes to create responsive horizontal layouts. By adding
gutter modifier classes
, we'll have gutters in horizontal and vertical directions. On narrow mobile viewports, the
.col-12
helps stack the form controls and more. The
.align-items-center
aligns the form elements to the middle, making the
.form-check
align properly.
Username
Preference
Choose...
Three
Remember me
Submit
html
form
class
row row-cols-lg-auto g-3 align-items-center
class
col-12
label
class
visually-hidden
inlineFormInputGroupUsername
Username
label
class
input-group
class
input-group-text
input
type
text
class
form-control
inlineFormInputGroupUsername
placeholder
Username
class
col-12
label
class
visually-hidden
inlineFormSelectPref
Preference
label
select
class
form-select
inlineFormSelectPref
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
class
col-12
class
form-check
input
class
form-check-input
type
checkbox
inlineFormCheck
label
class
form-check-label
inlineFormCheck
Remember me
label
class
col-12
button
type
submit
class
btn btn-primary
Submit
button
form


--- 099_layout_containers.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/containers
--------------------------------------------------
How they work
Containers are the most basic layout element in Bootstrap and are
required when using our default grid system
. Containers are used to contain, pad, and (sometimes) center the content within them. While containers
be nested, most layouts do not require a nested container.
.container
, which sets a
max-width
at each responsive breakpoint
.container-{breakpoint}
, which is
width: 100%
until the specified breakpoint
.container-fluid
, which is
width: 100%
at all breakpoints
The table below illustrates how each container’s
max-width
compares to the original
.container
.container-fluid
across each breakpoint.
See them in action and compare them in our
Grid example
Extra small
<576px
Small
≥576px
Medium
≥768px
Large
≥992px
X-Large
≥1200px
XX-Large
≥1400px
.container
100%
540px
720px
960px
1140px
1320px
.container-sm
100%
540px
720px
960px
1140px
1320px
.container-md
100%
100%
720px
960px
1140px
1320px
.container-lg
100%
100%
100%
960px
1140px
1320px
.container-xl
100%
100%
100%
100%
1140px
1320px
.container-xxl
100%
100%
100%
100%
100%
1320px
.container-fluid
100%
100%
100%
100%
100%
100%
Default container
Our default
.container
class is a responsive, fixed-width container, meaning its
max-width
changes at each breakpoint.
class
container
<!-- Content here -->
Responsive containers
Responsive containers allow you to specify a class that is 100% wide until the specified breakpoint is reached, after which we apply
max-width
s for each of the higher breakpoints. For example,
.container-sm
is 100% wide to start until the
breakpoint is reached, where it will scale up with
, and
class
container-sm
100% wide until small breakpoint
class
container-md
100% wide until medium breakpoint
class
container-lg
100% wide until large breakpoint
class
container-xl
100% wide until extra large breakpoint
class
container-xxl
100% wide until extra extra large breakpoint
Fluid containers
.container-fluid
for a full width container, spanning the entire width of the viewport.
class
container-fluid
Sass variables
As shown above, Bootstrap generates a series of predefined container classes to help you build the layouts you desire. You may customize these predefined container classes by modifying the Sass map (found in
_variables.scss
) that powers them:
scss/_variables.scss
$container-max-widths
540px
720px
960px
1140px
1320px
For more information and examples on how to modify our Sass maps and variables, please refer to
the Sass section of the Grid documentation
Sass mixins
In addition to customizing the Sass, you can also create your own containers with our Sass mixin.
// Source mixin
@mixin
make-container
$padding-x
$container-padding-x
width
100%
padding-right
$padding-x
padding-left
$padding-x
margin-right
auto
margin-left
auto
// Usage
.custom-container
@include
make-container


--- 126_examples_grid.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/grid
--------------------------------------------------
Basic grid layouts to get you familiar with building within the Bootstrap grid system.
In these examples the
.themed-grid-col
class is added to the columns to add some theming. This is not a class that is available in Bootstrap by default.
Five grid tiers
There are five tiers to the Bootstrap grid system, one for each range of devices we support. Each tier starts at a minimum viewport size and automatically applies to the larger devices unless overridden.
.col-4
.col-4
.col-4
.col-sm-4
.col-sm-4
.col-sm-4
.col-md-4
.col-md-4
.col-md-4
.col-lg-4
.col-lg-4
.col-lg-4
.col-xl-4
.col-xl-4
.col-xl-4
.col-xxl-4
.col-xxl-4
.col-xxl-4
Three equal columns
Get three equal-width columns
starting at desktops and scaling to large desktops
. On mobile devices, tablets and below, the columns will automatically stack.
.col-md-4
.col-md-4
.col-md-4
Three equal columns alternative
By using the
.row-cols-*
classes, you can easily create a grid with equal columns.
.col
child of
.row-cols-md-3
.col
child of
.row-cols-md-3
.col
child of
.row-cols-md-3
Three unequal columns
Get three columns
starting at desktops and scaling to large desktops
of various widths. Remember, grid columns should add up to twelve for a single horizontal block. More than that, and columns start stacking no matter the viewport.
.col-md-3
.col-md-6
.col-md-3
Two columns
Get two columns
starting at desktops and scaling to large desktops
.col-md-8
.col-md-4
Full width, single column
No grid classes are necessary for full-width elements.
Two columns with two nested columns
Per the documentation, nesting is easy—just put a row of columns within an existing column. This gives you two columns
starting at desktops and scaling to large desktops
, with another two (equal widths) within the larger column.
At mobile device sizes, tablets and down, these columns and their nested columns will stack.
.col-md-8
.col-md-6
.col-md-6
.col-md-4
Mixed: mobile and desktop
The Bootstrap v5 grid system has six tiers of classes: xs (extra small, this class infix is not used), sm (small), md (medium), lg (large), xl (x-large), and xxl (xx-large). You can use nearly any combination of these classes to create more dynamic and flexible layouts.
Each tier of classes scales up, meaning if you plan on setting the same widths for md, lg, xl and xxl, you only need to specify md.
.col-md-8
.col-6 .col-md-4
.col-6 .col-md-4
.col-6 .col-md-4
.col-6 .col-md-4
.col-6
.col-6
Mixed: mobile, tablet, and desktop
.col-sm-6 .col-lg-8
.col-6 .col-lg-4
.col-6 .col-sm-4
.col-6 .col-sm-4
.col-6 .col-sm-4
Gutters
With
.gx-*
classes, the horizontal gutters can be adjusted.
.col
with
.gx-4
gutters
.col
with
.gx-4
gutters
.col
with
.gx-4
gutters
.col
with
.gx-4
gutters
.col
with
.gx-4
gutters
.col
with
.gx-4
gutters
Use the
.gy-*
classes to control the vertical gutters.
.col
with
.gy-4
gutters
.col
with
.gy-4
gutters
.col
with
.gy-4
gutters
.col
with
.gy-4
gutters
.col
with
.gy-4
gutters
.col
with
.gy-4
gutters
With
.g-*
classes, the gutters in both directions can be adjusted.
.col
with
.g-3
gutters
.col
with
.g-3
gutters
.col
with
.g-3
gutters
.col
with
.g-3
gutters
.col
with
.g-3
gutters
.col
with
.g-3
gutters
Containers
Additional classes added in Bootstrap v4.4 allow containers that are 100% wide until a particular breakpoint. v5 adds a new
breakpoint.
.container
.container-sm
.container-md
.container-lg
.container-xl
.container-xxl
.container-fluid


--- 127_layout_grid.txt ---
URL: https://getbootstrap.com/docs/5.3/layout/grid
--------------------------------------------------
Example
flexbox
and is fully responsive. Below is an example and an in-depth explanation for how the grid system comes together.
New to or unfamiliar with flexbox?
Read this CSS Tricks flexbox guide
for background, terminology, guidelines, and code snippets.
Column
Column
Column
html
class
container text-center
class
class
Column
class
Column
class
Column
The above example creates three equal-width columns across all devices and viewports using our predefined grid classes. Those columns are centered in the page with the parent
.container
How it works
Breaking it down, here’s how the grid system comes together:
Our grid supports
six responsive breakpoints
Breakpoints are based on
min-width
media queries, meaning they affect that breakpoint and all those above it (e.g.,
.col-sm-4
applies to
, and
). This means you can control container and column sizing and behavior by each breakpoint.
Containers center and horizontally pad your content.
.container
for a responsive pixel width,
.container-fluid
width: 100%
across all viewports and devices, or a responsive container (e.g.,
.container-md
) for a combination of fluid and pixel widths.
Rows are wrappers for columns.
Each column has horizontal
padding
(called a gutter) for controlling the space between them. This
padding
is then counteracted on the rows with negative margins to ensure the content in your columns is visually aligned down the left side. Rows also support modifier classes to
uniformly apply column sizing
gutter classes
to change the spacing of your content.
Columns are incredibly flexible.
There are 12 template columns available per row, allowing you to create different combinations of elements that span any number of columns. Column classes indicate the number of template columns to span (e.g.,
col-4
spans four).
width
s are set in percentages so you always have the same relative sizing.
Gutters are also responsive and customizable.
Gutter classes are available
across all breakpoints, with all the same sizes as our
margin and padding spacing
. Change horizontal gutters with
.gx-*
classes, vertical gutters with
.gy-*
, or all gutters with
.g-*
classes.
.g-0
is also available to remove gutters.
Sass variables, maps, and mixins power the grid.
If you don’t want to use the predefined grid classes in Bootstrap, you can use our
grid’s source Sass
to create your own with more semantic markup. We also include some CSS custom properties to consume these Sass variables for even greater flexibility for you.
Be aware of the limitations and
bugs around flexbox
, like the
inability to use some HTML elements as flex containers
Grid options
Extra small (xs)
Small (sm)
Medium (md)
Large (lg)
Extra large (xl)
Extra extra large (xxl)
As noted above, each of these breakpoints have their own container, unique class prefix, and modifiers. Here’s how the grid changes across these breakpoints:
<576px
≥576px
≥768px
≥992px
≥1200px
≥1400px
Container
max-width
None (auto)
540px
720px
960px
1140px
1320px
Class prefix
.col-
.col-sm-
.col-md-
.col-lg-
.col-xl-
.col-xxl-
# of columns
Gutter width
1.5rem (.75rem on left and right)
Custom gutters
Nestable
Column ordering
Auto-layout columns
Utilize breakpoint-specific column classes for easy column sizing without an explicit numbered class like
.col-sm-6
Equal-width
For example, here are two grid layouts that apply to every device and viewport, from
. Add any number of unit-less classes for each breakpoint you need and every column will be the same width.
1 of 2
2 of 2
1 of 3
2 of 3
3 of 3
html
class
container text-center
class
class
1 of 2
class
2 of 2
class
class
1 of 3
class
2 of 3
class
3 of 3
Setting one column width
Auto-layout for flexbox grid columns also means you can set the width of one column and have the sibling columns automatically resize around it. You may use predefined grid classes (as shown below), grid mixins, or inline widths. Note that the other columns will resize no matter the width of the center column.
1 of 3
2 of 3 (wider)
3 of 3
1 of 3
2 of 3 (wider)
3 of 3
html
class
container text-center
class
class
1 of 3
class
col-6
2 of 3 (wider)
class
3 of 3
class
class
1 of 3
class
col-5
2 of 3 (wider)
class
3 of 3
Variable width content
col-{breakpoint}-auto
classes to size columns based on the natural width of their content.
1 of 3
Variable width content
3 of 3
1 of 3
Variable width content
3 of 3
html
class
container text-center
class
row justify-content-md-center
class
col col-lg-2
1 of 3
class
col-md-auto
Variable width content
class
col col-lg-2
3 of 3
class
class
1 of 3
class
col-md-auto
Variable width content
class
col col-lg-2
3 of 3
Responsive classes
All breakpoints
For grids that are the same from the smallest of devices to the largest, use the
.col
.col-*
classes. Specify a numbered class when you need a particularly sized column; otherwise, feel free to stick to
.col
col-8
col-4
html
class
container text-center
class
class
class
class
class
class
class
col-8
col-8
class
col-4
col-4
Stacked to horizontal
Using a single set of
.col-sm-*
classes, you can create a basic grid system that starts out stacked and becomes horizontal at the small breakpoint (
col-sm-8
col-sm-4
col-sm
col-sm
col-sm
html
class
container text-center
class
class
col-sm-8
col-sm-8
class
col-sm-4
col-sm-4
class
class
col-sm
col-sm
class
col-sm
col-sm
class
col-sm
col-sm
Mix and match
Don’t want your columns to simply stack in some grid tiers? Use a combination of different classes for each tier as needed. See the example below for a better idea of how it all works.
.col-md-8
.col-6 .col-md-4
.col-6 .col-md-4
.col-6 .col-md-4
.col-6 .col-md-4
.col-6
.col-6
html
class
container text-center
<!-- Stack the columns on mobile by making one full-width and the other half-width -->
class
class
col-md-8
.col-md-8
class
col-6 col-md-4
.col-6 .col-md-4
<!-- Columns start at 50% wide on mobile and bump up to 33.3% wide on desktop -->
class
class
col-6 col-md-4
.col-6 .col-md-4
class
col-6 col-md-4
.col-6 .col-md-4
class
col-6 col-md-4
.col-6 .col-md-4
<!-- Columns are always 50% wide, on mobile and desktop -->
class
class
col-6
.col-6
class
col-6
.col-6
Row columns
Use the responsive
.row-cols-*
classes to quickly set the number of columns that best render your content and layout. Whereas normal
.col-*
classes apply to the individual columns (e.g.,
.col-md-4
), the row columns classes are set on the parent
.row
as a shortcut. With
.row-cols-auto
you can give the columns their natural width.
Use these row columns classes to quickly create basic grid layouts or to control your card layouts.
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-2
class
Column
class
Column
class
Column
class
Column
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-3
class
Column
class
Column
class
Column
class
Column
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-auto
class
Column
class
Column
class
Column
class
Column
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-4
class
Column
class
Column
class
Column
class
Column
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-4
class
Column
class
Column
class
col-6
Column
class
Column
Column
Column
Column
Column
html
class
container text-center
class
row row-cols-1 row-cols-sm-2 row-cols-md-4
class
Column
class
Column
class
Column
class
Column
You can also use the accompanying Sass mixin,
row-cols()
.element
// Three columns to start
@include
row-cols
// Five columns from medium breakpoint up
@include
media-breakpoint-up
@include
row-cols
Nesting
To nest your content with the default grid, add a new
.row
and set of
.col-sm-*
columns within an existing
.col-sm-*
column. Nested rows should include a set of columns that add up to 12 or fewer (it is not required that you use all 12 available columns).
Level 1: .col-sm-3
Level 2: .col-8 .col-sm-6
Level 2: .col-4 .col-sm-6
html
class
container text-center
class
class
col-sm-3
Level 1: .col-sm-3
class
col-sm-9
class
class
col-8 col-sm-6
Level 2: .col-8 .col-sm-6
class
col-4 col-sm-6
Level 2: .col-4 .col-sm-6
When using Bootstrap’s source Sass files, you have the option of using Sass variables and mixins to create custom, semantic, and responsive page layouts. Our predefined grid classes use these same variables and mixins to provide a whole suite of ready-to-use classes for fast responsive layouts.
Sass variables
Variables and maps determine the number of columns, the gutter width, and the media query point at which to begin floating columns. We use these to generate the predefined grid classes documented above, as well as for the custom mixins listed below.
$grid-columns
$grid-gutter-width
1.5rem
$grid-row-columns
scss/_variables.scss
$grid-breakpoints
576px
768px
992px
1200px
1400px
scss/_variables.scss
$container-max-widths
540px
720px
960px
1140px
1320px
Sass mixins
Mixins are used in conjunction with the grid variables to generate semantic CSS for individual grid columns.
// Creates a wrapper for a series of columns
@include
make-row
// Make the element grid-ready (applying everything but the width)
@include
make-col-ready
// Without optional size values, the mixin will create equal columns (similar to using .col)
@include
make-col
@include
make-col
$size
$columns
$grid-columns
// Offset with margins
@include
make-col-offset
$size
$columns
$grid-columns
Example usage
You can modify the variables to your own custom values, or just use the mixins with their default values. Here’s an example of using the default settings to create a two-column layout with a gap between.
.example-container
@include
make-container
// Make sure to define this width after the mixin to override
// `width: 100%` generated by `make-container()`
width
800px
.example-row
@include
make-row
.example-content-main
@include
make-col-ready
@include
media-breakpoint-up
@include
make-col
@include
media-breakpoint-up
@include
make-col
.example-content-secondary
@include
make-col-ready
@include
media-breakpoint-up
@include
make-col
@include
media-breakpoint-up
@include
make-col
Main content
Secondary content
html
class
example-container
class
example-row
class
example-content-main
Main content
class
example-content-secondary
Secondary content
Customizing the grid
Using our built-in grid Sass variables and maps, it’s possible to completely customize the predefined grid classes. Change the number of tiers, the media query dimensions, and the container widths—then recompile.
Columns and gutters
The number of grid columns can be modified via Sass variables.
$grid-columns
is used to generate the widths (in percent) of each individual column while
$grid-gutter-width
sets the width for the column gutters.
$grid-row-columns
is used to set the maximum number of columns of
.row-cols-*
, any number over this limit is ignored.
$grid-columns
!default
$grid-gutter-width
1.5rem
!default
$grid-row-columns
!default
Grid tiers
Moving beyond the columns themselves, you may also customize the number of grid tiers. If you wanted just four grid tiers, you’d update the
$grid-breakpoints
$container-max-widths
to something like this:
$grid-breakpoints
480px
768px
1024px
$container-max-widths
420px
720px
960px
When making any changes to the Sass variables or maps, you’ll need to save your changes and recompile. Doing so will output a brand-new set of predefined grid classes for column widths, offsets, and ordering. Responsive visibility utilities will also be updated to use the custom breakpoints. Make sure to set grid values in
(not
, or


-------------------- End of Layout (11 pages) --------------------


========================= CONTENT =========================
Section: Content
Files: 5
======================================================================

--- 037_content_images.txt ---
URL: https://getbootstrap.com/docs/5.3/content/images
--------------------------------------------------
Responsive images
Images in Bootstrap are made responsive with
.img-fluid
. This applies
max-width: 100%;
height: auto;
to the image so that it scales with the parent width.
Placeholder
Responsive image
html
class
img-fluid
Image thumbnails
In addition to our
border-radius utilities
, you can use
.img-thumbnail
to give an image a rounded 1px border appearance.
A generic square placeholder image with a white border around it, making it resemble a photograph taken with an old instant camera
200x200
html
class
img-thumbnail
Aligning images
Align images with the
helper float classes
text alignment classes
block
-level images can be centered using
.mx-auto
margin utility class
Placeholder
200x200
Placeholder
200x200
html
class
rounded float-start
class
rounded float-end
Placeholder
200x200
html
class
rounded mx-auto d-block
Placeholder
200x200
html
class
text-center
class
rounded
Picture
If you are using the
<picture>
element to specify multiple
<source>
elements for a specific
<img>
, make sure to add the
.img-*
classes to the
<img>
and not to the
<picture>
tag.
picture
source
srcset
type
image/svg+xml
class
img-fluid img-thumbnail
picture
Sass variables
Variables are available for image thumbnails.
scss/_variables.scss
$thumbnail-padding
.25rem
$thumbnail-bg
#{$prefix}
body-bg
$thumbnail-border-width
#{$prefix}
border-width
$thumbnail-border-color
#{$prefix}
border-color
$thumbnail-border-radius
#{$prefix}
border-radius
$thumbnail-box-shadow
#{$prefix}
box-shadow-sm


--- 108_content_tables.txt ---
URL: https://getbootstrap.com/docs/5.3/content/tables
--------------------------------------------------
Overview
Due to the widespread use of
<table>
elements across third-party widgets like calendars and date pickers, Bootstrap’s tables are
opt-in
. Add the base class
.table
to any
<table>
, then extend with our optional modifier classes or custom styles. All table styles are not inherited in Bootstrap, meaning any nested tables can be styled independent from the parent.
Using the most basic table markup, here’s how
.table
-based tables look in Bootstrap.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table
thead
scope
scope
First
scope
Last
scope
Handle
thead
tbody
scope
Mark
Otto
@mdo
scope
Jacob
Thornton
@fat
scope
John
@social
tbody
table
Variants
Use contextual classes to color tables, table rows or individual cells.
Heads up!
Because of the more complicated CSS used to generate our table variants, they most likely won’t see color mode adaptive styling until v6.
Class
Heading
Heading
Default
Cell
Cell
Primary
Cell
Cell
Secondary
Cell
Cell
Success
Cell
Cell
Danger
Cell
Cell
Warning
Cell
Cell
Info
Cell
Cell
Light
Cell
Cell
Dark
Cell
Cell
<!-- On tables -->
table
class
table-primary
table
table
class
table-secondary
table
table
class
table-success
table
table
class
table-danger
table
table
class
table-warning
table
table
class
table-info
table
table
class
table-light
table
table
class
table-dark
table
<!-- On rows -->
class
table-primary
class
table-secondary
class
table-success
class
table-danger
class
table-warning
class
table-info
class
table-light
class
table-dark
<!-- On cells (`td` or `th`) -->
class
table-primary
class
table-secondary
class
table-success
class
table-danger
class
table-warning
class
table-info
class
table-light
class
table-dark
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Accented tables
Striped rows
.table-striped
to add zebra-striping to any table row within the
<tbody>
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-striped
table
Striped columns
.table-striped-columns
to add zebra-striping to any table column.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-striped-columns
table
These classes can also be added to table variants:
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark table-striped
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark table-striped-columns
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-success table-striped
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-success table-striped-columns
table
Hoverable rows
.table-hover
to enable a hover state on table rows within a
<tbody>
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-hover
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark table-hover
table
These hoverable rows can also be combined with the striped rows variant:
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-striped table-hover
table
Active tables
Highlight a table row or cell by adding a
.table-active
class.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table
thead
thead
tbody
class
table-active
scope
John
class
table-active
@social
tbody
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark
thead
thead
tbody
class
table-active
scope
John
class
table-active
@social
tbody
table
How do the variants and accented tables work?
For the accented tables (
striped rows
striped columns
hoverable rows
, and
active tables
), we used some techniques to make these effects work for all our
table variants
We start by setting the background of a table cell with the
--bs-table-bg
custom property. All table variants then set that custom property to colorize the table cells. This way, we don’t get into trouble if semi-transparent colors are used as table backgrounds.
Then we add an inset box shadow on the table cells with
box-shadow: inset 0 0 0 9999px var(--bs-table-bg-state, var(--bs-table-bg-type, var(--bs-table-accent-bg)));
to layer on top of any specified
background-color
. It uses custom cascade to override the
box-shadow
, regardless the CSS specificity. Because we use a huge spread and no blur, the color will be monotone. Since
--bs-table-accent-bg
is set to
transparent
by default, we don’t have a default box shadow.
When either
.table-striped
.table-striped-columns
.table-hover
.table-active
classes are added, either
--bs-table-bg-type
--bs-table-bg-state
(by default set to
initial
) are set to a semitransparent color (
--bs-table-striped-bg
--bs-table-active-bg
--bs-table-hover-bg
) to colorize the background and override default
--bs-table-accent-bg
For each table variant, we generate a
--bs-table-accent-bg
color with the highest contrast depending on that color. For example, the accent color for
.table-primary
is darker while
.table-dark
has a lighter accent color.
Text and border colors are generated the same way, and their colors are inherited by default.
Behind the scenes it looks like this:
scss/mixins/_table-variants.scss
@mixin
table-variant
$state
$background
.table-
#{$state}
$color
color-contrast
opaque
$body-bg
$background
$hover-bg
$color
$background
percentage
$table-hover-bg-factor
$striped-bg
$color
$background
percentage
$table-striped-bg-factor
$active-bg
$color
$background
percentage
$table-active-bg-factor
$table-border-color
$color
$background
percentage
$table-border-factor
#{$prefix}
table-color
#{$color}
#{$prefix}
table-bg
#{$background}
#{$prefix}
table-border-color
#{$table-border-color}
#{$prefix}
table-striped-bg
#{$striped-bg}
#{$prefix}
table-striped-color
color-contrast
$striped-bg
#{$prefix}
table-active-bg
#{$active-bg}
#{$prefix}
table-active-color
color-contrast
$active-bg
#{$prefix}
table-hover-bg
#{$hover-bg}
#{$prefix}
table-hover-color
color-contrast
$hover-bg
color
#{$prefix}
table-color
border-color
#{$prefix}
table-border-color
Table borders
Bordered tables
.table-bordered
for borders on all sides of the table and cells.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-bordered
table
Border color utilities
can be added to change colors:
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-bordered border-primary
table
Tables without borders
.table-borderless
for a table without borders.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-borderless
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark table-borderless
table
Small tables
.table-sm
to make any
.table
more compact by cutting all cell
padding
in half.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-sm
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-dark table-sm
table
Table group dividers
Add a thicker border, darker between table groups—
<thead>
<tbody>
, and
<tfoot>
—with
.table-group-divider
. Customize the color by changing the
border-top-color
(which we don’t currently provide a utility class for at this time).
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
html
table
class
table
thead
scope
scope
First
scope
Last
scope
Handle
thead
tbody
class
table-group-divider
scope
Mark
Otto
@mdo
scope
Jacob
Thornton
@fat
scope
John
@social
tbody
table
Vertical alignment
Table cells of
<thead>
are always vertical aligned to the bottom. Table cells in
<tbody>
inherit their alignment from
<table>
and are aligned to the top by default. Use the
vertical align
classes to re-align where needed.
Heading 1
Heading 2
Heading 3
Heading 4
This cell inherits
vertical-align: middle;
from the table
This cell inherits
vertical-align: middle;
from the table
This cell inherits
vertical-align: middle;
from the table
This here is some placeholder text, intended to take up quite a bit of vertical space, to demonstrate how the vertical alignment works in the preceding cells.
This cell inherits
vertical-align: bottom;
from the table row
This cell inherits
vertical-align: bottom;
from the table row
This cell inherits
vertical-align: bottom;
from the table row
This here is some placeholder text, intended to take up quite a bit of vertical space, to demonstrate how the vertical alignment works in the preceding cells.
This cell inherits
vertical-align: middle;
from the table
This cell inherits
vertical-align: middle;
from the table
This cell is aligned to the top.
This here is some placeholder text, intended to take up quite a bit of vertical space, to demonstrate how the vertical alignment works in the preceding cells.
class
table-responsive
table
class
table align-middle
thead
thead
tbody
class
align-bottom
class
align-top
This cell is aligned to the top.
tbody
table
Nesting
Border styles, active styles, and table variants are not inherited by nested tables.
First
Last
Handle
Mark
Otto
@mdo
Header
Header
Header
First
Last
First
Last
First
Last
John
@social
table
class
table table-striped table-bordered
thead
thead
tbody
colspan
table
class
table mb-0
table
tbody
table
How nesting works
To prevent
styles from leaking to nested tables, we use the child combinator (
) selector in our CSS. Since we need to target all the
s and
s in the
thead
tbody
, and
tfoot
, our selector would look pretty long without it. As such, we use the rather odd looking
.table > :not(caption) > * > *
selector to target all
s and
s of the
.table
, but none of any potential nested tables.
Note that if you add
<tr>
s as direct children of a table, those
<tr>
will be wrapped in a
<tbody>
by default, thus making our selectors work as intended.
Anatomy
Table head
Similar to tables and dark tables, use the modifier classes
.table-light
.table-dark
to make
<thead>
s appear light or dark gray.
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table
thead
class
table-light
thead
tbody
tbody
table
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table
thead
class
table-dark
thead
tbody
tbody
table
Table foot
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
Footer
Footer
Footer
Footer
table
class
table
thead
thead
tbody
tbody
tfoot
tfoot
table
Captions
<caption>
functions like a heading for a table. It helps users with screen readers to find a table and understand what it’s about and decide if they want to read it.
List of users
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
table
class
table table-sm
caption
List of users
caption
thead
thead
tbody
tbody
table
You can also put the
<caption>
on the top of the table with
.caption-top
List of users
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
html
table
class
table caption-top
caption
List of users
caption
thead
scope
scope
First
scope
Last
scope
Handle
thead
tbody
scope
Mark
Otto
@mdo
scope
Jacob
Thornton
@fat
scope
John
@social
tbody
table
Responsive tables
Responsive tables allow tables to be scrolled horizontally with ease. Make any table responsive across all viewports by wrapping a
.table
with
.table-responsive
. Or, pick a maximum breakpoint with which to have a responsive table up to by using
.table-responsive{-sm|-md|-lg|-xl|-xxl}
Vertical clipping/truncation
Responsive tables make use of
overflow-y: hidden
, which clips off any content that goes beyond the bottom or top edges of the table. In particular, this can clip off dropdown menus and other third-party widgets.
Always responsive
Across every breakpoint, use
.table-responsive
for horizontally scrolling tables.
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
class
table-responsive
table
class
table
table
Breakpoint specific
.table-responsive{-sm|-md|-lg|-xl|-xxl}
as needed to create responsive tables up to a particular breakpoint. From that breakpoint and up, the table will behave normally and not scroll horizontally.
These tables may appear broken until their responsive styles apply at specific viewport widths.
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Heading
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
Cell
class
table-responsive
table
class
table
table
class
table-responsive-sm
table
class
table
table
class
table-responsive-md
table
class
table
table
class
table-responsive-lg
table
class
table
table
class
table-responsive-xl
table
class
table
table
class
table-responsive-xxl
table
class
table
table
Sass variables
scss/_variables.scss
$table-cell-padding-y
.5rem
$table-cell-padding-x
.5rem
$table-cell-padding-y-sm
.25rem
$table-cell-padding-x-sm
.25rem
$table-cell-vertical-align
$table-color
#{$prefix}
emphasis-color
$table-bg
#{$prefix}
body-bg
$table-accent-bg
transparent
$table-th-font-weight
null
$table-striped-color
$table-color
$table-striped-bg-factor
$table-striped-bg
rgba
#{$prefix}
emphasis-color-rgb
$table-striped-bg-factor
$table-active-color
$table-color
$table-active-bg-factor
$table-active-bg
rgba
#{$prefix}
emphasis-color-rgb
$table-active-bg-factor
$table-hover-color
$table-color
$table-hover-bg-factor
.075
$table-hover-bg
rgba
#{$prefix}
emphasis-color-rgb
$table-hover-bg-factor
$table-border-factor
$table-border-width
#{$prefix}
border-width
$table-border-color
#{$prefix}
border-color
$table-striped-order
$table-striped-columns-order
even
$table-group-separator-color
currentcolor
$table-caption-color
#{$prefix}
secondary-color
$table-bg-scale
-80%
Sass loops
scss/_variables.scss
$table-variants
"primary"
shift-color
$primary
$table-bg-scale
"secondary"
shift-color
$secondary
$table-bg-scale
"success"
shift-color
$success
$table-bg-scale
"info"
shift-color
$info
$table-bg-scale
"warning"
shift-color
$warning
$table-bg-scale
"danger"
shift-color
$danger
$table-bg-scale
"light"
$light
"dark"
$dark
Customizing
The factor variables (
$table-striped-bg-factor
$table-active-bg-factor
$table-hover-bg-factor
) are used to determine the contrast in table variants.
Apart from the light & dark table variants, theme colors are lightened by the
$table-bg-scale
variable.


--- 117_content_typography.txt ---
URL: https://getbootstrap.com/docs/5.3/content/typography
--------------------------------------------------
Global settings
textual utility classes
Use a
native font stack
that selects the best
font-family
for each OS and device.
For a more inclusive and accessible type scale, we use the browser’s default root
font-size
(typically 16px) so visitors can customize their browser defaults as needed.
Use the
$font-family-base
$font-size-base
, and
$line-height-base
attributes as our typographic base applied to the
<body>
Set the global link color via
$link-color
$body-bg
to set a
background-color
on the
<body>
#fff
by default).
These styles can be found within
_reboot.scss
, and the global variables are defined in
_variables.scss
. Make sure to set
$font-size-base
Headings
All HTML headings,
<h1>
through
<h6>
, are available.
Heading
Example
<h1></h1>
h1. Bootstrap heading
<h2></h2>
h2. Bootstrap heading
<h3></h3>
h3. Bootstrap heading
<h4></h4>
h4. Bootstrap heading
<h5></h5>
h5. Bootstrap heading
<h6></h6>
h6. Bootstrap heading
h1. Bootstrap heading
h2. Bootstrap heading
h3. Bootstrap heading
h4. Bootstrap heading
h5. Bootstrap heading
h6. Bootstrap heading
through
classes are also available, for when you want to match the font styling of a heading but cannot use the associated HTML element.
h1. Bootstrap heading
h2. Bootstrap heading
h3. Bootstrap heading
h4. Bootstrap heading
h5. Bootstrap heading
h6. Bootstrap heading
html
class
h1. Bootstrap heading
class
h2. Bootstrap heading
class
h3. Bootstrap heading
class
h4. Bootstrap heading
class
h5. Bootstrap heading
class
h6. Bootstrap heading
Customizing headings
Use the included utility classes to recreate the small secondary heading text from Bootstrap 3.
Fancy display heading
With faded secondary text
html
Fancy display heading
small
class
text-body-secondary
With faded secondary text
small
Display headings
Traditional heading elements are designed to work best in the meat of your page content. When you need a heading to stand out, consider using a
display heading
—a larger, slightly more opinionated heading style.
Display 1
Display 2
Display 3
Display 4
Display 5
Display 6
class
display-1
Display 1
class
display-2
Display 2
class
display-3
Display 3
class
display-4
Display 4
class
display-5
Display 5
class
display-6
Display 6
Display headings are configured via the
$display-font-sizes
Sass map and two variables,
$display-font-weight
$display-line-height
Display headings are customizable via two variables,
$display-font-family
$display-font-style
scss/_variables.scss
$display-font-sizes
5rem
4.5rem
4rem
3.5rem
3rem
2.5rem
$display-font-family
null
$display-font-style
null
$display-font-weight
$display-line-height
$headings-line-height
Lead
Make a paragraph stand out by adding
.lead
This is a lead paragraph. It stands out from regular paragraphs.
html
class
lead
This is a lead paragraph. It stands out from regular paragraphs.
Inline text elements
Styling for common inline HTML5 elements.
You can use the mark tag to
highlight
text.
This line of text is meant to be treated as deleted text.
This line of text is meant to be treated as no longer accurate.
This line of text is meant to be treated as an addition to the document.
This line of text will render as underlined.
This line of text is meant to be treated as fine print.
This line rendered as bold text.
This line rendered as italicized text.
html
You can use the mark tag to
mark
highlight
mark
text.
This line of text is meant to be treated as deleted text.
This line of text is meant to be treated as no longer accurate.
This line of text is meant to be treated as an addition to the document.
This line of text will render as underlined.
small
This line of text is meant to be treated as fine print.
small
strong
This line rendered as bold text.
strong
This line rendered as italicized text.
Beware that those tags should be used for semantic purpose:
<mark>
represents text which is marked or highlighted for reference or notation purposes.
<small>
represents side-comments and small print, like copyright and legal text.
represents element that are no longer relevant or no longer accurate.
represents a span of inline text which should be rendered in a way that indicates that it has a non-textual annotation.
If you want to style your text, you should use the following classes instead:
.mark
will apply the same styles as
<mark>
.small
will apply the same styles as
<small>
.text-decoration-underline
will apply the same styles as
.text-decoration-line-through
will apply the same styles as
While not shown above, feel free to use
in HTML5.
is meant to highlight words or phrases without conveying additional importance, while
is mostly for voice, technical terms, etc.
Text utilities
Change text alignment, transform, style, weight, line-height, decoration and color with our
text utilities
color utilities
Abbreviations
Stylized implementation of HTML’s
<abbr>
element for abbreviations and acronyms to show the expanded version on hover. Abbreviations have a default underline and gain a help cursor to provide additional context on hover and to users of assistive technologies.
.initialism
to an abbreviation for a slightly smaller font-size.
attr
HTML
html
abbr
title
attribute
attr
abbr
abbr
title
HyperText Markup Language
class
initialism
HTML
abbr
Blockquotes
For quoting blocks of content from another source within your document. Wrap
<blockquote class="blockquote">
around any HTML as the quote.
A well-known quote, contained in a blockquote element.
html
blockquote
class
blockquote
A well-known quote, contained in a blockquote element.
blockquote
Naming a source
The HTML spec requires that blockquote attribution be placed outside the
<blockquote>
. When providing attribution, wrap your
<blockquote>
in a
<figure>
and use a
<figcaption>
or a block level element (e.g.,
) with the
.blockquote-footer
class. Be sure to wrap the name of the source work in
<cite>
as well.
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
html
figure
blockquote
class
blockquote
A well-known quote, contained in a blockquote element.
blockquote
figcaption
class
blockquote-footer
Someone famous in
cite
title
Source Title
Source Title
cite
figcaption
figure
Alignment
Use text utilities as needed to change the alignment of your blockquote.
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
html
figure
class
text-center
blockquote
class
blockquote
A well-known quote, contained in a blockquote element.
blockquote
figcaption
class
blockquote-footer
Someone famous in
cite
title
Source Title
Source Title
cite
figcaption
figure
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
html
figure
class
text-end
blockquote
class
blockquote
A well-known quote, contained in a blockquote element.
blockquote
figcaption
class
blockquote-footer
Someone famous in
cite
title
Source Title
Source Title
cite
figcaption
figure
Lists
Unstyled
Remove the default
list-style
and left margin on list items (immediate children only).
This only applies to immediate children list items
, meaning you will need to add the class for any nested lists as well.
This is a list.
It appears completely unstyled.
Structurally, it’s still a list.
However, this style only applies to immediate child elements.
Nested lists:
are unaffected by this style
will still show a bullet
and have appropriate left margin
This may still come in handy in some situations.
html
class
list-unstyled
This is a list.
It appears completely unstyled.
Structurally, it’s still a list.
However, this style only applies to immediate child elements.
Nested lists:
are unaffected by this style
will still show a bullet
and have appropriate left margin
This may still come in handy in some situations.
Inline
Remove a list’s bullets and apply some light
margin
with a combination of two classes,
.list-inline
.list-inline-item
This is a list item.
And another one.
But they’re displayed inline.
html
class
list-inline
class
list-inline-item
This is a list item.
class
list-inline-item
And another one.
class
list-inline-item
But they’re displayed inline.
Description list alignment
Align terms and descriptions horizontally by using our grid system’s predefined classes (or semantic mixins). For longer terms, you can optionally add a
.text-truncate
class to truncate the text with an ellipsis.
Description lists
A description list is perfect for defining terms.
Term
Definition for the term.
And some more placeholder definition text.
Another term
This definition is short, so no extra paragraphs or anything.
Truncated term is truncated
This can be useful when space is tight. Adds an ellipsis at the end.
Nesting
Nested definition list
I heard you like definition lists. Let me put a definition list inside your definition list.
html
class
class
col-sm-3
Description lists
class
col-sm-9
A description list is perfect for defining terms.
class
col-sm-3
Term
class
col-sm-9
Definition for the term.
And some more placeholder definition text.
class
col-sm-3
Another term
class
col-sm-9
This definition is short, so no extra paragraphs or anything.
class
col-sm-3 text-truncate
Truncated term is truncated
class
col-sm-9
This can be useful when space is tight. Adds an ellipsis at the end.
class
col-sm-3
Nesting
class
col-sm-9
class
class
col-sm-4
Nested definition list
class
col-sm-8
I heard you like definition lists. Let me put a definition list inside your definition list.
Responsive font sizes
In Bootstrap 5, we’ve enabled responsive font sizes by default, allowing text to scale more naturally across device and viewport sizes. Have a look at the
RFS page
to find out how this works.
Sass variables
Headings have some dedicated variables for sizing and spacing.
scss/_variables.scss
$headings-margin-bottom
$spacer
$headings-font-family
null
$headings-font-style
null
$headings-font-weight
$headings-line-height
$headings-color
inherit
Miscellaneous typography elements covered here and in
Reboot
also have dedicated variables.
scss/_variables.scss
$lead-font-size
$font-size-base
1.25
$lead-font-weight
$small-font-size
.875em
$sub-sup-font-size
.75em
// fusv-disable
$text-muted
#{$prefix}
secondary-color
// Deprecated in 5.3.0
// fusv-enable
$initialism-font-size
$small-font-size
$blockquote-margin-y
$spacer
$blockquote-font-size
$font-size-base
1.25
$blockquote-footer-color
$gray-600
$blockquote-footer-font-size
$small-font-size
$hr-margin-y
$spacer
$hr-color
inherit
// fusv-disable
$hr-bg-color
null
// Deprecated in v5.2.0
$hr-height
null
// Deprecated in v5.2.0
// fusv-enable
$hr-border-color
null
// Allows for inherited colors
$hr-border-width
#{$prefix}
border-width
$hr-opacity
// scss-docs-start vr-variables
$vr-border-width
#{$prefix}
border-width
// scss-docs-end vr-variables
$legend-margin-bottom
.5rem
$legend-font-size
1.5rem
$legend-font-weight
null
$dt-font-weight
$font-weight-bold
$list-inline-padding
.5rem
$mark-padding
.1875em
$mark-color
$body-color
$mark-bg
$yellow-100
Sass mixins
There are no dedicated mixins for typography, but Bootstrap does use
Responsive Font Sizing (RFS)


--- 119_content_reboot.txt ---
URL: https://getbootstrap.com/docs/5.3/content/reboot
--------------------------------------------------
Approach
Reboot builds upon Normalize, providing many HTML elements with somewhat opinionated styles using only element selectors. Additional styling is done only with classes. For example, we reboot some
<table>
styles for a simpler baseline and later provide
.table
.table-bordered
, and more.
Here are our guidelines and reasons for choosing what to override in Reboot:
Update some browser default values to use
s instead of
s for scalable component spacing.
Avoid
margin-top
. Vertical margins can collapse, yielding unexpected results. More importantly though, a single direction of
margin
is a simpler mental model.
For easier scaling across device sizes, block elements should use
s for
margin
Keep declarations of
font
-related properties to a minimum, using
inherit
whenever possible.
CSS variables
Added in v5.2.0
With v5.1.1, we standardized our required
@import
s across all our CSS bundles (including
, and
) to include
_root.scss
. This adds
:root
level CSS variables to all bundles, regardless of how many of them are used in that bundle. Ultimately Bootstrap 5 will continue to see more
CSS variables
added over time, in order to provide more real-time customization without the need to always recompile Sass. Our approach is to take our source Sass variables and transform them into CSS variables. That way, even if you don’t use CSS variables, you still have all the power of Sass.
This is still in-progress and will take time to fully implement.
For example, consider these
:root
CSS variables for common
<body>
styles:
scss/_root.scss
$font-size-root
!= null
#{$prefix}
root-font-size
#{$font-size-root}
#{$prefix}
body-font-family
inspect
$font-family-base
@include
$font-size-base
#{$prefix}
body-font-size
#{$prefix}
body-font-weight
#{$font-weight-base}
#{$prefix}
body-line-height
#{$line-height-base}
$body-text-align
!= null
#{$prefix}
body-text-align
#{$body-text-align}
#{$prefix}
body-color
#{$body-color}
#{$prefix}
body-color-rgb
to-rgb
$body-color
#{$prefix}
body-bg
#{$body-bg}
#{$prefix}
body-bg-rgb
to-rgb
$body-bg
#{$prefix}
emphasis-color
#{$body-emphasis-color}
#{$prefix}
emphasis-color-rgb
to-rgb
$body-emphasis-color
#{$prefix}
secondary-color
#{$body-secondary-color}
#{$prefix}
secondary-color-rgb
to-rgb
$body-secondary-color
#{$prefix}
secondary-bg
#{$body-secondary-bg}
#{$prefix}
secondary-bg-rgb
to-rgb
$body-secondary-bg
#{$prefix}
tertiary-color
#{$body-tertiary-color}
#{$prefix}
tertiary-color-rgb
to-rgb
$body-tertiary-color
#{$prefix}
tertiary-bg
#{$body-tertiary-bg}
#{$prefix}
tertiary-bg-rgb
to-rgb
$body-tertiary-bg
In practice, those variables are then applied in Reboot like so:
scss/_reboot.scss
body
margin
// 1
font-family
#{$prefix}
body-font-family
@include
font-size
#{$prefix}
body-font-size
font-weight
#{$prefix}
body-font-weight
line-height
#{$prefix}
body-line-height
color
#{$prefix}
body-color
text-align
#{$prefix}
body-text-align
background-color
#{$prefix}
body-bg
// 2
-webkit-text-size-adjust
100%
// 3
-webkit-tap-highlight-color
rgba
$black
// 4
Which allows you to make real-time customizations however you like:
body
style
--bs-body-color
#333
<!-- ... -->
body
Page defaults
<html>
<body>
elements are updated to provide better page-wide defaults. More specifically:
box-sizing
is globally set on every element—including
*::before
*::after
, to
border-box
. This ensures that the declared width of element is never exceeded due to padding or border.
No base
font-size
is declared on the
<html>
, but
16px
is assumed (the browser default).
font-size: 1rem
is applied on the
<body>
for easy responsive type-scaling via media queries while respecting user preferences and ensuring a more accessible approach. This browser default can be overridden by modifying the
$font-size-root
variable.
<body>
also sets a global
font-family
font-weight
line-height
, and
color
. This is inherited later by some form elements to prevent font inconsistencies.
For safety, the
<body>
has a declared
background-color
, defaulting to
#fff
Native font stack
native font stacks in this
Smashing Magazine
article
$font-family-sans-serif
// Cross-platform generic font family (default user interface font)
system-ui
// Safari for macOS and iOS (San Francisco)
-apple-system
// Windows
"Segoe UI"
// Android
Roboto
// older macOS and iOS
"Helvetica Neue"
// Linux
"Noto Sans"
"Liberation Sans"
// Basic web fallback
Arial
// Sans serif fallback
sans-serif
// Emoji fonts
"Apple Color Emoji"
"Segoe UI Emoji"
"Segoe UI Symbol"
"Noto Color Emoji"
!default
Note that because the font stack includes emoji fonts, many common symbol/dingbat Unicode characters will be rendered as multicolored pictographs. Their appearance will vary, depending on the style used in the browser/platform’s native emoji font, and they won’t be affected by any CSS
color
styles.
This
font-family
is applied to the
<body>
and automatically inherited globally throughout Bootstrap. To switch the global
font-family
, update
$font-family-base
and recompile Bootstrap.
Headings
All heading elements—
<h1>
<h6>
have their
margin-top
removed,
margin-bottom: .5rem
set, and
line-height
tightened. While headings inherit their
color
by default, you can also override it via optional CSS variable,
--bs-heading-color
Heading
Example
<h1></h1>
h1. Bootstrap heading
<h2></h2>
h2. Bootstrap heading
<h3></h3>
h3. Bootstrap heading
<h4></h4>
h4. Bootstrap heading
<h5></h5>
h5. Bootstrap heading
<h6></h6>
h6. Bootstrap heading
Paragraphs
elements have their
margin-top
removed and
margin-bottom: 1rem
set for easy spacing.
This is an example paragraph.
html
This is an example paragraph.
Links
Links have a default
color
and underline applied. While links change on
:hover
, they don’t change based on whether someone
:visited
the link. They also receive no special
:focus
styles.
This is an example link
html
href
This is an example link
As of v5.3.x, link
color
is set using
rgba()
and new
-rgb
CSS variables, allowing for easy customization of link color opacity. Change the link color opacity with the
--bs-link-opacity
CSS variable:
This is an example link
html
href
style
--bs-link-opacity
This is an example link
Placeholder links—those without an
href
—are targeted with a more specific selector and have their
color
text-decoration
reset to their default values.
This is a placeholder link
html
This is a placeholder link
Horizontal rules
<hr>
element has been simplified. Similar to browser defaults,
<hr>
s are styled via
border-top
, have a default
opacity: .25
, and automatically inherit their
border-color
color
, including when
color
is set via the parent. They can be modified with text, border, and opacity utilities.
html
class
text-success
class
border border-danger border-2 opacity-50
class
border border-primary border-3 opacity-75
Lists
All lists—
<ul>
<ol>
, and
<dl>
—have their
margin-top
removed and a
margin-bottom: 1rem
. Nested lists have no
margin-bottom
. We’ve also reset the
padding-left
<ul>
<ol>
elements.
All lists have their top margin removed
And their bottom margin normalized
Nested lists have no bottom margin
This way they have a more even appearance
Particularly when followed by more list items
The left padding has also been reset
Here’s an ordered list
With a few list items
It has the same overall look
As the previous unordered list
For simpler styling, clear hierarchy, and better spacing, description lists have updated
margin
<dd>
s reset
margin-left
and add
margin-bottom: .5rem
<dt>
s are
bolded
Description lists
A description list is perfect for defining terms.
Term
Definition for the term.
A second definition for the same term.
Another term
Definition for this other term.
Inline code
Wrap inline snippets of code with
<code>
. Be sure to escape HTML angle brackets.
For example,
<section>
should be wrapped as inline.
html
For example,
code
&lt;
section
&gt;
code
should be wrapped as inline.
Code blocks
<pre>
s for multiple lines of code. Once again, be sure to escape any angle brackets in the code for proper rendering. The
<pre>
element is reset to remove its
margin-top
and use
units for its
margin-bottom
<p>Sample text here...</p>
<p>And another line of sample text here...</p>
html
code
&lt;
&gt;
Sample text here...
&lt;
&gt;
&lt;
&gt;
And another line of sample text here...
&lt;
&gt;
code
Variables
For indicating variables use the
<var>
tag.
html
User input
Use the
<kbd>
to indicate input that is typically entered via keyboard.
To switch directories, type
followed by the name of the directory.
To edit settings, press
Ctrl
html
To switch directories, type
followed by the name of the directory.
To edit settings, press
Ctrl
Sample output
For indicating sample output from a program use the
<samp>
tag.
This text is meant to be treated as sample output from a computer program.
html
samp
This text is meant to be treated as sample output from a computer program.
samp
Tables
Tables are slightly adjusted to style
<caption>
s, collapse borders, and ensure consistent
text-align
throughout. Additional changes for borders, padding, and more come with
.table
class
This is an example table, and this is its caption to describe the contents.
Table heading
Table heading
Table heading
Table heading
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
html
table
caption
This is an example table, and this is its caption to describe the contents.
caption
thead
Table heading
Table heading
Table heading
Table heading
thead
tbody
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
Table cell
tbody
table
Forms
Various form elements have been rebooted for simpler base styles. Here are some of the most notable changes:
<fieldset>
s have no borders, padding, or margin so they can be easily used as wrappers for individual inputs or groups of inputs.
<legend>
s, like fieldsets, have also been restyled to be displayed as a heading of sorts.
<label>
s are set to
display: inline-block
to allow
margin
to be applied.
<input>
<select>
<textarea>
s, and
<button>
s are mostly addressed by Normalize, but Reboot removes their
margin
and sets
line-height: inherit
, too.
<textarea>
s are modified to only be resizable vertically as horizontal resizing often “breaks” page layout.
<button>
s and
<input>
button elements have
cursor: pointer
when
:not(:disabled)
These changes, and more, are demonstrated below.
Some date inputs types are
not fully supported
by the latest versions of Safari and Firefox.
Example legend
Example input
Example email
Example telephone
Example url
Example number
Example search
Example range
Example file input
Example select
Choose...
Option 1
Option 2
Option 3
Option 4
Option 5
Option 6
Check this checkbox
Option one is this and that
Option two is something else that’s also super long to demonstrate the wrapping of these fancy form controls.
Option three is disabled
Example textarea
Example date
Example time
Example password
Example datetime-local
Example week
Example month
Example color
Example output
Button submit
Button submit
Pointers on buttons
Reboot includes an enhancement for
role="button"
to change the default cursor to
pointer
. Add this attribute to elements to help indicate elements are interactive. This role isn’t necessary for
<button>
elements, which get their own
cursor
change.
Non-button element button
html
span
role
button
tabindex
Non-button element button
span
Misc elements
Address
<address>
element is updated to reset the browser default
font-style
from
italic
normal
line-height
is also now inherited, and
margin-bottom: 1rem
has been added.
<address>
s are for presenting contact information for the nearest ancestor (or an entire body of work). Preserve formatting by ending lines with
<br>
ACME Corporation
1123 Fictional St,
San Francisco, CA 94103
(123) 456-7890
Full Name
first.last@example.com
Blockquote
The default
margin
on blockquotes is
1em 40px
, so we reset that to
0 0 1rem
for something more consistent with other elements.
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
Inline elements
<abbr>
element receives basic styling to make it stand out amongst paragraph text.
HTML
abbreviation element.
Summary
The default
cursor
on summary is
text
, so we reset that to
pointer
to convey that the element can be interacted with by clicking on it.
Some details
More info about the details.
Even more details
Here are even more details about the details.
HTML5
[hidden]
attribute
HTML5 adds
a new global attribute named
[hidden]
, which is styled as
display: none
by default. Borrowing an idea from
PureCSS
, we improve upon this default by making
[hidden] { display: none !important; }
to help prevent its
display
from getting accidentally overridden.
input
type
text
hidden
Since
[hidden]
is not compatible with jQuery’s
$(...).hide()
$(...).show()
methods, we don’t specifically endorse
[hidden]
over other techniques for managing the
display
of elements.
To merely toggle the visibility of an element, meaning its
display
is not modified and the element can still affect the flow of the document, use
.invisible
class
instead.


--- 150_content_figures.txt ---
URL: https://getbootstrap.com/docs/5.3/content/figures
--------------------------------------------------
Anytime you need to display a piece of content—like an image with an optional caption, consider using a
<figure>
Use the included
.figure
.figure-img
.figure-caption
classes to provide some baseline styles for the HTML5
<figure>
<figcaption>
elements. Images in figures have no explicit size, so be sure to add the
.img-fluid
class to your
<img>
to make it responsive.
Placeholder
400x300
A caption for the above image.
html
figure
class
figure
class
figure-img img-fluid rounded
figcaption
class
figure-caption
A caption for the above image.
figcaption
figure
Aligning the figure’s caption is easy with our
text utilities
Placeholder
400x300
A caption for the above image.
html
figure
class
figure
class
figure-img img-fluid rounded
figcaption
class
figure-caption text-end
A caption for the above image.
figcaption
figure
Sass variables
scss/_variables.scss
$figure-caption-font-size
$small-font-size
$figure-caption-color
#{$prefix}
secondary-color


-------------------- End of Content (5 pages) --------------------


========================= FORMS =========================
Section: Forms
Files: 8
======================================================================

--- 014_forms_input-group.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/input-group
--------------------------------------------------
Basic example
Place one add-on or button on either side of an input. You may also place one on both sides of an input. Remember to place
<label>
s outside the input group.
@example.com
Your vanity URL
https://example.com/users/
Example help text goes outside the input group.
With textarea
html
class
input-group mb-3
span
class
input-group-text
basic-addon1
span
input
type
text
class
form-control
placeholder
Username
aria-label
Username
aria-describedby
basic-addon1
class
input-group mb-3
input
type
text
class
form-control
placeholder
Recipient’s username
aria-label
Recipient’s username
aria-describedby
basic-addon2
span
class
input-group-text
basic-addon2
@example.com
span
class
mb-3
label
basic-url
class
form-label
Your vanity URL
label
class
input-group
span
class
input-group-text
basic-addon3
https://example.com/users/
span
input
type
text
class
form-control
basic-url
aria-describedby
basic-addon3 basic-addon4
class
form-text
basic-addon4
Example help text goes outside the input group.
class
input-group mb-3
span
class
input-group-text
span
input
type
text
class
form-control
aria-label
Amount (to the nearest dollar)
span
class
input-group-text
span
class
input-group mb-3
input
type
text
class
form-control
placeholder
Username
aria-label
Username
span
class
input-group-text
span
input
type
text
class
form-control
placeholder
Server
aria-label
Server
class
input-group
span
class
input-group-text
With textarea
span
textarea
class
form-control
aria-label
With textarea
textarea
Wrapping
Input groups wrap by default via
flex-wrap: wrap
in order to accommodate custom form field validation within an input group. You may disable this with
.flex-nowrap
html
class
input-group flex-nowrap
span
class
input-group-text
addon-wrapping
span
input
type
text
class
form-control
placeholder
Username
aria-label
Username
aria-describedby
addon-wrapping
Border radius
Due to limitations of browser support at the time,
border-radius
styles can only be applied to the first and last children within the
.input-group
class. Any non-visible element in one of those positions will cause the input group to render incorrectly. This will unfortunately not be fixed until v6 most likely.
html
class
input-group
span
class
input-group-text
visible-addon
span
input
type
text
class
form-control
placeholder
Username
aria-label
Username
aria-describedby
visible-addon
input
type
text
class
form-control d-none
placeholder
Hidden input
aria-label
Hidden input
aria-describedby
visible-addon
Sizing
Add the relative form sizing classes to the
.input-group
itself and contents within will automatically resize—no need for repeating the form control size classes on each element.
Sizing on the individual input group elements isn’t supported.
Small
Default
Large
html
class
input-group input-group-sm mb-3
span
class
input-group-text
inputGroup-sizing-sm
Small
span
input
type
text
class
form-control
aria-label
Sizing example input
aria-describedby
inputGroup-sizing-sm
class
input-group mb-3
span
class
input-group-text
inputGroup-sizing-default
Default
span
input
type
text
class
form-control
aria-label
Sizing example input
aria-describedby
inputGroup-sizing-default
class
input-group input-group-lg
span
class
input-group-text
inputGroup-sizing-lg
Large
span
input
type
text
class
form-control
aria-label
Sizing example input
aria-describedby
inputGroup-sizing-lg
Checkboxes and radios
Place any checkbox or radio option within an input group’s addon instead of text. We recommend adding
.mt-0
to the
.form-check-input
when there’s no visible text next to the input.
html
class
input-group mb-3
class
input-group-text
input
class
form-check-input mt-0
type
checkbox
value
aria-label
Checkbox for following text input
input
type
text
class
form-control
aria-label
Text input with checkbox
class
input-group
class
input-group-text
input
class
form-check-input mt-0
type
radio
value
aria-label
Radio button for following text input
input
type
text
class
form-control
aria-label
Text input with radio button
Multiple inputs
While multiple
<input>
s are supported visually, validation styles are only available for input groups with a single
<input>
First and last name
html
class
input-group
span
class
input-group-text
First and last name
span
input
type
text
aria-label
First name
class
form-control
input
type
text
aria-label
Last name
class
form-control
Multiple addons
Multiple add-ons are supported and can be mixed with checkbox and radio input versions.
0.00
0.00
html
class
input-group mb-3
span
class
input-group-text
span
span
class
input-group-text
0.00
span
input
type
text
class
form-control
aria-label
Dollar amount (with dot and two decimal places)
class
input-group
input
type
text
class
form-control
aria-label
Dollar amount (with dot and two decimal places)
span
class
input-group-text
span
span
class
input-group-text
0.00
span
Button addons
Button
Button
Button
Button
Button
Button
html
class
input-group mb-3
button
class
btn btn-outline-secondary
type
button
button-addon1
Button
button
input
type
text
class
form-control
placeholder
aria-label
Example text with button addon
aria-describedby
button-addon1
class
input-group mb-3
input
type
text
class
form-control
placeholder
Recipient’s username
aria-label
Recipient’s username
aria-describedby
button-addon2
button
class
btn btn-outline-secondary
type
button
button-addon2
Button
button
class
input-group mb-3
button
class
btn btn-outline-secondary
type
button
Button
button
button
class
btn btn-outline-secondary
type
button
Button
button
input
type
text
class
form-control
placeholder
aria-label
Example text with two button addons
class
input-group
input
type
text
class
form-control
placeholder
Recipient’s username
aria-label
Recipient’s username with two button addons
button
class
btn btn-outline-secondary
type
button
Button
button
button
class
btn btn-outline-secondary
type
button
Button
button
Buttons with dropdowns
Dropdown
Action
Another action
Something else here
Separated link
Dropdown
Action
Another action
Something else here
Separated link
Dropdown
Action before
Another action before
Something else here
Separated link
Dropdown
Action
Another action
Something else here
Separated link
html
class
input-group mb-3
button
class
btn btn-outline-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
input
type
text
class
form-control
aria-label
Text input with dropdown button
class
input-group mb-3
input
type
text
class
form-control
aria-label
Text input with dropdown button
button
class
btn btn-outline-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu dropdown-menu-end
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
class
input-group
button
class
btn btn-outline-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Action before
class
dropdown-item
href
Another action before
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
input
type
text
class
form-control
aria-label
Text input with 2 dropdown buttons
button
class
btn btn-outline-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu dropdown-menu-end
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Segmented buttons
Action
Toggle Dropdown
Action
Another action
Something else here
Separated link
Action
Toggle Dropdown
Action
Another action
Something else here
Separated link
html
class
input-group mb-3
button
type
button
class
btn btn-outline-secondary
Action
button
button
type
button
class
btn btn-outline-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
input
type
text
class
form-control
aria-label
Text input with segmented dropdown button
class
input-group
input
type
text
class
form-control
aria-label
Text input with segmented dropdown button
button
type
button
class
btn btn-outline-secondary
Action
button
button
type
button
class
btn btn-outline-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu dropdown-menu-end
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Custom forms
Input groups include support for custom selects and custom file inputs. Browser default versions of these are not supported.
Custom select
Options
Choose...
Three
Choose...
Three
Options
Button
Choose...
Three
Choose...
Three
Button
html
class
input-group mb-3
label
class
input-group-text
inputGroupSelect01
Options
label
select
class
form-select
inputGroupSelect01
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
class
input-group mb-3
select
class
form-select
inputGroupSelect02
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
label
class
input-group-text
inputGroupSelect02
Options
label
class
input-group mb-3
button
class
btn btn-outline-secondary
type
button
Button
button
select
class
form-select
inputGroupSelect03
aria-label
Example select with button addon
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
class
input-group
select
class
form-select
inputGroupSelect04
aria-label
Example select with button addon
option
selected
Choose...
option
option
value
option
option
value
option
option
value
Three
option
select
button
class
btn btn-outline-secondary
type
button
Button
button
Custom file input
Upload
Upload
Button
Button
html
class
input-group mb-3
label
class
input-group-text
inputGroupFile01
Upload
label
input
type
file
class
form-control
inputGroupFile01
class
input-group mb-3
input
type
file
class
form-control
inputGroupFile02
label
class
input-group-text
inputGroupFile02
Upload
label
class
input-group mb-3
button
class
btn btn-outline-secondary
type
button
inputGroupFileAddon03
Button
button
input
type
file
class
form-control
inputGroupFile03
aria-describedby
inputGroupFileAddon03
aria-label
Upload
class
input-group
input
type
file
class
form-control
inputGroupFile04
aria-describedby
inputGroupFileAddon04
aria-label
Upload
button
class
btn btn-outline-secondary
type
button
inputGroupFileAddon04
Button
button
Sass variables
scss/_variables.scss
$input-group-addon-padding-y
$input-padding-y
$input-group-addon-padding-x
$input-padding-x
$input-group-addon-font-weight
$input-font-weight
$input-group-addon-color
$input-color
$input-group-addon-bg
#{$prefix}
tertiary-bg
$input-group-addon-border-color
$input-border-color


--- 043_forms_form-control.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/form-control
--------------------------------------------------
Example
Form controls are styled with a mix of Sass and CSS variables, allowing them to adapt to color modes and support any customization method.
Email address
Example textarea
html
class
mb-3
label
exampleFormControlInput1
class
form-label
Email address
label
input
type
email
class
form-control
exampleFormControlInput1
placeholder
name@example.com
class
mb-3
label
exampleFormControlTextarea1
class
form-label
Example textarea
label
textarea
class
form-control
exampleFormControlTextarea1
rows
textarea
Sizing
Set heights using classes like
.form-control-lg
.form-control-sm
html
input
class
form-control form-control-lg
type
text
placeholder
.form-control-lg
aria-label
.form-control-lg example
input
class
form-control
type
text
placeholder
Default input
aria-label
default input example
input
class
form-control form-control-sm
type
text
placeholder
.form-control-sm
aria-label
.form-control-sm example
Form text
Block-level or inline-level form text can be created using
.form-text
Form text should be explicitly associated with the form control it relates to using the
aria-describedby
attribute. This will ensure that assistive technologies—such as screen readers—will announce this form text when the user focuses or enters the control.
Form text below inputs can be styled with
.form-text
. If a block-level element will be used, a top margin is added for easy spacing from the inputs above.
Password
Your password must be 8-20 characters long, contain letters and numbers, and must not contain spaces, special characters, or emoji.
html
label
inputPassword5
class
form-label
Password
label
input
type
password
inputPassword5
class
form-control
aria-describedby
passwordHelpBlock
passwordHelpBlock
class
form-text
Your password must be 8-20 characters long, contain letters and numbers, and must not contain spaces, special characters, or emoji.
Inline text can use any typical inline HTML element (be it a
<span>
<small>
, or something else) with nothing more than the
.form-text
class.
Password
Must be 8-20 characters long.
html
class
row g-3 align-items-center
class
col-auto
label
inputPassword6
class
col-form-label
Password
label
class
col-auto
input
type
password
inputPassword6
class
form-control
aria-describedby
passwordHelpInline
class
col-auto
span
passwordHelpInline
class
form-text
Must be 8-20 characters long.
span
Disabled
Add the
disabled
boolean attribute on an input to give it a grayed out appearance, remove pointer events, and prevent focusing.
html
input
class
form-control
type
text
placeholder
Disabled input
aria-label
Disabled input example
disabled
input
class
form-control
type
text
value
Disabled readonly input
aria-label
Disabled input example
disabled
readonly
Readonly
Add the
readonly
boolean attribute on an input to prevent modification of the input’s value.
readonly
inputs can still be focused and selected, while
disabled
inputs cannot.
html
input
class
form-control
type
text
value
Readonly input here...
aria-label
readonly input example
readonly
Readonly plain text
If you want to have
<input readonly>
elements in your form styled as plain text, replace
.form-control
with
.form-control-plaintext
to remove the default form field styling and preserve the correct
margin
padding
Email
Password
html
class
mb-3 row
label
staticEmail
class
col-sm-2 col-form-label
Email
label
class
col-sm-10
input
type
text
readonly
class
form-control-plaintext
staticEmail
value
email@example.com
class
mb-3 row
label
inputPassword
class
col-sm-2 col-form-label
Password
label
class
col-sm-10
input
type
password
class
form-control
inputPassword
Email
Password
Confirm identity
html
form
class
row g-3
class
col-auto
label
staticEmail2
class
visually-hidden
Email
label
input
type
text
readonly
class
form-control-plaintext
staticEmail2
value
email@example.com
class
col-auto
label
inputPassword2
class
visually-hidden
Password
label
input
type
password
class
form-control
inputPassword2
placeholder
Password
class
col-auto
button
type
submit
class
btn btn-primary mb-3
Confirm identity
button
form
File input
Default file input example
Multiple files input example
Disabled file input example
Small file input example
Large file input example
html
class
mb-3
label
formFile
class
form-label
Default file input example
label
input
class
form-control
type
file
formFile
class
mb-3
label
formFileMultiple
class
form-label
Multiple files input example
label
input
class
form-control
type
file
formFileMultiple
multiple
class
mb-3
label
formFileDisabled
class
form-label
Disabled file input example
label
input
class
form-control
type
file
formFileDisabled
disabled
class
mb-3
label
formFileSm
class
form-label
Small file input example
label
input
class
form-control form-control-sm
formFileSm
type
file
label
formFileLg
class
form-label
Large file input example
label
input
class
form-control form-control-lg
formFileLg
type
file
Color
Set the
type="color"
and add
.form-control-color
to the
<input>
. We use the modifier class to set fixed
height
s and override some inconsistencies between browsers.
Color picker
html
label
exampleColorInput
class
form-label
Color picker
label
input
type
color
class
form-control form-control-color
exampleColorInput
value
#563d7c
title
Choose your color
Datalists
Datalists allow you to create a group of
<option>
s that can be accessed (and autocompleted) from within an
<input>
. These are similar to
<select>
elements, but come with more menu styling limitations and differences. While most browsers and operating systems include some support for
<datalist>
elements, their styling is inconsistent at best.
Learn more about
support for datalist elements
Datalist example
html
label
exampleDataList
class
form-label
Datalist example
label
input
class
form-control
list
datalistOptions
exampleDataList
placeholder
Type to search...
datalist
datalistOptions
option
value
San Francisco
option
value
New York
option
value
Seattle
option
value
Los Angeles
option
value
Chicago
datalist
Sass variables
$input-*
are shared across most of our form controls (and not buttons).
scss/_variables.scss
$input-padding-y
$input-btn-padding-y
$input-padding-x
$input-btn-padding-x
$input-font-family
$input-btn-font-family
$input-font-size
$input-btn-font-size
$input-font-weight
$font-weight-base
$input-line-height
$input-btn-line-height
$input-padding-y-sm
$input-btn-padding-y-sm
$input-padding-x-sm
$input-btn-padding-x-sm
$input-font-size-sm
$input-btn-font-size-sm
$input-padding-y-lg
$input-btn-padding-y-lg
$input-padding-x-lg
$input-btn-padding-x-lg
$input-font-size-lg
$input-btn-font-size-lg
$input-bg
#{$prefix}
body-bg
$input-disabled-color
null
$input-disabled-bg
#{$prefix}
secondary-bg
$input-disabled-border-color
null
$input-color
#{$prefix}
body-color
$input-border-color
#{$prefix}
border-color
$input-border-width
$input-btn-border-width
$input-box-shadow
#{$prefix}
box-shadow-inset
$input-border-radius
#{$prefix}
border-radius
$input-border-radius-sm
#{$prefix}
border-radius-sm
$input-border-radius-lg
#{$prefix}
border-radius-lg
$input-focus-bg
$input-bg
$input-focus-border-color
tint-color
$component-active-bg
$input-focus-color
$input-color
$input-focus-width
$input-btn-focus-width
$input-focus-box-shadow
$input-btn-focus-box-shadow
$input-placeholder-color
#{$prefix}
secondary-color
$input-plaintext-color
#{$prefix}
body-color
$input-height-border
calc
#{$input-border-width}
// stylelint-disable-line function-disallowed-list
$input-height-inner
$input-line-height
$input-padding-y
$input-height-inner-half
$input-line-height
.5em
$input-padding-y
$input-height-inner-quarter
$input-line-height
.25em
$input-padding-y
$input-height
$input-line-height
$input-padding-y
$input-height-border
false
$input-height-sm
$input-line-height
$input-padding-y-sm
$input-height-border
false
$input-height-lg
$input-line-height
$input-padding-y-lg
$input-height-border
false
$input-transition
border-color .15s ease-in-out
box-shadow .15s ease-in-out
$form-color-width
3rem
$form-label-*
$form-text-*
are for our
<label>
s and
.form-text
component.
scss/_variables.scss
$form-label-margin-bottom
.5rem
$form-label-font-size
null
$form-label-font-style
null
$form-label-font-weight
null
$form-label-color
null
scss/_variables.scss
$form-text-margin-top
.25rem
$form-text-font-size
$small-font-size
$form-text-font-style
null
$form-text-font-weight
null
$form-text-color
#{$prefix}
secondary-color
$form-file-*
are for file input.
scss/_variables.scss
$form-file-button-color
$input-color
$form-file-button-bg
#{$prefix}
tertiary-bg
$form-file-button-hover-bg
#{$prefix}
secondary-bg


--- 049_forms_select.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/select
--------------------------------------------------
Default
Custom
<select>
menus need only a custom class,
.form-select
to trigger the custom styles. Custom styles are limited to the
<select>
’s initial appearance and cannot modify the
<option>
s due to browser limitations.
Open this select menu
Three
html
select
class
form-select
aria-label
Default select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
Sizing
You may also choose from small and large custom selects to match our similarly sized text inputs.
Open this select menu
Three
Open this select menu
Three
html
select
class
form-select form-select-lg mb-3
aria-label
Large select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
select
class
form-select form-select-sm
aria-label
Small select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
multiple
attribute is also supported:
Open this select menu
Three
html
select
class
form-select
multiple
aria-label
Multiple select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
As is the
size
attribute:
Open this select menu
Three
html
select
class
form-select
size
aria-label
Size 3 select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
Disabled
Add the
disabled
boolean attribute on a select to give it a grayed out appearance and remove pointer events.
Open this select menu
Three
html
select
class
form-select
aria-label
Disabled select example
disabled
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
Sass variables
scss/_variables.scss
$form-select-padding-y
$input-padding-y
$form-select-padding-x
$input-padding-x
$form-select-font-family
$input-font-family
$form-select-font-size
$input-font-size
$form-select-indicator-padding
$form-select-padding-x
// Extra padding for background-image
$form-select-font-weight
$input-font-weight
$form-select-line-height
$input-line-height
$form-select-color
$input-color
$form-select-bg
$input-bg
$form-select-disabled-color
null
$form-select-disabled-bg
$input-disabled-bg
$form-select-disabled-border-color
$input-disabled-border-color
$form-select-bg-position
right
$form-select-padding-x
center
$form-select-bg-size
16px 12px
// In pixels because image dimensions
$form-select-indicator-color
$gray-800
$form-select-indicator
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'><path fill='none' stroke='#{$form-select-indicator-color}' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='m2 5 6 6 6-6'/></svg>"
$form-select-feedback-icon-padding-end
$form-select-padding-x
$form-select-indicator-padding
$form-select-feedback-icon-position
center right
$form-select-indicator-padding
$form-select-feedback-icon-size
$input-height-inner-half
$input-height-inner-half
$form-select-border-width
$input-border-width
$form-select-border-color
$input-border-color
$form-select-border-radius
$input-border-radius
$form-select-box-shadow
#{$prefix}
box-shadow-inset
$form-select-focus-border-color
$input-focus-border-color
$form-select-focus-width
$input-focus-width
$form-select-focus-box-shadow
0 0 0
$form-select-focus-width
$input-btn-focus-color
$form-select-padding-y-sm
$input-padding-y-sm
$form-select-padding-x-sm
$input-padding-x-sm
$form-select-font-size-sm
$input-font-size-sm
$form-select-border-radius-sm
$input-border-radius-sm
$form-select-padding-y-lg
$input-padding-y-lg
$form-select-padding-x-lg
$input-padding-x-lg
$form-select-font-size-lg
$input-font-size-lg
$form-select-border-radius-lg
$input-border-radius-lg
$form-select-transition
$input-transition


--- 079_forms_validation.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/validation
--------------------------------------------------
We are aware that currently the client-side custom validation styles and tooltips are not accessible, since they are not exposed to assistive technologies. While we work on a solution, we’d recommend either using the server-side option or the default browser validation method.
How it works
Here’s how form validation works with Bootstrap:
HTML form validation is applied via CSS’s two pseudo-classes,
:invalid
:valid
. It applies to
<input>
<select>
, and
<textarea>
elements.
:invalid
:valid
styles to parent
.was-validated
class, usually applied to the
<form>
. Otherwise, any required field without a value shows up as invalid on page load. This way, you may choose when to activate them (typically after form submission is attempted).
To reset the appearance of the form (for instance, in the case of dynamic form submissions using Ajax), remove the
.was-validated
class from the
<form>
again after submission.
As a fallback,
.is-invalid
.is-valid
classes may be used instead of the pseudo-classes for
server-side validation
. They do not require a
.was-validated
parent class.
Due to constraints in how CSS works, we cannot (at present) apply styles to a
<label>
that comes before a form control in the DOM without the help of custom JavaScript.
All modern browsers support the
constraint validation API
, a series of JavaScript methods for validating form controls.
Feedback messages may utilize the
browser defaults
(different for each browser, and unstylable via CSS) or our custom feedback styles with additional HTML and CSS.
You may provide custom validity messages with
setCustomValidity
in JavaScript.
With that in mind, consider the following demos for our custom form validation styles, optional server-side classes, and browser defaults.
Custom styles
For custom Bootstrap form validation messages, you’ll need to add the
novalidate
boolean attribute to your
<form>
. This disables the browser default feedback tooltips, but still provides access to the form validation APIs in JavaScript. Try to submit the form below; our JavaScript will intercept the submit button and relay feedback to you. When attempting to submit, you’ll see the
:invalid
:valid
styles applied to your form controls.
Custom feedback styles apply custom colors, borders, focus styles, and background icons to better communicate feedback. Background icons for
<select>
s are only available with
.form-select
, and not
.form-control
First name
Looks good!
Last name
Looks good!
Username
Please choose a username.
City
Please provide a valid city.
State
Choose...
Please select a valid state.
Please provide a valid zip.
Agree to terms and conditions
You must agree before submitting.
Submit form
html
form
class
row g-3 needs-validation
novalidate
class
col-md-4
label
validationCustom01
class
form-label
First name
label
input
type
text
class
form-control
validationCustom01
value
Mark
required
class
valid-feedback
Looks good!
class
col-md-4
label
validationCustom02
class
form-label
Last name
label
input
type
text
class
form-control
validationCustom02
value
Otto
required
class
valid-feedback
Looks good!
class
col-md-4
label
validationCustomUsername
class
form-label
Username
label
class
input-group has-validation
span
class
input-group-text
inputGroupPrepend
span
input
type
text
class
form-control
validationCustomUsername
aria-describedby
inputGroupPrepend
required
class
invalid-feedback
Please choose a username.
class
col-md-6
label
validationCustom03
class
form-label
City
label
input
type
text
class
form-control
validationCustom03
required
class
invalid-feedback
Please provide a valid city.
class
col-md-3
label
validationCustom04
class
form-label
State
label
select
class
form-select
validationCustom04
required
option
selected
disabled
value
Choose...
option
option
option
select
class
invalid-feedback
Please select a valid state.
class
col-md-3
label
validationCustom05
class
form-label
label
input
type
text
class
form-control
validationCustom05
required
class
invalid-feedback
Please provide a valid zip.
class
col-12
class
form-check
input
class
form-check-input
type
checkbox
value
invalidCheck
required
label
class
form-check-label
invalidCheck
Agree to terms and conditions
label
class
invalid-feedback
You must agree before submitting.
class
col-12
button
class
btn btn-primary
type
submit
Submit form
button
form
// Example starter JavaScript for disabling form submissions if there are invalid fields
'use strict'
// Fetch all the forms we want to apply custom Bootstrap validation styles to
const
forms
document
querySelectorAll
'.needs-validation'
// Loop over them and prevent submission
Array
from
forms
forEach
form
form
addEventListener
'submit'
event
form
checkValidity
event
preventDefault
event
stopPropagation
form
classList
'was-validated'
false
Browser defaults
Not interested in custom validation feedback messages or writing JavaScript to change form behaviors? All good, you can use the browser defaults. Try submitting the form below. Depending on your browser and OS, you’ll see a slightly different style of feedback.
While these feedback styles cannot be styled with CSS, you can still customize the feedback text through JavaScript.
First name
Last name
Username
City
State
Choose...
Agree to terms and conditions
Submit form
html
form
class
row g-3
class
col-md-4
label
validationDefault01
class
form-label
First name
label
input
type
text
class
form-control
validationDefault01
value
Mark
required
class
col-md-4
label
validationDefault02
class
form-label
Last name
label
input
type
text
class
form-control
validationDefault02
value
Otto
required
class
col-md-4
label
validationDefaultUsername
class
form-label
Username
label
class
input-group
span
class
input-group-text
inputGroupPrepend2
span
input
type
text
class
form-control
validationDefaultUsername
aria-describedby
inputGroupPrepend2
required
class
col-md-6
label
validationDefault03
class
form-label
City
label
input
type
text
class
form-control
validationDefault03
required
class
col-md-3
label
validationDefault04
class
form-label
State
label
select
class
form-select
validationDefault04
required
option
selected
disabled
value
Choose...
option
option
option
select
class
col-md-3
label
validationDefault05
class
form-label
label
input
type
text
class
form-control
validationDefault05
required
class
col-12
class
form-check
input
class
form-check-input
type
checkbox
value
invalidCheck2
required
label
class
form-check-label
invalidCheck2
Agree to terms and conditions
label
class
col-12
button
class
btn btn-primary
type
submit
Submit form
button
form
Server-side
We recommend using client-side validation, but in case you require server-side validation, you can indicate invalid and valid form fields with
.is-invalid
.is-valid
. Note that
.invalid-feedback
is also supported with these classes.
For invalid fields, ensure that the invalid feedback/error message is associated with the relevant form field using
aria-describedby
(noting that this attribute allows more than one
to be referenced, in case the field already points to additional form text).
To fix
issues with border radius
, input groups require an additional
.has-validation
class.
First name
Looks good!
Last name
Looks good!
Username
Please choose a username.
City
Please provide a valid city.
State
Choose...
Please select a valid state.
Please provide a valid zip.
Agree to terms and conditions
You must agree before submitting.
Submit form
html
form
class
row g-3
class
col-md-4
label
validationServer01
class
form-label
First name
label
input
type
text
class
form-control is-valid
validationServer01
value
Mark
required
class
valid-feedback
Looks good!
class
col-md-4
label
validationServer02
class
form-label
Last name
label
input
type
text
class
form-control is-valid
validationServer02
value
Otto
required
class
valid-feedback
Looks good!
class
col-md-4
label
validationServerUsername
class
form-label
Username
label
class
input-group has-validation
span
class
input-group-text
inputGroupPrepend3
span
input
type
text
class
form-control is-invalid
validationServerUsername
aria-describedby
inputGroupPrepend3 validationServerUsernameFeedback
required
validationServerUsernameFeedback
class
invalid-feedback
Please choose a username.
class
col-md-6
label
validationServer03
class
form-label
City
label
input
type
text
class
form-control is-invalid
validationServer03
aria-describedby
validationServer03Feedback
required
validationServer03Feedback
class
invalid-feedback
Please provide a valid city.
class
col-md-3
label
validationServer04
class
form-label
State
label
select
class
form-select is-invalid
validationServer04
aria-describedby
validationServer04Feedback
required
option
selected
disabled
value
Choose...
option
option
option
select
validationServer04Feedback
class
invalid-feedback
Please select a valid state.
class
col-md-3
label
validationServer05
class
form-label
label
input
type
text
class
form-control is-invalid
validationServer05
aria-describedby
validationServer05Feedback
required
validationServer05Feedback
class
invalid-feedback
Please provide a valid zip.
class
col-12
class
form-check
input
class
form-check-input is-invalid
type
checkbox
value
invalidCheck3
aria-describedby
invalidCheck3Feedback
required
label
class
form-check-label
invalidCheck3
Agree to terms and conditions
label
invalidCheck3Feedback
class
invalid-feedback
You must agree before submitting.
class
col-12
button
class
btn btn-primary
type
submit
Submit form
button
form
Supported elements
Validation styles are available for the following form controls and components:
<input>
s and
<textarea>
s with
.form-control
(including up to one
.form-control
in input groups)
<select>
s with
.form-select
.form-check
Textarea
Please enter a message in the textarea.
Check this checkbox
Example invalid feedback text
Toggle this radio
Or toggle this other radio
More example invalid feedback text
Open this select menu
Three
Example invalid select feedback
Example invalid form file feedback
Submit form
html
form
class
was-validated
class
mb-3
label
validationTextarea
class
form-label
Textarea
label
textarea
class
form-control
validationTextarea
placeholder
Required example textarea
required
textarea
class
invalid-feedback
Please enter a message in the textarea.
class
form-check mb-3
input
type
checkbox
class
form-check-input
validationFormCheck1
required
label
class
form-check-label
validationFormCheck1
Check this checkbox
label
class
invalid-feedback
Example invalid feedback text
class
form-check
input
type
radio
class
form-check-input
validationFormCheck2
name
radio-stacked
required
label
class
form-check-label
validationFormCheck2
Toggle this radio
label
class
form-check mb-3
input
type
radio
class
form-check-input
validationFormCheck3
name
radio-stacked
required
label
class
form-check-label
validationFormCheck3
Or toggle this other radio
label
class
invalid-feedback
More example invalid feedback text
class
mb-3
select
class
form-select
required
aria-label
select example
option
value
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
class
invalid-feedback
Example invalid select feedback
class
mb-3
input
type
file
class
form-control
aria-label
file example
required
class
invalid-feedback
Example invalid form file feedback
class
mb-3
button
class
btn btn-primary
type
submit
disabled
Submit form
button
form
Tooltips
If your form layout allows it, you can swap the
.{valid|invalid}-feedback
classes for
.{valid|invalid}-tooltip
classes to display validation feedback in a styled tooltip. Be sure to have a parent with
position: relative
on it for tooltip positioning. In the example below, our column classes have this already, but your project may require an alternative setup.
First name
Looks good!
Last name
Looks good!
Username
Please choose a unique and valid username.
City
Please provide a valid city.
State
Choose...
Please select a valid state.
Please provide a valid zip.
Submit form
html
form
class
row g-3 needs-validation
novalidate
class
col-md-4 position-relative
label
validationTooltip01
class
form-label
First name
label
input
type
text
class
form-control
validationTooltip01
value
Mark
required
class
valid-tooltip
Looks good!
class
col-md-4 position-relative
label
validationTooltip02
class
form-label
Last name
label
input
type
text
class
form-control
validationTooltip02
value
Otto
required
class
valid-tooltip
Looks good!
class
col-md-4 position-relative
label
validationTooltipUsername
class
form-label
Username
label
class
input-group has-validation
span
class
input-group-text
validationTooltipUsernamePrepend
span
input
type
text
class
form-control
validationTooltipUsername
aria-describedby
validationTooltipUsernamePrepend
required
class
invalid-tooltip
Please choose a unique and valid username.
class
col-md-6 position-relative
label
validationTooltip03
class
form-label
City
label
input
type
text
class
form-control
validationTooltip03
required
class
invalid-tooltip
Please provide a valid city.
class
col-md-3 position-relative
label
validationTooltip04
class
form-label
State
label
select
class
form-select
validationTooltip04
required
option
selected
disabled
value
Choose...
option
option
option
select
class
invalid-tooltip
Please select a valid state.
class
col-md-3 position-relative
label
validationTooltip05
class
form-label
label
input
type
text
class
form-control
validationTooltip05
required
class
invalid-tooltip
Please provide a valid zip.
class
col-12
button
class
btn btn-primary
type
submit
Submit form
button
form
Variables
Added in v5.3.0
As part of Bootstrap’s evolving CSS variables approach, forms now use local CSS variables for validation for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_root.scss
#{$prefix}
form-valid-color
#{$form-valid-color}
#{$prefix}
form-valid-border-color
#{$form-valid-border-color}
#{$prefix}
form-invalid-color
#{$form-invalid-color}
#{$prefix}
form-invalid-border-color
#{$form-invalid-border-color}
These variables are also color mode adaptive, meaning they change color while in dark mode.
Sass variables
scss/_variables.scss
$form-feedback-margin-top
$form-text-margin-top
$form-feedback-font-size
$form-text-font-size
$form-feedback-font-style
$form-text-font-style
$form-feedback-valid-color
$success
$form-feedback-invalid-color
$danger
$form-feedback-icon-valid-color
$form-feedback-valid-color
$form-feedback-icon-valid
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 8 8'><path fill='#{$form-feedback-icon-valid-color}' d='M2.3 6.73.6 4.53c-.4-1.04.46-1.4 1.1-.8l1.1 1.4 3.4-3.8c.6-.63 1.6-.27 1.2.7l-4 4.6c-.43.5-.8.4-1.1.1'/></svg>"
$form-feedback-icon-invalid-color
$form-feedback-invalid-color
$form-feedback-icon-invalid
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 12' width='12' height='12' fill='none' stroke='#{$form-feedback-icon-invalid-color}'><circle cx='6' cy='6' r='4.5'/><path stroke-linejoin='round' d='M5.8 3.6h.4L6 6.5z'/><circle cx='6' cy='8.2' r='.6' fill='#{$form-feedback-icon-invalid-color}' stroke='none'/></svg>"
scss/_variables.scss
$form-valid-color
$form-feedback-valid-color
$form-valid-border-color
$form-feedback-valid-color
$form-invalid-color
$form-feedback-invalid-color
$form-invalid-border-color
$form-feedback-invalid-color
scss/_variables-dark.scss
$form-valid-color-dark
$green-300
$form-valid-border-color-dark
$green-300
$form-invalid-color-dark
$red-300
$form-invalid-border-color-dark
$red-300
Sass mixins
Two mixins are combined, through our
loop
, to generate our form validation feedback styles.
scss/mixins/_forms.scss
@mixin
form-validation-state-selector
$state
$state
"valid"
$state
"invalid"
.was-validated #
#{$state}
.is-
#{$state}
@content
@else
.is-
#{$state}
@content
@mixin
form-validation-state
$state
$color
$icon
$tooltip-color
color-contrast
$color
$tooltip-bg-color
rgba
$color
$form-feedback-tooltip-opacity
$focus-box-shadow
$input-btn-focus-blur
$input-focus-width
rgba
$color
$input-btn-focus-color-opacity
$border-color
$color
#{$state}
-feedback
display
none
width
100%
margin-top
$form-feedback-margin-top
@include
font-size
$form-feedback-font-size
font-style
$form-feedback-font-style
color
$color
#{$state}
-tooltip
position
absolute
100%
z-index
display
none
max-width
100%
// Contain to parent when possible
padding
$form-feedback-tooltip-padding-y
$form-feedback-tooltip-padding-x
margin-top
.1rem
@include
font-size
$form-feedback-tooltip-font-size
line-height
$form-feedback-tooltip-line-height
color
$tooltip-color
background-color
$tooltip-bg-color
@include
border-radius
$form-feedback-tooltip-border-radius
@include
form-validation-state-selector
$state
#{$state}
-feedback,
#{$state}
-tooltip
display
block
.form-control
@include
form-validation-state-selector
$state
border-color
$border-color
$enable-validation-icons
padding-right
$input-height-inner
background-image
escape-svg
$icon
background-repeat
no-repeat
background-position
right
$input-height-inner-quarter
center
background-size
$input-height-inner-half
$input-height-inner-half
:focus
border-color
$border-color
$enable-shadows
@include
box-shadow
$input-box-shadow
$focus-box-shadow
@else
// Avoid using mixin so we can pass custom focus shadow properly
box-shadow
$focus-box-shadow
// stylelint-disable-next-line selector-no-qualifying-type
textarea.form-control
@include
form-validation-state-selector
$state
$enable-validation-icons
padding-right
$input-height-inner
background-position
$input-height-inner-quarter
right
$input-height-inner-quarter
.form-select
@include
form-validation-state-selector
$state
border-color
$border-color
$enable-validation-icons
[multiple]
[size]
[multiple]
[size="1"]
#{$prefix}
form-select-bg-icon
escape-svg
$icon
padding-right
$form-select-feedback-icon-padding-end
background-position
$form-select-bg-position
$form-select-feedback-icon-position
background-size
$form-select-bg-size
$form-select-feedback-icon-size
:focus
border-color
$border-color
$enable-shadows
@include
box-shadow
$form-select-box-shadow
$focus-box-shadow
@else
// Avoid using mixin so we can pass custom focus shadow properly
box-shadow
$focus-box-shadow
.form-control-color
@include
form-validation-state-selector
$state
$enable-validation-icons
width
$form-color-width
$input-height-inner
.form-check-input
@include
form-validation-state-selector
$state
border-color
$border-color
:checked
background-color
$color
:focus
box-shadow
$focus-box-shadow
~ .form-check-label
color
$color
.form-check-inline .form-check-input
#{$state}
-feedback
margin-left
.5em
.input-group
form-control
focus
form-select
focus
form-floating
focus-within
@include
form-validation-state-selector
$state
$state
== "valid"
z-index
@else if
$state
== "invalid"
z-index
Sass maps
This is the validation Sass map from
_variables.scss
. Override or extend this to generate different or additional states.
scss/_variables.scss
$form-validation-states
"valid"
"color"
#{$prefix}
form-valid-color
"icon"
$form-feedback-icon-valid
"tooltip-color"
#fff
"tooltip-bg-color"
#{$prefix}
success
"focus-box-shadow"
$input-btn-focus-blur
$input-focus-width
rgba
#{$prefix}
success-rgb
$input-btn-focus-color-opacity
"border-color"
#{$prefix}
form-valid-border-color
"invalid"
"color"
#{$prefix}
form-invalid-color
"icon"
$form-feedback-icon-invalid
"tooltip-color"
#fff
"tooltip-bg-color"
#{$prefix}
danger
"focus-box-shadow"
$input-btn-focus-blur
$input-focus-width
rgba
#{$prefix}
danger-rgb
$input-btn-focus-color-opacity
"border-color"
#{$prefix}
form-invalid-border-color
Maps of
$form-validation-states
can contain three optional parameters to override tooltips and focus styles.
Sass loops
Used to iterate over
$form-validation-states
map values to generate our validation styles. Any modifications to the above Sass map will be reflected in your compiled CSS via this loop.
scss/forms/_validation.scss
@each
$state
$data
$form-validation-states
@include
form-validation-state
$state
$data
Customizing
Validation states can be customized via Sass with the
$form-validation-states
map. Located in our
_variables.scss
file, this Sass map is how we generate the default
valid
invalid
validation states. Included is a nested map for customizing each state’s color, icon, tooltip color, and focus shadow. While no other states are supported by browsers, those using custom styles can easily add more complex form feedback.


--- 081_forms_floating-labels.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/floating-labels
--------------------------------------------------
Example
Wrap a pair of
<input class="form-control">
<label>
elements in
.form-floating
to enable floating labels with Bootstrap’s textual form fields.
A non-empty
placeholder
attribute is required on each
<input>
as our CSS-only floating label implementation relies on the
:placeholder-shown
pseudo-element to detect when the input is empty. The placeholder text itself is not visible; only the
<label>
is shown to users.
Also note that the
<input>
must come first so we can utilize a sibling selector (i.e.,
Email address
Password
html
class
form-floating mb-3
input
type
email
class
form-control
floatingInput
placeholder
name@example.com
label
floatingInput
Email address
label
class
form-floating
input
type
password
class
form-control
floatingPassword
placeholder
Password
label
floatingPassword
Password
label
When there’s a
value
already defined,
<label>
s will automatically adjust to their floated position.
Input with value
html
form
class
form-floating
input
type
email
class
form-control
floatingInputValue
placeholder
name@example.com
value
test@example.com
label
floatingInputValue
Input with value
label
form
Form validation styles also work as expected.
Invalid input
html
form
class
form-floating
input
type
email
class
form-control is-invalid
floatingInputInvalid
placeholder
name@example.com
value
test@example.com
label
floatingInputInvalid
Invalid input
label
form
Textareas
By default,
<textarea>
s with
.form-control
will be the same height as
<input>
Comments
html
class
form-floating
textarea
class
form-control
placeholder
Leave a comment here
floatingTextarea
textarea
label
floatingTextarea
Comments
label
To set a custom height on your
<textarea>
, do not use the
rows
attribute. Instead, set an explicit
height
(either inline or via custom CSS).
Comments
html
class
form-floating
textarea
class
form-control
placeholder
Leave a comment here
floatingTextarea2
style
height
100px
textarea
label
floatingTextarea2
Comments
label
Selects
Other than
.form-control
, floating labels are only available on
.form-select
s. They work in the same way, but unlike
<input>
s, they’ll always show the
<label>
in its floated state.
Selects with
size
multiple
are not supported.
Open this select menu
Three
Works with selects
html
class
form-floating
select
class
form-select
floatingSelect
aria-label
Floating label select example
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
label
floatingSelect
Works with selects
label
Disabled
Add the
disabled
boolean attribute on an input, a textarea or a select to give it a grayed out appearance, remove pointer events, and prevent focusing.
Email address
Comments
Disabled textarea with some text inside
Comments
Open this select menu
Three
Works with selects
html
class
form-floating mb-3
input
type
email
class
form-control
floatingInputDisabled
placeholder
name@example.com
disabled
label
floatingInputDisabled
Email address
label
class
form-floating mb-3
textarea
class
form-control
placeholder
Leave a comment here
floatingTextareaDisabled
disabled
textarea
label
floatingTextareaDisabled
Comments
label
class
form-floating mb-3
textarea
class
form-control
placeholder
Leave a comment here
floatingTextarea2Disabled
style
height
100px
disabled
Disabled textarea with some text inside
textarea
label
floatingTextarea2Disabled
Comments
label
class
form-floating
select
class
form-select
floatingSelectDisabled
aria-label
Floating label disabled select example
disabled
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
label
floatingSelectDisabled
Works with selects
label
Readonly plaintext
Floating labels also support
.form-control-plaintext
, which can be helpful for toggling from an editable
<input>
to a plaintext value without affecting the page layout.
Empty input
Input with value
html
class
form-floating mb-3
input
type
email
readonly
class
form-control-plaintext
floatingEmptyPlaintextInput
placeholder
name@example.com
label
floatingEmptyPlaintextInput
Empty input
label
class
form-floating mb-3
input
type
email
readonly
class
form-control-plaintext
floatingPlaintextInput
placeholder
name@example.com
value
name@example.com
label
floatingPlaintextInput
Input with value
label
Input groups
Floating labels also support
.input-group
Username
html
class
input-group mb-3
span
class
input-group-text
span
class
form-floating
input
type
text
class
form-control
floatingInputGroup1
placeholder
Username
label
floatingInputGroup1
Username
label
When using
.input-group
.form-floating
along with form validation, the
-feedback
should be placed outside of the
.form-floating
, but inside of the
.input-group
. This means that the feedback will need to be shown using javascript.
Username
Please choose a username.
html
class
input-group has-validation
span
class
input-group-text
span
class
form-floating is-invalid
input
type
text
class
form-control is-invalid
floatingInputGroup2
placeholder
Username
required
label
floatingInputGroup2
Username
label
class
invalid-feedback
Please choose a username.
Layout
When working with the Bootstrap grid system, be sure to place form elements within column classes.
Email address
Open this select menu
Three
Works with selects
html
class
row g-2
class
col-md
class
form-floating
input
type
email
class
form-control
floatingInputGrid
placeholder
name@example.com
value
mdo@example.com
label
floatingInputGrid
Email address
label
class
col-md
class
form-floating
select
class
form-select
floatingSelectGrid
option
selected
Open this select menu
option
option
value
option
option
value
option
option
value
Three
option
select
label
floatingSelectGrid
Works with selects
label
Sass variables
scss/_variables.scss
$form-floating-height
3.5rem
$input-height-border
$form-floating-line-height
1.25
$form-floating-padding-x
$input-padding-x
$form-floating-padding-y
1rem
$form-floating-input-padding-t
1.625rem
$form-floating-input-padding-b
.625rem
$form-floating-label-height
1.5em
$form-floating-label-opacity
$form-floating-label-transform
scale
translateY
-.5rem
translateX
.15rem
$form-floating-label-disabled-color
$gray-600
$form-floating-transition
opacity .1s ease-in-out
transform .1s ease-in-out


--- 092_forms_range.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/range
--------------------------------------------------
Overview
Create custom
<input type="range">
controls with
.form-range
. The track (the background) and thumb (the value) are both styled to appear the same across browsers. As only Firefox supports “filling” their track from the left or right of the thumb as a means to visually indicate progress, we do not currently support it.
Example range
html
label
customRange1
class
form-label
Example range
label
input
type
range
class
form-range
customRange1
Disabled
Add the
disabled
boolean attribute on an input to give it a grayed out appearance, remove pointer events, and prevent focusing.
Disabled range
html
label
disabledRange
class
form-label
Disabled range
label
input
type
range
class
form-range
disabledRange
disabled
Min and max
Range inputs have implicit values for
, respectively. You may specify new values for those using the
attributes.
Example range
html
label
customRange2
class
form-label
Example range
label
input
type
range
class
form-range
customRange2
Steps
By default, range inputs “snap” to integer values. To change this, you can specify a
step
value. In the example below, we double the number of steps by using
step="0.5"
Example range
html
label
customRange3
class
form-label
Example range
label
input
type
range
class
form-range
step
customRange3
Output value
The value of the range input can be shown using the
output
element and a bit of JavaScript.
Example range
html
label
customRange4
class
form-label
Example range
label
input
type
range
class
form-range
value
customRange4
output
customRange4
rangeValue
aria-hidden
true
output
script
// This is an example script, please modify as needed
const
rangeInput
document
getElementById
'customRange4'
const
rangeOutput
document
getElementById
'rangeValue'
// Set initial value
rangeOutput
textContent
rangeInput
value
rangeInput
addEventListener
'input'
function
rangeOutput
textContent
this
value
script
Sass variables
scss/_variables.scss
$form-range-track-width
100%
$form-range-track-height
.5rem
$form-range-track-cursor
pointer
$form-range-track-bg
#{$prefix}
secondary-bg
$form-range-track-border-radius
1rem
$form-range-track-box-shadow
#{$prefix}
box-shadow-inset
$form-range-thumb-width
1rem
$form-range-thumb-height
$form-range-thumb-width
$form-range-thumb-bg
$component-active-bg
$form-range-thumb-border
$form-range-thumb-border-radius
1rem
$form-range-thumb-box-shadow
0 .1rem .25rem
rgba
$black
$form-range-thumb-focus-box-shadow
0 0 0 1px
$body-bg
$input-focus-box-shadow
$form-range-thumb-focus-box-shadow-width
$input-focus-width
// For focus box shadow issue in Edge
$form-range-thumb-active-bg
tint-color
$component-active-bg
$form-range-thumb-disabled-bg
#{$prefix}
secondary-color
$form-range-thumb-transition
background-color .15s ease-in-out
border-color .15s ease-in-out
box-shadow .15s ease-in-out


--- 109_forms_overview.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/overview
--------------------------------------------------
Form control
Style textual inputs and textareas with support for multiple states.
Select
Improve browser default select elements with a custom initial appearance.
Checks & radios
Use our custom radio buttons and checkboxes in forms for selecting input options.
Range
Replace browser default range inputs with our custom version.
Input group
Attach labels and buttons to your inputs for increased semantic value.
Floating labels
Create beautifully simple form labels that float over your input fields.
Layout
Create inline, horizontal, or complex grid-based layouts with your forms.
Validation
Validate your forms with custom or native validation behaviors and styles.
Overview
our Rebooted form styles
with classes. Use these classes to opt into their customized displays for a more consistent rendering across browsers and devices.
Be sure to use an appropriate
type
attribute on all inputs (e.g.,
email
for email address or
number
for numerical information) to take advantage of newer input controls like email verification, number selection, and more.
Here’s a quick example to demonstrate Bootstrap’s form styles. Keep reading for documentation on required classes, form layout, and more.
Email address
We'll never share your email with anyone else.
Password
Check me out
Submit
html
form
class
mb-3
label
exampleInputEmail1
class
form-label
Email address
label
input
type
email
class
form-control
exampleInputEmail1
aria-describedby
emailHelp
emailHelp
class
form-text
We'll never share your email with anyone else.
class
mb-3
label
exampleInputPassword1
class
form-label
Password
label
input
type
password
class
form-control
exampleInputPassword1
class
mb-3 form-check
input
type
checkbox
class
form-check-input
exampleCheck1
label
class
form-check-label
exampleCheck1
Check me out
label
button
type
submit
class
btn btn-primary
Submit
button
form
Disabled forms
Add the
disabled
boolean attribute on an input to prevent user interactions and make it appear lighter.
input
class
form-control
disabledInput
type
text
placeholder
Disabled input here...
disabled
Add the
disabled
attribute to a
<fieldset>
to disable all the controls within. Browsers treat all native form controls (
<input>
<select>
, and
<button>
elements) inside a
<fieldset disabled>
as disabled, preventing both keyboard and mouse interactions on them.
However, if your form also includes custom button-like elements such as
<a class="btn btn-*">...</a>
, these will only be given a style of
pointer-events: none
, meaning they are still focusable and operable using the keyboard. In this case, you must manually modify these controls by adding
tabindex="-1"
to prevent them from receiving focus and
aria-disabled="disabled"
to signal their state to assistive technologies.
Disabled fieldset example
Disabled input
Disabled select menu
Disabled select
Can’t check this
Submit
html
form
fieldset
disabled
legend
Disabled fieldset example
legend
class
mb-3
label
disabledTextInput
class
form-label
Disabled input
label
input
type
text
disabledTextInput
class
form-control
placeholder
Disabled input
class
mb-3
label
disabledSelect
class
form-label
Disabled select menu
label
select
disabledSelect
class
form-select
option
Disabled select
option
select
class
mb-3
class
form-check
input
class
form-check-input
type
checkbox
disabledFieldsetCheck
disabled
label
class
form-check-label
disabledFieldsetCheck
Can’t check this
label
button
type
submit
class
btn btn-primary
Submit
button
fieldset
form
Accessibility
Ensure that all form controls have an appropriate accessible name so that their purpose can be conveyed to users of assistive technologies. The simplest way to achieve this is to use a
<label>
element, or—in the case of buttons—to include sufficiently descriptive text as part of the
<button>...</button>
content.
For situations where it’s not possible to include a visible
<label>
or appropriate text content, there are alternative ways of still providing an accessible name, such as:
<label>
elements hidden using the
.visually-hidden
class
Pointing to an existing element that can act as a label using
aria-labelledby
Providing a
title
attribute
Explicitly setting the accessible name on an element using
aria-label
If none of these are present, assistive technologies may resort to using the
placeholder
attribute as a fallback for the accessible name on
<input>
<textarea>
elements. The examples in this section provide a few suggested, case-specific approaches.
While using visually hidden content (
.visually-hidden
aria-label
, and even
placeholder
content, which disappears once a form field has content) will benefit assistive technology users, a lack of visible label text may still be problematic for certain users. Some form of visible label is generally the best approach, both for accessibility and usability.
Many form variables are set at a general level to be re-used and extended by individual form components. You’ll see these most often as
$input-btn-*
$input-*
variables.
Sass variables
$input-btn-*
variables are shared global variables between our
buttons
and our form components. You’ll find these frequently reassigned as values to other component-specific variables.
scss/_variables.scss
$input-btn-padding-y
.375rem
$input-btn-padding-x
.75rem
$input-btn-font-family
null
$input-btn-font-size
$font-size-base
$input-btn-line-height
$line-height-base
$input-btn-focus-width
$focus-ring-width
$input-btn-focus-color-opacity
$focus-ring-opacity
$input-btn-focus-color
$focus-ring-color
$input-btn-focus-blur
$focus-ring-blur
$input-btn-focus-box-shadow
$focus-ring-box-shadow
$input-btn-padding-y-sm
.25rem
$input-btn-padding-x-sm
.5rem
$input-btn-font-size-sm
$font-size-sm
$input-btn-padding-y-lg
.5rem
$input-btn-padding-x-lg
1rem
$input-btn-font-size-lg
$font-size-lg
$input-btn-border-width
#{$prefix}
border-width


--- 129_forms_checks-radios.txt ---
URL: https://getbootstrap.com/docs/5.3/forms/checks-radios
--------------------------------------------------
Approach
Browser default checkboxes and radios are replaced with the help of
.form-check
, a series of classes for both input types that improves the layout and behavior of their HTML elements, that provide greater customization and cross browser consistency. Checkboxes are for selecting one or several options in a list, while radios are for selecting one option from many.
Structurally, our
<input>
s and
<label>
s are sibling elements as opposed to an
<input>
within a
<label>
. This is slightly more verbose as you must specify
attributes to relate the
<input>
<label>
. We use the sibling selector (
) for all our
<input>
states, like
:checked
:disabled
. When combined with the
.form-check-label
class, we can easily style the text for each item based on the
<input>
’s state.
Our checks use custom Bootstrap icons to indicate checked or indeterminate states.
Checks
Default checkbox
Checked checkbox
html
class
form-check
input
class
form-check-input
type
checkbox
value
checkDefault
label
class
form-check-label
checkDefault
Default checkbox
label
class
form-check
input
class
form-check-input
type
checkbox
value
checkChecked
checked
label
class
form-check-label
checkChecked
Checked checkbox
label
Indeterminate
Checkboxes can utilize the
:indeterminate
pseudo class when manually set via JavaScript (there is no available HTML attribute for specifying it).
Indeterminate checkbox
html
class
form-check
input
class
form-check-input
type
checkbox
value
checkIndeterminate
label
class
form-check-label
checkIndeterminate
Indeterminate checkbox
label
Disabled
Add the
disabled
attribute and the associated
<label>
s are automatically styled to match with a lighter color to help indicate the input’s state.
Disabled indeterminate checkbox
Disabled checkbox
Disabled checked checkbox
html
class
form-check
input
class
form-check-input
type
checkbox
value
checkIndeterminateDisabled
disabled
label
class
form-check-label
checkIndeterminateDisabled
Disabled indeterminate checkbox
label
class
form-check
input
class
form-check-input
type
checkbox
value
checkDisabled
disabled
label
class
form-check-label
checkDisabled
Disabled checkbox
label
class
form-check
input
class
form-check-input
type
checkbox
value
checkCheckedDisabled
checked
disabled
label
class
form-check-label
checkCheckedDisabled
Disabled checked checkbox
label
Radios
Default radio
Default checked radio
html
class
form-check
input
class
form-check-input
type
radio
name
radioDefault
radioDefault1
label
class
form-check-label
radioDefault1
Default radio
label
class
form-check
input
class
form-check-input
type
radio
name
radioDefault
radioDefault2
checked
label
class
form-check-label
radioDefault2
Default checked radio
label
Disabled
Add the
disabled
attribute and the associated
<label>
s are automatically styled to match with a lighter color to help indicate the input’s state.
Disabled radio
Disabled checked radio
html
class
form-check
input
class
form-check-input
type
radio
name
radioDisabled
radioDisabled
disabled
label
class
form-check-label
radioDisabled
Disabled radio
label
class
form-check
input
class
form-check-input
type
radio
name
radioDisabled
radioCheckedDisabled
checked
disabled
label
class
form-check-label
radioCheckedDisabled
Disabled checked radio
label
Switches
A switch has the markup of a custom checkbox but uses the
.form-switch
class to render a toggle switch. Consider using
role="switch"
to more accurately convey the nature of the control to assistive technologies that support this role. In older assistive technologies, it will simply be announced as a regular checkbox as a fallback. Switches also support the
disabled
attribute.
Default switch checkbox input
Checked switch checkbox input
Disabled switch checkbox input
Disabled checked switch checkbox input
html
class
form-check form-switch
input
class
form-check-input
type
checkbox
role
switch
switchCheckDefault
label
class
form-check-label
switchCheckDefault
Default switch checkbox input
label
class
form-check form-switch
input
class
form-check-input
type
checkbox
role
switch
switchCheckChecked
checked
label
class
form-check-label
switchCheckChecked
Checked switch checkbox input
label
class
form-check form-switch
input
class
form-check-input
type
checkbox
role
switch
switchCheckDisabled
disabled
label
class
form-check-label
switchCheckDisabled
Disabled switch checkbox input
label
class
form-check form-switch
input
class
form-check-input
type
checkbox
role
switch
switchCheckCheckedDisabled
checked
disabled
label
class
form-check-label
switchCheckCheckedDisabled
Disabled checked switch checkbox input
label
Native switches
Progressively enhance your switches for mobile Safari (iOS 17.4+) by adding a
switch
attribute to your input to enable haptic feedback when toggling switches, just like native iOS switches. There are no style changes attached to using this attribute in Bootstrap as all our switches use custom styles.
Native switch haptics
html
class
form-check form-switch
input
class
form-check-input
type
checkbox
value
checkNativeSwitch
switch
label
class
form-check-label
checkNativeSwitch
Native switch haptics
label
Be sure to read more about
the switch attribute on the WebKit blog
. Safari 17.4+ on macOS and iOS both have native-style switches in HTML while other browsers simply fall back to the standard checkbox appearance. Applying the attribute to a non-Bootstrap checkbox in more recent versions of Safari will render a native switch.
Default (stacked)
By default, any number of checkboxes and radios that are immediate sibling will be vertically stacked and appropriately spaced with
.form-check
Default checkbox
Disabled checkbox
html
class
form-check
input
class
form-check-input
type
checkbox
value
defaultCheck1
label
class
form-check-label
defaultCheck1
Default checkbox
label
class
form-check
input
class
form-check-input
type
checkbox
value
defaultCheck2
disabled
label
class
form-check-label
defaultCheck2
Disabled checkbox
label
Default radio
Second default radio
Disabled radio
html
class
form-check
input
class
form-check-input
type
radio
name
exampleRadios
exampleRadios1
value
option1
checked
label
class
form-check-label
exampleRadios1
Default radio
label
class
form-check
input
class
form-check-input
type
radio
name
exampleRadios
exampleRadios2
value
option2
label
class
form-check-label
exampleRadios2
Second default radio
label
class
form-check
input
class
form-check-input
type
radio
name
exampleRadios
exampleRadios3
value
option3
disabled
label
class
form-check-label
exampleRadios3
Disabled radio
label
Inline
Group checkboxes or radios on the same horizontal row by adding
.form-check-inline
to any
.form-check
3 (disabled)
html
class
form-check form-check-inline
input
class
form-check-input
type
checkbox
inlineCheckbox1
value
option1
label
class
form-check-label
inlineCheckbox1
label
class
form-check form-check-inline
input
class
form-check-input
type
checkbox
inlineCheckbox2
value
option2
label
class
form-check-label
inlineCheckbox2
label
class
form-check form-check-inline
input
class
form-check-input
type
checkbox
inlineCheckbox3
value
option3
disabled
label
class
form-check-label
inlineCheckbox3
3 (disabled)
label
3 (disabled)
html
class
form-check form-check-inline
input
class
form-check-input
type
radio
name
inlineRadioOptions
inlineRadio1
value
option1
label
class
form-check-label
inlineRadio1
label
class
form-check form-check-inline
input
class
form-check-input
type
radio
name
inlineRadioOptions
inlineRadio2
value
option2
label
class
form-check-label
inlineRadio2
label
class
form-check form-check-inline
input
class
form-check-input
type
radio
name
inlineRadioOptions
inlineRadio3
value
option3
disabled
label
class
form-check-label
inlineRadio3
3 (disabled)
label
Reverse
Put your checkboxes, radios, and switches on the opposite side with the
.form-check-reverse
modifier class.
Reverse checkbox
Disabled reverse checkbox
Reverse switch checkbox input
html
class
form-check form-check-reverse
input
class
form-check-input
type
checkbox
value
reverseCheck1
label
class
form-check-label
reverseCheck1
Reverse checkbox
label
class
form-check form-check-reverse
input
class
form-check-input
type
checkbox
value
reverseCheck2
disabled
label
class
form-check-label
reverseCheck2
Disabled reverse checkbox
label
class
form-check form-switch form-check-reverse
input
class
form-check-input
type
checkbox
switchCheckReverse
label
class
form-check-label
switchCheckReverse
Reverse switch checkbox input
label
Without labels
Omit the wrapping
.form-check
for checkboxes and radios that have no label text. Remember to still provide some form of accessible name for assistive technologies (for instance, using
aria-label
). See the
forms overview accessibility
section for details.
html
input
class
form-check-input
type
checkbox
checkboxNoLabel
value
aria-label
input
class
form-check-input
type
radio
name
radioNoLabel
radioNoLabel1
value
aria-label
Toggle buttons
Create button-like checkboxes and radio buttons by using
.btn
styles rather than
.form-check-label
on the
<label>
elements. These toggle buttons can further be grouped in a
button group
if needed.
Checkbox toggle buttons
Single toggle
Checked
Disabled
html
input
type
checkbox
class
btn-check
btn-check
autocomplete
label
class
btn btn-primary
btn-check
Single toggle
label
input
type
checkbox
class
btn-check
btn-check-2
checked
autocomplete
label
class
btn btn-primary
btn-check-2
Checked
label
input
type
checkbox
class
btn-check
btn-check-3
autocomplete
disabled
label
class
btn btn-primary
btn-check-3
Disabled
label
Single toggle
Checked
Disabled
html
input
type
checkbox
class
btn-check
btn-check-4
autocomplete
label
class
btn-check-4
Single toggle
label
input
type
checkbox
class
btn-check
btn-check-5
checked
autocomplete
label
class
btn-check-5
Checked
label
input
type
checkbox
class
btn-check
btn-check-6
autocomplete
disabled
label
class
btn-check-6
Disabled
label
Visually, these checkbox toggle buttons are identical to the
button plugin toggle buttons
. However, they are conveyed differently by assistive technologies: the checkbox toggles will be announced by screen readers as “checked“/“not checked“ (since, despite their appearance, they are fundamentally still checkboxes), whereas the button plugin toggle buttons will be announced as “button“/“button pressed“. The choice between these two approaches will depend on the type of toggle you are creating, and whether or not the toggle will make sense to users when announced as a checkbox or as an actual button.
Radio toggle buttons
Checked
Radio
Disabled
Radio
html
input
type
radio
class
btn-check
name
options
option1
autocomplete
checked
label
class
btn btn-secondary
option1
Checked
label
input
type
radio
class
btn-check
name
options
option2
autocomplete
label
class
btn btn-secondary
option2
Radio
label
input
type
radio
class
btn-check
name
options
option3
autocomplete
disabled
label
class
btn btn-secondary
option3
Disabled
label
input
type
radio
class
btn-check
name
options
option4
autocomplete
label
class
btn btn-secondary
option4
Radio
label
Checked
Radio
Disabled
Radio
html
input
type
radio
class
btn-check
name
options-base
option5
autocomplete
checked
label
class
option5
Checked
label
input
type
radio
class
btn-check
name
options-base
option6
autocomplete
label
class
option6
Radio
label
input
type
radio
class
btn-check
name
options-base
option7
autocomplete
disabled
label
class
option7
Disabled
label
input
type
radio
class
btn-check
name
options-base
option8
autocomplete
label
class
option8
Radio
label
Outlined styles
Different variants of
.btn
, such as the various outlined styles, are supported.
Single toggle
Checked
Checked success radio
Danger radio
html
input
type
checkbox
class
btn-check
btn-check-outlined
autocomplete
label
class
btn btn-outline-primary
btn-check-outlined
Single toggle
label
input
type
checkbox
class
btn-check
btn-check-2-outlined
checked
autocomplete
label
class
btn btn-outline-secondary
btn-check-2-outlined
Checked
label
input
type
radio
class
btn-check
name
options-outlined
success-outlined
autocomplete
checked
label
class
btn btn-outline-success
success-outlined
Checked success radio
label
input
type
radio
class
btn-check
name
options-outlined
danger-outlined
autocomplete
label
class
btn btn-outline-danger
danger-outlined
Danger radio
label
Sass variables
Variables for checks:
scss/_variables.scss
$form-check-input-width
$form-check-min-height
$font-size-base
$line-height-base
$form-check-padding-start
$form-check-input-width
.5em
$form-check-margin-bottom
.125rem
$form-check-label-color
null
$form-check-label-cursor
null
$form-check-transition
null
$form-check-input-active-filter
brightness
$form-check-input-bg
$input-bg
$form-check-input-border
#{$prefix}
border-width
solid
#{$prefix}
border-color
$form-check-input-border-radius
.25em
$form-check-radio-border-radius
$form-check-input-focus-border
$input-focus-border-color
$form-check-input-focus-box-shadow
$focus-ring-box-shadow
$form-check-input-checked-color
$component-active-color
$form-check-input-checked-bg-color
$component-active-bg
$form-check-input-checked-border-color
$form-check-input-checked-bg-color
$form-check-input-checked-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 20 20'><path fill='none' stroke='#{$form-check-input-checked-color}' stroke-linecap='round' stroke-linejoin='round' stroke-width='3' d='m6 10 3 3 6-6'/></svg>"
$form-check-radio-checked-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'><circle r='2' fill='#{$form-check-input-checked-color}'/></svg>"
$form-check-input-indeterminate-color
$component-active-color
$form-check-input-indeterminate-bg-color
$component-active-bg
$form-check-input-indeterminate-border-color
$form-check-input-indeterminate-bg-color
$form-check-input-indeterminate-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 20 20'><path fill='none' stroke='#{$form-check-input-indeterminate-color}' stroke-linecap='round' stroke-linejoin='round' stroke-width='3' d='M6 10h8'/></svg>"
$form-check-input-disabled-opacity
$form-check-label-disabled-opacity
$form-check-input-disabled-opacity
$form-check-btn-check-disabled-opacity
$btn-disabled-opacity
$form-check-inline-margin-end
1rem
Variables for switches:
scss/_variables.scss
$form-switch-color
rgba
$black
$form-switch-width
$form-switch-padding-start
$form-switch-width
.5em
$form-switch-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'><circle r='3' fill='#{$form-switch-color}'/></svg>"
$form-switch-border-radius
$form-switch-width
$form-switch-transition
background-position .15s ease-in-out
$form-switch-focus-color
$input-focus-border-color
$form-switch-focus-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'><circle r='3' fill='#{$form-switch-focus-color}'/></svg>"
$form-switch-checked-color
$component-active-color
$form-switch-checked-bg-image
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'><circle r='3' fill='#{$form-switch-checked-color}'/></svg>"
$form-switch-checked-bg-position
right center


-------------------- End of Forms (8 pages) --------------------


========================= COMPONENTS =========================
Section: Components
Files: 38
======================================================================

--- 001_examples_carousel.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/carousel
--------------------------------------------------
Example headline.
Some representative placeholder content for the first slide of the carousel.
Sign up today
Another example headline.
Some representative placeholder content for the second slide of the carousel.
Learn more
One more for good measure.
Some representative placeholder content for the third slide of this carousel.
Browse gallery
Previous
Next
Placeholder
Heading
Some representative placeholder content for the three columns of text below the carousel. This is the first column.
View details »
Placeholder
Heading
Another exciting bit of representative placeholder content. This time, we've moved on to the second column.
View details »
Placeholder
Heading
And lastly this, the third column of representative placeholder content.
View details »
First featurette heading.
It’ll blow your mind.
Some great placeholder content for the first featurette here. Imagine some exciting prose here.
Placeholder
500x500
Oh yeah, it’s that good.
See for yourself.
Another featurette? Of course. More placeholder content here to give you an idea of how this layout would work with some actual real-world content in place.
Placeholder
500x500
And lastly, this one.
Checkmate.
And yes, this is the last block of representative placeholder content. Again, not really intended to be actually read, simply here to give you a better view of what this would look like with some actual content. Your content.
Placeholder
500x500


--- 004_components_buttons.txt ---
URL: https://getbootstrap.com/docs/5.3/components/buttons
--------------------------------------------------
Base class
.btn
class that sets up basic styles such as padding and content alignment. By default,
.btn
controls have a transparent border and background color, and lack any explicit focus and hover styles.
Base class
html
button
type
button
class
Base class
button
.btn
class is intended to be used in conjunction with our button variants, or to serve as a basis for your own custom styles.
If you are using the
.btn
class on its own, remember to at least define some explicit
:focus
and/or
:focus-visible
styles.
Variants
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Link
html
button
type
button
class
btn btn-primary
Primary
button
button
type
button
class
btn btn-secondary
Secondary
button
button
type
button
class
btn btn-success
Success
button
button
type
button
class
btn btn-danger
Danger
button
button
type
button
class
btn btn-warning
Warning
button
button
type
button
class
btn btn-info
Info
button
button
type
button
class
btn btn-light
Light
button
button
type
button
class
btn btn-dark
Dark
button
button
type
button
class
btn btn-link
Link
button
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Disable text wrapping
If you don’t want the button text to wrap, you can add the
.text-nowrap
class to the button. In Sass, you can set
$btn-white-space: nowrap
to disable text wrapping for each button.
Button tags
.btn
classes are designed to be used with the
<button>
element. However, you can also use these classes on
<input>
elements (though some browsers may apply a slightly different rendering).
When using button classes on
elements that are used to trigger in-page functionality (like collapsing content), rather than linking to new pages or sections within the current page, these links should be given a
role="button"
to appropriately convey their purpose to assistive technologies such as screen readers.
Link
Button
html
class
btn btn-primary
href
role
button
Link
button
class
btn btn-primary
type
submit
Button
button
input
class
btn btn-primary
type
button
value
Input
input
class
btn btn-primary
type
submit
value
Submit
input
class
btn btn-primary
type
reset
value
Reset
Outline buttons
In need of a button, but not the hefty background colors they bring? Replace the default modifier classes with the
.btn-outline-*
ones to remove all background images and colors on any button.
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
html
button
type
button
class
btn btn-outline-primary
Primary
button
button
type
button
class
btn btn-outline-secondary
Secondary
button
button
type
button
class
btn btn-outline-success
Success
button
button
type
button
class
btn btn-outline-danger
Danger
button
button
type
button
class
btn btn-outline-warning
Warning
button
button
type
button
class
btn btn-outline-info
Info
button
button
type
button
class
btn btn-outline-light
Light
button
button
type
button
class
btn btn-outline-dark
Dark
button
Some of the button styles use a relatively light foreground color, and should only be used on a dark background in order to have sufficient contrast.
Sizes
Fancy larger or smaller buttons? Add
.btn-lg
.btn-sm
for additional sizes.
Large button
Large button
html
button
type
button
class
btn btn-primary btn-lg
Large button
button
button
type
button
class
btn btn-secondary btn-lg
Large button
button
Small button
Small button
html
button
type
button
class
btn btn-primary btn-sm
Small button
button
button
type
button
class
btn btn-secondary btn-sm
Small button
button
You can even roll your own custom sizing with CSS variables:
Custom button
html
button
type
button
class
btn btn-primary
style
--bs-btn-padding-y
.25rem
--bs-btn-padding-x
.5rem
--bs-btn-font-size
.75rem
Custom button
button
Disabled state
Make buttons look inactive by adding the
disabled
boolean attribute to any
<button>
element. Disabled buttons have
pointer-events: none
applied to, preventing hover and active states from triggering.
Primary button
Button
Primary button
Button
html
button
type
button
class
btn btn-primary
disabled
Primary button
button
button
type
button
class
btn btn-secondary
disabled
Button
button
button
type
button
class
btn btn-outline-primary
disabled
Primary button
button
button
type
button
class
btn btn-outline-secondary
disabled
Button
button
Disabled buttons using the
element behave a bit different:
s don’t support the
disabled
attribute, so you must add the
.disabled
class to make it visually appear disabled.
Some future-friendly styles are included to disable all
pointer-events
on anchor buttons.
Disabled buttons using
should include the
aria-disabled="true"
attribute to indicate the state of the element to assistive technologies.
Disabled buttons using
should not
include the
href
attribute.
Primary link
Link
html
class
btn btn-primary disabled
role
button
aria-disabled
true
Primary link
class
btn btn-secondary disabled
role
button
aria-disabled
true
Link
Link functionality caveat
To cover cases where you have to keep the
href
attribute on a disabled link, the
.disabled
class uses
pointer-events: none
to try to disable the link functionality of
s. Note that this CSS property is not yet standardized for HTML, but all modern browsers support it. In addition, even in browsers that do support
pointer-events: none
, keyboard navigation remains unaffected, meaning that sighted keyboard users and users of assistive technologies will still be able to activate these links. So to be safe, in addition to
aria-disabled="true"
, also include a
tabindex="-1"
attribute on these links to prevent them from receiving keyboard focus, and use custom JavaScript to disable their functionality altogether.
Primary link
Link
html
href
class
btn btn-primary disabled
tabindex
role
button
aria-disabled
true
Primary link
href
class
btn btn-secondary disabled
tabindex
role
button
aria-disabled
true
Link
Block buttons
Create responsive stacks of full-width, “block buttons” like those in Bootstrap 4 with a mix of our display and gap utilities. By using utilities instead of button-specific classes, we have much greater control over spacing, alignment, and responsive behaviors.
Button
Button
html
class
d-grid gap-2
button
class
btn btn-primary
type
button
Button
button
button
class
btn btn-primary
type
button
Button
button
Here we create a responsive variation, starting with vertically stacked buttons until the
breakpoint, where
.d-md-block
replaces the
.d-grid
class, thus nullifying the
gap-2
utility. Resize your browser to see them change.
Button
Button
html
class
d-grid gap-2 d-md-block
button
class
btn btn-primary
type
button
Button
button
button
class
btn btn-primary
type
button
Button
button
You can adjust the width of your block buttons with grid column width classes. For example, for a half-width “block button”, use
.col-6
. Center it horizontally with
.mx-auto
, too.
Button
Button
html
class
d-grid gap-2 col-6 mx-auto
button
class
btn btn-primary
type
button
Button
button
button
class
btn btn-primary
type
button
Button
button
Additional utilities can be used to adjust the alignment of buttons when horizontal. Here we’ve taken our previous responsive example and added some flex utilities and a margin utility on the button to right-align the buttons when they’re no longer stacked.
Button
Button
html
class
d-grid gap-2 d-md-flex justify-content-md-end
button
class
btn btn-primary me-md-2
type
button
Button
button
button
class
btn btn-primary
type
button
Button
button
Button plugin
The button plugin allows you to create simple on/off toggle buttons.
Visually, these toggle buttons are identical to the
checkbox toggle buttons
. However, they are conveyed differently by assistive technologies: the checkbox toggles will be announced by screen readers as “checked”/“not checked” (since, despite their appearance, they are fundamentally still checkboxes), whereas these toggle buttons will be announced as “button”/“button pressed”. The choice between these two approaches will depend on the type of toggle you are creating, and whether or not the toggle will make sense to users when announced as a checkbox or as an actual button.
Toggle states
data-bs-toggle="button"
to toggle a button’s
active
state. If you’re pre-toggling a button, you must manually add the
.active
class
aria-pressed="true"
to ensure that it is conveyed appropriately to assistive technologies.
Toggle button
Active toggle button
Disabled toggle button
Toggle button
Active toggle button
Disabled toggle button
html
class
d-inline-flex gap-1
button
type
button
class
data-bs-toggle
button
Toggle button
button
button
type
button
class
btn active
data-bs-toggle
button
aria-pressed
true
Active toggle button
button
button
type
button
class
disabled
data-bs-toggle
button
Disabled toggle button
button
class
d-inline-flex gap-1
button
type
button
class
btn btn-primary
data-bs-toggle
button
Toggle button
button
button
type
button
class
btn btn-primary active
data-bs-toggle
button
aria-pressed
true
Active toggle button
button
button
type
button
class
btn btn-primary
disabled
data-bs-toggle
button
Disabled toggle button
button
Toggle link
Active toggle link
Disabled toggle link
Toggle link
Active toggle link
Disabled toggle link
html
class
d-inline-flex gap-1
href
class
role
button
data-bs-toggle
button
Toggle link
href
class
btn active
role
button
data-bs-toggle
button
aria-pressed
true
Active toggle link
class
btn disabled
aria-disabled
true
role
button
data-bs-toggle
button
Disabled toggle link
class
d-inline-flex gap-1
href
class
btn btn-primary
role
button
data-bs-toggle
button
Toggle link
href
class
btn btn-primary active
role
button
data-bs-toggle
button
aria-pressed
true
Active toggle link
class
btn btn-primary disabled
aria-disabled
true
role
button
data-bs-toggle
button
Disabled toggle link
Methods
You can create a button instance with the button constructor, for example:
const
bsButton
Button
'#myButton'
Method
Description
dispose
Destroys an element’s button. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the button instance associated with a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a button instance associated with a DOM element or creates a new one in case it wasn’t initialized. You can use it like this:
toggle
Toggles push state. Gives the button the appearance that it has been activated.
For example, to toggle all buttons
document
querySelectorAll
'.btn'
forEach
buttonElement
const
button
Button
getOrCreateInstance
buttonElement
button
toggle
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, buttons now use local CSS variables on
.btn
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_buttons.scss
#{$prefix}
btn-padding-x
#{$btn-padding-x}
#{$prefix}
btn-padding-y
#{$btn-padding-y}
#{$prefix}
btn-font-family
#{$btn-font-family}
@include
$btn-font-size
#{$prefix}
btn-font-size
#{$prefix}
btn-font-weight
#{$btn-font-weight}
#{$prefix}
btn-line-height
#{$btn-line-height}
#{$prefix}
btn-color
#{$btn-color}
#{$prefix}
btn-bg
transparent
#{$prefix}
btn-border-width
#{$btn-border-width}
#{$prefix}
btn-border-color
transparent
#{$prefix}
btn-border-radius
#{$btn-border-radius}
#{$prefix}
btn-hover-border-color
transparent
#{$prefix}
btn-box-shadow
#{$btn-box-shadow}
#{$prefix}
btn-disabled-opacity
#{$btn-disabled-opacity}
#{$prefix}
btn-focus-box-shadow
0 0 0
#{$btn-focus-width}
rgba
#{$prefix}
btn-focus-shadow-rgb
Each
.btn-*
modifier class updates the appropriate CSS variables to minimize additional CSS rules with our
button-variant()
button-outline-variant()
, and
button-size()
mixins.
Here’s an example of building a custom
.btn-*
modifier class as we do for the buttons unique to our docs by reassigning Bootstrap’s CSS variables with a mixture of our own CSS and Sass variables.
Custom button
site/src/scss/_buttons.scss
.btn-bd-primary
--bs-btn-font-weight
--bs-btn-color
--bs-white
--bs-btn-bg
--bd-violet-bg
--bs-btn-border-color
--bd-violet-bg
--bs-btn-hover-color
--bs-white
--bs-btn-hover-bg
shade-color
$bd-violet
--bs-btn-hover-border-color
shade-color
$bd-violet
--bs-btn-focus-shadow-rgb
--bd-violet-rgb
--bs-btn-active-color
--bs-btn-hover-color
--bs-btn-active-bg
shade-color
$bd-violet
--bs-btn-active-border-color
shade-color
$bd-violet
Sass variables
scss/_variables.scss
$btn-color
#{$prefix}
body-color
$btn-padding-y
$input-btn-padding-y
$btn-padding-x
$input-btn-padding-x
$btn-font-family
$input-btn-font-family
$btn-font-size
$input-btn-font-size
$btn-line-height
$input-btn-line-height
$btn-white-space
null
// Set to `nowrap` to prevent text wrapping
$btn-padding-y-sm
$input-btn-padding-y-sm
$btn-padding-x-sm
$input-btn-padding-x-sm
$btn-font-size-sm
$input-btn-font-size-sm
$btn-padding-y-lg
$input-btn-padding-y-lg
$btn-padding-x-lg
$input-btn-padding-x-lg
$btn-font-size-lg
$input-btn-font-size-lg
$btn-border-width
$input-btn-border-width
$btn-font-weight
$font-weight-normal
$btn-box-shadow
inset 0 1px 0
rgba
$white
0 1px 1px
rgba
$black
.075
$btn-focus-width
$input-btn-focus-width
$btn-focus-box-shadow
$input-btn-focus-box-shadow
$btn-disabled-opacity
$btn-active-box-shadow
inset 0 3px 5px
rgba
$black
.125
$btn-link-color
#{$prefix}
link-color
$btn-link-hover-color
#{$prefix}
link-hover-color
$btn-link-disabled-color
$gray-600
$btn-link-focus-shadow-rgb
to-rgb
color-contrast
$link-color
$link-color
// Allows for customizing button radius independently from global border radius
$btn-border-radius
#{$prefix}
border-radius
$btn-border-radius-sm
#{$prefix}
border-radius-sm
$btn-border-radius-lg
#{$prefix}
border-radius-lg
$btn-transition
color .15s ease-in-out
background-color .15s ease-in-out
border-color .15s ease-in-out
box-shadow .15s ease-in-out
$btn-hover-bg-shade-amount
$btn-hover-bg-tint-amount
$btn-hover-border-shade-amount
$btn-hover-border-tint-amount
$btn-active-bg-shade-amount
$btn-active-bg-tint-amount
$btn-active-border-shade-amount
$btn-active-border-tint-amount
Sass mixins
There are three mixins for buttons: button and button outline variant mixins (both based on
$theme-colors
), plus a button size mixin.
scss/mixins/_buttons.scss
@mixin
button-variant
$background
$border
$color
color-contrast
$background
$hover-background
$color
$color-contrast-light
shade-color
$background
$btn-hover-bg-shade-amount
tint-color
$background
$btn-hover-bg-tint-amount
$hover-border
$color
$color-contrast-light
shade-color
$border
$btn-hover-border-shade-amount
tint-color
$border
$btn-hover-border-tint-amount
$hover-color
color-contrast
$hover-background
$active-background
$color
$color-contrast-light
shade-color
$background
$btn-active-bg-shade-amount
tint-color
$background
$btn-active-bg-tint-amount
$active-border
$color
$color-contrast-light
shade-color
$border
$btn-active-border-shade-amount
tint-color
$border
$btn-active-border-tint-amount
$active-color
color-contrast
$active-background
$disabled-background
$background
$disabled-border
$border
$disabled-color
color-contrast
$disabled-background
#{$prefix}
btn-color
#{$color}
#{$prefix}
btn-bg
#{$background}
#{$prefix}
btn-border-color
#{$border}
#{$prefix}
btn-hover-color
#{$hover-color}
#{$prefix}
btn-hover-bg
#{$hover-background}
#{$prefix}
btn-hover-border-color
#{$hover-border}
#{$prefix}
btn-focus-shadow-rgb
to-rgb
$color
$border
#{$prefix}
btn-active-color
#{$active-color}
#{$prefix}
btn-active-bg
#{$active-background}
#{$prefix}
btn-active-border-color
#{$active-border}
#{$prefix}
btn-active-shadow
#{$btn-active-box-shadow}
#{$prefix}
btn-disabled-color
#{$disabled-color}
#{$prefix}
btn-disabled-bg
#{$disabled-background}
#{$prefix}
btn-disabled-border-color
#{$disabled-border}
scss/mixins/_buttons.scss
@mixin
button-outline-variant
$color
$color-hover
color-contrast
$color
$active-background
$color
$active-border
$color
$active-color
color-contrast
$active-background
#{$prefix}
btn-color
#{$color}
#{$prefix}
btn-border-color
#{$color}
#{$prefix}
btn-hover-color
#{$color-hover}
#{$prefix}
btn-hover-bg
#{$active-background}
#{$prefix}
btn-hover-border-color
#{$active-border}
#{$prefix}
btn-focus-shadow-rgb
to-rgb
$color
#{$prefix}
btn-active-color
#{$active-color}
#{$prefix}
btn-active-bg
#{$active-background}
#{$prefix}
btn-active-border-color
#{$active-border}
#{$prefix}
btn-active-shadow
#{$btn-active-box-shadow}
#{$prefix}
btn-disabled-color
#{$color}
#{$prefix}
btn-disabled-bg
transparent
#{$prefix}
btn-disabled-border-color
#{$color}
#{$prefix}
gradient
none
scss/mixins/_buttons.scss
@mixin
button-size
$padding-y
$padding-x
$font-size
$border-radius
#{$prefix}
btn-padding-y
#{$padding-y}
#{$prefix}
btn-padding-x
#{$padding-x}
@include
$font-size
#{$prefix}
btn-font-size
#{$prefix}
btn-border-radius
#{$border-radius}
Sass loops
Button variants (for regular and outline buttons) use their respective mixins with our
$theme-colors
map to generate the modifier classes in
scss/_buttons.scss
scss/_buttons.scss
@each
$color
$value
$theme-colors
.btn-
#{$color}
$color
== "light"
@include
button-variant
$value
$value
$hover-background
shade-color
$value
$btn-hover-bg-shade-amount
$hover-border
shade-color
$value
$btn-hover-border-shade-amount
$active-background
shade-color
$value
$btn-active-bg-shade-amount
$active-border
shade-color
$value
$btn-active-border-shade-amount
@else if
$color
== "dark"
@include
button-variant
$value
$value
$hover-background
tint-color
$value
$btn-hover-bg-tint-amount
$hover-border
tint-color
$value
$btn-hover-border-tint-amount
$active-background
tint-color
$value
$btn-active-bg-tint-amount
$active-border
tint-color
$value
$btn-active-border-tint-amount
@else
@include
button-variant
$value
$value
@each
$color
$value
$theme-colors
.btn-outline-
#{$color}
@include
button-outline-variant
$value


--- 007_components_alerts.txt ---
URL: https://getbootstrap.com/docs/5.3/components/alerts
--------------------------------------------------
Examples
Alerts are available for any length of text, as well as an optional close button. For proper styling, use one of the eight
required
contextual classes (e.g.,
.alert-success
). For inline dismissal, use the
alerts JavaScript plugin
Heads up!
As of v5.3.0, the
alert-variant()
Sass mixin is deprecated. Alert variants now have their CSS variables overridden in
a Sass loop
A simple primary alert—check it out!
A simple secondary alert—check it out!
A simple success alert—check it out!
A simple danger alert—check it out!
A simple warning alert—check it out!
A simple info alert—check it out!
A simple light alert—check it out!
A simple dark alert—check it out!
html
class
alert alert-primary
role
alert
A simple primary alert—check it out!
class
alert alert-secondary
role
alert
A simple secondary alert—check it out!
class
alert alert-success
role
alert
A simple success alert—check it out!
class
alert alert-danger
role
alert
A simple danger alert—check it out!
class
alert alert-warning
role
alert
A simple warning alert—check it out!
class
alert alert-info
role
alert
A simple info alert—check it out!
class
alert alert-light
role
alert
A simple light alert—check it out!
class
alert alert-dark
role
alert
A simple dark alert—check it out!
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Live example
Click the button below to show an alert (hidden with inline styles to start), then dismiss (and destroy) it with the built-in close button.
Show live alert
html
liveAlertPlaceholder
button
type
button
class
btn btn-primary
liveAlertBtn
Show live alert
button
We use the following JavaScript to trigger our live alert demo:
site/src/assets/partials/snippets.js
const
alertPlaceholder
document
getElementById
'liveAlertPlaceholder'
const
appendAlert
message
type
const
wrapper
document
createElement
'div'
wrapper
innerHTML
<div class="alert alert-
type
alert-dismissible" role="alert">
<div>
message
</div>
'   <button type="button" class="btn-close" data-bs-dismiss="alert" aria-label="Close"></button>'
'</div>'
join
alertPlaceholder
append
wrapper
const
alertTrigger
document
getElementById
'liveAlertBtn'
alertTrigger
alertTrigger
addEventListener
'click'
appendAlert
'Nice, you triggered this alert message!'
'success'
Link color
Use the
.alert-link
utility class to quickly provide matching colored links within any alert.
A simple primary alert with
an example link
. Give it a click if you like.
A simple secondary alert with
an example link
. Give it a click if you like.
A simple success alert with
an example link
. Give it a click if you like.
A simple danger alert with
an example link
. Give it a click if you like.
A simple warning alert with
an example link
. Give it a click if you like.
A simple info alert with
an example link
. Give it a click if you like.
A simple light alert with
an example link
. Give it a click if you like.
A simple dark alert with
an example link
. Give it a click if you like.
html
class
alert alert-primary
role
alert
A simple primary alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-secondary
role
alert
A simple secondary alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-success
role
alert
A simple success alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-danger
role
alert
A simple danger alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-warning
role
alert
A simple warning alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-info
role
alert
A simple info alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-light
role
alert
A simple light alert with
href
class
alert-link
an example link
. Give it a click if you like.
class
alert alert-dark
role
alert
A simple dark alert with
href
class
alert-link
an example link
. Give it a click if you like.
Additional content
Alerts can also contain additional HTML elements like headings, paragraphs and dividers.
Well done!
Aww yeah, you successfully read this important alert message. This example text is going to run a bit longer so that you can see how spacing within an alert works with this kind of content.
Whenever you need to, be sure to use margin utilities to keep things nice and tidy.
html
class
alert alert-success
role
alert
class
alert-heading
Well done!
Aww yeah, you successfully read this important alert message. This example text is going to run a bit longer so that you can see how spacing within an alert works with this kind of content.
class
mb-0
Whenever you need to, be sure to use margin utilities to keep things nice and tidy.
Icons
Similarly, you can use
flexbox utilities
to create alerts with icons. Depending on your icons and content, you may want to add more utilities or custom styles.
An example alert with an icon
html
class
alert alert-primary d-flex align-items-center
role
alert
xmlns
http://www.w3.org/2000/svg
class
bi flex-shrink-0 me-2
viewBox
0 0 16 16
role
aria-label
Warning:
path
M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z
An example alert with an icon
Need more than one icon for your alerts? Consider using more Bootstrap Icons and making a local SVG sprite like so to easily reference the same icons repeatedly.
An example alert with an icon
An example success alert with an icon
An example warning alert with an icon
An example danger alert with an icon
html
xmlns
http://www.w3.org/2000/svg
class
d-none
symbol
check-circle-fill
viewBox
0 0 16 16
path
M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-3.97-3.03a.75.75 0 0 0-1.08.022L7.477 9.417 5.384 7.323a.75.75 0 0 0-1.06 1.06L6.97 11.03a.75.75 0 0 0 1.079-.02l3.992-4.99a.75.75 0 0 0-.01-1.05z
symbol
symbol
info-fill
viewBox
0 0 16 16
path
M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm.93-9.412-1 4.705c-.07.34.029.533.304.533.194 0 .487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703 0-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381 2.29-.287zM8 5.5a1 1 0 1 1 0-2 1 1 0 0 1 0 2z
symbol
symbol
exclamation-triangle-fill
viewBox
0 0 16 16
path
M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z
symbol
class
alert alert-primary d-flex align-items-center
role
alert
class
bi flex-shrink-0 me-2
role
aria-label
Info:
xlink:
href
#info-fill
An example alert with an icon
class
alert alert-success d-flex align-items-center
role
alert
class
bi flex-shrink-0 me-2
role
aria-label
Success:
xlink:
href
#check-circle-fill
An example success alert with an icon
class
alert alert-warning d-flex align-items-center
role
alert
class
bi flex-shrink-0 me-2
role
aria-label
Warning:
xlink:
href
#exclamation-triangle-fill
An example warning alert with an icon
class
alert alert-danger d-flex align-items-center
role
alert
class
bi flex-shrink-0 me-2
role
aria-label
Danger:
xlink:
href
#exclamation-triangle-fill
An example danger alert with an icon
Dismissing
Using the alert JavaScript plugin, it’s possible to dismiss any alert inline. Here’s how:
Be sure you’ve loaded the alert plugin, or the compiled Bootstrap JavaScript.
Add a
close button
and the
.alert-dismissible
class, which adds extra padding to the right of the alert and positions the close button.
On the close button, add the
data-bs-dismiss="alert"
attribute, which triggers the JavaScript functionality. Be sure to use the
<button>
element with it for proper behavior across all devices.
To animate alerts when dismissing them, be sure to add the
.fade
.show
classes.
You can see this in action with a live demo:
Holy guacamole!
You should check in on some of those fields below.
html
class
alert alert-warning alert-dismissible fade show
role
alert
strong
Holy guacamole!
strong
You should check in on some of those fields below.
button
type
button
class
btn-close
data-bs-dismiss
alert
aria-label
Close
button
When an alert is dismissed, the element is completely removed from the page structure. If a keyboard user dismisses the alert using the close button, their focus will suddenly be lost and, depending on the browser, reset to the start of the page/document. For this reason, we recommend including additional JavaScript that listens for the
closed.bs.alert
event and programmatically sets
focus()
to the most appropriate location in the page. If you’re planning to move focus to a non-interactive element that normally does not receive focus, make sure to add
tabindex="-1"
to the element.
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, alerts now use local CSS variables on
.alert
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_alert.scss
#{$prefix}
alert-bg
transparent
#{$prefix}
alert-padding-x
#{$alert-padding-x}
#{$prefix}
alert-padding-y
#{$alert-padding-y}
#{$prefix}
alert-margin-bottom
#{$alert-margin-bottom}
#{$prefix}
alert-color
inherit
#{$prefix}
alert-border-color
transparent
#{$prefix}
alert-border
#{$alert-border-width}
solid
#{$prefix}
alert-border-color
#{$prefix}
alert-border-radius
#{$alert-border-radius}
#{$prefix}
alert-link-color
inherit
Sass variables
scss/_variables.scss
$alert-padding-y
$spacer
$alert-padding-x
$spacer
$alert-margin-bottom
1rem
$alert-border-radius
#{$prefix}
border-radius
$alert-link-font-weight
$font-weight-bold
$alert-border-width
#{$prefix}
border-width
$alert-dismissible-padding-r
$alert-padding-x
// 3x covers width of x plus default padding on either side
Sass mixins
Deprecated in v5.3.0
scss/mixins/_alert.scss
@mixin
alert-variant
$background
$border
$color
#{$prefix}
alert-color
#{$color}
#{$prefix}
alert-bg
#{$background}
#{$prefix}
alert-border-color
#{$border}
#{$prefix}
alert-link-color
shade-color
$color
$enable-gradients
background-image
#{$prefix}
gradient
.alert-link
color
#{$prefix}
alert-link-color
Sass loops
Loop that generates the modifier classes with an overriding of CSS variables.
scss/_alert.scss
// Generate contextual modifier classes for colorizing the alert
@each
$state
map-keys
$theme-colors
.alert-
#{$state}
#{$prefix}
alert-color
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
alert-bg
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
alert-border-color
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
alert-link-color
#{$prefix}
#{$state}
-text-emphasis
JavaScript behavior
Initialize
Initialize elements as alerts
const
alertList
document
querySelectorAll
'.alert'
const
alerts
alertList
element
Alert
element
For the sole purpose of dismissing an alert, it isn’t necessary to initialize the component manually via the JS API. By making use of
data-bs-dismiss="alert"
, the component will be initialized automatically and properly dismissed.
See the
triggers
section for more details.
Triggers
Dismissal can be achieved with the
data-bs-dismiss
attribute on a button
within the alert
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
alert
aria-label
Close
button
or on a button
outside the alert
using the additional
data-bs-target
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
alert
data-bs-target
#my-alert
aria-label
Close
button
Note that closing an alert will remove it from the DOM.
Methods
You can create an alert instance with the alert constructor, for example:
const
bsAlert
Alert
'#myAlert'
This makes an alert listen for click events on descendant elements which have the
data-bs-dismiss="alert"
attribute. (Not necessary when using the data-api’s auto-initialization.)
Method
Description
close
Closes an alert by removing it from the DOM. If the
.fade
.show
classes are present on the element, the alert will fade out before it is removed.
dispose
Destroys an element’s alert. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the alert instance associated to a DOM element. For example:
getOrCreateInstance
Static method which returns an alert instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
Basic usage:
const
alert
Alert
getOrCreateInstance
'#myAlert'
alert
close
Events
Event
Description
close.bs.alert
Fires immediately when the
close
instance method is called.
closed.bs.alert
Fired when the alert has been closed and CSS transitions have completed.
const
myAlert
document
getElementById
'myAlert'
myAlert
addEventListener
'closed.bs.alert'
event
// do something, for instance, explicitly move focus to the most appropriate element,
// so it doesn’t get lost/reset to the start of the page
// document.getElementById('...').focus()


--- 013_components_spinners.txt ---
URL: https://getbootstrap.com/docs/5.3/components/spinners
--------------------------------------------------
About
For accessibility purposes, each loader here includes
role="status"
and a nested
<span class="visually-hidden">Loading...</span>
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Border spinner
Use the border spinners for a lightweight loading indicator.
Loading...
html
class
spinner-border
role
status
span
class
visually-hidden
Loading...
span
Colors
The border spinner uses
currentColor
for its
border-color
, meaning you can customize the color with
text color utilities
. You can use any of our text color utilities on the standard spinner.
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
html
class
spinner-border text-primary
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-secondary
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-success
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-danger
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-warning
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-info
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-light
role
status
span
class
visually-hidden
Loading...
span
class
spinner-border text-dark
role
status
span
class
visually-hidden
Loading...
span
Why not use
border-color
utilities?
Each border spinner specifies a
transparent
border for at least one side, so
.border-{color}
utilities would override that.
Growing spinner
If you don’t fancy a border spinner, switch to the grow spinner. While it doesn’t technically spin, it does repeatedly grow!
Loading...
html
class
spinner-grow
role
status
span
class
visually-hidden
Loading...
span
Once again, this spinner is built with
currentColor
, so you can easily change its appearance with
text color utilities
. Here it is in blue, along with the supported variants.
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
html
class
spinner-grow text-primary
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-secondary
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-success
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-danger
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-warning
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-info
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-light
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow text-dark
role
status
span
class
visually-hidden
Loading...
span
Alignment
Spinners in Bootstrap are built with
currentColor
, and
display: inline-flex
. This means they can easily be resized, recolored, and quickly aligned.
Margin
margin utilities
like
.m-5
for easy spacing.
Loading...
html
class
spinner-border m-5
role
status
span
class
visually-hidden
Loading...
span
Placement
flexbox utilities
float utilities
, or
text alignment
utilities to place spinners exactly where you need them in any situation.
Flex
Loading...
html
class
d-flex justify-content-center
class
spinner-border
role
status
span
class
visually-hidden
Loading...
span
Loading...
html
class
d-flex align-items-center
strong
role
status
Loading...
strong
class
spinner-border ms-auto
aria-hidden
true
Floats
Loading...
html
class
clearfix
class
spinner-border float-end
role
status
span
class
visually-hidden
Loading...
span
Text align
Loading...
html
class
text-center
class
spinner-border
role
status
span
class
visually-hidden
Loading...
span
Size
.spinner-border-sm
.spinner-grow-sm
to make a smaller spinner that can quickly be used within other components.
Loading...
Loading...
html
class
spinner-border spinner-border-sm
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow spinner-grow-sm
role
status
span
class
visually-hidden
Loading...
span
Or, use custom CSS or inline styles to change the dimensions as needed.
Loading...
Loading...
html
class
spinner-border
style
width
3rem
height
3rem
role
status
span
class
visually-hidden
Loading...
span
class
spinner-grow
style
width
3rem
height
3rem
role
status
span
class
visually-hidden
Loading...
span
Buttons
Use spinners within buttons to indicate an action is currently processing or taking place. You may also swap the text out of the spinner element and utilize button text as needed.
Loading...
Loading...
html
button
class
btn btn-primary
type
button
disabled
span
class
spinner-border spinner-border-sm
aria-hidden
true
span
span
class
visually-hidden
role
status
Loading...
span
button
button
class
btn btn-primary
type
button
disabled
span
class
spinner-border spinner-border-sm
aria-hidden
true
span
span
role
status
Loading...
span
button
Loading...
Loading...
html
button
class
btn btn-primary
type
button
disabled
span
class
spinner-grow spinner-grow-sm
aria-hidden
true
span
span
class
visually-hidden
role
status
Loading...
span
button
button
class
btn btn-primary
type
button
disabled
span
class
spinner-grow spinner-grow-sm
aria-hidden
true
span
span
role
status
Loading...
span
button
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, spinners now use local CSS variables on
.spinner-border
.spinner-grow
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
Border spinner variables:
scss/_spinners.scss
#{$prefix}
spinner-width
#{$spinner-width}
#{$prefix}
spinner-height
#{$spinner-height}
#{$prefix}
spinner-vertical-align
#{$spinner-vertical-align}
#{$prefix}
spinner-border-width
#{$spinner-border-width}
#{$prefix}
spinner-animation-speed
#{$spinner-animation-speed}
#{$prefix}
spinner-animation-name
spinner-border
Growing spinner variables:
scss/_spinners.scss
#{$prefix}
spinner-width
#{$spinner-width}
#{$prefix}
spinner-height
#{$spinner-height}
#{$prefix}
spinner-vertical-align
#{$spinner-vertical-align}
#{$prefix}
spinner-animation-speed
#{$spinner-animation-speed}
#{$prefix}
spinner-animation-name
spinner-grow
For both spinners, small spinner modifier classes are used to update the values of these CSS variables as needed. For example, the
.spinner-border-sm
class does the following:
scss/_spinners.scss
#{$prefix}
spinner-width
#{$spinner-width-sm}
#{$prefix}
spinner-height
#{$spinner-height-sm}
#{$prefix}
spinner-border-width
#{$spinner-border-width-sm}
Sass variables
scss/_variables.scss
$spinner-width
2rem
$spinner-height
$spinner-width
$spinner-vertical-align
-.125em
$spinner-border-width
.25em
$spinner-animation-speed
.75s
$spinner-width-sm
1rem
$spinner-height-sm
$spinner-width-sm
$spinner-border-width-sm
.2em
Keyframes
Used for creating the CSS animations for our spinners. Included in
scss/_spinners.scss
scss/_spinners.scss
@keyframes
spinner-border
transform
rotate
360deg
"/* rtl:ignore */"
scss/_spinners.scss
@keyframes
spinner-grow
transform
scale
opacity
transform
none


--- 020_components_progress.txt ---
URL: https://getbootstrap.com/docs/5.3/components/progress
--------------------------------------------------
New markup in v5.3.0 —
We’ve deprecated the previous HTML structure for progress bars and replaced it with a more accessible one. The previous structure will continue to work until v6.
See what’s changed in our migration guide.
How it works
Progress components are built with two HTML elements, some CSS to set the width, and a few attributes. We don’t use
the HTML5
<progress>
element
, ensuring you can stack progress bars, animate them, and place text labels over them.
We use the
.progress
as a wrapper to indicate the max value of the progress bar.
.progress
wrapper also requires a
role="progressbar"
aria
attributes to make it accessible, including an accessible name (using
aria-label
aria-labelledby
, or similar).
We use the inner
.progress-bar
purely for the visual bar and label.
.progress-bar
requires an inline style, utility class, or custom CSS to set its width.
We provide a special
.progress-stacked
class to create multiple/stacked progress bars.
Put that all together, and you have the following examples.
html
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
100%
Bar sizing
Width
utilities for setting width
. Depending on your needs, these may help with quickly configuring the width of the
.progress-bar
html
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar w-75
Height
You only set a
height
value on the
.progress
container, so if you change that value, the inner
.progress-bar
will automatically resize accordingly.
html
class
progress
role
progressbar
aria-label
Example 1px high
aria-valuenow
aria-valuemin
aria-valuemax
style
height
class
progress-bar
style
width
class
progress
role
progressbar
aria-label
Example 20px high
aria-valuenow
aria-valuemin
aria-valuemax
style
height
20px
class
progress-bar
style
width
Labels
Add labels to your progress bars by placing text within the
.progress-bar
html
class
progress
role
progressbar
aria-label
Example with label
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
Long labels
Note that by default, the content inside the
.progress-bar
is controlled with
overflow: hidden
, so it doesn’t bleed out of the bar. If your progress bar is shorter than its label, the content will be capped and may become unreadable. To change this behavior, you can use
.overflow-visible
from the
overflow utilities
Labels longer than the progress bar within may not be fully accessible using this method because it relies on the text color having the correct contrast ratio with both the
.progress
.progress-bar
background colors. Use caution when implementing this example.
If the text can overlap the progress bar, we often recommend displaying the label outside of the progress bar for better accessibility.
Backgrounds
Use background utility classes to change the appearance of individual progress bars.
html
class
progress
role
progressbar
aria-label
Success example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-success
style
width
class
progress
role
progressbar
aria-label
Info example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-info
style
width
class
progress
role
progressbar
aria-label
Warning example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-warning
style
width
class
progress
role
progressbar
aria-label
Danger example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-danger
style
width
100%
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
If you’re adding labels to progress bars with a custom background color, make sure to also set an appropriate
text color
, so the labels remain readable and have sufficient contrast. We recommend using the
color and background
helper classes.
100%
html
class
progress
role
progressbar
aria-label
Success example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar text-bg-success
style
width
class
progress
role
progressbar
aria-label
Info example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar text-bg-info
style
width
class
progress
role
progressbar
aria-label
Warning example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar text-bg-warning
style
width
class
progress
role
progressbar
aria-label
Danger example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar text-bg-danger
style
width
100%
100%
Multiple bars
You can include multiple progress components inside a container with
.progress-stacked
to create a single stacked progress bar. Note that in this case, the styling to set the visual width of the progress bar
must
be applied to the
.progress
elements, rather than the
.progress-bar
html
class
progress-stacked
class
progress
role
progressbar
aria-label
Segment one
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar
class
progress
role
progressbar
aria-label
Segment two
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar bg-success
class
progress
role
progressbar
aria-label
Segment three
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar bg-info
Striped
.progress-bar-striped
to any
.progress-bar
to apply a stripe via CSS gradient over the progress bar’s background color.
html
class
progress
role
progressbar
aria-label
Default striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped
style
width
class
progress
role
progressbar
aria-label
Success striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped bg-success
style
width
class
progress
role
progressbar
aria-label
Info striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped bg-info
style
width
class
progress
role
progressbar
aria-label
Warning striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped bg-warning
style
width
class
progress
role
progressbar
aria-label
Danger striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped bg-danger
style
width
100%
Animated stripes
The striped gradient can also be animated. Add
.progress-bar-animated
.progress-bar
to animate the stripes right to left via CSS3 animations.
html
class
progress
role
progressbar
aria-label
Animated striped example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar progress-bar-striped progress-bar-animated
style
width
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, progress bars now use local CSS variables on
.progress
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_progress.scss
#{$prefix}
progress-height
#{$progress-height}
@include
$progress-font-size
#{$prefix}
progress-font-size
#{$prefix}
progress-bg
#{$progress-bg}
#{$prefix}
progress-border-radius
#{$progress-border-radius}
#{$prefix}
progress-box-shadow
#{$progress-box-shadow}
#{$prefix}
progress-bar-color
#{$progress-bar-color}
#{$prefix}
progress-bar-bg
#{$progress-bar-bg}
#{$prefix}
progress-bar-transition
#{$progress-bar-transition}
Sass variables
scss/_variables.scss
$progress-height
1rem
$progress-font-size
$font-size-base
$progress-bg
#{$prefix}
secondary-bg
$progress-border-radius
#{$prefix}
border-radius
$progress-box-shadow
#{$prefix}
box-shadow-inset
$progress-bar-color
$white
$progress-bar-bg
$primary
$progress-bar-animation-timing
1s linear infinite
$progress-bar-transition
width .6s ease
Keyframes
Used for creating the CSS animations for
.progress-bar-animated
. Included in
scss/_progress-bar.scss
scss/_progress.scss
$enable-transitions
@keyframes
progress-bar-stripes
background-position-x
#{$prefix}
progress-height


--- 024_components_card.txt ---
URL: https://getbootstrap.com/docs/5.3/components/card
--------------------------------------------------
About
card
is a flexible and extensible content container. It includes options for headers and footers, a wide variety of content, contextual background colors, and powerful display options. If you’re familiar with Bootstrap 3, cards replace our old panels, wells, and thumbnails. Similar functionality to those components is available as modifier classes for cards.
Example
Cards are built with as little markup and styles as possible, but still manage to deliver a ton of control and customization. Built with flexbox, they offer easy alignment and mix well with other Bootstrap components. They have no
margin
by default, so use
spacing utilities
as needed.
Below is an example of a basic card with mixed content and a fixed width. Cards have no fixed width to start, so they’ll naturally fill the full width of its parent element. This is easily customized with our various
sizing options
Placeholder
Image cap
Card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Go somewhere
html
class
card
style
width
18rem
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
href
class
btn btn-primary
Go somewhere
Content types
Cards support a wide variety of content, including images, text, list groups, links, and more. Below are examples of what’s supported.
Body
The building block of a card is the
.card-body
. Use it whenever you need a padded section within a card.
This is some text within a card body.
html
class
card
class
card-body
This is some text within a card body.
Titles, text, and links
Card titles are used by adding
.card-title
to a
<h*>
tag. In the same way, links are added and placed next to each other by adding
.card-link
to an
tag.
Subtitles are used by adding a
.card-subtitle
to a
<h*>
tag. If the
.card-title
and the
.card-subtitle
items are placed in a
.card-body
item, the card title and subtitle are aligned nicely.
Card title
Card subtitle
Some quick example text to build on the card title and make up the bulk of the card’s content.
Card link
Another link
html
class
card
style
width
18rem
class
card-body
class
card-title
Card title
class
card-subtitle mb-2 text-body-secondary
Card subtitle
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
href
class
card-link
Card link
href
class
card-link
Another link
Images
.card-img-top
.card-img-bottom
respectively set the top and bottom corners rounded to match the card’s borders. With
.card-text
, text can be added to the card. Text within
.card-text
can also be styled with the standard HTML tags.
Placeholder
Image cap
Some quick example text to build on the card title and make up the bulk of the card’s content.
html
class
card
style
width
18rem
class
card-img-top
class
card-body
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
List groups
Create lists of content in a card with a flush list group.
An item
A second item
A third item
html
class
card
style
width
18rem
class
list-group list-group-flush
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
Featured
An item
A second item
A third item
html
class
card
style
width
18rem
class
card-header
Featured
class
list-group list-group-flush
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
An item
A second item
A third item
Card footer
html
class
card
style
width
18rem
class
list-group list-group-flush
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
card-footer
Card footer
Kitchen sink
Mix and match multiple content types to create the card you need, or throw everything in there. Shown below are image styles, blocks, text styles, and a list group—all wrapped in a fixed-width card.
Placeholder
Image cap
Card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
An item
A second item
A third item
Card link
Another link
html
class
card
style
width
18rem
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
list-group list-group-flush
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
card-body
href
class
card-link
Card link
href
class
card-link
Another link
Header and footer
Add an optional header and/or footer within a card.
Featured
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card
class
card-header
Featured
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Card headers can be styled by adding
.card-header
<h*>
elements.
Featured
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card
class
card-header
Featured
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Quote
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
html
class
card
class
card-header
Quote
class
card-body
figure
blockquote
class
blockquote
A well-known quote, contained in a blockquote element.
blockquote
figcaption
class
blockquote-footer
Someone famous in
cite
title
Source Title
Source Title
cite
figcaption
figure
Featured
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
2 days ago
html
class
card text-center
class
card-header
Featured
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
class
card-footer text-body-secondary
2 days ago
Sizing
Cards assume no specific
width
to start, so they’ll be 100% wide unless otherwise stated. You can change this as needed with custom CSS, grid classes, grid Sass mixins, or utilities.
Using grid markup
Using the grid, wrap cards in columns and rows as needed.
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
class
col-sm-6 mb-3 mb-sm-0
class
card
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
class
col-sm-6
class
card
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Using utilities
Use our handful of
available sizing utilities
to quickly set a card’s width.
Card title
With supporting text below as a natural lead-in to additional content.
Button
Card title
With supporting text below as a natural lead-in to additional content.
Button
html
class
card w-75 mb-3
class
card-body
class
card-title
Card title
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Button
class
card w-50
class
card-body
class
card-title
Card title
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Button
Using custom CSS
Use custom CSS in your stylesheets or as inline styles to set a width.
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card
style
width
18rem
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Text alignment
You can quickly change the text alignment of any card—in its entirety or specific parts—with our
text align classes
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card mb-3
style
width
18rem
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
class
card text-center mb-3
style
width
18rem
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
class
card text-end
style
width
18rem
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Navigation
Add some navigation to a card’s header (or block) with Bootstrap’s
nav components
Active
Link
Disabled
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card text-center
class
card-header
class
nav nav-tabs card-header-tabs
class
nav-item
class
nav-link active
aria-current
true
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Active
Link
Disabled
Special title treatment
With supporting text below as a natural lead-in to additional content.
Go somewhere
html
class
card text-center
class
card-header
class
nav nav-pills card-header-pills
class
nav-item
class
nav-link active
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
class
card-body
class
card-title
Special title treatment
class
card-text
With supporting text below as a natural lead-in to additional content.
href
class
btn btn-primary
Go somewhere
Images
Cards include a few options for working with images. Choose from appending “image caps” at either end of a card, overlaying images with card content, or simply embedding the image in a card.
Image caps
Similar to headers and footers, cards can include top and bottom “image caps”—images at the top or bottom of a card.
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Placeholder
Image cap
html
class
card mb-3
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card-img-bottom
Image overlays
Turn an image into a card background and overlay your card’s text. Depending on the image, you may or may not need additional styles or utilities.
Placeholder
Card image
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
html
class
card text-bg-dark
class
card-img
class
card-img-overlay
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-text
small
Last updated 3 mins ago
small
Note that content should not be larger than the height of the image. If content is larger than the image the content will be displayed outside the image.
Horizontal
Using a combination of grid and utility classes, cards can be made horizontal in a mobile-friendly and responsive way. In the example below, we remove the grid gutters with
.g-0
and use
.col-md-*
classes to make the card horizontal at the
breakpoint. Further adjustments may be needed depending on your card content.
Placeholder
Image
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
html
class
card mb-3
style
max-width
540px
class
row g-0
class
col-md-4
class
img-fluid rounded-start
class
col-md-8
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
Card styles
Cards include various options for customizing their backgrounds, borders, and color.
Background and color
Added in v5.2.0
Set a
background-color
with contrasting foreground
color
with
.text-bg-{color}
helpers
. Previously it was required to manually pair your choice of
.text-{color}
.bg-{color}
utilities for styling, which you still may use if you prefer.
Header
Primary card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Secondary card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Success card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Danger card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Warning card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Info card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Light card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Dark card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
html
class
card text-bg-primary mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Primary card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-secondary mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Secondary card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-success mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Success card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-danger mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Danger card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-warning mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Warning card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-info mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Info card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-light mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Light card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-dark mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Dark card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Border
border utilities
to change just the
border-color
of a card. Note that you can put
.text-{color}
classes on the parent
.card
or a subset of the card’s contents as shown below.
Header
Primary card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Secondary card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Success card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Danger card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Warning card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Info card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Light card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Dark card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
html
class
card border-primary mb-3
style
max-width
18rem
class
card-header
Header
class
card-body text-primary
class
card-title
Primary card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-secondary mb-3
style
max-width
18rem
class
card-header
Header
class
card-body text-secondary
class
card-title
Secondary card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-success mb-3
style
max-width
18rem
class
card-header
Header
class
card-body text-success
class
card-title
Success card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-danger mb-3
style
max-width
18rem
class
card-header
Header
class
card-body text-danger
class
card-title
Danger card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-warning mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Warning card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-info mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Info card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-light mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Light card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card border-dark mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-title
Dark card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
Mixins utilities
You can also change the borders on the card header and footer as needed, and even remove their
background-color
with
.bg-transparent
Header
Success card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Footer
html
class
card border-success mb-3
style
max-width
18rem
class
card-header bg-transparent border-success
Header
class
card-body text-success
class
card-title
Success card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card-footer bg-transparent border-success
Footer
Card layout
In addition to styling the content within cards, Bootstrap includes a few options for laying out series of cards. For the time being,
these layout options are not yet responsive
Card groups
Use card groups to render cards as a single, attached element with equal width and height columns. Card groups start off stacked and use
display: flex;
to become attached with uniform dimensions starting at the
breakpoint.
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This card has supporting text below as a natural lead-in to additional content.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
Last updated 3 mins ago
html
class
card-group
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This card has supporting text below as a natural lead-in to additional content.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
class
card-text
small
class
text-body-secondary
Last updated 3 mins ago
small
When using card groups with footers, their content will automatically line up.
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This card has supporting text below as a natural lead-in to additional content.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
Last updated 3 mins ago
html
class
card-group
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This card has supporting text below as a natural lead-in to additional content.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
Grid cards
Use the Bootstrap grid system and its
.row-cols
classes
to control how many grid columns (wrapped around your cards) you show per row. For example, here’s
.row-cols-1
laying out the cards on one column, and
.row-cols-md-2
splitting four cards to equal width across multiple rows, from the medium breakpoint up.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
html
class
row row-cols-1 row-cols-md-2 g-4
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Change it to
.row-cols-3
and you’ll see the fourth card wrap.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
html
class
row row-cols-1 row-cols-md-3 g-4
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content.
class
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
When you need equal height, add
.h-100
to the cards. If you want equal heights by default, you can set
$card-height: 100%
in Sass.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Placeholder
Image cap
Card title
This is a short card.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content.
Placeholder
Image cap
Card title
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
html
class
row row-cols-1 row-cols-md-3 g-4
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a short card.
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content.
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Just like with card groups, card footers will automatically line up.
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This card has supporting text below as a natural lead-in to additional content.
Last updated 3 mins ago
Placeholder
Image cap
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
Last updated 3 mins ago
html
class
row row-cols-1 row-cols-md-3 g-4
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This card has supporting text below as a natural lead-in to additional content.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
class
class
card h-100
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
This is a wider card with supporting text below as a natural lead-in to additional content. This card has even longer content than the first to show that equal height action.
class
card-footer
small
class
text-body-secondary
Last updated 3 mins ago
small
Masonry
we used a CSS-only technique to mimic the behavior of
Masonry
-like columns, but this technique came with lots of unpleasant
side effects
. If you want to have this type of layout in
, you can just make use of Masonry plugin.
Masonry is not included in Bootstrap
, but we’ve made a
demo example
to help you get started.
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, cards now use local CSS variables on
.card
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_card.scss
#{$prefix}
card-spacer-y
#{$card-spacer-y}
#{$prefix}
card-spacer-x
#{$card-spacer-x}
#{$prefix}
card-title-spacer-y
#{$card-title-spacer-y}
#{$prefix}
card-title-color
#{$card-title-color}
#{$prefix}
card-subtitle-color
#{$card-subtitle-color}
#{$prefix}
card-border-width
#{$card-border-width}
#{$prefix}
card-border-color
#{$card-border-color}
#{$prefix}
card-border-radius
#{$card-border-radius}
#{$prefix}
card-box-shadow
#{$card-box-shadow}
#{$prefix}
card-inner-border-radius
#{$card-inner-border-radius}
#{$prefix}
card-cap-padding-y
#{$card-cap-padding-y}
#{$prefix}
card-cap-padding-x
#{$card-cap-padding-x}
#{$prefix}
card-cap-bg
#{$card-cap-bg}
#{$prefix}
card-cap-color
#{$card-cap-color}
#{$prefix}
card-height
#{$card-height}
#{$prefix}
card-color
#{$card-color}
#{$prefix}
card-bg
#{$card-bg}
#{$prefix}
card-img-overlay-padding
#{$card-img-overlay-padding}
#{$prefix}
card-group-margin
#{$card-group-margin}
Sass variables
scss/_variables.scss
$card-spacer-y
$spacer
$card-spacer-x
$spacer
$card-title-spacer-y
$spacer
$card-title-color
null
$card-subtitle-color
null
$card-border-width
#{$prefix}
border-width
$card-border-color
#{$prefix}
border-color-translucent
$card-border-radius
#{$prefix}
border-radius
$card-box-shadow
null
$card-inner-border-radius
subtract
$card-border-radius
$card-border-width
$card-cap-padding-y
$card-spacer-y
$card-cap-padding-x
$card-spacer-x
$card-cap-bg
rgba
#{$prefix}
body-color-rgb
$card-cap-color
null
$card-height
null
$card-color
null
$card-bg
#{$prefix}
body-bg
$card-img-overlay-padding
$spacer
$card-group-margin
$grid-gutter-width


--- 025_components_navs-tabs.txt ---
URL: https://getbootstrap.com/docs/5.3/components/navs-tabs
--------------------------------------------------
Base nav
Navigation available in Bootstrap share general markup and styles, from the base
.nav
class to the active and disabled states. Swap modifier classes to switch between each style.
The base
.nav
component is built with flexbox and provide a strong foundation for building all types of navigation components. It includes some style overrides (for working with lists), some link padding for larger hit areas, and basic disabled styling.
The base
.nav
component does not include any
.active
state. The following examples include the class, mainly to demonstrate that this particular class does not trigger any special styling.
To convey the active state to assistive technologies, use the
aria-current
attribute — using the
page
value for current page, or
true
for the current item in a set.
Active
Link
Link
Disabled
html
class
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Classes are used throughout, so your markup can be super flexible. Use
<ul>
s like above,
<ol>
if the order of your items is important, or roll your own with a
<nav>
element. Because the
.nav
uses
display: flex
, the nav links behave the same as nav items would, but without the extra markup.
html
class
class
nav-link active
aria-current
page
href
Active
class
nav-link
href
Link
class
nav-link
href
Link
class
nav-link disabled
aria-disabled
true
Disabled
Available styles
Change the style of
.nav
s component with modifiers and utilities. Mix and match as needed, or build your own.
Horizontal alignment
Change the horizontal alignment of your nav with
flexbox utilities
. By default, navs are left-aligned, but you can easily change them to center or right-aligned.
Centered with
.justify-content-center
Active
Link
Link
Disabled
html
class
nav justify-content-center
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Right-aligned with
.justify-content-end
Active
Link
Link
Disabled
html
class
nav justify-content-end
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Vertical
Stack your navigation by changing the flex item direction with the
.flex-column
utility. Need to stack them on some viewports but not others? Use the responsive versions (e.g.,
.flex-sm-column
Active
Link
Link
Disabled
html
class
nav flex-column
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
As always, vertical navigation is possible without
<ul>
s, too.
html
class
nav flex-column
class
nav-link active
aria-current
page
href
Active
class
nav-link
href
Link
class
nav-link
href
Link
class
nav-link disabled
aria-disabled
true
Disabled
Tabs
Takes the basic nav from above and adds the
.nav-tabs
class to generate a tabbed interface. Use them to create tabbable regions with our
tab JavaScript plugin
Active
Link
Link
Disabled
html
class
nav nav-tabs
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Pills
Take that same HTML, but use
.nav-pills
instead:
Active
Link
Link
Disabled
html
class
nav nav-pills
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Underline
Take that same HTML, but use
.nav-underline
instead:
Active
Link
Link
Disabled
html
class
nav nav-underline
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Fill and justify
Force your
.nav
’s contents to extend the full available width with one of two modifier classes. To proportionately fill all available space with your
.nav-item
s, use
.nav-fill
. Notice that all horizontal space is occupied, but not every nav item has the same width.
Active
Much longer nav link
Link
Disabled
html
class
nav nav-pills nav-fill
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Much longer nav link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
When using a
<nav>
-based navigation, you can safely omit
.nav-item
as only
.nav-link
is required for styling
elements.
html
class
nav nav-pills nav-fill
class
nav-link active
aria-current
page
href
Active
class
nav-link
href
Much longer nav link
class
nav-link
href
Link
class
nav-link disabled
aria-disabled
true
Disabled
For equal-width elements, use
.nav-justified
. All horizontal space will be occupied by nav links, but unlike the
.nav-fill
above, every nav item will be the same width.
Active
Much longer nav link
Link
Disabled
html
class
nav nav-pills nav-justified
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item
class
nav-link
href
Much longer nav link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Similar to the
.nav-fill
example using a
<nav>
-based navigation.
html
class
nav nav-pills nav-justified
class
nav-link active
aria-current
page
href
Active
class
nav-link
href
Much longer nav link
class
nav-link
href
Link
class
nav-link disabled
aria-disabled
true
Disabled
Working with flex utilities
If you need responsive nav variations, consider using a series of
flexbox utilities
. While more verbose, these utilities offer greater customization across responsive breakpoints. In the example below, our nav will be stacked on the lowest breakpoint, then adapt to a horizontal layout that fills the available width starting from the small breakpoint.
html
class
nav nav-pills flex-column flex-sm-row
class
flex-sm-fill text-sm-center nav-link active
aria-current
page
href
Active
class
flex-sm-fill text-sm-center nav-link
href
Longer nav link
class
flex-sm-fill text-sm-center nav-link
href
Link
class
flex-sm-fill text-sm-center nav-link disabled
aria-disabled
true
Disabled
Regarding accessibility
If you’re using navs to provide a navigation bar, be sure to add a
role="navigation"
to the most logical parent container of the
<ul>
, or wrap a
<nav>
element around the whole navigation. Do not add the role to the
<ul>
itself, as this would prevent it from being announced as an actual list by assistive technologies.
Note that navigation bars, even if visually styled as tabs with the
.nav-tabs
class, should
be given
role="tablist"
role="tab"
role="tabpanel"
attributes. These are only appropriate for dynamic tabbed interfaces, as described in the
ARIA Authoring Practices Guide tabs pattern
. See
JavaScript behavior
for dynamic tabbed interfaces in this section for an example. The
aria-current
attribute is not necessary on dynamic tabbed interfaces since our JavaScript handles the selected state by adding
aria-selected="true"
on the active tab.
Using dropdowns
Add dropdown menus with a little extra HTML and the
dropdowns JavaScript plugin
Tabs with dropdowns
Active
Dropdown
Action
Another action
Something else here
Separated link
Link
Disabled
html
class
nav nav-tabs
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item dropdown
class
nav-link dropdown-toggle
data-bs-toggle
dropdown
href
role
button
aria-expanded
false
Dropdown
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Pills with dropdowns
Active
Dropdown
Action
Another action
Something else here
Separated link
Link
Disabled
html
class
nav nav-pills
class
nav-item
class
nav-link active
aria-current
page
href
Active
class
nav-item dropdown
class
nav-link dropdown-toggle
data-bs-toggle
dropdown
href
role
button
aria-expanded
false
Dropdown
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, navs now use local CSS variables on
.nav
.nav-tabs
, and
.nav-pills
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
On the
.nav
base class:
scss/_nav.scss
#{$prefix}
nav-link-padding-x
#{$nav-link-padding-x}
#{$prefix}
nav-link-padding-y
#{$nav-link-padding-y}
@include
$nav-link-font-size
#{$prefix}
nav-link-font-size
#{$prefix}
nav-link-font-weight
#{$nav-link-font-weight}
#{$prefix}
nav-link-color
#{$nav-link-color}
#{$prefix}
nav-link-hover-color
#{$nav-link-hover-color}
#{$prefix}
nav-link-disabled-color
#{$nav-link-disabled-color}
On the
.nav-tabs
modifier class:
scss/_nav.scss
#{$prefix}
nav-tabs-border-width
#{$nav-tabs-border-width}
#{$prefix}
nav-tabs-border-color
#{$nav-tabs-border-color}
#{$prefix}
nav-tabs-border-radius
#{$nav-tabs-border-radius}
#{$prefix}
nav-tabs-link-hover-border-color
#{$nav-tabs-link-hover-border-color}
#{$prefix}
nav-tabs-link-active-color
#{$nav-tabs-link-active-color}
#{$prefix}
nav-tabs-link-active-bg
#{$nav-tabs-link-active-bg}
#{$prefix}
nav-tabs-link-active-border-color
#{$nav-tabs-link-active-border-color}
On the
.nav-pills
modifier class:
scss/_nav.scss
#{$prefix}
nav-pills-border-radius
#{$nav-pills-border-radius}
#{$prefix}
nav-pills-link-active-color
#{$nav-pills-link-active-color}
#{$prefix}
nav-pills-link-active-bg
#{$nav-pills-link-active-bg}
Added in v5.3.0
On the
.nav-underline
modifier class:
scss/_nav.scss
#{$prefix}
nav-underline-gap
#{$nav-underline-gap}
#{$prefix}
nav-underline-border-width
#{$nav-underline-border-width}
#{$prefix}
nav-underline-link-active-color
#{$nav-underline-link-active-color}
Sass variables
scss/_variables.scss
$nav-link-padding-y
.5rem
$nav-link-padding-x
1rem
$nav-link-font-size
null
$nav-link-font-weight
null
$nav-link-color
#{$prefix}
link-color
$nav-link-hover-color
#{$prefix}
link-hover-color
$nav-link-transition
color .15s ease-in-out
background-color .15s ease-in-out
border-color .15s ease-in-out
$nav-link-disabled-color
#{$prefix}
secondary-color
$nav-link-focus-box-shadow
$focus-ring-box-shadow
$nav-tabs-border-color
#{$prefix}
border-color
$nav-tabs-border-width
#{$prefix}
border-width
$nav-tabs-border-radius
#{$prefix}
border-radius
$nav-tabs-link-hover-border-color
#{$prefix}
secondary-bg
#{$prefix}
secondary-bg
$nav-tabs-border-color
$nav-tabs-link-active-color
#{$prefix}
emphasis-color
$nav-tabs-link-active-bg
#{$prefix}
body-bg
$nav-tabs-link-active-border-color
#{$prefix}
border-color
#{$prefix}
border-color
$nav-tabs-link-active-bg
$nav-pills-border-radius
#{$prefix}
border-radius
$nav-pills-link-active-color
$component-active-color
$nav-pills-link-active-bg
$component-active-bg
$nav-underline-gap
1rem
$nav-underline-border-width
.125rem
$nav-underline-link-active-color
#{$prefix}
emphasis-color
JavaScript behavior
Use the tab JavaScript plugin—include it individually or through the compiled
file—to extend our navigational tabs and pills to create tabbable panes of local content.
Home
Profile
Contact
Disabled
This is some placeholder content the
Home tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Profile tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Contact tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Disabled tab’s
associated content.
class
nav nav-tabs
myTab
role
tablist
class
nav-item
role
presentation
button
class
nav-link active
home-tab
data-bs-toggle
data-bs-target
#home-tab-pane
type
button
role
aria-controls
home-tab-pane
aria-selected
true
Home
button
class
nav-item
role
presentation
button
class
nav-link
profile-tab
data-bs-toggle
data-bs-target
#profile-tab-pane
type
button
role
aria-controls
profile-tab-pane
aria-selected
false
Profile
button
class
nav-item
role
presentation
button
class
nav-link
contact-tab
data-bs-toggle
data-bs-target
#contact-tab-pane
type
button
role
aria-controls
contact-tab-pane
aria-selected
false
Contact
button
class
nav-item
role
presentation
button
class
nav-link
disabled-tab
data-bs-toggle
data-bs-target
#disabled-tab-pane
type
button
role
aria-controls
disabled-tab-pane
aria-selected
false
disabled
Disabled
button
class
tab-content
myTabContent
class
tab-pane fade show active
home-tab-pane
role
tabpanel
aria-labelledby
home-tab
tabindex
class
tab-pane fade
profile-tab-pane
role
tabpanel
aria-labelledby
profile-tab
tabindex
class
tab-pane fade
contact-tab-pane
role
tabpanel
aria-labelledby
contact-tab
tabindex
class
tab-pane fade
disabled-tab-pane
role
tabpanel
aria-labelledby
disabled-tab
tabindex
To help fit your needs, this works with
<ul>
-based markup, as shown above, or with any arbitrary “roll your own” markup. Note that if you’re using
<nav>
, you shouldn’t add
role="tablist"
directly to it, as this would override the element’s native role as a navigation landmark. Instead, switch to an alternative element (in the example below, a simple
<div>
) and wrap the
<nav>
around it.
This is some placeholder content the
Home tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Profile tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Contact tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Disabled tab’s
associated content.
class
nav nav-tabs
nav-tab
role
tablist
button
class
nav-link active
nav-home-tab
data-bs-toggle
data-bs-target
#nav-home
type
button
role
aria-controls
nav-home
aria-selected
true
Home
button
button
class
nav-link
nav-profile-tab
data-bs-toggle
data-bs-target
#nav-profile
type
button
role
aria-controls
nav-profile
aria-selected
false
Profile
button
button
class
nav-link
nav-contact-tab
data-bs-toggle
data-bs-target
#nav-contact
type
button
role
aria-controls
nav-contact
aria-selected
false
Contact
button
button
class
nav-link
nav-disabled-tab
data-bs-toggle
data-bs-target
#nav-disabled
type
button
role
aria-controls
nav-disabled
aria-selected
false
disabled
Disabled
button
class
tab-content
nav-tabContent
class
tab-pane fade show active
nav-home
role
tabpanel
aria-labelledby
nav-home-tab
tabindex
class
tab-pane fade
nav-profile
role
tabpanel
aria-labelledby
nav-profile-tab
tabindex
class
tab-pane fade
nav-contact
role
tabpanel
aria-labelledby
nav-contact-tab
tabindex
class
tab-pane fade
nav-disabled
role
tabpanel
aria-labelledby
nav-disabled-tab
tabindex
The tabs plugin also works with pills.
Home
Profile
Contact
Disabled
This is some placeholder content the
Home tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Profile tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Contact tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Disabled tab’s
associated content.
class
nav nav-pills mb-3
pills-tab
role
tablist
class
nav-item
role
presentation
button
class
nav-link active
pills-home-tab
data-bs-toggle
pill
data-bs-target
#pills-home
type
button
role
aria-controls
pills-home
aria-selected
true
Home
button
class
nav-item
role
presentation
button
class
nav-link
pills-profile-tab
data-bs-toggle
pill
data-bs-target
#pills-profile
type
button
role
aria-controls
pills-profile
aria-selected
false
Profile
button
class
nav-item
role
presentation
button
class
nav-link
pills-contact-tab
data-bs-toggle
pill
data-bs-target
#pills-contact
type
button
role
aria-controls
pills-contact
aria-selected
false
Contact
button
class
nav-item
role
presentation
button
class
nav-link
pills-disabled-tab
data-bs-toggle
pill
data-bs-target
#pills-disabled
type
button
role
aria-controls
pills-disabled
aria-selected
false
disabled
Disabled
button
class
tab-content
pills-tabContent
class
tab-pane fade show active
pills-home
role
tabpanel
aria-labelledby
pills-home-tab
tabindex
class
tab-pane fade
pills-profile
role
tabpanel
aria-labelledby
pills-profile-tab
tabindex
class
tab-pane fade
pills-contact
role
tabpanel
aria-labelledby
pills-contact-tab
tabindex
class
tab-pane fade
pills-disabled
role
tabpanel
aria-labelledby
pills-disabled-tab
tabindex
And with vertical pills. Ideally, for vertical tabs, you should also add
aria-orientation="vertical"
to the tab list container.
Home
Profile
Disabled
Messages
Settings
This is some placeholder content the
Home tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Profile tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Disabled tab’s
associated content.
This is some placeholder content the
Messages tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Settings tab’s
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
class
d-flex align-items-start
class
nav flex-column nav-pills me-3
v-pills-tab
role
tablist
aria-orientation
vertical
button
class
nav-link active
v-pills-home-tab
data-bs-toggle
pill
data-bs-target
#v-pills-home
type
button
role
aria-controls
v-pills-home
aria-selected
true
Home
button
button
class
nav-link
v-pills-profile-tab
data-bs-toggle
pill
data-bs-target
#v-pills-profile
type
button
role
aria-controls
v-pills-profile
aria-selected
false
Profile
button
button
class
nav-link
v-pills-disabled-tab
data-bs-toggle
pill
data-bs-target
#v-pills-disabled
type
button
role
aria-controls
v-pills-disabled
aria-selected
false
disabled
Disabled
button
button
class
nav-link
v-pills-messages-tab
data-bs-toggle
pill
data-bs-target
#v-pills-messages
type
button
role
aria-controls
v-pills-messages
aria-selected
false
Messages
button
button
class
nav-link
v-pills-settings-tab
data-bs-toggle
pill
data-bs-target
#v-pills-settings
type
button
role
aria-controls
v-pills-settings
aria-selected
false
Settings
button
class
tab-content
v-pills-tabContent
class
tab-pane fade show active
v-pills-home
role
tabpanel
aria-labelledby
v-pills-home-tab
tabindex
class
tab-pane fade
v-pills-profile
role
tabpanel
aria-labelledby
v-pills-profile-tab
tabindex
class
tab-pane fade
v-pills-disabled
role
tabpanel
aria-labelledby
v-pills-disabled-tab
tabindex
class
tab-pane fade
v-pills-messages
role
tabpanel
aria-labelledby
v-pills-messages-tab
tabindex
class
tab-pane fade
v-pills-settings
role
tabpanel
aria-labelledby
v-pills-settings-tab
tabindex
Accessibility
Dynamic tabbed interfaces, as described in the
ARIA Authoring Practices Guide tabs pattern
, require
role="tablist"
role="tab"
role="tabpanel"
, and additional
aria-
attributes in order to convey their structure, functionality, and current state to users of assistive technologies (such as screen readers). As a best practice, we recommend using
<button>
elements for the tabs, as these are controls that trigger a dynamic change, rather than links that navigate to a new page or location.
In line with the ARIA Authoring Practices pattern, only the currently active tab receives keyboard focus. When the JavaScript plugin is initialized, it will set
tabindex="-1"
on all inactive tab controls. Once the currently active tab has focus, the cursor keys activate the previous/next tab. The
Home
keys activate the first and last tabs, respectively. The plugin will change the
roving
tabindex
accordingly. However, note that the JavaScript plugin does not distinguish between horizontal and vertical tab lists when it comes to cursor key interactions: regardless of the tab list’s orientation, both the up
left cursor go to the previous tab, and down
right cursor go to the next tab.
In general, to facilitate keyboard navigation, it’s recommended to make the tab panels themselves focusable as well, unless the first element containing meaningful content inside the tab panel is already focusable. The JavaScript plugin does not try to handle this aspect—where appropriate, you’ll need to explicitly make your tab panels focusable by adding
tabindex="0"
in your markup.
The tab JavaScript plugin
does not
support tabbed interfaces that contain dropdown menus, as these cause both usability and accessibility issues. From a usability perspective, the fact that the currently displayed tab’s trigger element is not immediately visible (as it’s inside the closed dropdown menu) can cause confusion. From an accessibility point of view, there is currently no sensible way to map this sort of construct to a standard WAI ARIA pattern, meaning that it cannot be easily made understandable to users of assistive technologies.
Using data attributes
You can activate a tab or pill navigation without writing any JavaScript by simply specifying
data-bs-toggle="tab"
data-bs-toggle="pill"
on an element. Use these data attributes on
.nav-tabs
.nav-pills
<!-- Nav tabs -->
class
nav nav-tabs
myTab
role
tablist
class
nav-item
role
presentation
button
class
nav-link active
home-tab
data-bs-toggle
data-bs-target
#home
type
button
role
aria-controls
home
aria-selected
true
Home
button
class
nav-item
role
presentation
button
class
nav-link
profile-tab
data-bs-toggle
data-bs-target
#profile
type
button
role
aria-controls
profile
aria-selected
false
Profile
button
class
nav-item
role
presentation
button
class
nav-link
messages-tab
data-bs-toggle
data-bs-target
#messages
type
button
role
aria-controls
messages
aria-selected
false
Messages
button
class
nav-item
role
presentation
button
class
nav-link
settings-tab
data-bs-toggle
data-bs-target
#settings
type
button
role
aria-controls
settings
aria-selected
false
Settings
button
<!-- Tab panes -->
class
tab-content
class
tab-pane active
home
role
tabpanel
aria-labelledby
home-tab
tabindex
class
tab-pane
profile
role
tabpanel
aria-labelledby
profile-tab
tabindex
class
tab-pane
messages
role
tabpanel
aria-labelledby
messages-tab
tabindex
class
tab-pane
settings
role
tabpanel
aria-labelledby
settings-tab
tabindex
Via JavaScript
Enable tabbable tabs via JavaScript (each tab needs to be activated individually):
const
triggerTabList
document
querySelectorAll
'#myTab button'
triggerTabList
forEach
triggerEl
const
tabTrigger
triggerEl
triggerEl
addEventListener
'click'
event
event
preventDefault
tabTrigger
show
You can activate individual tabs in several ways:
const
triggerEl
document
querySelector
'#myTab button[data-bs-target="#profile"]'
getInstance
triggerEl
show
// Select tab by name
const
triggerFirstTabEl
document
querySelector
'#myTab li:first-child button'
getInstance
triggerFirstTabEl
show
// Select first tab
Fade effect
To make tabs fade in, add
.fade
to each
.tab-pane
. The first tab pane must also have
.show
to make the initial content visible.
class
tab-content
class
tab-pane fade show active
home
role
tabpanel
aria-labelledby
home-tab
tabindex
class
tab-pane fade
profile
role
tabpanel
aria-labelledby
profile-tab
tabindex
class
tab-pane fade
messages
role
tabpanel
aria-labelledby
messages-tab
tabindex
class
tab-pane fade
settings
role
tabpanel
aria-labelledby
settings-tab
tabindex
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Activates your content as a tab element.
You can create a tab instance with the constructor, for example:
const
bsTab
'#myTab'
Method
Description
dispose
Destroys an element’s tab.
getInstance
Static method which allows you to get the tab instance associated with a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a tab instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
show
Selects the given tab and shows its associated pane. Any other tab that was previously selected becomes unselected and its associated pane is hidden.
Returns to the caller before the tab pane has actually been shown
(i.e. before the
shown.bs.tab
event occurs).
Events
When showing a new tab, the events fire in the following order:
hide.bs.tab
(on the current active tab)
show.bs.tab
(on the to-be-shown tab)
hidden.bs.tab
(on the previous active tab, the same one as for the
hide.bs.tab
event)
shown.bs.tab
(on the newly-active just-shown tab, the same one as for the
show.bs.tab
event)
If no tab was already active, then the
hide.bs.tab
hidden.bs.tab
events will not be fired.
Event type
Description
hide.bs.tab
This event fires when a new tab is to be shown (and thus the previous active tab is to be hidden). Use
event.target
event.relatedTarget
to target the current active tab and the new soon-to-be-active tab, respectively.
hidden.bs.tab
This event fires after a new tab is shown (and thus the previous active tab is hidden). Use
event.target
event.relatedTarget
to target the previous active tab and the new active tab, respectively.
show.bs.tab
This event fires on tab show, but before the new tab has been shown. Use
event.target
event.relatedTarget
to target the active tab and the previous active tab (if available) respectively.
shown.bs.tab
This event fires on tab show after a tab has been shown. Use
event.target
event.relatedTarget
to target the active tab and the previous active tab (if available) respectively.
const
tabEl
document
querySelector
'button[data-bs-toggle="tab"]'
tabEl
addEventListener
'shown.bs.tab'
event
event
target
// newly activated tab
event
relatedTarget
// previous active tab


--- 029_components_breadcrumb.txt ---
URL: https://getbootstrap.com/docs/5.3/components/breadcrumb
--------------------------------------------------
Example
Use an ordered or unordered list with linked list items to create a minimally styled breadcrumb. Use our utilities to add additional styles as desired.
html
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item active
aria-current
page
Home
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item
href
Home
class
breadcrumb-item active
aria-current
page
Library
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item
href
Home
class
breadcrumb-item
href
Library
class
breadcrumb-item active
aria-current
page
Data
Dividers
Dividers are automatically added in CSS through
::before
content
. They can be changed by modifying a local CSS custom property
--bs-breadcrumb-divider
, or through the
$breadcrumb-divider
Sass variable — and
$breadcrumb-divider-flipped
for its RTL counterpart, if needed. We default to our Sass variable, which is set as a fallback to the custom property. This way, you get a global divider that you can override without recompiling CSS at any time.
html
style
--bs-breadcrumb-divider
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item
href
Home
class
breadcrumb-item active
aria-current
page
Library
When modifying via Sass, the
quote
function is required to generate the quotes around a string. For example, using
as the divider, you can use this:
$breadcrumb-divider
quote
It’s also possible to use an
embedded SVG icon
. Apply it via our CSS custom property, or use the Sass variable.
Inlined SVG requires properly escaped characters.
Some reserved characters, such as
, must be URL-encoded or escaped. We do this with the
$breadcrumb-divider
variable using our
escape-svg()
Sass function
. When customizing the CSS variable, you must handle this yourself. Read
Kevin Weber’s explanations on CodePen
for more info.
html
style
--bs-breadcrumb-divider
&#34
data
image/svg+xml
%3Csvg xmlns=
'http://www.w3.org/2000/svg'
width=
height=
%3E%3Cpath d=
'M2.5 0L1 1.5 3.5 4 1 6.5 2.5 8l4-4-4-4z'
fill=
'%236c757d'
/%3E%3C/svg%3E&#34
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item
href
Home
class
breadcrumb-item active
aria-current
page
Library
$breadcrumb-divider
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' width='8' height='8'><path d='M2.5 0L1 1.5 3.5 4 1 6.5 2.5 8l4-4-4-4z' fill='#{$breadcrumb-divider-color}'/></svg>"
You can also remove the divider setting
--bs-breadcrumb-divider: '';
(empty strings in CSS custom properties counts as a value), or setting the Sass variable to
$breadcrumb-divider: none;
html
style
--bs-breadcrumb-divider
aria-label
breadcrumb
class
breadcrumb
class
breadcrumb-item
href
Home
class
breadcrumb-item active
aria-current
page
Library
$breadcrumb-divider
none
Accessibility
Since breadcrumbs provide a navigation, it’s a good idea to add a meaningful label such as
aria-label="breadcrumb"
to describe the type of navigation provided in the
<nav>
element, as well as applying an
aria-current="page"
to the last item of the set to indicate that it represents the current page.
For more information, see the
ARIA Authoring Practices Guide breadcrumb pattern
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, breadcrumbs now use local CSS variables on
.breadcrumb
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_breadcrumb.scss
#{$prefix}
breadcrumb-padding-x
#{$breadcrumb-padding-x}
#{$prefix}
breadcrumb-padding-y
#{$breadcrumb-padding-y}
#{$prefix}
breadcrumb-margin-bottom
#{$breadcrumb-margin-bottom}
@include
$breadcrumb-font-size
#{$prefix}
breadcrumb-font-size
#{$prefix}
breadcrumb-bg
#{$breadcrumb-bg}
#{$prefix}
breadcrumb-border-radius
#{$breadcrumb-border-radius}
#{$prefix}
breadcrumb-divider-color
#{$breadcrumb-divider-color}
#{$prefix}
breadcrumb-item-padding-x
#{$breadcrumb-item-padding-x}
#{$prefix}
breadcrumb-item-active-color
#{$breadcrumb-active-color}
Sass variables
scss/_variables.scss
$breadcrumb-font-size
null
$breadcrumb-padding-y
$breadcrumb-padding-x
$breadcrumb-item-padding-x
.5rem
$breadcrumb-margin-bottom
1rem
$breadcrumb-bg
null
$breadcrumb-divider-color
#{$prefix}
secondary-color
$breadcrumb-active-color
#{$prefix}
secondary-color
$breadcrumb-divider
quote
$breadcrumb-divider-flipped
$breadcrumb-divider
$breadcrumb-border-radius
null


--- 030_components_badge.txt ---
URL: https://getbootstrap.com/docs/5.3/components/badge
--------------------------------------------------
Examples
Badges scale to match the size of the immediate parent element by using relative font sizing and
units. As of v5, badges no longer have focus or hover styles for links.
Headings
Example heading
Example heading
Example heading
Example heading
Example heading
Example heading
html
Example heading
span
class
badge text-bg-secondary
span
Example heading
span
class
badge text-bg-secondary
span
Example heading
span
class
badge text-bg-secondary
span
Example heading
span
class
badge text-bg-secondary
span
Example heading
span
class
badge text-bg-secondary
span
Example heading
span
class
badge text-bg-secondary
span
Buttons
Badges can be used as part of links or buttons to provide a counter.
Notifications
html
button
type
button
class
btn btn-primary
Notifications
span
class
badge text-bg-secondary
span
button
Note that depending on how they are used, badges may be confusing for users of screen readers and similar assistive technologies. While the styling of badges provides a visual cue as to their purpose, these users will simply be presented with the content of the badge. Depending on the specific situation, these badges may seem like random additional words or numbers at the end of a sentence, link, or button.
Unless the context is clear (as with the “Notifications” example, where it is understood that the “4” is the number of notifications), consider including additional context with a visually hidden piece of additional text.
Positioned
Use utilities to modify a
.badge
and position it in the corner of a link or button.
Inbox
unread messages
html
button
type
button
class
btn btn-primary position-relative
Inbox
span
class
position-absolute top-0 start-100 translate-middle badge rounded-pill bg-danger
span
class
visually-hidden
unread messages
span
span
button
You can also replace the
.badge
class with a few more utilities without a count for a more generic indicator.
Profile
New alerts
html
button
type
button
class
btn btn-primary position-relative
Profile
span
class
position-absolute top-0 start-100 translate-middle p-2 bg-danger border border-light rounded-circle
span
class
visually-hidden
New alerts
span
span
button
Background colors
Added in v5.2.0
Set a
background-color
with contrasting foreground
color
with
.text-bg-{color}
helpers
. Previously it was required to manually pair your choice of
.text-{color}
.bg-{color}
utilities for styling, which you still may use if you prefer.
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
html
span
class
badge text-bg-primary
Primary
span
span
class
badge text-bg-secondary
Secondary
span
span
class
badge text-bg-success
Success
span
span
class
badge text-bg-danger
Danger
span
span
class
badge text-bg-warning
Warning
span
span
class
badge text-bg-info
Info
span
span
class
badge text-bg-light
Light
span
span
class
badge text-bg-dark
Dark
span
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Pill badges
Use the
.rounded-pill
utility class to make badges more rounded with a larger
border-radius
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
html
span
class
badge rounded-pill text-bg-primary
Primary
span
span
class
badge rounded-pill text-bg-secondary
Secondary
span
span
class
badge rounded-pill text-bg-success
Success
span
span
class
badge rounded-pill text-bg-danger
Danger
span
span
class
badge rounded-pill text-bg-warning
Warning
span
span
class
badge rounded-pill text-bg-info
Info
span
span
class
badge rounded-pill text-bg-light
Light
span
span
class
badge rounded-pill text-bg-dark
Dark
span
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, badges now use local CSS variables on
.badge
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_badge.scss
#{$prefix}
badge-padding-x
#{$badge-padding-x}
#{$prefix}
badge-padding-y
#{$badge-padding-y}
@include
$badge-font-size
#{$prefix}
badge-font-size
#{$prefix}
badge-font-weight
#{$badge-font-weight}
#{$prefix}
badge-color
#{$badge-color}
#{$prefix}
badge-border-radius
#{$badge-border-radius}
Sass variables
scss/_variables.scss
$badge-font-size
.75em
$badge-font-weight
$font-weight-bold
$badge-color
$white
$badge-padding-y
.35em
$badge-padding-x
.65em
$badge-border-radius
#{$prefix}
border-radius


--- 038_components_dropdowns.txt ---
URL: https://getbootstrap.com/docs/5.3/components/dropdowns
--------------------------------------------------
Overview
Dropdowns are toggleable, contextual overlays for displaying lists of links and more. They’re made interactive with the included Bootstrap dropdown JavaScript plugin. They’re toggled by clicking, not by hovering; this is
an intentional design decision
Dropdowns are built on a third party library,
Popper
, which provides dynamic positioning and viewport detection. Be sure to include
popper.min.js
before Bootstrap’s JavaScript or use
which contains Popper. Popper isn’t used to position dropdowns in navbars though as dynamic positioning isn’t required.
Accessibility
ARIA
standard defines an actual
role="menu"
widget
, but this is specific to application-like menus which trigger actions or functions.
ARIA
menus can only contain menu items, checkbox menu items, radio button menu items, radio button groups, and sub-menus.
role
aria-
attributes required for true
ARIA
menus. Authors will have to include these more specific attributes themselves.
However, Bootstrap does add built-in support for most standard keyboard menu interactions, such as the ability to move through individual
.dropdown-item
elements using the cursor keys and close the menu with the
key.
Examples
Wrap the dropdown’s toggle (your button or link) and the dropdown menu within
.dropdown
, or another element that declares
position: relative;
. Ideally, you should use a
<button>
element as the dropdown trigger, but the plugin will work with
elements as well. The examples shown here use semantic
<ul>
elements where appropriate, but custom markup is supported.
Single button
Any single
.btn
can be turned into a dropdown toggle with some markup changes. Here’s how you can put them to work with
<button>
elements:
Dropdown button
Action
Another action
Something else here
html
class
dropdown
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown button
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
While
<button>
is the recommended control for a dropdown toggle, there might be situations where you have to use an
element. If you do, we recommend adding a
role="button"
attribute to appropriately convey control’s purpose to assistive technologies such as screen readers.
Dropdown link
Action
Another action
Something else here
html
class
dropdown
class
btn btn-secondary dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown link
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
The best part is you can do this with any button variant, too:
Primary
Action
Another action
Something else here
Separated link
Secondary
Action
Another action
Something else here
Separated link
Success
Action
Another action
Something else here
Separated link
Info
Action
Another action
Something else here
Separated link
Warning
Action
Another action
Something else here
Separated link
Danger
Action
Another action
Something else here
Separated link
<!-- Example single danger button -->
class
btn-group
button
type
button
class
btn btn-danger dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Danger
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Split button
Similarly, create split button dropdowns with virtually the same markup as single button dropdowns, but with the addition of
.dropdown-toggle-split
for proper spacing around the dropdown caret.
We use this extra class to reduce the horizontal
padding
on either side of the caret by 25% and remove the
margin-left
that’s added for regular button dropdowns. Those extra changes keep the caret centered in the split button and provide a more appropriately sized hit area next to the main button.
Primary
Toggle Dropdown
Action
Another action
Something else here
Separated link
Secondary
Toggle Dropdown
Action
Another action
Something else here
Separated link
Success
Toggle Dropdown
Action
Another action
Something else here
Separated link
Info
Toggle Dropdown
Action
Another action
Something else here
Separated link
Warning
Toggle Dropdown
Action
Another action
Something else here
Separated link
Danger
Toggle Dropdown
Action
Another action
Something else here
Separated link
<!-- Example split danger button -->
class
btn-group
button
type
button
class
btn btn-danger
Danger
button
button
type
button
class
btn btn-danger dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Sizing
Button dropdowns work with buttons of all sizes, including default and split dropdown buttons.
Large button
Action
Another action
Something else here
Separated link
Large split button
Toggle Dropdown
Action
Another action
Something else here
Separated link
<!-- Large button groups (default and split) -->
class
btn-group
button
class
btn btn-secondary btn-lg dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Large button
button
class
dropdown-menu
class
btn-group
button
class
btn btn-secondary btn-lg
type
button
Large split button
button
button
type
button
class
btn btn-lg btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
Small button
Action
Another action
Something else here
Separated link
Small split button
Toggle Dropdown
Action
Another action
Something else here
Separated link
class
btn-group
button
class
btn btn-secondary btn-sm dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Small button
button
class
dropdown-menu
class
btn-group
button
class
btn btn-secondary btn-sm
type
button
Small split button
button
button
type
button
class
btn btn-sm btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
Dark dropdowns
Deprecated in v5.3.0
Opt into darker dropdowns to match a dark navbar or custom style by adding
.dropdown-menu-dark
onto an existing
.dropdown-menu
. No changes are required to the dropdown items.
Heads up!
Dark variants for components were deprecated in v5.3.0 with the introduction of color modes.
Instead of adding
.dropdown-menu-dark
, set
data-bs-theme="dark"
on the root element, a parent
wrapper, or the component itself.
Dropdown button
Action
Another action
Something else here
Separated link
html
class
dropdown
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown button
button
class
dropdown-menu dropdown-menu-dark
class
dropdown-item active
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
And putting it to use in a navbar:
html
class
navbar navbar-expand-lg navbar-dark bg-dark
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarNavDarkDropdown
aria-controls
navbarNavDarkDropdown
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarNavDarkDropdown
class
navbar-nav
class
nav-item dropdown
button
class
btn btn-dark dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu dropdown-menu-dark
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
Directions
Directions are flipped in RTL mode.
As such,
.dropstart
will appear on the right side.
Centered
Make the dropdown menu centered below the toggle with
.dropdown-center
on the parent element.
Centered dropdown
Action
Action two
Action three
html
class
dropdown-center
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Centered dropdown
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Action two
class
dropdown-item
href
Action three
Dropup
Trigger dropdown menus above elements by adding
.dropup
to the parent element.
Dropup
Action
Another action
Something else here
Separated link
Split dropup
Toggle Dropdown
Action
Another action
Something else here
Separated link
<!-- Default dropup button -->
class
btn-group dropup
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropup
button
class
dropdown-menu
<!-- Dropdown menu links -->
<!-- Split dropup button -->
class
btn-group dropup
button
type
button
class
btn btn-secondary
Split dropup
button
button
type
button
class
btn btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
<!-- Dropdown menu links -->
Dropup centered
Make the dropup menu centered above the toggle with
.dropup-center
on the parent element.
Centered dropup
Action
Action two
Action three
html
class
dropup-center dropup
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Centered dropup
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Action two
class
dropdown-item
href
Action three
Dropend
Trigger dropdown menus at the right of the elements by adding
.dropend
to the parent element.
Dropend
Action
Another action
Something else here
Separated link
Split dropend
Toggle Dropend
Action
Another action
Something else here
Separated link
<!-- Default dropend button -->
class
btn-group dropend
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropend
button
class
dropdown-menu
<!-- Dropdown menu links -->
<!-- Split dropend button -->
class
btn-group dropend
button
type
button
class
btn btn-secondary
Split dropend
button
button
type
button
class
btn btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropend
span
button
class
dropdown-menu
<!-- Dropdown menu links -->
Dropstart
Trigger dropdown menus at the left of the elements by adding
.dropstart
to the parent element.
Dropstart
Action
Another action
Something else here
Separated link
Toggle Dropstart
Action
Another action
Something else here
Separated link
Split dropstart
<!-- Default dropstart button -->
class
btn-group dropstart
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropstart
button
class
dropdown-menu
<!-- Dropdown menu links -->
<!-- Split dropstart button -->
class
btn-group dropstart
button
type
button
class
btn btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
span
class
visually-hidden
Toggle Dropstart
span
button
class
dropdown-menu
<!-- Dropdown menu links -->
button
type
button
class
btn btn-secondary
Split dropstart
button
Menu items
You can use
<button>
elements as dropdown items.
Dropdown
Action
Another action
Something else here
html
class
dropdown
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
button
class
dropdown-item
type
button
Action
button
button
class
dropdown-item
type
button
Another action
button
button
class
dropdown-item
type
button
Something else here
button
You can also create non-interactive dropdown items with
.dropdown-item-text
. Feel free to style further with custom CSS or text utilities.
Dropdown item text
Action
Another action
Something else here
html
class
dropdown-menu
span
class
dropdown-item-text
Dropdown item text
span
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
Active
.active
to items in the dropdown to
style them as active
. To convey the active state to assistive technologies, use the
aria-current
attribute — using the
page
value for the current page, or
true
for the current item in a set.
Regular link
Active link
Another link
html
class
dropdown-menu
class
dropdown-item
href
Regular link
class
dropdown-item active
href
aria-current
true
Active link
class
dropdown-item
href
Another link
Disabled
.disabled
to items in the dropdown to
style them as disabled
Regular link
Disabled link
Another link
html
class
dropdown-menu
class
dropdown-item
href
Regular link
class
dropdown-item disabled
aria-disabled
true
Disabled link
class
dropdown-item
href
Another link
Menu alignment
By default, a dropdown menu is automatically positioned 100% from the top and along the left side of its parent. You can change this with the directional
.drop*
classes, but you can also control them with additional modifier classes.
.dropdown-menu-end
to a
.dropdown-menu
to right align the dropdown menu. Directions are mirrored when using Bootstrap in RTL, meaning
.dropdown-menu-end
will appear on the left side.
Heads up!
Dropdowns are positioned thanks to Popper except when they are contained in a navbar.
Right-aligned menu example
Action
Another action
Something else here
html
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Right-aligned menu example
button
class
dropdown-menu dropdown-menu-end
button
class
dropdown-item
type
button
Action
button
button
class
dropdown-item
type
button
Another action
button
button
class
dropdown-item
type
button
Something else here
button
Responsive alignment
If you want to use responsive alignment, disable dynamic positioning by adding the
data-bs-display="static"
attribute and use the responsive variation classes.
To align
right
the dropdown menu with the given breakpoint or larger, add
.dropdown-menu{-sm|-md|-lg|-xl|-xxl}-end
Left-aligned but right aligned when large screen
Action
Another action
Something else here
html
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
data-bs-display
static
aria-expanded
false
Left-aligned but right aligned when large screen
button
class
dropdown-menu dropdown-menu-lg-end
button
class
dropdown-item
type
button
Action
button
button
class
dropdown-item
type
button
Another action
button
button
class
dropdown-item
type
button
Something else here
button
To align
left
the dropdown menu with the given breakpoint or larger, add
.dropdown-menu-end
.dropdown-menu{-sm|-md|-lg|-xl|-xxl}-start
Right-aligned but left aligned when large screen
Action
Another action
Something else here
html
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
data-bs-display
static
aria-expanded
false
Right-aligned but left aligned when large screen
button
class
dropdown-menu dropdown-menu-end dropdown-menu-lg-start
button
class
dropdown-item
type
button
Action
button
button
class
dropdown-item
type
button
Another action
button
button
class
dropdown-item
type
button
Something else here
button
Note that you don’t need to add a
data-bs-display="static"
attribute to dropdown buttons in navbars, since Popper isn’t used in navbars.
Alignment options
Taking most of the options shown above, here’s a small kitchen sink demo of various dropdown alignment options in one place.
Dropdown
Menu item
Menu item
Menu item
Right-aligned menu
Menu item
Menu item
Menu item
Left-aligned, right-aligned lg
Menu item
Menu item
Menu item
Right-aligned, left-aligned lg
Menu item
Menu item
Menu item
Dropstart
Menu item
Menu item
Menu item
Dropend
Menu item
Menu item
Menu item
Dropup
Menu item
Menu item
Menu item
html
class
btn-group
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Right-aligned menu
button
class
dropdown-menu dropdown-menu-end
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
data-bs-display
static
aria-expanded
false
Left-aligned, right-aligned lg
button
class
dropdown-menu dropdown-menu-lg-end
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
data-bs-display
static
aria-expanded
false
Right-aligned, left-aligned lg
button
class
dropdown-menu dropdown-menu-end dropdown-menu-lg-start
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group dropstart
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropstart
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group dropend
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropend
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group dropup
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropup
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
Menu content
Headers
Add a header to label sections of actions in any dropdown menu.
Dropdown header
Action
Another action
html
class
dropdown-menu
class
dropdown-header
Dropdown header
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
Dividers
Separate groups of related menu items with a divider.
Action
Another action
Something else here
Separated link
html
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Text
Place any freeform text within a dropdown menu with text and use
spacing utilities
. Note that you’ll likely need additional sizing styles to constrain the menu width.
Some example text that’s free-flowing within the dropdown menu.
And this is more example text.
html
class
dropdown-menu p-4 text-body-secondary
style
max-width
200px
Some example text that’s free-flowing within the dropdown menu.
class
mb-0
And this is more example text.
Forms
Put a form within a dropdown menu, or make it into a dropdown menu, and use
margin or padding utilities
to give it the negative space you require.
Email address
Password
Remember me
Sign in
New around here? Sign up
Forgot password?
html
class
dropdown-menu
form
class
px-4 py-3
class
mb-3
label
exampleDropdownFormEmail1
class
form-label
Email address
label
input
type
email
class
form-control
exampleDropdownFormEmail1
placeholder
email@example.com
class
mb-3
label
exampleDropdownFormPassword1
class
form-label
Password
label
input
type
password
class
form-control
exampleDropdownFormPassword1
placeholder
Password
class
mb-3
class
form-check
input
type
checkbox
class
form-check-input
dropdownCheck
label
class
form-check-label
dropdownCheck
Remember me
label
button
type
submit
class
btn btn-primary
Sign in
button
form
class
dropdown-divider
class
dropdown-item
href
New around here? Sign up
class
dropdown-item
href
Forgot password?
Dropdown form
Email address
Password
Remember me
Sign in
html
class
dropdown
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
data-bs-auto-close
outside
Dropdown form
button
form
class
dropdown-menu p-4
class
mb-3
label
exampleDropdownFormEmail2
class
form-label
Email address
label
input
type
email
class
form-control
exampleDropdownFormEmail2
placeholder
email@example.com
class
mb-3
label
exampleDropdownFormPassword2
class
form-label
Password
label
input
type
password
class
form-control
exampleDropdownFormPassword2
placeholder
Password
class
mb-3
class
form-check
input
type
checkbox
class
form-check-input
dropdownCheck2
label
class
form-check-label
dropdownCheck2
Remember me
label
button
type
submit
class
btn btn-primary
Sign in
button
form
Dropdown options
data-bs-offset
data-bs-reference
to change the location of the dropdown.
Offset
Action
Another action
Something else here
Reference
Toggle Dropdown
Action
Another action
Something else here
Separated link
html
class
d-flex
class
dropdown me-1
button
type
button
class
btn btn-secondary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
data-bs-offset
10,20
Offset
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
btn-group
button
type
button
class
btn btn-secondary
Reference
button
button
type
button
class
btn btn-secondary dropdown-toggle dropdown-toggle-split
data-bs-toggle
dropdown
aria-expanded
false
data-bs-reference
parent
span
class
visually-hidden
Toggle Dropdown
span
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
Auto close behavior
By default, the dropdown menu is closed when clicking inside or outside the dropdown menu. You can use the
autoClose
option to change this behavior of the dropdown.
Default dropdown
Menu item
Menu item
Menu item
Clickable inside
Menu item
Menu item
Menu item
Clickable outside
Menu item
Menu item
Menu item
Manual close
Menu item
Menu item
Menu item
html
class
btn-group
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
data-bs-auto-close
true
aria-expanded
false
Default dropdown
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
data-bs-auto-close
inside
aria-expanded
false
Clickable inside
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
data-bs-auto-close
outside
aria-expanded
false
Clickable outside
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
btn-group
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
data-bs-auto-close
false
aria-expanded
false
Manual close
button
class
dropdown-menu
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
class
dropdown-item
href
Menu item
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, dropdowns now use local CSS variables on
.dropdown-menu
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_dropdown.scss
#{$prefix}
dropdown-zindex
#{$zindex-dropdown}
#{$prefix}
dropdown-min-width
#{$dropdown-min-width}
#{$prefix}
dropdown-padding-x
#{$dropdown-padding-x}
#{$prefix}
dropdown-padding-y
#{$dropdown-padding-y}
#{$prefix}
dropdown-spacer
#{$dropdown-spacer}
@include
$dropdown-font-size
#{$prefix}
dropdown-font-size
#{$prefix}
dropdown-color
#{$dropdown-color}
#{$prefix}
dropdown-bg
#{$dropdown-bg}
#{$prefix}
dropdown-border-color
#{$dropdown-border-color}
#{$prefix}
dropdown-border-radius
#{$dropdown-border-radius}
#{$prefix}
dropdown-border-width
#{$dropdown-border-width}
#{$prefix}
dropdown-inner-border-radius
#{$dropdown-inner-border-radius}
#{$prefix}
dropdown-divider-bg
#{$dropdown-divider-bg}
#{$prefix}
dropdown-divider-margin-y
#{$dropdown-divider-margin-y}
#{$prefix}
dropdown-box-shadow
#{$dropdown-box-shadow}
#{$prefix}
dropdown-link-color
#{$dropdown-link-color}
#{$prefix}
dropdown-link-hover-color
#{$dropdown-link-hover-color}
#{$prefix}
dropdown-link-hover-bg
#{$dropdown-link-hover-bg}
#{$prefix}
dropdown-link-active-color
#{$dropdown-link-active-color}
#{$prefix}
dropdown-link-active-bg
#{$dropdown-link-active-bg}
#{$prefix}
dropdown-link-disabled-color
#{$dropdown-link-disabled-color}
#{$prefix}
dropdown-item-padding-x
#{$dropdown-item-padding-x}
#{$prefix}
dropdown-item-padding-y
#{$dropdown-item-padding-y}
#{$prefix}
dropdown-header-color
#{$dropdown-header-color}
#{$prefix}
dropdown-header-padding-x
#{$dropdown-header-padding-x}
#{$prefix}
dropdown-header-padding-y
#{$dropdown-header-padding-y}
Dropdown items include at least one variable that is not set on
.dropdown
. This allows you to provide a new value while Bootstrap defaults to a fallback value.
--bs-dropdown-item-border-radius
Customization through CSS variables can be seen on the
.dropdown-menu-dark
class where we override specific values without adding duplicate CSS selectors.
scss/_dropdown.scss
#{$prefix}
dropdown-color
#{$dropdown-dark-color}
#{$prefix}
dropdown-bg
#{$dropdown-dark-bg}
#{$prefix}
dropdown-border-color
#{$dropdown-dark-border-color}
#{$prefix}
dropdown-box-shadow
#{$dropdown-dark-box-shadow}
#{$prefix}
dropdown-link-color
#{$dropdown-dark-link-color}
#{$prefix}
dropdown-link-hover-color
#{$dropdown-dark-link-hover-color}
#{$prefix}
dropdown-divider-bg
#{$dropdown-dark-divider-bg}
#{$prefix}
dropdown-link-hover-bg
#{$dropdown-dark-link-hover-bg}
#{$prefix}
dropdown-link-active-color
#{$dropdown-dark-link-active-color}
#{$prefix}
dropdown-link-active-bg
#{$dropdown-dark-link-active-bg}
#{$prefix}
dropdown-link-disabled-color
#{$dropdown-dark-link-disabled-color}
#{$prefix}
dropdown-header-color
#{$dropdown-dark-header-color}
Sass variables
Variables for all dropdowns:
scss/_variables.scss
$dropdown-min-width
10rem
$dropdown-padding-x
$dropdown-padding-y
.5rem
$dropdown-spacer
.125rem
$dropdown-font-size
$font-size-base
$dropdown-color
#{$prefix}
body-color
$dropdown-bg
#{$prefix}
body-bg
$dropdown-border-color
#{$prefix}
border-color-translucent
$dropdown-border-radius
#{$prefix}
border-radius
$dropdown-border-width
#{$prefix}
border-width
$dropdown-inner-border-radius
calc
#{$dropdown-border-radius}
#{$dropdown-border-width}
// stylelint-disable-line function-disallowed-list
$dropdown-divider-bg
$dropdown-border-color
$dropdown-divider-margin-y
$spacer
$dropdown-box-shadow
#{$prefix}
box-shadow
$dropdown-link-color
#{$prefix}
body-color
$dropdown-link-hover-color
$dropdown-link-color
$dropdown-link-hover-bg
#{$prefix}
tertiary-bg
$dropdown-link-active-color
$component-active-color
$dropdown-link-active-bg
$component-active-bg
$dropdown-link-disabled-color
#{$prefix}
tertiary-color
$dropdown-item-padding-y
$spacer
$dropdown-item-padding-x
$spacer
$dropdown-header-color
$gray-600
$dropdown-header-padding-x
$dropdown-item-padding-x
$dropdown-header-padding-y
$dropdown-padding-y
// fusv-disable
$dropdown-header-padding
$dropdown-header-padding-y
$dropdown-header-padding-x
// Deprecated in v5.2.0
// fusv-enable
Variables for the
dark dropdown
scss/_variables.scss
$dropdown-dark-color
$gray-300
$dropdown-dark-bg
$gray-800
$dropdown-dark-border-color
$dropdown-border-color
$dropdown-dark-divider-bg
$dropdown-divider-bg
$dropdown-dark-box-shadow
null
$dropdown-dark-link-color
$dropdown-dark-color
$dropdown-dark-link-hover-color
$white
$dropdown-dark-link-hover-bg
rgba
$white
$dropdown-dark-link-active-color
$dropdown-link-active-color
$dropdown-dark-link-active-bg
$dropdown-link-active-bg
$dropdown-dark-link-disabled-color
$gray-500
$dropdown-dark-header-color
$gray-500
Variables for the CSS-based carets that indicate a dropdown’s interactivity:
scss/_variables.scss
$caret-width
.3em
$caret-vertical-align
$caret-width
$caret-spacing
$caret-width
Sass mixins
Mixins are used to generate the CSS-based carets and can be found in
scss/mixins/_caret.scss
scss/mixins/_caret.scss
@mixin
caret-down
$width
$caret-width
border-top
$width
solid
border-right
$width
solid transparent
border-bottom
border-left
$width
solid transparent
@mixin
caret-up
$width
$caret-width
border-top
border-right
$width
solid transparent
border-bottom
$width
solid
border-left
$width
solid transparent
@mixin
caret-end
$width
$caret-width
border-top
$width
solid transparent
border-right
border-bottom
$width
solid transparent
border-left
$width
solid
@mixin
caret-start
$width
$caret-width
border-top
$width
solid transparent
border-right
$width
solid
border-bottom
$width
solid transparent
@mixin
caret
$direction
down
$width
$caret-width
$spacing
$caret-spacing
$vertical-align
$caret-vertical-align
$enable-caret
::after
display
inline-block
margin-left
$spacing
vertical-align
$vertical-align
content
$direction
== down
@include
caret-down
$width
@else if
$direction
== up
@include
caret-up
$width
@else if
$direction
== end
@include
caret-end
$width
$direction
== start
::after
display
none
::before
display
inline-block
margin-right
$spacing
vertical-align
$vertical-align
content
@include
caret-start
$width
:empty::after
margin-left
Usage
Via data attributes or JavaScript, the dropdown plugin toggles hidden content (dropdown menus) by toggling the
.show
class on the parent
.dropdown-menu
. The
data-bs-toggle="dropdown"
attribute is relied on for closing dropdown menus at an application level, so it’s a good idea to always use it.
On touch-enabled devices, opening a dropdown adds empty
mouseover
handlers to the immediate children of the
<body>
element. This admittedly ugly hack is necessary to work around a
quirk in iOs’ event delegation
, which would otherwise prevent a tap anywhere outside of the dropdown from triggering the code that closes the dropdown. Once the dropdown is closed, these additional empty
mouseover
handlers are removed.
Via data attributes
data-bs-toggle="dropdown"
to a link or button to toggle a dropdown.
class
dropdown
button
type
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown trigger
button
class
dropdown-menu
Via JavaScript
Dropdowns must have
data-bs-toggle="dropdown"
on their trigger element, regardless of whether you call your dropdown via JavaScript or use the data-api.
Call the dropdowns via JavaScript:
const
dropdownElementList
document
querySelectorAll
'.dropdown-toggle'
const
dropdownList
dropdownElementList
dropdownToggleEl
Dropdown
dropdownToggleEl
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
autoClose
boolean, string
true
Configure the auto close behavior of the dropdown:
true
- the dropdown will be closed by clicking outside or inside the dropdown menu.
false
- the dropdown will be closed by clicking the toggle button and manually calling
hide
toggle
method. (Also will not be closed by pressing
key)
'inside'
- the dropdown will be closed (only) by clicking inside the dropdown menu.
'outside'
- the dropdown will be closed (only) by clicking outside the dropdown menu.
Note: the dropdown can always be closed with the
key.
boundary
string, element
'clippingParents'
Overflow constraint boundary of the dropdown menu (applies only to Popper’s preventOverflow modifier). By default it’s
clippingParents
and can accept an HTMLElement reference (via JavaScript only). For more information refer to Popper’s
detectOverflow docs
display
string
'dynamic'
By default, we use Popper for dynamic positioning. Disable this with
static
offset
array, string, function
[0, 2]
Offset of the dropdown relative to its target. You can pass a string in data attributes with comma separated values like:
data-bs-offset="10,20"
. When a function is used to determine the offset, it is called with an object containing the popper placement, the reference, and popper rects as its first argument. The triggering element DOM node is passed as the second argument. The function must return an array with two numbers:
skidding
distance
. For more information refer to Popper’s
offset docs
popperConfig
null, object, function
null
To change Bootstrap’s default Popper config, see
Popper’s configuration
. When a function is used to create the Popper configuration, it’s called with an object that contains the Bootstrap’s default Popper configuration. It helps you use and merge the default with your own configuration. The function must return a configuration object for Popper.
reference
string, element, object
'toggle'
Reference element of the dropdown menu. Accepts the values of
'toggle'
'parent'
, an HTMLElement reference or an object providing
getBoundingClientRect
. For more information refer to Popper’s
constructor docs
virtual element docs
Using function with
popperConfig
const
dropdown
Dropdown
element
popperConfig
defaultBsPopperConfig
// const newPopperConfig = {...}
// use defaultBsPopperConfig if needed...
// return newPopperConfig
Methods
Method
Description
dispose
Destroys an element’s dropdown. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the dropdown instance associated to a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a dropdown instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
hide
Hides the dropdown menu of a given navbar or tabbed navigation.
show
Shows the dropdown menu of a given navbar or tabbed navigation.
toggle
Toggles the dropdown menu of a given navbar or tabbed navigation.
update
Updates the position of an element’s dropdown.
Events
All dropdown events are fired at the toggling element and then bubbled up. So you can also add event listeners on the
.dropdown-menu
’s parent element.
hide.bs.dropdown
hidden.bs.dropdown
events have a
clickEvent
property (only when the original Event type is
click
) that contains an Event Object for the click event.
Event type
Description
hide.bs.dropdown
Fires immediately when the
hide
instance method has been called.
hidden.bs.dropdown
Fired when the dropdown has finished being hidden from the user and CSS transitions have completed.
show.bs.dropdown
Fires immediately when the
show
instance method is called.
shown.bs.dropdown
Fired when the dropdown has been made visible to the user and CSS transitions have completed.
const
myDropdown
document
getElementById
'myDropdown'
myDropdown
addEventListener
'show.bs.dropdown'
event
// do something...


--- 045_components_placeholders.txt ---
URL: https://getbootstrap.com/docs/5.3/components/placeholders
--------------------------------------------------
About
Placeholders can be used to enhance the experience of your application. They’re built only with HTML and CSS, meaning you don’t need any JavaScript to create them. You will, however, need some custom JavaScript to toggle their visibility. Their appearance, color, and sizing can be easily customized with our utility classes.
Example
In the example below, we take a typical card component and recreate it with placeholders applied to create a “loading card”. Size and proportions are the same between the two.
Placeholder
Card title
Some quick example text to build on the card title and make up the bulk of the card’s content.
Go somewhere
Placeholder
class
card
class
card-img-top
class
card-body
class
card-title
Card title
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
href
class
btn btn-primary
Go somewhere
class
card
aria-hidden
true
class
card-img-top
class
card-body
class
card-title placeholder-glow
span
class
placeholder col-6
span
class
card-text placeholder-glow
span
class
placeholder col-7
span
span
class
placeholder col-4
span
span
class
placeholder col-4
span
span
class
placeholder col-6
span
span
class
placeholder col-8
span
class
btn btn-primary disabled placeholder col-6
aria-disabled
true
How it works
Create placeholders with the
.placeholder
class and a grid column class (e.g.,
.col-6
) to set the
width
. They can replace the text inside an element or be added as a modifier class to an existing component.
We apply additional styling to
.btn
s via
::before
to ensure the
height
is respected. You may extend this pattern for other situations as needed, or add a
&nbsp;
within the element to reflect the height when actual text is rendered in its place.
html
aria-hidden
true
span
class
placeholder col-6
span
class
btn btn-primary disabled placeholder col-4
aria-disabled
true
The use of
aria-hidden="true"
only indicates that the element should be hidden to screen readers. The
loading
behavior of the placeholder depends on how authors will actually use the placeholder styles, how they plan to update things, etc. Some JavaScript code may be needed to
swap
the state of the placeholder and inform AT users of the update.
Width
You can change the
width
through grid column classes, width utilities, or inline styles.
html
span
class
placeholder col-6
span
span
class
placeholder w-75
span
span
class
placeholder
style
width
span
Color
By default, the
placeholder
uses
currentColor
. This can be overridden with a custom color or utility class.
html
span
class
placeholder col-12
span
span
class
placeholder col-12 bg-primary
span
span
class
placeholder col-12 bg-secondary
span
span
class
placeholder col-12 bg-success
span
span
class
placeholder col-12 bg-danger
span
span
class
placeholder col-12 bg-warning
span
span
class
placeholder col-12 bg-info
span
span
class
placeholder col-12 bg-light
span
span
class
placeholder col-12 bg-dark
span
Sizing
The size of
.placeholder
s are based on the typographic style of the parent element. Customize them with sizing modifiers:
.placeholder-lg
.placeholder-sm
, or
.placeholder-xs
html
span
class
placeholder col-12 placeholder-lg
span
span
class
placeholder col-12
span
span
class
placeholder col-12 placeholder-sm
span
span
class
placeholder col-12 placeholder-xs
span
Animation
Animate placeholders with
.placeholder-glow
.placeholder-wave
to better convey the perception of something being
actively
loaded.
html
class
placeholder-glow
span
class
placeholder col-12
span
class
placeholder-wave
span
class
placeholder col-12
span
Sass variables
scss/_variables.scss
$placeholder-opacity-max
$placeholder-opacity-min


--- 046_components_scrollspy.txt ---
URL: https://getbootstrap.com/docs/5.3/components/scrollspy
--------------------------------------------------
How it works
Scrollspy toggles the
.active
class on anchor (
) elements when the element with the
referenced by the anchor’s
href
is scrolled into view. Scrollspy is best used in conjunction with a Bootstrap
nav component
list group
, but it will also work with any anchor elements in the current page. Here’s how it works.
To start, scrollspy requires two things: a navigation, list group, or a simple set of links, plus a scrollable container. The scrollable container can be the
<body>
or a custom element with a set
height
overflow-y: scroll
On the scrollable container, add
data-bs-spy="scroll"
data-bs-target="#navId"
where
navId
is the unique
of the associated navigation. If there is no focusable element inside the element, be sure to also include a
tabindex="0"
to ensure keyboard access.
As you scroll the “spied” container, an
.active
class is added and removed from anchor links within the associated navigation. Links must have resolvable
targets, otherwise they’re ignored. For example, a
<a href="#home">home</a>
must correspond to something in the DOM like
<div id="home"></div>
Target elements that are not visible will be ignored. See the
Non-visible elements
section below.
Examples
Navbar
Scroll the area below the navbar and watch the active class change. Open the dropdown menu and watch the dropdown items be highlighted as well.
First heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Second heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Third heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Fourth heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Fifth heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
navbar-example2
class
navbar bg-body-tertiary px-3 mb-3
class
navbar-brand
href
Navbar
class
nav nav-pills
class
nav-item
class
nav-link
href
#scrollspyHeading1
First
class
nav-item
class
nav-link
href
#scrollspyHeading2
Second
class
nav-item dropdown
class
nav-link dropdown-toggle
data-bs-toggle
dropdown
href
role
button
aria-expanded
false
Dropdown
class
dropdown-menu
class
dropdown-item
href
#scrollspyHeading3
Third
class
dropdown-item
href
#scrollspyHeading4
Fourth
class
dropdown-divider
class
dropdown-item
href
#scrollspyHeading5
Fifth
data-bs-spy
scroll
data-bs-target
#navbar-example2
data-bs-root-margin
0px 0px -40%
data-bs-smooth-scroll
true
class
scrollspy-example bg-body-tertiary p-3 rounded-2
tabindex
scrollspyHeading1
First heading
scrollspyHeading2
Second heading
scrollspyHeading3
Third heading
scrollspyHeading4
Fourth heading
scrollspyHeading5
Fifth heading
Nested nav
Scrollspy also works with nested
.nav
s. If a nested
.nav
.active
, its parents will also be
.active
. Scroll the area next to the navbar and watch the active class change.
Item 1
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 1-1
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 1-2
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 2
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 3
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 3-1
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
Item 3-2
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Keep in mind that the JavaScript plugin tries to pick the right element among all that may be visible. Multiple visible scrollspy targets at the same time may cause some issues.
class
class
col-4
navbar-example3
class
h-100 flex-column align-items-stretch pe-4 border-end
class
nav nav-pills flex-column
class
nav-link
href
#item-1
Item 1
class
nav nav-pills flex-column
class
nav-link ms-3 my-1
href
#item-1-1
Item 1-1
class
nav-link ms-3 my-1
href
#item-1-2
Item 1-2
class
nav-link
href
#item-2
Item 2
class
nav-link
href
#item-3
Item 3
class
nav nav-pills flex-column
class
nav-link ms-3 my-1
href
#item-3-1
Item 3-1
class
nav-link ms-3 my-1
href
#item-3-2
Item 3-2
class
col-8
data-bs-spy
scroll
data-bs-target
#navbar-example3
data-bs-smooth-scroll
true
class
scrollspy-example-2
tabindex
item-1
Item 1
item-1-1
Item 1-1
item-1-2
Item 1-2
item-2
Item 2
item-3
Item 3
item-3-1
Item 3-1
item-3-2
Item 3-2
List group
Scrollspy also works with
.list-group
s. Scroll the area next to the list group and watch the active class change.
Item 1
Item 2
Item 3
Item 4
Item 1
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 2
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 3
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 4
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
class
class
col-4
list-example
class
list-group
class
list-group-item list-group-item-action
href
#list-item-1
Item 1
class
list-group-item list-group-item-action
href
#list-item-2
Item 2
class
list-group-item list-group-item-action
href
#list-item-3
Item 3
class
list-group-item list-group-item-action
href
#list-item-4
Item 4
class
col-8
data-bs-spy
scroll
data-bs-target
#list-example
data-bs-smooth-scroll
true
class
scrollspy-example
tabindex
list-item-1
Item 1
list-item-2
Item 2
list-item-3
Item 3
list-item-4
Item 4
Simple anchors
Scrollspy is not limited to nav components and list groups, so it will work on any
anchor elements in the current document. Scroll the area and watch the
.active
class change.
Item 1
Item 2
Item 3
Item 4
Item 5
Item 1
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 2
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 3
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 4
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Item 5
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It’s repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
class
class
col-4
simple-list-example
class
d-flex flex-column gap-2 simple-list-example-scrollspy text-center
class
p-1 rounded
href
#simple-list-item-1
Item 1
class
p-1 rounded
href
#simple-list-item-2
Item 2
class
p-1 rounded
href
#simple-list-item-3
Item 3
class
p-1 rounded
href
#simple-list-item-4
Item 4
class
p-1 rounded
href
#simple-list-item-5
Item 5
class
col-8
data-bs-spy
scroll
data-bs-target
#simple-list-example
data-bs-offset
data-bs-smooth-scroll
true
class
scrollspy-example
tabindex
simple-list-item-1
Item 1
simple-list-item-2
Item 2
simple-list-item-3
Item 3
simple-list-item-4
Item 4
simple-list-item-5
Item 5
Non-visible elements
Target elements that aren’t visible will be ignored and their corresponding nav items won’t receive an
.active
class. Scrollspy instances initialized in a non-visible wrapper will ignore all target elements. Use the
refresh
method to check for observable elements once the wrapper becomes visible.
document
querySelectorAll
'#nav-tab>[data-bs-toggle="tab"]'
forEach
addEventListener
'shown.bs.tab'
const
target
getAttribute
'data-bs-target'
const
scrollElem
document
querySelector
target
[data-bs-spy="scroll"]
ScrollSpy
getOrCreateInstance
scrollElem
refresh
Usage
Via data attributes
To easily add scrollspy behavior to your topbar navigation, add
data-bs-spy="scroll"
to the element you want to spy on (most typically this would be the
<body>
). Then add the
data-bs-target
attribute with the
or class name of the parent element of any Bootstrap
.nav
component.
body
data-bs-spy
scroll
data-bs-target
#navbar-example
navbar-example
class
nav nav-tabs
role
tablist
body
Via JavaScript
const
scrollSpy
ScrollSpy
document
body
target
'#navbar-example'
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
rootMargin
string
0px 0px -25%
Intersection Observer
rootMargin
valid units, when calculating scroll position.
smoothScroll
boolean
false
Enables smooth scrolling when a user clicks on a link that refers to ScrollSpy observables.
target
string, DOM element
null
Specifies element to apply Scrollspy plugin.
threshold
array
[0.1, 0.5, 1]
IntersectionObserver
threshold
valid input, when calculating scroll position.
Deprecated Options
Up until v5.1.3 we were using
offset
method
options, which are now deprecated and replaced by
rootMargin
To keep backwards compatibility, we will continue to parse a given
offset
rootMargin
, but this feature will be removed in
Methods
Method
Description
dispose
Destroys an element’s scrollspy. (Removes stored data on the DOM element)
getInstance
Static
method to get the scrollspy instance associated with a DOM element.
getOrCreateInstance
Static
method to get the scrollspy instance associated with a DOM element, or to create a new one in case it wasn’t initialized.
refresh
When adding or removing elements in the DOM, you’ll need to call the refresh method.
Here’s an example using the refresh method:
const
dataSpyList
document
querySelectorAll
'[data-bs-spy="scroll"]'
dataSpyList
forEach
dataSpyEl
ScrollSpy
getInstance
dataSpyEl
refresh
Events
Event
Description
activate.bs.scrollspy
This event fires on the scroll element whenever an anchor is activated by the scrollspy.
const
firstScrollSpyEl
document
querySelector
'[data-bs-spy="scroll"]'
firstScrollSpyEl
addEventListener
'activate.bs.scrollspy'
// do something...


--- 047_examples_navbars-offcanvas.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/navbars-offcanvas
--------------------------------------------------
Navbar with offcanvas examples
This example shows how responsive offcanvas menus work within the navbar. For positioning of navbars, checkout the
fixed top
examples.
From the top down, you'll see a dark navbar, light navbar and a responsive navbar—each with offcanvases built in. Resize your browser window to the large breakpoint to see the toggle for the offcanvas.
Learn more about offcanvas navbars »


--- 048_examples_dropdowns.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/dropdowns
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Action
Another action
Something else here
Separated link
Action
Another action
Something else here
Separated link
Action
Another action
Something else here
Separated link
Action
Another action
Something else here
Separated link
Documents
Photos
Movies
Music
Games
Trash
Documents
Photos
Movies
Music
Games
Trash
June
January
February
March
April
June
July
August
September
October
November
December
June
January
February
March
April
June
July
August
September
October
November
December


--- 050_components_close-button.txt ---
URL: https://getbootstrap.com/docs/5.3/components/close-button
--------------------------------------------------
Example
Provide an option to dismiss or close a component with
.btn-close
. Default styling is limited, but highly customizable. Modify the Sass variables to replace the default
background-image
Be sure to include text for screen readers
, as we’ve done with
aria-label
html
button
type
button
class
btn-close
aria-label
Close
button
Disabled state
Disabled close buttons change their
opacity
. We’ve also applied
pointer-events: none
user-select: none
to preventing hover and active states from triggering.
html
button
type
button
class
btn-close
disabled
aria-label
Close
button
Dark variant
Deprecated in v5.3.0
Heads up!
As of v5.3.0, the
.btn-close-white
class is deprecated. Instead, use
data-bs-theme="dark"
to change the color mode of the close button.
data-bs-theme="dark"
to the
.btn-close
, or to its parent element, to invert the close button. This uses the
filter
property to invert the
background-image
without overriding its value.
html
data-bs-theme
dark
button
type
button
class
btn-close
aria-label
Close
button
button
type
button
class
btn-close
disabled
aria-label
Close
button
Variables
Added in v5.3.0
As part of Bootstrap’s evolving CSS variables approach, close button now uses local CSS variables on
.btn-close
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_close.scss
#{$prefix}
btn-close-color
#{$btn-close-color}
#{$prefix}
btn-close-bg: #
escape-svg
$btn-close-bg
#{$prefix}
btn-close-opacity
#{$btn-close-opacity}
#{$prefix}
btn-close-hover-opacity
#{$btn-close-hover-opacity}
#{$prefix}
btn-close-focus-shadow
#{$btn-close-focus-shadow}
#{$prefix}
btn-close-focus-opacity
#{$btn-close-focus-opacity}
#{$prefix}
btn-close-disabled-opacity
#{$btn-close-disabled-opacity}
Sass variables
scss/_variables.scss
$btn-close-width
$btn-close-height
$btn-close-width
$btn-close-padding-x
.25em
$btn-close-padding-y
$btn-close-padding-x
$btn-close-color
$black
$btn-close-bg
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='#{$btn-close-color}'><path d='M.293.293a1 1 0 0 1 1.414 0L8 6.586 14.293.293a1 1 0 1 1 1.414 1.414L9.414 8l6.293 6.293a1 1 0 0 1-1.414 1.414L8 9.414l-6.293 6.293a1 1 0 0 1-1.414-1.414L6.586 8 .293 1.707a1 1 0 0 1 0-1.414'/></svg>"
$btn-close-focus-shadow
$focus-ring-box-shadow
$btn-close-opacity
$btn-close-hover-opacity
$btn-close-focus-opacity
$btn-close-disabled-opacity
$btn-close-filter
null
$btn-close-white-filter
invert
grayscale
100%
brightness
200%
// Deprecated in v5.3.4


--- 051_examples_navbar-static.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/navbar-static
--------------------------------------------------
Navbar example
This example is a quick exercise to illustrate how the top-aligned navbar works. As you scroll, this navbar remains in its original position and moves with the rest of the page.
View navbar docs »


--- 064_components_navbar.txt ---
URL: https://getbootstrap.com/docs/5.3/components/navbar
--------------------------------------------------
How it works
Here’s what you need to know before getting started with the navbar:
Navbars require a wrapping
.navbar
with
.navbar-expand{-sm|-md|-lg|-xl|-xxl}
for responsive collapsing and
color scheme
classes.
Navbars and their contents are fluid by default. Change the
container
to limit their horizontal width in different ways.
Use our
spacing
flex
utility classes for controlling spacing and alignment within navbars.
Navbars are responsive by default, but you can easily modify them to change that. Responsive behavior depends on our Collapse JavaScript plugin.
Ensure accessibility by using a
<nav>
element or, if using a more generic element such as a
<div>
, add a
role="navigation"
to every navbar to explicitly identify it as a landmark region for users of assistive technologies.
Indicate the current item by using
aria-current="page"
for the current page or
aria-current="true"
for the current item in a set.
New in v5.2.0:
Navbars can be themed with CSS variables that are scoped to the
.navbar
base class.
.navbar-light
has been deprecated and
.navbar-dark
has been rewritten to override CSS variables instead of adding additional styles.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Supported content
Navbars come with built-in support for a handful of sub-components. Choose from the following as needed:
.navbar-brand
for your company, product, or project name.
.navbar-nav
for a full-height and lightweight navigation (including support for dropdowns).
.navbar-toggler
for use with our collapse plugin and other
navigation toggling
behaviors.
Flex and spacing utilities for any form controls and actions.
.navbar-text
for adding vertically centered strings of text.
.collapse.navbar-collapse
for grouping and hiding navbar contents by a parent breakpoint.
Add an optional
.navbar-nav-scroll
to set a
max-height
scroll expanded navbar content
Here’s an example of all the sub-components included in a responsive light-themed navbar that automatically collapses at the
(large) breakpoint.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarSupportedContent
aria-controls
navbarSupportedContent
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarSupportedContent
class
navbar-nav me-auto mb-2 mb-lg-0
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item dropdown
class
nav-link dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-divider
class
dropdown-item
href
Something else here
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
This example uses
background
bg-body-tertiary
) and
spacing
me-auto
mb-2
mb-lg-0
me-2
) utility classes.
Brand
.navbar-brand
can be applied to most elements, but an anchor works best, as some elements might require utility classes or custom styles.
Text
Add your text within an element with the
.navbar-brand
class.
html
<!-- As a link -->
class
navbar bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
<!-- As a heading -->
class
navbar bg-body-tertiary
class
container-fluid
span
class
navbar-brand mb-0 h1
Navbar
span
Image
You can replace the text within the
.navbar-brand
with an
<img>
html
class
navbar bg-body-tertiary
class
container
class
navbar-brand
href
/docs/5.3/assets/brand/bootstrap-logo.svg
width
height
Image and text
You can also make use of some additional utilities to add an image and text at the same time. Note the addition of
.d-inline-block
.align-text-top
on the
<img>
html
class
navbar bg-body-tertiary
class
container-fluid
class
navbar-brand
href
/docs/5.3/assets/brand/bootstrap-logo.svg
Logo
width
height
class
d-inline-block align-text-top
Navbar navigation links build on our
.nav
options with their own modifier class and require the use of
toggler classes
for proper responsive styling.
Navigation in navbars will also grow to occupy as much horizontal space as possible
to keep your navbar contents securely aligned.
Add the
.active
class on
.nav-link
to indicate the current page.
Please note that you should also add the
aria-current
attribute on the active
.nav-link
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarNav
aria-controls
navbarNav
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarNav
class
navbar-nav
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Features
class
nav-item
class
nav-link
href
Pricing
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
And because we use classes for our navs, you can avoid the list-based approach entirely if you like.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarNavAltMarkup
aria-controls
navbarNavAltMarkup
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarNavAltMarkup
class
navbar-nav
class
nav-link active
aria-current
page
href
Home
class
nav-link
href
Features
class
nav-link
href
Pricing
class
nav-link disabled
aria-disabled
true
Disabled
You can also use dropdowns in your navbar. Dropdown menus require a wrapping element for positioning, so be sure to use separate and nested elements for
.nav-item
.nav-link
as shown below.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarNavDropdown
aria-controls
navbarNavDropdown
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarNavDropdown
class
navbar-nav
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Features
class
nav-item
class
nav-link
href
Pricing
class
nav-item dropdown
class
nav-link dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown link
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
Forms
Place various form controls and components within a navbar:
html
class
navbar bg-body-tertiary
class
container-fluid
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
Immediate child elements of
.navbar
use flex layout and will default to
justify-content: space-between
. Use additional
flex utilities
as needed to adjust this behavior.
html
class
navbar bg-body-tertiary
class
container-fluid
class
navbar-brand
Navbar
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
Input groups work, too. If your navbar is an entire form, or mostly a form, you can use the
<form>
element as the container and save some HTML.
html
class
navbar bg-body-tertiary
form
class
container-fluid
class
input-group
span
class
input-group-text
basic-addon1
span
input
type
text
class
form-control
placeholder
Username
aria-label
Username
aria-describedby
basic-addon1
form
Various buttons are supported as part of these navbar forms, too. This is also a great reminder that vertical alignment utilities can be used to align different sized elements.
html
class
navbar bg-body-tertiary
form
class
container-fluid justify-content-start
button
class
btn btn-outline-success me-2
type
button
Main button
button
button
class
btn btn-sm btn-outline-secondary
type
button
Smaller button
button
form
Text
Navbars may contain bits of text with the help of
.navbar-text
. This class adjusts vertical alignment and horizontal spacing for strings of text.
html
class
navbar bg-body-tertiary
class
container-fluid
span
class
navbar-text
Navbar text with an inline element
span
Mix and match with other components and utilities as needed.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar w/ text
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarText
aria-controls
navbarText
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarText
class
navbar-nav me-auto mb-2 mb-lg-0
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Features
class
nav-item
class
nav-link
href
Pricing
span
class
navbar-text
Navbar text with an inline element
span
Color schemes
New dark navbars in v5.3.0 —
We’ve deprecated
.navbar-dark
in favor of the new
data-bs-theme="dark"
. Add
data-bs-theme="dark"
to the
.navbar
to enable a component-specific color mode.
Learn more about our color modes.
New in v5.2.0  —
Navbar theming is now powered by CSS variables and
.navbar-light
has been deprecated. CSS variables are applied to
.navbar
, defaulting to the “light” appearance, and can be overridden with
.navbar-dark
Navbar themes are easier than ever thanks to Bootstrap’s combination of Sass and CSS variables. The default is our “light navbar” for use with light background colors, but you can also apply
data-bs-theme="dark"
to the
.navbar
parent for dark background colors. Then, customize with
.bg-*
and additional utilities.
class
navbar bg-dark border-bottom border-body
data-bs-theme
dark
<!-- Navbar content -->
class
navbar bg-primary
data-bs-theme
dark
<!-- Navbar content -->
class
navbar
style
background-color
#e3f2fd
data-bs-theme
light
<!-- Navbar content -->
Containers
Although it’s not required, you can wrap a navbar in a
.container
to center it on a page–though note that an inner container is still required. Or you can add a container inside the
.navbar
to only center the contents of a
fixed or static top navbar
html
class
container
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
Use any of the responsive containers to change how wide the content in your navbar is presented.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-md
class
navbar-brand
href
Navbar
Placement
Use our
position utilities
to place navbars in non-static positions. Choose from fixed to the top, fixed to the bottom, stickied to the top (scrolls with the page until it reaches the top, then stays there), or stickied to the bottom (scrolls with the page until it reaches the bottom, then stays there).
Fixed navbars use
position: fixed
, meaning they’re pulled from the normal flow of the DOM and may require custom CSS (e.g.,
padding-top
on the
<body>
) to prevent overlap with other elements.
html
class
navbar bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Default
html
class
navbar fixed-top bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Fixed top
html
class
navbar fixed-bottom bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Fixed bottom
html
class
navbar sticky-top bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Sticky top
html
class
navbar sticky-bottom bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Sticky bottom
Scrolling
.navbar-nav-scroll
to a
.navbar-nav
(or other navbar sub-component) to enable vertical scrolling within the toggleable contents of a collapsed navbar. By default, scrolling kicks in at
75vh
(or 75% of the viewport height), but you can override that with the local CSS custom property
--bs-navbar-height
or custom styles. At larger viewports when the navbar is expanded, content will appear as it does in a default navbar.
Please note that this behavior comes with a potential drawback of
overflow
—when setting
overflow-y: auto
(required to scroll the content here),
overflow-x
is the equivalent of
auto
, which will crop some horizontal content.
Here’s an example navbar using
.navbar-nav-scroll
with
style="--bs-scroll-height: 100px;"
, with some extra margin utilities for optimum spacing.
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar scroll
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarScroll
aria-controls
navbarScroll
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarScroll
class
navbar-nav me-auto my-2 my-lg-0 navbar-nav-scroll
style
--bs-scroll-height
100px
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item dropdown
class
nav-link dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Link
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-divider
class
dropdown-item
href
Something else here
class
nav-item
class
nav-link disabled
aria-disabled
true
Link
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
Responsive behaviors
Navbars can use
.navbar-toggler
.navbar-collapse
, and
.navbar-expand{-sm|-md|-lg|-xl|-xxl}
classes to determine when their content collapses behind a button. In combination with other utilities, you can easily choose when to show or hide particular elements.
For navbars that never collapse, add the
.navbar-expand
class on the navbar. For navbars that always collapse, don’t add any
.navbar-expand
class.
Toggler
Navbar togglers are left-aligned by default, but should they follow a sibling element like a
.navbar-brand
, they’ll automatically be aligned to the far right. Reversing your markup will reverse the placement of the toggler. Below are examples of different toggle styles.
With no
.navbar-brand
shown at the smallest breakpoint:
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarTogglerDemo01
aria-controls
navbarTogglerDemo01
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarTogglerDemo01
class
navbar-brand
href
Hidden brand
class
navbar-nav me-auto mb-2 mb-lg-0
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
With a brand name shown on the left and toggler on the right:
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
class
navbar-brand
href
Navbar
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarTogglerDemo02
aria-controls
navbarTogglerDemo02
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
collapse navbar-collapse
navbarTogglerDemo02
class
navbar-nav me-auto mb-2 mb-lg-0
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
With a toggler on the left and brand name on the right:
html
class
navbar navbar-expand-lg bg-body-tertiary
class
container-fluid
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarTogglerDemo03
aria-controls
navbarTogglerDemo03
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
class
navbar-brand
href
Navbar
class
collapse navbar-collapse
navbarTogglerDemo03
class
navbar-nav me-auto mb-2 mb-lg-0
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item
class
nav-link disabled
aria-disabled
true
Disabled
form
class
d-flex
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
External content
Sometimes you want to use the collapse plugin to trigger a container element for content that structurally sits outside of the
.navbar
. Because our plugin works on the
data-bs-target
matching, that’s easily done!
Collapsed content
Toggleable via the navbar brand.
html
class
collapse
navbarToggleExternalContent
data-bs-theme
dark
class
bg-dark p-4
class
text-body-emphasis h4
Collapsed content
span
class
text-body-secondary
Toggleable via the navbar brand.
span
class
navbar navbar-dark bg-dark
class
container-fluid
button
class
navbar-toggler
type
button
data-bs-toggle
collapse
data-bs-target
#navbarToggleExternalContent
aria-controls
navbarToggleExternalContent
aria-expanded
false
aria-label
span
class
navbar-toggler-icon
span
button
When you do this, we recommend including additional JavaScript to move the focus programmatically to the container when it is opened. Otherwise, keyboard users and users of assistive technologies will likely have a hard time finding the newly revealed content - particularly if the container that was opened comes
before
the toggler in the document’s structure. We also recommend making sure that the toggler has the
aria-controls
attribute, pointing to the
of the content container. In theory, this allows assistive technology users to jump directly from the toggler to the container it controls–but support for this is currently quite patchy.
Offcanvas
Transform your expanding and collapsing navbar into an offcanvas drawer with the
offcanvas component
. We extend both the offcanvas default styles and use our
.navbar-expand-*
classes to create a dynamic and flexible navigation sidebar.
In the example below, to create an offcanvas navbar that is always collapsed across all breakpoints, omit the
.navbar-expand-*
class entirely.
html
class
navbar bg-body-tertiary fixed-top
class
container-fluid
class
navbar-brand
href
Offcanvas navbar
button
class
navbar-toggler
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasNavbar
aria-controls
offcanvasNavbar
aria-label
span
class
navbar-toggler-icon
span
button
class
offcanvas offcanvas-end
tabindex
offcanvasNavbar
aria-labelledby
offcanvasNavbarLabel
class
offcanvas-header
class
offcanvas-title
offcanvasNavbarLabel
Offcanvas
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
class
navbar-nav justify-content-end flex-grow-1 pe-3
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item dropdown
class
nav-link dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-divider
class
dropdown-item
href
Something else here
form
class
d-flex mt-3
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-outline-success
type
submit
Search
button
form
To create an offcanvas navbar that expands into a normal navbar at a specific breakpoint like
, use
.navbar-expand-lg
class
navbar navbar-expand-lg bg-body-tertiary fixed-top
class
navbar-brand
href
Offcanvas navbar
button
class
navbar-toggler
type
button
data-bs-toggle
offcanvas
data-bs-target
#navbarOffcanvasLg
aria-controls
navbarOffcanvasLg
aria-label
span
class
navbar-toggler-icon
span
button
class
offcanvas offcanvas-end
tabindex
navbarOffcanvasLg
aria-labelledby
navbarOffcanvasLgLabel
When using offcanvas in a dark navbar, be aware that you may need to have a dark background on the offcanvas content to avoid the text becoming illegible. In the example below, we add
.navbar-dark
.bg-dark
to the
.navbar
.text-bg-dark
to the
.offcanvas
.dropdown-menu-dark
.dropdown-menu
, and
.btn-close-white
.btn-close
for proper styling with a dark offcanvas.
html
class
navbar navbar-dark bg-dark fixed-top
class
container-fluid
class
navbar-brand
href
Offcanvas dark navbar
button
class
navbar-toggler
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasDarkNavbar
aria-controls
offcanvasDarkNavbar
aria-label
span
class
navbar-toggler-icon
span
button
class
offcanvas offcanvas-end text-bg-dark
tabindex
offcanvasDarkNavbar
aria-labelledby
offcanvasDarkNavbarLabel
class
offcanvas-header
class
offcanvas-title
offcanvasDarkNavbarLabel
Dark offcanvas
button
type
button
class
btn-close btn-close-white
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
class
navbar-nav justify-content-end flex-grow-1 pe-3
class
nav-item
class
nav-link active
aria-current
page
href
Home
class
nav-item
class
nav-link
href
Link
class
nav-item dropdown
class
nav-link dropdown-toggle
href
role
button
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
class
dropdown-menu dropdown-menu-dark
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-divider
class
dropdown-item
href
Something else here
form
class
d-flex mt-3
role
search
input
class
form-control me-2
type
search
placeholder
Search
aria-label
Search
button
class
btn btn-success
type
submit
Search
button
form
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, navbars now use local CSS variables on
.navbar
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_navbar.scss
#{$prefix}
navbar-padding-x
$navbar-padding-x
null
$navbar-padding-x
#{$prefix}
navbar-padding-y
#{$navbar-padding-y}
#{$prefix}
navbar-color
#{$navbar-light-color}
#{$prefix}
navbar-hover-color
#{$navbar-light-hover-color}
#{$prefix}
navbar-disabled-color
#{$navbar-light-disabled-color}
#{$prefix}
navbar-active-color
#{$navbar-light-active-color}
#{$prefix}
navbar-brand-padding-y
#{$navbar-brand-padding-y}
#{$prefix}
navbar-brand-margin-end
#{$navbar-brand-margin-end}
#{$prefix}
navbar-brand-font-size
#{$navbar-brand-font-size}
#{$prefix}
navbar-brand-color
#{$navbar-light-brand-color}
#{$prefix}
navbar-brand-hover-color
#{$navbar-light-brand-hover-color}
#{$prefix}
navbar-nav-link-padding-x
#{$navbar-nav-link-padding-x}
#{$prefix}
navbar-toggler-padding-y
#{$navbar-toggler-padding-y}
#{$prefix}
navbar-toggler-padding-x
#{$navbar-toggler-padding-x}
#{$prefix}
navbar-toggler-font-size
#{$navbar-toggler-font-size}
#{$prefix}
navbar-toggler-icon-bg
escape-svg
$navbar-light-toggler-icon-bg
#{$prefix}
navbar-toggler-border-color
#{$navbar-light-toggler-border-color}
#{$prefix}
navbar-toggler-border-radius
#{$navbar-toggler-border-radius}
#{$prefix}
navbar-toggler-focus-width
#{$navbar-toggler-focus-width}
#{$prefix}
navbar-toggler-transition
#{$navbar-toggler-transition}
Some additional CSS variables are also present on
.navbar-nav
scss/_navbar.scss
#{$prefix}
nav-link-padding-x
#{$prefix}
nav-link-padding-y
#{$nav-link-padding-y}
@include
$nav-link-font-size
#{$prefix}
nav-link-font-size
#{$prefix}
nav-link-font-weight
#{$nav-link-font-weight}
#{$prefix}
nav-link-color
#{$prefix}
navbar-color
#{$prefix}
nav-link-hover-color
#{$prefix}
navbar-hover-color
#{$prefix}
nav-link-disabled-color
#{$prefix}
navbar-disabled-color
Customization through CSS variables can be seen on the
.navbar-dark
class where we override specific values without adding duplicate CSS selectors.
scss/_navbar.scss
#{$prefix}
navbar-color
#{$navbar-dark-color}
#{$prefix}
navbar-hover-color
#{$navbar-dark-hover-color}
#{$prefix}
navbar-disabled-color
#{$navbar-dark-disabled-color}
#{$prefix}
navbar-active-color
#{$navbar-dark-active-color}
#{$prefix}
navbar-brand-color
#{$navbar-dark-brand-color}
#{$prefix}
navbar-brand-hover-color
#{$navbar-dark-brand-hover-color}
#{$prefix}
navbar-toggler-border-color
#{$navbar-dark-toggler-border-color}
#{$prefix}
navbar-toggler-icon-bg
escape-svg
$navbar-dark-toggler-icon-bg
Sass variables
Variables for all navbars:
scss/_variables.scss
$navbar-padding-y
$spacer
$navbar-padding-x
null
$navbar-nav-link-padding-x
.5rem
$navbar-brand-font-size
$font-size-lg
// Compute the navbar-brand padding-y so the navbar-brand will have the same height as navbar-text and nav-link
$nav-link-height
$font-size-base
$line-height-base
$nav-link-padding-y
$navbar-brand-height
$navbar-brand-font-size
$line-height-base
$navbar-brand-padding-y
$nav-link-height
$navbar-brand-height
$navbar-brand-margin-end
1rem
$navbar-toggler-padding-y
.25rem
$navbar-toggler-padding-x
.75rem
$navbar-toggler-font-size
$font-size-lg
$navbar-toggler-border-radius
$btn-border-radius
$navbar-toggler-focus-width
$btn-focus-width
$navbar-toggler-transition
box-shadow .15s ease-in-out
$navbar-light-color
rgba
#{$prefix}
emphasis-color-rgb
$navbar-light-hover-color
rgba
#{$prefix}
emphasis-color-rgb
$navbar-light-active-color
rgba
#{$prefix}
emphasis-color-rgb
$navbar-light-disabled-color
rgba
#{$prefix}
emphasis-color-rgb
$navbar-light-icon-color
rgba
$body-color
$navbar-light-toggler-icon-bg
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke='#{$navbar-light-icon-color}' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg>"
$navbar-light-toggler-border-color
rgba
#{$prefix}
emphasis-color-rgb
$navbar-light-brand-color
$navbar-light-active-color
$navbar-light-brand-hover-color
$navbar-light-active-color
Variables for the
dark navbar
scss/_variables.scss
$navbar-dark-color
rgba
$white
$navbar-dark-hover-color
rgba
$white
$navbar-dark-active-color
$white
$navbar-dark-disabled-color
rgba
$white
$navbar-dark-icon-color
$navbar-dark-color
$navbar-dark-toggler-icon-bg
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke='#{$navbar-dark-icon-color}' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg>"
$navbar-dark-toggler-border-color
rgba
$white
$navbar-dark-brand-color
$navbar-dark-active-color
$navbar-dark-brand-hover-color
$navbar-dark-active-color
Sass loops
Responsive navbar expand/collapse classes
(e.g.,
.navbar-expand-lg
) are combined with the
$breakpoints
map and generated through a loop in
scss/_navbar.scss
scss/_navbar.scss
// Generate series of `.navbar-expand-*` responsive classes for configuring
// where your navbar collapses.
.navbar-expand
@each
$breakpoint
map-keys
$grid-breakpoints
$next
breakpoint-next
$breakpoint
$grid-breakpoints
$infix
breakpoint-infix
$next
$grid-breakpoints
// stylelint-disable-next-line scss/selector-no-union-class-name
#{$infix}
@include
media-breakpoint-up
$next
flex-wrap
nowrap
justify-content
flex-start
.navbar-nav
flex-direction
.dropdown-menu
position
absolute
.nav-link
padding-right
#{$prefix}
navbar-nav-link-padding-x
padding-left
#{$prefix}
navbar-nav-link-padding-x
.navbar-nav-scroll
overflow
visible
.navbar-collapse
display
flex
!important
// stylelint-disable-line declaration-no-important
flex-basis
auto
.navbar-toggler
display
none
.offcanvas
// stylelint-disable declaration-no-important
position
static
z-index
auto
flex-grow
width
auto
!important
height
auto
!important
visibility
visible
!important
background-color
transparent
!important
border
!important
transform
none
!important
@include
box-shadow
none
@include
transition
none
// stylelint-enable declaration-no-important
.offcanvas-header
display
none
.offcanvas-body
display
flex
flex-grow
padding
overflow-y
visible


--- 066_customize_components.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/components
--------------------------------------------------
Base classes
.btn
, and then group individual styles for each variant into modifier classes, like
.btn-primary
.btn-success
To build our modifier classes, we use Sass’s
@each
loops to iterate over a Sass map. This is especially helpful for generating variants of a component by our
$theme-colors
and creating responsive variants for each breakpoint. As you customize these Sass maps and recompile, you’ll automatically see your changes reflected in these loops.
Check out
our Sass maps and loops docs
for how to customize these loops and extend Bootstrap’s base-modifier approach to your own code.
Modifiers
Many of Bootstrap’s components are built with a base-modifier class approach. This means the bulk of the styling is contained to a base class (e.g.,
.btn
) while style variations are confined to modifier classes (e.g.,
.btn-danger
). These modifier classes are built from the
$theme-colors
map to make customizing the number and name of our modifier classes.
Here are two examples of how we loop over the
$theme-colors
map to generate modifiers to the
.alert
.list-group
components.
scss/_alert.scss
// Generate contextual modifier classes for colorizing the alert
@each
$state
map-keys
$theme-colors
.alert-
#{$state}
#{$prefix}
alert-color
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
alert-bg
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
alert-border-color
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
alert-link-color
#{$prefix}
#{$state}
-text-emphasis
scss/_list-group.scss
// List group contextual variants
// Add modifier classes to change text and background color on individual items.
// Organizationally, this must come after the `:hover` states.
@each
$state
map-keys
$theme-colors
.list-group-item-
#{$state}
#{$prefix}
list-group-color
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
list-group-bg
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
list-group-border-color
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-action-hover-color
#{$prefix}
emphasis-color
#{$prefix}
list-group-action-hover-bg
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-action-active-color
#{$prefix}
emphasis-color
#{$prefix}
list-group-action-active-bg
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-active-color
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
list-group-active-bg
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
list-group-active-border-color
#{$prefix}
#{$state}
-text-emphasis
Responsive
These Sass loops aren’t limited to color maps, either. You can also generate responsive variations of your components. Take for example our responsive alignment of the dropdowns where we mix an
@each
loop for the
$grid-breakpoints
Sass map with a media query include.
scss/_dropdown.scss
// We deliberately hardcode the `bs-` prefix because we check
// this custom property in JS to determine Popper's positioning
@each
$breakpoint
map-keys
$grid-breakpoints
@include
media-breakpoint-up
$breakpoint
$infix
breakpoint-infix
$breakpoint
$grid-breakpoints
.dropdown-menu
#{$infix}
-start
--bs-position
start
[data-bs-popper]
right
auto
left
.dropdown-menu
#{$infix}
-end
--bs-position
[data-bs-popper]
right
left
auto
Should you modify your
$grid-breakpoints
, your changes will apply to all the loops iterating over that map.
scss/_variables.scss
$grid-breakpoints
576px
768px
992px
1200px
1400px
For more information and examples on how to modify our Sass maps and variables, please refer to
the CSS section of the Grid documentation
Creating your own
We encourage you to adopt these guidelines when building with Bootstrap to create your own components. We’ve extended this approach ourselves to the custom components in our documentation and examples. Components like our callouts are built just like our provided components with base and modifier classes.
This is a callout.
We built it custom for our docs so our messages to you stand out. It has three variants via modifier classes.
class
callout
In your CSS, you’d have something like the following where the bulk of the styling is done via
.callout
. Then, the unique styles between each variant is controlled via modifier class.
// Base class
.callout
// Modifier classes
.callout-info
.callout-warning
.callout-danger
For the callouts, that unique styling is just a
border-left-color
. When you combine that base class with one of those modifier classes, you get your complete component family:
This is an info callout.
Example text to show it in action.
This is a warning callout.
Example text to show it in action.
This is a danger callout.
Example text to show it in action.


--- 068_examples_list-groups.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/list-groups
--------------------------------------------------
Toggle theme
Light
Dark
Auto
List group item heading
Some placeholder content in a paragraph.
Another title here
Some placeholder content in a paragraph that goes a little longer so it wraps to a new line.
Third heading
Some placeholder content in a paragraph.
First checkbox
With support text underneath to add more detail
Second checkbox
Some other text goes here
Third checkbox
And we end with another snippet of text
First radio
With support text underneath to add more detail
Second radio
Some other text goes here
Third radio
And we end with another snippet of text
Finish sales report
1:00–2:00pm
Weekly All Hands
2:00–2:30pm
Out of office
Tomorrow
Add new task...
Choose list...
First radio
With support text underneath to add more detail
Second radio
Some other text goes here
Third radio
And we end with another snippet of text
Fourth disabled radio
This option is disabled
First radio
With support text underneath to add more detail
Second radio
Some other text goes here
Third radio
And we end with another snippet of text
Fourth disabled radio
This option is disabled


--- 070_components_offcanvas.txt ---
URL: https://getbootstrap.com/docs/5.3/components/offcanvas
--------------------------------------------------
How it works
Offcanvas is a sidebar component that can be toggled via JavaScript to appear from the left, right, top, or bottom edge of the viewport. Buttons or anchors are used as triggers that are attached to specific elements you toggle, and
data
attributes are used to invoke our JavaScript.
Offcanvas shares some of the same JavaScript code as modals. Conceptually, they are quite similar, but they are separate plugins.
Similarly, some
source Sass
variables for offcanvas’s styles and dimensions are inherited from the modal’s variables.
When shown, offcanvas includes a default backdrop that can be clicked to hide the offcanvas.
Similar to modals, only one offcanvas can be shown at a time.
Heads up!
Given how CSS handles animations, you cannot use
margin
translate
on an
.offcanvas
element. Instead, use the class as an independent wrapping element.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Examples
Offcanvas components
Below is an offcanvas example that is shown by default (via
.show
.offcanvas
). Offcanvas includes support for a header with a close button and an optional body class for some initial
padding
. We suggest that you include offcanvas headers with dismiss actions whenever possible, or provide an explicit dismiss action.
Offcanvas
Content for the offcanvas goes here. You can place just about any Bootstrap component or custom elements here.
html
class
offcanvas offcanvas-start show
tabindex
offcanvas
aria-labelledby
offcanvasLabel
class
offcanvas-header
class
offcanvas-title
offcanvasLabel
Offcanvas
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Content for the offcanvas goes here. You can place just about any Bootstrap component or custom elements here.
Live demo
Use the buttons below to show and hide an offcanvas element via JavaScript that toggles the
.show
class on an element with the
.offcanvas
class.
.offcanvas
hides content (default)
.offcanvas.show
shows content
You can use a link with the
href
attribute, or a button with the
data-bs-target
attribute. In both cases, the
data-bs-toggle="offcanvas"
is required.
Link with href
Button with data-bs-target
Offcanvas
Some text as placeholder. In real life you can have the elements you have chosen. Like, text, images, lists, etc.
Dropdown button
Action
Another action
Something else here
html
class
btn btn-primary
data-bs-toggle
offcanvas
href
#offcanvasExample
role
button
aria-controls
offcanvasExample
Link with href
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasExample
aria-controls
offcanvasExample
Button with data-bs-target
button
class
offcanvas offcanvas-start
tabindex
offcanvasExample
aria-labelledby
offcanvasExampleLabel
class
offcanvas-header
class
offcanvas-title
offcanvasExampleLabel
Offcanvas
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Some text as placeholder. In real life you can have the elements you have chosen. Like, text, images, lists, etc.
class
dropdown mt-3
button
class
btn btn-secondary dropdown-toggle
type
button
data-bs-toggle
dropdown
Dropdown button
button
class
dropdown-menu
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
Body scrolling
Scrolling the
<body>
element is disabled when an offcanvas and its backdrop are visible. Use the
data-bs-scroll
attribute to enable
<body>
scrolling.
Enable body scrolling
Offcanvas with body scrolling
Try scrolling the rest of the page to see this option in action.
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasScrolling
aria-controls
offcanvasScrolling
Enable body scrolling
button
class
offcanvas offcanvas-start
data-bs-scroll
true
data-bs-backdrop
false
tabindex
offcanvasScrolling
aria-labelledby
offcanvasScrollingLabel
class
offcanvas-header
class
offcanvas-title
offcanvasScrollingLabel
Offcanvas with body scrolling
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Try scrolling the rest of the page to see this option in action.
Body scrolling and backdrop
You can also enable
<body>
scrolling with a visible backdrop.
Enable both scrolling & backdrop
Backdrop with scrolling
Try scrolling the rest of the page to see this option in action.
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasWithBothOptions
aria-controls
offcanvasWithBothOptions
Enable both scrolling & backdrop
button
class
offcanvas offcanvas-start
data-bs-scroll
true
tabindex
offcanvasWithBothOptions
aria-labelledby
offcanvasWithBothOptionsLabel
class
offcanvas-header
class
offcanvas-title
offcanvasWithBothOptionsLabel
Backdrop with scrolling
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Try scrolling the rest of the page to see this option in action.
Static backdrop
When backdrop is set to static, the offcanvas will not close when clicking outside of it.
Toggle static offcanvas
Offcanvas
I will not close if you click outside of me.
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#staticBackdrop
aria-controls
staticBackdrop
Toggle static offcanvas
button
class
offcanvas offcanvas-start
data-bs-backdrop
static
tabindex
staticBackdrop
aria-labelledby
staticBackdropLabel
class
offcanvas-header
class
offcanvas-title
staticBackdropLabel
Offcanvas
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
I will not close if you click outside of me.
Dark offcanvas
Deprecated in v5.3.0
Added in v5.2.0
Change the appearance of offcanvases with utilities to better match them to different contexts like dark navbars. Here we add
.text-bg-dark
to the
.offcanvas
.btn-close-white
.btn-close
for proper styling with a dark offcanvas. If you have dropdowns within, consider also adding
.dropdown-menu-dark
.dropdown-menu
Heads up!
Dark variants for components were deprecated in v5.3.0 with the introduction of color modes. Instead of manually adding classes mentioned above, set
data-bs-theme="dark"
on the root element, a parent wrapper, or the component itself.
Offcanvas
Place offcanvas content here.
html
class
offcanvas offcanvas-start show text-bg-dark
tabindex
offcanvasDark
aria-labelledby
offcanvasDarkLabel
class
offcanvas-header
class
offcanvas-title
offcanvasDarkLabel
Offcanvas
button
type
button
class
btn-close btn-close-white
data-bs-dismiss
offcanvasDark
aria-label
Close
button
class
offcanvas-body
Place offcanvas content here.
Responsive
Added in v5.2.0
Responsive offcanvas classes hide content outside the viewport from a specified breakpoint and down. Above that breakpoint, the contents within will behave as usual. For example,
.offcanvas-lg
hides content in an offcanvas below the
breakpoint, but shows the content above the
breakpoint. Responsive offcanvas classes are available for each breakpoint.
.offcanvas
.offcanvas-sm
.offcanvas-md
.offcanvas-lg
.offcanvas-xl
.offcanvas-xxl
To make a responsive offcanvas, replace the
.offcanvas
base class with a responsive variant and ensure your close button has an explicit
data-bs-target
Toggle offcanvas
Resize your browser to show the responsive offcanvas toggle.
Responsive offcanvas
This is content within an
.offcanvas-lg
html
button
class
btn btn-primary d-lg-none
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasResponsive
aria-controls
offcanvasResponsive
Toggle offcanvas
button
class
alert alert-info d-none d-lg-block
Resize your browser to show the responsive offcanvas toggle.
class
offcanvas-lg offcanvas-end
tabindex
offcanvasResponsive
aria-labelledby
offcanvasResponsiveLabel
class
offcanvas-header
class
offcanvas-title
offcanvasResponsiveLabel
Responsive offcanvas
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
data-bs-target
#offcanvasResponsive
aria-label
Close
button
class
offcanvas-body
class
mb-0
This is content within an
code
.offcanvas-lg
code
Placement
There’s no default placement for offcanvas components, so you must add one of the modifier classes below.
.offcanvas-start
places offcanvas on the left of the viewport (shown above)
.offcanvas-end
places offcanvas on the right of the viewport
.offcanvas-top
places offcanvas on the top of the viewport
.offcanvas-bottom
places offcanvas on the bottom of the viewport
Try the top, right, and bottom examples out below.
Toggle top offcanvas
Offcanvas top
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasTop
aria-controls
offcanvasTop
Toggle top offcanvas
button
class
offcanvas offcanvas-top
tabindex
offcanvasTop
aria-labelledby
offcanvasTopLabel
class
offcanvas-header
class
offcanvas-title
offcanvasTopLabel
Offcanvas top
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Toggle right offcanvas
Offcanvas right
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasRight
aria-controls
offcanvasRight
Toggle right offcanvas
button
class
offcanvas offcanvas-end
tabindex
offcanvasRight
aria-labelledby
offcanvasRightLabel
class
offcanvas-header
class
offcanvas-title
offcanvasRightLabel
Offcanvas right
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body
Toggle bottom offcanvas
Offcanvas bottom
html
button
class
btn btn-primary
type
button
data-bs-toggle
offcanvas
data-bs-target
#offcanvasBottom
aria-controls
offcanvasBottom
Toggle bottom offcanvas
button
class
offcanvas offcanvas-bottom
tabindex
offcanvasBottom
aria-labelledby
offcanvasBottomLabel
class
offcanvas-header
class
offcanvas-title
offcanvasBottomLabel
Offcanvas bottom
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
class
offcanvas-body small
Accessibility
Since the offcanvas panel is conceptually a modal dialog, be sure to add
aria-labelledby="..."
—referencing the offcanvas title—to
.offcanvas
. Note that you don’t need to add
role="dialog"
since we already add it via JavaScript.
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, offcanvas now uses local CSS variables on
.offcanvas
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_offcanvas.scss
#{$prefix}
offcanvas-zindex
#{$zindex-offcanvas}
#{$prefix}
offcanvas-width
#{$offcanvas-horizontal-width}
#{$prefix}
offcanvas-height
#{$offcanvas-vertical-height}
#{$prefix}
offcanvas-padding-x
#{$offcanvas-padding-x}
#{$prefix}
offcanvas-padding-y
#{$offcanvas-padding-y}
#{$prefix}
offcanvas-color
#{$offcanvas-color}
#{$prefix}
offcanvas-bg
#{$offcanvas-bg-color}
#{$prefix}
offcanvas-border-width
#{$offcanvas-border-width}
#{$prefix}
offcanvas-border-color
#{$offcanvas-border-color}
#{$prefix}
offcanvas-box-shadow
#{$offcanvas-box-shadow}
#{$prefix}
offcanvas-transition
transform
$offcanvas-transition-duration
ease-in-out
#{$prefix}
offcanvas-title-line-height
#{$offcanvas-title-line-height}
Sass variables
scss/_variables.scss
$offcanvas-padding-y
$modal-inner-padding
$offcanvas-padding-x
$modal-inner-padding
$offcanvas-horizontal-width
400px
$offcanvas-vertical-height
30vh
$offcanvas-transition-duration
$offcanvas-border-color
$modal-content-border-color
$offcanvas-border-width
$modal-content-border-width
$offcanvas-title-line-height
$modal-title-line-height
$offcanvas-bg-color
#{$prefix}
body-bg
$offcanvas-color
#{$prefix}
body-color
$offcanvas-box-shadow
$modal-content-box-shadow-xs
$offcanvas-backdrop-bg
$modal-backdrop-bg
$offcanvas-backdrop-opacity
$modal-backdrop-opacity
Usage
The offcanvas plugin utilizes a few classes and attributes to handle the heavy lifting:
.offcanvas
hides the content
.offcanvas.show
shows the content
.offcanvas-start
hides the offcanvas on the left
.offcanvas-end
hides the offcanvas on the right
.offcanvas-top
hides the offcanvas on the top
.offcanvas-bottom
hides the offcanvas on the bottom
Add a dismiss button with the
data-bs-dismiss="offcanvas"
attribute, which triggers the JavaScript functionality. Be sure to use the
<button>
element with it for proper behavior across all devices.
Via data attributes
Toggle
data-bs-toggle="offcanvas"
and a
data-bs-target
href
to the element to automatically assign control of one offcanvas element. The
data-bs-target
attribute accepts a CSS selector to apply the offcanvas to. Be sure to add the class
offcanvas
to the offcanvas element. If you’d like it to default open, add the additional class
show
Dismiss
Dismissal can be achieved with the
data-bs-dismiss
attribute on a button
within the offcanvas
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
aria-label
Close
button
or on a button
outside the offcanvas
using the additional
data-bs-target
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
offcanvas
data-bs-target
#my-offcanvas
aria-label
Close
button
While both ways to dismiss an offcanvas are supported, keep in mind that dismissing from outside an offcanvas does not match the
ARIA Authoring Practices Guide dialog (modal) pattern
. Do this at your own risk.
Via JavaScript
Enable manually with:
const
offcanvasElementList
document
querySelectorAll
'.offcanvas'
const
offcanvasList
offcanvasElementList
offcanvasEl
Offcanvas
offcanvasEl
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
backdrop
boolean or the string
static
true
Apply a backdrop on body while offcanvas is open. Alternatively, specify
static
for a backdrop which doesn’t close the offcanvas when clicked.
keyboard
boolean
true
Closes the offcanvas when escape key is pressed.
scroll
boolean
false
Allow body scrolling while offcanvas is open.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Activates your content as an offcanvas element. Accepts an optional options
object
You can create an offcanvas instance with the constructor, for example:
const
bsOffcanvas
Offcanvas
'#myOffcanvas'
Method
Description
dispose
Destroys an element’s offcanvas.
getInstance
Static
method which allows you to get the offcanvas instance associated with a DOM element.
getOrCreateInstance
Static
method which allows you to get the offcanvas instance associated with a DOM element, or create a new one in case it wasn’t initialized.
hide
Hides an offcanvas element.
Returns to the caller before the offcanvas element has actually been hidden
(i.e. before the
hidden.bs.offcanvas
event occurs).
show
Shows an offcanvas element.
Returns to the caller before the offcanvas element has actually been shown
(i.e. before the
shown.bs.offcanvas
event occurs).
toggle
Toggles an offcanvas element to shown or hidden.
Returns to the caller before the offcanvas element has actually been shown or hidden
(i.e. before the
shown.bs.offcanvas
hidden.bs.offcanvas
event occurs).
Events
Event type
Description
hide.bs.offcanvas
This event is fired immediately when the
hide
method has been called.
hidden.bs.offcanvas
This event is fired when an offcanvas element has been hidden from the user (will wait for CSS transitions to complete).
hidePrevented.bs.offcanvas
This event is fired when the offcanvas is shown, its backdrop is
static
and a click outside of the offcanvas is performed. The event is also fired when the escape key is pressed and the
keyboard
option is set to
false
show.bs.offcanvas
This event fires immediately when the
show
instance method is called.
shown.bs.offcanvas
This event is fired when an offcanvas element has been made visible to the user (will wait for CSS transitions to complete).
const
myOffcanvas
document
getElementById
'myOffcanvas'
myOffcanvas
addEventListener
'hidden.bs.offcanvas'
event
// do something...


--- 073_examples_offcanvas-navbar.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/offcanvas-navbar
--------------------------------------------------
Since 2011
Recent updates
Placeholder
32x32
@username
Some representative placeholder content, with some information about this user. Imagine this being some sort of status update, perhaps?
Placeholder
32x32
@username
Some more representative placeholder content, related to this other user. Another status update, perhaps.
Placeholder
32x32
@username
This user also gets some representative placeholder content. Maybe they did something interesting, and you really want to highlight this in the recent updates.
All updates
Suggestions
Placeholder
32x32
Full Name
Follow
@username
Placeholder
32x32
Full Name
Follow
@username
Placeholder
32x32
Full Name
Follow
@username
All suggestions


--- 078_components_popovers.txt ---
URL: https://getbootstrap.com/docs/5.3/components/popovers
--------------------------------------------------
Overview
Things to know when using the popover plugin:
Popovers rely on the third party library
Popper
for positioning. You must include
popper.min.js
before
, or use one
which contains Popper.
Popovers require the
popover plugin
as a dependency.
Popovers are opt-in for performance reasons, so
you must initialize them yourself
Zero-length
title
content
values will never show a popover.
Specify
container: 'body'
to avoid rendering problems in more complex components (like our input groups, button groups, etc).
Triggering popovers on hidden elements will not work.
Popovers for
.disabled
disabled
elements must be triggered on a wrapper element.
When triggered from anchors that wrap across multiple lines, popovers will be centered between the anchors’ overall width. Use
.text-nowrap
on your
s to avoid this behavior.
Popovers must be hidden before their corresponding elements have been removed from the DOM.
Popovers can be triggered thanks to an element inside a shadow DOM.
By default, this component uses the built-in content sanitizer, which strips out any HTML elements that are not explicitly allowed. See the
sanitizer section in our JavaScript documentation
for more details.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Keep reading to see how popovers work with some examples.
Examples
Enable popovers
As mentioned above, you must initialize popovers before they can be used. One way to initialize all popovers on a page would be to select them by their
data-bs-toggle
attribute, like so:
const
popoverTriggerList
document
querySelectorAll
'[data-bs-toggle="popover"]'
const
popoverList
popoverTriggerList
popoverTriggerEl
Popover
popoverTriggerEl
Live demo
We use JavaScript similar to the snippet above to render the following live popover. Titles are set via
data-bs-title
and body content is set via
data-bs-content
Feel free to use either
title
data-bs-title
in your HTML. When
title
is used, Popper will replace it automatically with
data-bs-title
when the element is rendered.
Click to toggle popover
html
button
type
button
class
btn btn-lg btn-danger
data-bs-toggle
popover
data-bs-title
Popover title
data-bs-content
And here’s some amazing content. It’s very engaging. Right?
Click to toggle popover
button
Four directions
Four options are available: top, right, bottom, and left. Directions are mirrored when using Bootstrap in RTL. Set
data-bs-placement
to change the direction.
Popover on top
Popover on right
Popover on bottom
Popover on left
html
button
type
button
class
btn btn-secondary
data-bs-container
body
data-bs-toggle
popover
data-bs-placement
data-bs-content
Top popover
Popover on top
button
button
type
button
class
btn btn-secondary
data-bs-container
body
data-bs-toggle
popover
data-bs-placement
right
data-bs-content
Right popover
Popover on right
button
button
type
button
class
btn btn-secondary
data-bs-container
body
data-bs-toggle
popover
data-bs-placement
bottom
data-bs-content
Bottom popover
Popover on bottom
button
button
type
button
class
btn btn-secondary
data-bs-container
body
data-bs-toggle
popover
data-bs-placement
left
data-bs-content
Left popover
Popover on left
button
Custom
container
When you have some styles on a parent element that interfere with a popover, you’ll want to specify a custom
container
so that the popover’s HTML appears within that element instead. This is common in responsive tables, input groups, and the like.
const
popover
Popover
'.example-popover'
container
'body'
Another situation where you’ll want to set an explicit custom
container
are popovers inside a
modal dialog
, to make sure that the popover itself is appended to the modal. This is particularly important for popovers that contain interactive elements – modal dialogs will trap focus, so unless the popover is a child element of the modal, users won’t be able to focus or activate these interactive elements.
const
popover
Popover
'.example-popover'
container
'.modal-body'
Custom popovers
Added in v5.2.0
You can customize the appearance of popovers using
CSS variables
. We set a custom class with
data-bs-custom-class="custom-popover"
to scope our custom appearance and use it to override some of the local CSS variables.
site/src/scss/_component-examples.scss
.custom-popover
--bs-popover-max-width
200px
--bs-popover-border-color
--bd-violet-bg
--bs-popover-header-bg
--bd-violet-bg
--bs-popover-header-color
--bs-white
--bs-popover-body-padding-x
1rem
--bs-popover-body-padding-y
.5rem
Custom popover
html
button
type
button
class
btn btn-secondary
data-bs-toggle
popover
data-bs-placement
right
data-bs-custom-class
custom-popover
data-bs-title
Custom popover
data-bs-content
This popover is themed via CSS variables.
Custom popover
button
Dismiss on next click
Use the
focus
trigger to dismiss popovers on the user’s next click of an element other than the toggle element.
Dismissing on next click requires specific HTML for proper cross-browser and cross-platform behavior.
You can only use
elements, not
<button>
s, and you must include a
tabindex
Dismissible popover
html
tabindex
class
btn btn-lg btn-danger
role
button
data-bs-toggle
popover
data-bs-trigger
focus
data-bs-title
Dismissible popover
data-bs-content
And here’s some amazing content. It’s very engaging. Right?
Dismissible popover
const
popover
Popover
'.popover-dismiss'
trigger
'focus'
Disabled elements
Elements with the
disabled
attribute aren’t interactive, meaning users cannot hover or click them to trigger a popover (or tooltip). As a workaround, you’ll want to trigger the popover from a wrapper
<div>
<span>
, ideally made keyboard-focusable using
tabindex="0"
For disabled popover triggers, you may also prefer
data-bs-trigger="hover focus"
so that the popover appears as immediate visual feedback to your users as they may not expect to
click
on a disabled element.
Disabled button
html
span
class
d-inline-block
tabindex
data-bs-toggle
popover
data-bs-trigger
hover focus
data-bs-content
Disabled popover
button
class
btn btn-primary
type
button
disabled
Disabled button
button
span
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, popovers now use local CSS variables on
.popover
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_popover.scss
#{$prefix}
popover-zindex
#{$zindex-popover}
#{$prefix}
popover-max-width
#{$popover-max-width}
@include
$popover-font-size
#{$prefix}
popover-font-size
#{$prefix}
popover-bg
#{$popover-bg}
#{$prefix}
popover-border-width
#{$popover-border-width}
#{$prefix}
popover-border-color
#{$popover-border-color}
#{$prefix}
popover-border-radius
#{$popover-border-radius}
#{$prefix}
popover-inner-border-radius
#{$popover-inner-border-radius}
#{$prefix}
popover-box-shadow
#{$popover-box-shadow}
#{$prefix}
popover-header-padding-x
#{$popover-header-padding-x}
#{$prefix}
popover-header-padding-y
#{$popover-header-padding-y}
@include
$popover-header-font-size
#{$prefix}
popover-header-font-size
#{$prefix}
popover-header-color
#{$popover-header-color}
#{$prefix}
popover-header-bg
#{$popover-header-bg}
#{$prefix}
popover-body-padding-x
#{$popover-body-padding-x}
#{$prefix}
popover-body-padding-y
#{$popover-body-padding-y}
#{$prefix}
popover-body-color
#{$popover-body-color}
#{$prefix}
popover-arrow-width
#{$popover-arrow-width}
#{$prefix}
popover-arrow-height
#{$popover-arrow-height}
#{$prefix}
popover-arrow-border
#{$prefix}
popover-border-color
Sass variables
scss/_variables.scss
$popover-font-size
$font-size-sm
$popover-bg
#{$prefix}
body-bg
$popover-max-width
276px
$popover-border-width
#{$prefix}
border-width
$popover-border-color
#{$prefix}
border-color-translucent
$popover-border-radius
#{$prefix}
border-radius-lg
$popover-inner-border-radius
calc
#{$popover-border-radius}
#{$popover-border-width}
// stylelint-disable-line function-disallowed-list
$popover-box-shadow
#{$prefix}
box-shadow
$popover-header-font-size
$font-size-base
$popover-header-bg
#{$prefix}
secondary-bg
$popover-header-color
$headings-color
$popover-header-padding-y
.5rem
$popover-header-padding-x
$spacer
$popover-body-color
#{$prefix}
body-color
$popover-body-padding-y
$spacer
$popover-body-padding-x
$spacer
$popover-arrow-width
1rem
$popover-arrow-height
.5rem
Usage
Enable popovers via JavaScript:
const
exampleEl
document
getElementById
'example'
const
popover
Popover
exampleEl
options
Keep popovers accessible to keyboard and assistive technology users
by only adding them to HTML elements that are traditionally keyboard-focusable and interactive (such as links or form controls). While other HTML elements can be made focusable by adding
tabindex="0"
, this can create annoying and confusing tab stops on non-interactive elements for keyboard users, and most assistive technologies currently do not announce popovers in this situation. Additionally, do not rely solely on
hover
as the trigger for your popovers as this will make them impossible to trigger for keyboard users.
Avoid adding an excessive amount of content in popovers with the
html
option. Once popovers are displayed, their content is tied to the trigger element with the
aria-describedby
attribute, causing all of the popover’s content to be announced to assistive technology users as one long, uninterrupted stream.
Popovers do not manage keyboard focus order, and their placement can be random in the DOM, so be careful when adding interactive elements (like forms or links), as it may lead to an illogical focus order or make the popover content itself completely unreachable for keyboard users. In cases where you must use these elements, consider using a modal dialog instead.
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Note that for security reasons the
sanitize
sanitizeFn
, and
allowList
options cannot be supplied using data attributes.
Name
Type
Default
Description
allowList
object
Default value
An object containing allowed tags and attributes. Those not explicitly allowed will be removed by
the content sanitizer
Exercise caution when adding to this list.
Refer to
OWASP’s Cross Site Scripting Prevention Cheat Sheet
for more information.
animation
boolean
true
Apply a CSS fade transition to the popover.
boundary
string, element
'clippingParents'
Overflow constraint boundary of the popover (applies only to Popper’s preventOverflow modifier). By default, it’s
'clippingParents'
and can accept an HTMLElement reference (via JavaScript only). For more information refer to Popper’s
detectOverflow docs
container
string, element, false
false
Appends the popover to a specific element. Example:
container: 'body'
. This option is particularly useful in that it allows you to position the popover in the flow of the document near the triggering element - which will prevent the popover from floating away from the triggering element during a window resize.
content
string, element, function
The popover’s text content. If a function is given, it will be called with its
this
reference set to the element that the popover is attached to.
customClass
string, function
Add classes to the popover when it is shown. Note that these classes will be added in addition to any classes specified in the template. To add multiple classes, separate them with spaces:
'class-1 class-2'
. You can also pass a function that should return a single string containing additional class names.
delay
number, object
Delay showing and hiding the popover (ms)—doesn’t apply to manual trigger type. If a number is supplied, delay is applied to both hide/show. Object structure is:
delay: { "show": 500, "hide": 100 }
fallbackPlacements
string, array
['top', 'right', 'bottom', 'left']
Define fallback placements by providing a list of placements in array (in order of preference). For more information refer to Popper’s
behavior docs
html
boolean
false
Allow HTML in the popover. If true, HTML tags in the popover’s
title
will be rendered in the popover. If false,
innerText
property will be used to insert content into the DOM. Prefer text when dealing with user-generated input to
prevent XSS attacks
offset
number, string, function
[0, 8]
Offset of the popover relative to its target. You can pass a string in data attributes with comma separated values like:
data-bs-offset="10,20"
. When a function is used to determine the offset, it is called with an object containing the popper placement, the reference, and popper rects as its first argument. The triggering element DOM node is passed as the second argument. The function must return an array with two numbers:
skidding
distance
. For more information refer to Popper’s
offset docs
placement
string, function
'right'
How to position the popover: auto, top, bottom, left, right. When
auto
is specified, it will dynamically reorient the popover. When a function is used to determine the placement, it is called with the popover DOM node as its first argument and the triggering element DOM node as its second. The
this
context is set to the popover instance.
popperConfig
null, object, function
null
To change Bootstrap’s default Popper config, see
Popper’s configuration
. When a function is used to create the Popper configuration, it’s called with an object that contains the Bootstrap’s default Popper configuration. It helps you use and merge the default with your own configuration. The function must return a configuration object for Popper.
sanitize
boolean
true
Enable
content sanitization
. If true, the
template
content
title
options will be sanitized.
Exercise caution when disabling content sanitization.
Refer to
OWASP’s Cross Site Scripting Prevention Cheat Sheet
for more information. Vulnerabilities caused solely by disabling content sanitization are not considered within scope for Bootstrap’s security model.
sanitizeFn
null, function
null
Provide an alternative
content sanitization
function. This can be useful if you prefer to use a dedicated library to perform sanitization.
selector
string, false
false
If a selector is provided, popover objects will be delegated to the specified targets. In practice, this is used to also apply popovers to dynamically added DOM elements (
jQuery.on
support). See
this issue
an informative example
Note
title
attribute must not be used as a selector.
template
string
'<div class="popover" role="tooltip"><div class="popover-arrow"></div><h3 class="popover-header"></h3><div class="popover-body"></div></div>'
Base HTML to use when creating the popover. The popover’s
title
will be injected into the
.popover-header
. The popover’s
content
will be injected into the
.popover-body
.popover-arrow
will become the popover’s arrow. The outermost wrapper element should have the
.popover
class and
role="tooltip"
title
string, element, function
The popover title. If a function is given, it will be called with its
this
reference set to the element that the popover is attached to.
trigger
string
'click'
How popover is triggered: click, hover, focus, manual. You may pass multiple triggers; separate them with a space.
'manual'
indicates that the popover will be triggered programmatically via the
.popover('show')
.popover('hide')
.popover('toggle')
methods; this value cannot be combined with any other trigger.
'hover'
on its own will result in popovers that cannot be triggered via the keyboard, and should only be used if alternative methods for conveying the same information for keyboard users is present.
Data attributes for individual popovers
Options for individual popovers can alternatively be specified through the use of data attributes, as explained above.
Using function with
popperConfig
const
popover
Popover
element
popperConfig
defaultBsPopperConfig
// const newPopperConfig = {...}
// use defaultBsPopperConfig if needed...
// return newPopperConfig
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Method
Description
disable
Removes the ability for an element’s popover to be shown. The popover will only be able to be shown if it is re-enabled.
dispose
Hides and destroys an element’s popover (Removes stored data on the DOM element). Popovers that use delegation (which are created using
selector
option
) cannot be individually destroyed on descendant trigger elements.
enable
Gives an element’s popover the ability to be shown.
Popovers are enabled by default.
getInstance
Static
method which allows you to get the popover instance associated with a DOM element.
getOrCreateInstance
Static
method which allows you to get the popover instance associated with a DOM element, or create a new one in case it wasn’t initialized.
hide
Hides an element’s popover.
Returns to the caller before the popover has actually been hidden
(i.e. before the
hidden.bs.popover
event occurs). This is considered a “manual” triggering of the popover.
setContent
Gives a way to change the popover’s content after its initialization.
show
Reveals an element’s popover.
Returns to the caller before the popover has actually been shown
(i.e. before the
shown.bs.popover
event occurs). This is considered a “manual” triggering of the popover. Popovers whose title and content are both zero-length are never displayed.
toggle
Toggles an element’s popover.
Returns to the caller before the popover has actually been shown or hidden
(i.e. before the
shown.bs.popover
hidden.bs.popover
event occurs). This is considered a “manual” triggering of the popover.
toggleEnabled
Toggles the ability for an element’s popover to be shown or hidden.
update
Updates the position of an element’s popover.
// getOrCreateInstance example
const
popover
Popover
getOrCreateInstance
'#example'
// Returns a Bootstrap popover instance
// setContent example
popover
setContent
'.popover-header'
'another title'
'.popover-body'
'another content'
setContent
method accepts an
object
argument, where each property-key is a valid
string
selector within the popover template, and each related property-value can be
string
element
function
null
Events
Event
Description
hide.bs.popover
This event is fired immediately when the
hide
instance method has been called.
hidden.bs.popover
This event is fired when the popover has finished being hidden from the user (will wait for CSS transitions to complete).
inserted.bs.popover
This event is fired after the
show.bs.popover
event when the popover template has been added to the DOM.
show.bs.popover
This event fires immediately when the
show
instance method is called.
shown.bs.popover
This event is fired when the popover has been made visible to the user (will wait for CSS transitions to complete).
const
myPopoverTrigger
document
getElementById
'myPopover'
myPopoverTrigger
addEventListener
'hidden.bs.popover'
// do something...


--- 085_components_modal.txt ---
URL: https://getbootstrap.com/docs/5.3/components/modal
--------------------------------------------------
How it works
Before getting started with Bootstrap’s modal component, be sure to read the following as our menu options have recently changed.
Modals are built with HTML, CSS, and JavaScript. They’re positioned over everything else in the document and remove scroll from the
<body>
so that modal content scrolls instead.
Clicking on the modal “backdrop” will automatically close the modal.
Modals use
position: fixed
, which can sometimes be a bit particular about its rendering. Whenever possible, place your modal HTML in a top-level position to avoid potential interference from other elements. You’ll likely run into issues when nesting a
.modal
within another fixed element.
Once again, due to
position: fixed
, there are some caveats with using modals on mobile devices.
See our browser support docs
for details.
Due to how HTML5 defines its semantics,
autofocus
HTML attribute
has no effect in Bootstrap modals. To achieve the same effect, use some custom JavaScript:
const
myModal
document
getElementById
'myModal'
const
myInput
document
getElementById
'myInput'
myModal
addEventListener
'shown.bs.modal'
myInput
focus
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Keep reading for demos and usage guidelines.
Examples
Modal components
Below is a
static
modal example (meaning its
position
display
have been overridden). Included are the modal header, modal body (required for
padding
), and modal footer (optional). We ask that you include modal headers with dismiss actions whenever possible, or provide another explicit dismiss action.
Modal title
Modal body text goes here.
Close
Save changes
class
modal
tabindex
class
modal-dialog
class
modal-content
class
modal-header
class
modal-title
Modal title
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
Modal body text goes here.
class
modal-footer
button
type
button
class
btn btn-secondary
data-bs-dismiss
modal
Close
button
button
type
button
class
btn btn-primary
Save changes
button
In the above static example, we use
<h5>
, to avoid issues with the heading hierarchy in the documentation page. Structurally, however, a modal dialog represents its own separate document/context, so the
.modal-title
should ideally be an
<h1>
. If necessary, you can use the
font size utilities
to control the heading’s appearance. All the following live examples use this approach.
Live demo
Toggle a working modal demo by clicking the button below. It will slide down and fade in from the top of the page.
Modal title
Woo-hoo, you’re reading this text in a modal!
Close
Save changes
Launch demo modal
<!-- Button trigger modal -->
button
type
button
class
btn btn-primary
data-bs-toggle
modal
data-bs-target
#exampleModal
Launch demo modal
button
<!-- Modal -->
class
modal fade
exampleModal
tabindex
aria-labelledby
exampleModalLabel
aria-hidden
true
class
modal-dialog
class
modal-content
class
modal-header
class
modal-title fs-5
exampleModalLabel
Modal title
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
class
modal-footer
button
type
button
class
btn btn-secondary
data-bs-dismiss
modal
Close
button
button
type
button
class
btn btn-primary
Save changes
button
Static backdrop
When backdrop is set to static, the modal will not close when clicking outside of it. Click the button below to try it.
Modal title
I will not close if you click outside of me. Don’t even try to press escape key.
Close
Understood
Launch static backdrop modal
<!-- Button trigger modal -->
button
type
button
class
btn btn-primary
data-bs-toggle
modal
data-bs-target
#staticBackdrop
Launch static backdrop modal
button
<!-- Modal -->
class
modal fade
staticBackdrop
data-bs-backdrop
static
data-bs-keyboard
false
tabindex
aria-labelledby
staticBackdropLabel
aria-hidden
true
class
modal-dialog
class
modal-content
class
modal-header
class
modal-title fs-5
staticBackdropLabel
Modal title
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
class
modal-footer
button
type
button
class
btn btn-secondary
data-bs-dismiss
modal
Close
button
button
type
button
class
btn btn-primary
Understood
button
Scrolling long content
When modals become too long for the user’s viewport or device, they scroll independent of the page itself. Try the demo below to see what we mean.
Modal title
This is some placeholder content to show the scrolling behavior for modals. Instead of repeating the text in the modal, we use an inline style to set a minimum height, thereby extending the length of the overall modal and demonstrating the overflow scrolling. When content becomes longer than the height of the viewport, scrolling will move the modal as needed.
Close
Save changes
Launch demo modal
You can also create a scrollable modal that allows scrolling the modal body by adding
.modal-dialog-scrollable
.modal-dialog
Modal title
This is some placeholder content to show the scrolling behavior for modals. We use repeated line breaks to demonstrate how content can exceed minimum inner height, thereby showing inner scrolling. When content becomes longer than the predefined max-height of modal, content will be cropped and scrollable within the modal.
This content should appear at the bottom after you scroll.
Close
Save changes
Launch demo modal
<!-- Scrollable modal -->
class
modal-dialog modal-dialog-scrollable
Vertically centered
.modal-dialog-centered
.modal-dialog
to vertically center the modal.
Modal title
This is a vertically centered modal.
Close
Save changes
Modal title
This is some placeholder content to show a vertically centered modal. We’ve added some extra copy here to show how vertically centering the modal works when combined with scrollable modals. We also use some repeated line breaks to quickly extend the height of the content, thereby triggering the scrolling. When content becomes longer than the predefined max-height of modal, content will be cropped and scrollable within the modal.
Just like that.
Close
Save changes
Vertically centered modal
Vertically centered scrollable modal
<!-- Vertically centered modal -->
class
modal-dialog modal-dialog-centered
<!-- Vertically centered scrollable modal -->
class
modal-dialog modal-dialog-centered modal-dialog-scrollable
Tooltips and popovers
Tooltips
popovers
can be placed within modals as needed. When modals are closed, any tooltips and popovers within are also automatically dismissed.
Modal title
Popover in a modal
This
button
triggers a popover on click.
Tooltips in a modal
This link
that link
have tooltips on hover.
Close
Save changes
Launch demo modal
class
modal-body
class
fs-5
Popover in a modal
This
button
class
btn btn-secondary
data-bs-toggle
popover
title
Popover title
data-bs-content
Popover body content is set in this attribute.
button
button
triggers a popover on click.
class
fs-5
Tooltips in a modal
href
data-bs-toggle
tooltip
title
Tooltip
This link
href
data-bs-toggle
tooltip
title
Tooltip
that link
have tooltips on hover.
Using the grid
Utilize the Bootstrap grid system within a modal by nesting
.container-fluid
within the
.modal-body
. Then, use the normal grid system classes as you would anywhere else.
Grids in modals
.col-md-4
.col-md-4 .ms-auto
.col-md-3 .ms-auto
.col-md-2 .ms-auto
.col-md-6 .ms-auto
Level 1: .col-sm-9
Level 2: .col-8 .col-sm-6
Level 2: .col-4 .col-sm-6
Close
Save changes
Launch demo modal
class
modal-body
class
container-fluid
class
class
col-md-4
.col-md-4
class
col-md-4 ms-auto
.col-md-4 .ms-auto
class
class
col-md-3 ms-auto
.col-md-3 .ms-auto
class
col-md-2 ms-auto
.col-md-2 .ms-auto
class
class
col-md-6 ms-auto
.col-md-6 .ms-auto
class
class
col-sm-9
Level 1: .col-sm-9
class
class
col-8 col-sm-6
Level 2: .col-8 .col-sm-6
class
col-4 col-sm-6
Level 2: .col-4 .col-sm-6
Varying modal content
Have a bunch of buttons that all trigger the same modal with slightly different contents? Use
event.relatedTarget
HTML
data-bs-*
attributes
to vary the contents of the modal depending on which button was clicked.
Below is a live demo followed by example HTML and JavaScript. For more information,
read the modal events docs
for details on
relatedTarget
Open modal for @mdo
Open modal for @fat
Open modal for @getbootstrap
New message
Recipient:
Message:
Close
Send message
html
button
type
button
class
btn btn-primary
data-bs-toggle
modal
data-bs-target
#exampleModal
data-bs-whatever
@mdo
Open modal for @mdo
button
button
type
button
class
btn btn-primary
data-bs-toggle
modal
data-bs-target
#exampleModal
data-bs-whatever
@fat
Open modal for @fat
button
button
type
button
class
btn btn-primary
data-bs-toggle
modal
data-bs-target
#exampleModal
data-bs-whatever
@getbootstrap
Open modal for @getbootstrap
button
class
modal fade
exampleModal
tabindex
aria-labelledby
exampleModalLabel
aria-hidden
true
class
modal-dialog
class
modal-content
class
modal-header
class
modal-title fs-5
exampleModalLabel
New message
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
form
class
mb-3
label
recipient-name
class
col-form-label
Recipient:
label
input
type
text
class
form-control
recipient-name
class
mb-3
label
message-text
class
col-form-label
Message:
label
textarea
class
form-control
message-text
textarea
form
class
modal-footer
button
type
button
class
btn btn-secondary
data-bs-dismiss
modal
Close
button
button
type
button
class
btn btn-primary
Send message
button
site/src/assets/partials/snippets.js
const
exampleModal
document
getElementById
'exampleModal'
exampleModal
exampleModal
addEventListener
'show.bs.modal'
event
// Button that triggered the modal
const
button
event
relatedTarget
// Extract info from data-bs-* attributes
const
recipient
button
getAttribute
'data-bs-whatever'
// If necessary, you could initiate an Ajax request here
// and then do the updating in a callback.
// Update the modal's content.
const
modalTitle
exampleModal
querySelector
'.modal-title'
const
modalBodyInput
exampleModal
querySelector
'.modal-body input'
modalTitle
textContent
New message to
recipient
modalBodyInput
value
recipient
Toggle between modals
Toggle between multiple modals with some clever placement of the
data-bs-target
data-bs-toggle
attributes. For example, you could toggle a password reset modal from within an already open sign in modal.
Please note multiple modals cannot be open at the same time
—this method simply toggles between two separate modals.
Modal 1
Show a second modal and hide this one with the button below.
Open second modal
Modal 2
Hide this modal and show the first with the button below.
Back to first
Open first modal
html
class
modal fade
exampleModalToggle
aria-hidden
true
aria-labelledby
exampleModalToggleLabel
tabindex
class
modal-dialog modal-dialog-centered
class
modal-content
class
modal-header
class
modal-title fs-5
exampleModalToggleLabel
Modal 1
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
Show a second modal and hide this one with the button below.
class
modal-footer
button
class
btn btn-primary
data-bs-target
#exampleModalToggle2
data-bs-toggle
modal
Open second modal
button
class
modal fade
exampleModalToggle2
aria-hidden
true
aria-labelledby
exampleModalToggleLabel2
tabindex
class
modal-dialog modal-dialog-centered
class
modal-content
class
modal-header
class
modal-title fs-5
exampleModalToggleLabel2
Modal 2
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
class
modal-body
Hide this modal and show the first with the button below.
class
modal-footer
button
class
btn btn-primary
data-bs-target
#exampleModalToggle
data-bs-toggle
modal
Back to first
button
button
class
btn btn-primary
data-bs-target
#exampleModalToggle
data-bs-toggle
modal
Open first modal
button
Change animation
$modal-fade-transform
variable determines the transform state of
.modal-dialog
before the modal fade-in animation, the
$modal-show-transform
variable determines the transform of
.modal-dialog
at the end of the modal fade-in animation.
If you want for example a zoom-in animation, you can set
$modal-fade-transform: scale(.8)
Remove animation
For modals that simply appear rather than fade in to view, remove the
.fade
class from your modal markup.
class
modal
tabindex
aria-labelledby
aria-hidden
true
Dynamic heights
If the height of a modal changes while it is open, you should call
myModal.handleUpdate()
to readjust the modal’s position in case a scrollbar appears.
Accessibility
Be sure to add
aria-labelledby="..."
, referencing the modal title, to
.modal
. Additionally, you may give a description of your modal dialog with
aria-describedby
.modal
. Note that you don’t need to add
role="dialog"
since we already add it via JavaScript.
Embedding YouTube videos
Embedding YouTube videos in modals requires additional JavaScript not in Bootstrap to automatically stop playback and more.
See this helpful Stack Overflow post
for more information.
Optional sizes
Modals have three optional sizes, available via modifier classes to be placed on a
.modal-dialog
. These sizes kick in at certain breakpoints to avoid horizontal scrollbars on narrower viewports.
Size
Class
Modal max-width
Small
.modal-sm
300px
Default
None
500px
Large
.modal-lg
800px
Extra large
.modal-xl
1140px
Our default modal without modifier class constitutes the “medium” size modal.
Extra large modal
Large modal
Small modal
class
modal-dialog modal-xl
class
modal-dialog modal-lg
class
modal-dialog modal-sm
Extra large modal
Large modal
Small modal
Fullscreen Modal
Another override is the option to pop up a modal that covers the user viewport, available via modifier classes that are placed on a
.modal-dialog
Class
Availability
.modal-fullscreen
Always
.modal-fullscreen-sm-down
576px
.modal-fullscreen-md-down
768px
.modal-fullscreen-lg-down
992px
.modal-fullscreen-xl-down
1200px
.modal-fullscreen-xxl-down
1400px
Full screen
Full screen below sm
Full screen below md
Full screen below lg
Full screen below xl
Full screen below xxl
<!-- Full screen modal -->
class
modal-dialog modal-fullscreen-sm-down
Full screen modal
Close
Full screen below sm
Close
Full screen below md
Close
Full screen below lg
Close
Full screen below xl
Close
Full screen below xxl
Close
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, modals now use local CSS variables on
.modal
.modal-backdrop
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_modal.scss
#{$prefix}
modal-zindex
#{$zindex-modal}
#{$prefix}
modal-width
#{$modal-md}
#{$prefix}
modal-padding
#{$modal-inner-padding}
#{$prefix}
modal-margin
#{$modal-dialog-margin}
#{$prefix}
modal-color
#{$modal-content-color}
#{$prefix}
modal-bg
#{$modal-content-bg}
#{$prefix}
modal-border-color
#{$modal-content-border-color}
#{$prefix}
modal-border-width
#{$modal-content-border-width}
#{$prefix}
modal-border-radius
#{$modal-content-border-radius}
#{$prefix}
modal-box-shadow
#{$modal-content-box-shadow-xs}
#{$prefix}
modal-inner-border-radius
#{$modal-content-inner-border-radius}
#{$prefix}
modal-header-padding-x
#{$modal-header-padding-x}
#{$prefix}
modal-header-padding-y
#{$modal-header-padding-y}
#{$prefix}
modal-header-padding
#{$modal-header-padding}
// Todo in v6: Split this padding into x and y
#{$prefix}
modal-header-border-color
#{$modal-header-border-color}
#{$prefix}
modal-header-border-width
#{$modal-header-border-width}
#{$prefix}
modal-title-line-height
#{$modal-title-line-height}
#{$prefix}
modal-footer-gap
#{$modal-footer-margin-between}
#{$prefix}
modal-footer-bg
#{$modal-footer-bg}
#{$prefix}
modal-footer-border-color
#{$modal-footer-border-color}
#{$prefix}
modal-footer-border-width
#{$modal-footer-border-width}
scss/_modal.scss
#{$prefix}
backdrop-zindex
#{$zindex-modal-backdrop}
#{$prefix}
backdrop-bg
#{$modal-backdrop-bg}
#{$prefix}
backdrop-opacity
#{$modal-backdrop-opacity}
Sass variables
scss/_variables.scss
$modal-inner-padding
$spacer
$modal-footer-margin-between
.5rem
$modal-dialog-margin
.5rem
$modal-dialog-margin-y-sm-up
1.75rem
$modal-title-line-height
$line-height-base
$modal-content-color
#{$prefix}
body-color
$modal-content-bg
#{$prefix}
body-bg
$modal-content-border-color
#{$prefix}
border-color-translucent
$modal-content-border-width
#{$prefix}
border-width
$modal-content-border-radius
#{$prefix}
border-radius-lg
$modal-content-inner-border-radius
subtract
$modal-content-border-radius
$modal-content-border-width
$modal-content-box-shadow-xs
#{$prefix}
box-shadow-sm
$modal-content-box-shadow-sm-up
#{$prefix}
box-shadow
$modal-backdrop-bg
$black
$modal-backdrop-opacity
$modal-header-border-color
#{$prefix}
border-color
$modal-header-border-width
$modal-content-border-width
$modal-header-padding-y
$modal-inner-padding
$modal-header-padding-x
$modal-inner-padding
$modal-header-padding
$modal-header-padding-y
$modal-header-padding-x
// Keep this for backwards compatibility
$modal-footer-bg
null
$modal-footer-border-color
$modal-header-border-color
$modal-footer-border-width
$modal-header-border-width
$modal-sm
300px
$modal-md
500px
$modal-lg
800px
$modal-xl
1140px
$modal-fade-transform
translate
-50px
$modal-show-transform
none
$modal-transition
transform .3s ease-out
$modal-scale-transform
scale
1.02
Sass loops
Responsive fullscreen modals
are generated via the
$breakpoints
map and a loop in
scss/_modal.scss
scss/_modal.scss
@each
$breakpoint
map-keys
$grid-breakpoints
$infix
breakpoint-infix
$breakpoint
$grid-breakpoints
$postfix
$infix
$infix
"-down"
@include
media-breakpoint-down
$breakpoint
.modal-fullscreen
#{$postfix}
width
100vw
max-width
none
height
100%
margin
.modal-content
height
100%
border
@include
border-radius
.modal-header,
.modal-footer
@include
border-radius
.modal-body
overflow-y
auto
Usage
The modal plugin toggles your hidden content on demand, via data attributes or JavaScript. It also overrides default scrolling behavior and generates a
.modal-backdrop
to provide a click area for dismissing shown modals when clicking outside the modal.
Via data attributes
Toggle
Activate a modal without writing JavaScript. Set
data-bs-toggle="modal"
on a controller element, like a button, along with a
data-bs-target="#foo"
href="#foo"
to target a specific modal to toggle.
button
type
button
data-bs-toggle
modal
data-bs-target
#myModal
Launch modal
button
Dismiss
Dismissal can be achieved with the
data-bs-dismiss
attribute on a button
within the modal
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
modal
aria-label
Close
button
or on a button
outside the modal
using the additional
data-bs-target
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
modal
data-bs-target
#my-modal
aria-label
Close
button
While both ways to dismiss a modal are supported, keep in mind that dismissing from outside a modal does not match the
ARIA Authoring Practices Guide dialog (modal) pattern
. Do this at your own risk.
Via JavaScript
Create a modal with a single line of JavaScript:
const
myModal
Modal
document
getElementById
'myModal'
options
// or
const
myModalAlternative
Modal
'#myModal'
options
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
backdrop
boolean,
’static'
true
Includes a modal-backdrop element. Alternatively, specify
static
for a backdrop which doesn’t close the modal when clicked.
focus
boolean
true
Puts the focus on the modal when initialized.
keyboard
boolean
true
Closes the modal when escape key is pressed.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Passing options
Activates your content as a modal. Accepts an optional options
object
const
myModal
Modal
'#myModal'
keyboard
false
Method
Description
dispose
Destroys an element’s modal. (Removes stored data on the DOM element)
getInstance
Static
method which allows you to get the modal instance associated with a DOM element.
getOrCreateInstance
Static
method which allows you to get the modal instance associated with a DOM element, or create a new one in case it wasn’t initialized.
handleUpdate
Manually readjust the modal’s position if the height of a modal changes while it is open (i.e. in case a scrollbar appears).
hide
Manually hides a modal.
Returns to the caller before the modal has actually been hidden
(i.e. before the
hidden.bs.modal
event occurs).
show
Manually opens a modal.
Returns to the caller before the modal has actually been shown
(i.e. before the
shown.bs.modal
event occurs). Also, you can pass a DOM element as an argument that can be received in the modal events (as the
relatedTarget
property). (i.e.
const modalToggle = document.getElementById('toggleMyModal'); myModal.show(modalToggle)
toggle
Manually toggles a modal.
Returns to the caller before the modal has actually been shown or hidden
(i.e. before the
shown.bs.modal
hidden.bs.modal
event occurs).
Events
<div class="modal">
Event
Description
hide.bs.modal
This event is fired immediately when the
hide
instance method has been called. Can be prevented by calling
event.preventDefault()
. See
JavaScript events documentation
for more details on event prevention.
hidden.bs.modal
This event is fired when the modal has finished being hidden from the user (will wait for CSS transitions to complete).
hidePrevented.bs.modal
This event is fired when the modal is shown, its backdrop is
static
and a click outside of the modal is performed. The event is also fired when the escape key is pressed and the
keyboard
option is set to
false
show.bs.modal
This event fires immediately when the
show
instance method is called. If caused by a click, the clicked element is available as the
relatedTarget
property of the event.
shown.bs.modal
This event is fired when the modal has been made visible to the user (will wait for CSS transitions to complete). If caused by a click, the clicked element is available as the
relatedTarget
property of the event.
const
myModalEl
document
getElementById
'myModal'
myModalEl
addEventListener
'hidden.bs.modal'
event
// do something...


--- 089_components_carousel.txt ---
URL: https://getbootstrap.com/docs/5.3/components/carousel
--------------------------------------------------
How it works
The carousel is a slideshow for cycling through a series of content, built with CSS 3D transforms and a bit of JavaScript. It works with a series of images, text, or custom markup. It also includes support for previous/next controls and indicators.
For performance reasons,
carousels must be manually initialized
using the
carousel constructor method
. Without initialization, some of the event listeners (specifically, the events needed touch/swipe support) will not be registered until a user has explicitly activated a control or indicator.
The only exception are
autoplaying carousels
with the
data-bs-ride="carousel"
attribute as these are initialized automatically on page load. If you’re using autoplaying carousels with the data attribute,
don’t explicitly initialize the same carousels with the constructor method.
Nested carousels are not supported. You should also be aware that carousels in general can often cause usability and accessibility challenges.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Basic examples
Here is a basic example of a carousel with three slides. Note the previous/next controls. We recommend using
<button>
elements, but you can also use
elements with
role="button"
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExample
class
carousel slide
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExample
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExample
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Carousels don’t automatically normalize slide dimensions. As such, you may need to use additional utilities or custom styles to appropriately size content. While carousels support previous/next controls and indicators, they’re not explicitly required. Add and customize as you see fit.
You must add the
.active
class to one of the slides
, otherwise the carousel will not be visible. Also be sure to set a unique
on the
.carousel
for optional controls, especially if you’re using multiple carousels on a single page. Control and indicator elements must have a
data-bs-target
attribute (or
href
for links) that matches the
of the
.carousel
element.
Indicators
You can add indicators to the carousel, alongside the previous/next controls. The indicators let users jump directly to a particular slide.
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleIndicators
class
carousel slide
class
carousel-indicators
button
type
button
data-bs-target
#carouselExampleIndicators
data-bs-slide-to
class
active
aria-current
true
aria-label
Slide 1
button
button
type
button
data-bs-target
#carouselExampleIndicators
data-bs-slide-to
aria-label
Slide 2
button
button
type
button
data-bs-target
#carouselExampleIndicators
data-bs-slide-to
aria-label
Slide 3
button
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleIndicators
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleIndicators
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Captions
You can add captions to your slides with the
.carousel-caption
element within any
.carousel-item
. They can be easily hidden on smaller viewports, as shown below, with optional
display utilities
. We hide them initially with
.d-none
and bring them back on medium-sized devices with
.d-md-block
Placeholder
First slide
First slide label
Some representative placeholder content for the first slide.
Placeholder
Second slide
Second slide label
Some representative placeholder content for the second slide.
Placeholder
Third slide
Third slide label
Some representative placeholder content for the third slide.
Previous
Next
html
carouselExampleCaptions
class
carousel slide
class
carousel-indicators
button
type
button
data-bs-target
#carouselExampleCaptions
data-bs-slide-to
class
active
aria-current
true
aria-label
Slide 1
button
button
type
button
data-bs-target
#carouselExampleCaptions
data-bs-slide-to
aria-label
Slide 2
button
button
type
button
data-bs-target
#carouselExampleCaptions
data-bs-slide-to
aria-label
Slide 3
button
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-caption d-none d-md-block
First slide label
Some representative placeholder content for the first slide.
class
carousel-item
class
d-block w-100
class
carousel-caption d-none d-md-block
Second slide label
Some representative placeholder content for the second slide.
class
carousel-item
class
d-block w-100
class
carousel-caption d-none d-md-block
Third slide label
Some representative placeholder content for the third slide.
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleCaptions
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleCaptions
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Crossfade
.carousel-fade
to your carousel to animate slides with a fade transition instead of a slide. Depending on your carousel content (e.g., text only slides), you may want to add
.bg-body
or some custom CSS to the
.carousel-item
s for proper crossfading.
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleFade
class
carousel slide carousel-fade
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleFade
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleFade
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Autoplaying carousels
You can make your carousels autoplay on page load by setting the
ride
option to
carousel
. Autoplaying carousels automatically pause while hovered with the mouse. This behavior can be controlled with the
pause
option. In browsers that support the
Page Visibility API
, the carousel will stop cycling when the webpage is not visible to the user (such as when the browser tab is inactive, or when the browser window is minimized).
For accessibility reasons, we recommend avoiding the use of autoplaying carousels. If your page does include an autoplaying carousel, we recommend providing an additional button or control to explicitly pause/stop the carousel.
WCAG 2.2 Success Criterion 2.2.2 Pause, Stop, Hide
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleAutoplaying
class
carousel slide
data-bs-ride
carousel
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleAutoplaying
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleAutoplaying
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
When the
ride
option is set to
true
, rather than
carousel
, the carousel won’t automatically start to cycle on page load. Instead, it will only start after the first user interaction.
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleRide
class
carousel slide
data-bs-ride
true
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleRide
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleRide
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Individual
.carousel-item
interval
data-bs-interval=""
to a
.carousel-item
to change the amount of time to delay between automatically cycling to the next item.
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleInterval
class
carousel slide
data-bs-ride
carousel
class
carousel-inner
class
carousel-item active
data-bs-interval
10000
class
d-block w-100
class
carousel-item
data-bs-interval
2000
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleInterval
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleInterval
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Autoplaying carousels without controls
Here’s a carousel with slides only. Note the presence of the
.d-block
.w-100
on carousel images to prevent browser default image alignment.
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
html
carouselExampleSlidesOnly
class
carousel slide
data-bs-ride
carousel
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
Disable touch swiping
Carousels support swiping left/right on touchscreen devices to move between slides. This can be disabled by setting the
touch
option to
false
Placeholder
First slide
Placeholder
Second slide
Placeholder
Third slide
Previous
Next
html
carouselExampleControlsNoTouching
class
carousel slide
data-bs-touch
false
class
carousel-inner
class
carousel-item active
class
d-block w-100
class
carousel-item
class
d-block w-100
class
carousel-item
class
d-block w-100
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleControlsNoTouching
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleControlsNoTouching
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Dark variant
Deprecated in v5.3.0
.carousel-dark
to the
.carousel
for darker controls, indicators, and captions. Controls are inverted compared to their default white fill with the
filter
CSS property. Captions and controls have additional Sass variables that customize the
color
background-color
Heads up!
Dark variants for components were deprecated in v5.3.0 with the introduction of color modes.
Instead of adding
.carousel-dark
, set
data-bs-theme="dark"
on the root element, a parent
wrapper, or the component itself.
Placeholder
First slide
First slide label
Some representative placeholder content for the first slide.
Placeholder
Second slide
Second slide label
Some representative placeholder content for the second slide.
Placeholder
Third slide
Third slide label
Some representative placeholder content for the third slide.
Previous
Next
html
carouselExampleDark
class
carousel carousel-dark slide
class
carousel-indicators
button
type
button
data-bs-target
#carouselExampleDark
data-bs-slide-to
class
active
aria-current
true
aria-label
Slide 1
button
button
type
button
data-bs-target
#carouselExampleDark
data-bs-slide-to
aria-label
Slide 2
button
button
type
button
data-bs-target
#carouselExampleDark
data-bs-slide-to
aria-label
Slide 3
button
class
carousel-inner
class
carousel-item active
data-bs-interval
10000
class
d-block w-100
class
carousel-caption d-none d-md-block
First slide label
Some representative placeholder content for the first slide.
class
carousel-item
data-bs-interval
2000
class
d-block w-100
class
carousel-caption d-none d-md-block
Second slide label
Some representative placeholder content for the second slide.
class
carousel-item
class
d-block w-100
class
carousel-caption d-none d-md-block
Third slide label
Some representative placeholder content for the third slide.
button
class
carousel-control-prev
type
button
data-bs-target
#carouselExampleDark
data-bs-slide
prev
span
class
carousel-control-prev-icon
aria-hidden
true
span
span
class
visually-hidden
Previous
span
button
button
class
carousel-control-next
type
button
data-bs-target
#carouselExampleDark
data-bs-slide
next
span
class
carousel-control-next-icon
aria-hidden
true
span
span
class
visually-hidden
Next
span
button
Custom transition
The transition duration of
.carousel-item
can be changed with the
$carousel-transition-duration
Sass variable before compiling or custom styles if you’re using the compiled CSS. If multiple transitions are applied, make sure the transform transition is defined first (e.g.
transition: transform 2s ease, opacity .5s ease-out
Sass variables
Variables for all carousels:
scss/_variables.scss
$carousel-control-color
$white
$carousel-control-width
$carousel-control-opacity
$carousel-control-hover-opacity
$carousel-control-transition
opacity .15s ease
$carousel-control-icon-filter
null
$carousel-indicator-width
30px
$carousel-indicator-height
$carousel-indicator-hit-area-height
10px
$carousel-indicator-spacer
$carousel-indicator-opacity
$carousel-indicator-active-bg
$white
$carousel-indicator-active-opacity
$carousel-indicator-transition
opacity .6s ease
$carousel-caption-width
$carousel-caption-color
$white
$carousel-caption-padding-y
1.25rem
$carousel-caption-spacer
1.25rem
$carousel-control-icon-width
2rem
$carousel-control-prev-icon-bg
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='#{$carousel-control-color}'><path d='M11.354 1.646a.5.5 0 0 1 0 .708L5.707 8l5.647 5.646a.5.5 0 0 1-.708.708l-6-6a.5.5 0 0 1 0-.708l6-6a.5.5 0 0 1 .708 0'/></svg>"
$carousel-control-next-icon-bg
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='#{$carousel-control-color}'><path d='M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708'/></svg>"
$carousel-transition-duration
$carousel-transition
transform
$carousel-transition-duration
ease-in-out
// Define transform transition first if using multiple transitions (e.g., `transform 2s ease, opacity .5s ease-out`)
Variables for the
dark carousel
scss/_variables.scss
$carousel-dark-indicator-active-bg
$black
// Deprecated in v5.3.4
$carousel-dark-caption-color
$black
// Deprecated in v5.3.4
$carousel-dark-control-icon-filter
invert
grayscale
// Deprecated in v5.3.4
Usage
Via data attributes
Use data attributes to easily control the position of the carousel.
data-bs-slide
accepts the keywords
prev
next
, which alters the slide position relative to its current position. Alternatively, use
data-bs-slide-to
to pass a raw slide index to the carousel
data-bs-slide-to="2"
, which shifts the slide position to a particular index beginning with
Via JavaScript
Call carousel manually with:
const
carousel
Carousel
'#myCarousel'
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
interval
number
5000
The amount of time to delay between automatically cycling an item.
keyboard
boolean
true
Whether the carousel should react to keyboard events.
pause
string, boolean
"hover"
If set to
"hover"
, pauses the cycling of the carousel on
mouseenter
and resumes the cycling of the carousel on
mouseleave
. If set to
false
, hovering over the carousel won’t pause it. On touch-enabled devices, when set to
"hover"
, cycling will pause on
touchend
(once the user finished interacting with the carousel) for two intervals, before automatically resuming. This is in addition to the mouse behavior.
ride
string, boolean
false
If set to
true
, autoplays the carousel after the user manually cycles the first item. If set to
"carousel"
, autoplays the carousel on load.
touch
boolean
true
Whether the carousel should support left/right swipe interactions on touchscreen devices.
wrap
boolean
true
Whether the carousel should cycle continuously or have hard stops.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
You can create a carousel instance with the carousel constructor, and pass on any additional options. For example, to manually initialize an autoplaying carousel (assuming you’re not using the
data-bs-ride="carousel"
attribute in the markup itself) with a specific interval and with touch support disabled, you can use:
const
myCarouselElement
document
querySelector
'#myCarousel'
const
carousel
Carousel
myCarouselElement
interval
2000
touch
false
Method
Description
cycle
Starts cycling through the carousel items from left to right.
dispose
Destroys an element’s carousel. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the carousel instance associated to a DOM element. You can use it like this:
getOrCreateInstance
Static method which returns a carousel instance associated to a DOM element, or creates a new one in case it wasn’t initialized. You can use it like this:
next
Cycles to the next item.
Returns to the caller before the next item has been shown
(e.g., before the
slid.bs.carousel
event occurs).
nextWhenVisible
Don’t cycle carousel to next when the page, the carousel, or the carousel’s parent aren’t visible.
Returns to the caller before the target item has been shown
pause
Stops the carousel from cycling through items.
prev
Cycles to the previous item.
Returns to the caller before the previous item has been shown
(e.g., before the
slid.bs.carousel
event occurs).
Cycles the carousel to a particular frame (0 based, similar to an array).
Returns to the caller before the target item has been shown
(e.g., before the
slid.bs.carousel
event occurs).
Events
direction
: The direction in which the carousel is sliding (either
"left"
"right"
relatedTarget
: The DOM element that is being slid into place as the active item.
from
: The index of the current item
: The index of the next item
All carousel events are fired at the carousel itself (i.e. at the
<div class="carousel">
Event type
Description
slid.bs.carousel
Fired when the carousel has completed its slide transition.
slide.bs.carousel
Fires immediately when the
slide
instance method is invoked.
const
myCarousel
document
getElementById
'myCarousel'
myCarousel
addEventListener
'slide.bs.carousel'
event
// do something...


--- 093_examples_buttons.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/buttons
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Link
Secondary action
Primary action
Primary icon
Secondary icon
Loading...
Loading...
Dismiss
Dismiss
Dismiss
Dismiss


--- 100_components_pagination.txt ---
URL: https://getbootstrap.com/docs/5.3/components/pagination
--------------------------------------------------
Overview
We use a large block of connected links for our pagination, making links hard to miss and easily scalable—all while providing large hit areas. Pagination is built with list HTML elements so screen readers can announce the number of available links. Use a wrapping
<nav>
element to identify it as a navigation section to screen readers and other assistive technologies.
In addition, as pages likely have more than one such navigation section, it’s advisable to provide a descriptive
aria-label
for the
<nav>
to reflect its purpose. For example, if the pagination component is used to navigate between a set of search results, an appropriate label could be
aria-label="Search results pages"
html
aria-label
Page navigation example
class
pagination
class
page-item
class
page-link
href
Previous
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Next
Working with icons
Looking to use an icon or symbol in place of text for some pagination links? Be sure to provide proper screen reader support with
aria
attributes.
html
aria-label
Page navigation example
class
pagination
class
page-item
class
page-link
href
aria-label
Previous
span
aria-hidden
true
&laquo;
span
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
aria-label
Next
span
aria-hidden
true
&raquo;
span
Active
.active
to indicate a
.page-item
is the one currently being viewed. If using an
on the current page,
aria-current="page"
should be added for assistive technologies.
html
aria-label
class
pagination
class
page-item
href
class
page-link
Previous
class
page-item
class
page-link
href
class
page-item active
class
page-link
href
aria-current
page
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Next
If using a non-interactive element, like a
<span>
for the current page, you may omit the
aria-current
attribute.
class
page-item active
span
class
page-link
span
Disabled
.disabled
to a
.page-item
to make it appear un-clickable. While
.disabled
uses
pointer-events: none
to disable the link‘s interactivity, that CSS property is not yet standardized and doesn’t account for keyboard navigation. As such, you should always add
tabindex="-1"
on disabled links and use custom JavaScript to fully disable their functionality.
html
aria-label
class
pagination
class
page-item disabled
class
page-link
Previous
class
page-item
class
page-link
href
class
page-item active
class
page-link
href
aria-current
page
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Next
And just like active page items, you can swap out the disabled
for a
<span>
to remove click functionality and prevent keyboard focus while retaining intended styles.
class
page-item disabled
span
class
page-link
Previous
span
Sizing
Fancy larger or smaller pagination? Add
.pagination-lg
.pagination-sm
for additional sizes.
html
aria-label
class
pagination pagination-lg
class
page-item active
class
page-link
aria-current
page
class
page-item
class
page-link
href
class
page-item
class
page-link
href
html
aria-label
class
pagination pagination-sm
class
page-item active
class
page-link
aria-current
page
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Alignment
Change the alignment of pagination components with
flexbox utilities
. For example, with
.justify-content-center
html
aria-label
Page navigation example
class
pagination justify-content-center
class
page-item disabled
class
page-link
Previous
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Next
Or with
.justify-content-end
html
aria-label
Page navigation example
class
pagination justify-content-end
class
page-item disabled
class
page-link
Previous
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
class
page-item
class
page-link
href
Next
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, pagination now uses local CSS variables on
.pagination
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_pagination.scss
#{$prefix}
pagination-padding-x
#{$pagination-padding-x}
#{$prefix}
pagination-padding-y
#{$pagination-padding-y}
@include
$pagination-font-size
#{$prefix}
pagination-font-size
#{$prefix}
pagination-color
#{$pagination-color}
#{$prefix}
pagination-bg
#{$pagination-bg}
#{$prefix}
pagination-border-width
#{$pagination-border-width}
#{$prefix}
pagination-border-color
#{$pagination-border-color}
#{$prefix}
pagination-border-radius
#{$pagination-border-radius}
#{$prefix}
pagination-hover-color
#{$pagination-hover-color}
#{$prefix}
pagination-hover-bg
#{$pagination-hover-bg}
#{$prefix}
pagination-hover-border-color
#{$pagination-hover-border-color}
#{$prefix}
pagination-focus-color
#{$pagination-focus-color}
#{$prefix}
pagination-focus-bg
#{$pagination-focus-bg}
#{$prefix}
pagination-focus-box-shadow
#{$pagination-focus-box-shadow}
#{$prefix}
pagination-active-color
#{$pagination-active-color}
#{$prefix}
pagination-active-bg
#{$pagination-active-bg}
#{$prefix}
pagination-active-border-color
#{$pagination-active-border-color}
#{$prefix}
pagination-disabled-color
#{$pagination-disabled-color}
#{$prefix}
pagination-disabled-bg
#{$pagination-disabled-bg}
#{$prefix}
pagination-disabled-border-color
#{$pagination-disabled-border-color}
Sass variables
scss/_variables.scss
$pagination-padding-y
.375rem
$pagination-padding-x
.75rem
$pagination-padding-y-sm
.25rem
$pagination-padding-x-sm
.5rem
$pagination-padding-y-lg
.75rem
$pagination-padding-x-lg
1.5rem
$pagination-font-size
$font-size-base
$pagination-color
#{$prefix}
link-color
$pagination-bg
#{$prefix}
body-bg
$pagination-border-radius
#{$prefix}
border-radius
$pagination-border-width
#{$prefix}
border-width
$pagination-margin-start
calc
#{$pagination-border-width}
// stylelint-disable-line function-disallowed-list
$pagination-border-color
#{$prefix}
border-color
$pagination-focus-color
#{$prefix}
link-hover-color
$pagination-focus-bg
#{$prefix}
secondary-bg
$pagination-focus-box-shadow
$focus-ring-box-shadow
$pagination-focus-outline
$pagination-hover-color
#{$prefix}
link-hover-color
$pagination-hover-bg
#{$prefix}
tertiary-bg
$pagination-hover-border-color
#{$prefix}
border-color
// Todo in v6: remove this?
$pagination-active-color
$component-active-color
$pagination-active-bg
$component-active-bg
$pagination-active-border-color
$component-active-bg
$pagination-disabled-color
#{$prefix}
secondary-color
$pagination-disabled-bg
#{$prefix}
secondary-bg
$pagination-disabled-border-color
#{$prefix}
border-color
$pagination-transition
color .15s ease-in-out
background-color .15s ease-in-out
border-color .15s ease-in-out
box-shadow .15s ease-in-out
$pagination-border-radius-sm
#{$prefix}
border-radius-sm
$pagination-border-radius-lg
#{$prefix}
border-radius-lg
Sass mixins
scss/mixins/_pagination.scss
@mixin
pagination-size
$padding-y
$padding-x
$font-size
$border-radius
#{$prefix}
pagination-padding-x
#{$padding-x}
#{$prefix}
pagination-padding-y
#{$padding-y}
@include
$font-size
#{$prefix}
pagination-font-size
#{$prefix}
pagination-border-radius
#{$border-radius}


--- 112_examples_navbar-fixed.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/navbar-fixed
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Navbar example
This example is a quick exercise to illustrate how fixed to top navbar works. As you scroll, it will remain fixed to the top of your browser’s viewport.
View navbar docs »


--- 116_components_collapse.txt ---
URL: https://getbootstrap.com/docs/5.3/components/collapse
--------------------------------------------------
How it works
The collapse JavaScript plugin is used to show and hide content. Buttons or anchors are used as triggers that are mapped to specific elements you toggle. Collapsing an element will animate the
height
from its current value to
. Given how CSS handles animations, you cannot use
padding
on a
.collapse
element. Instead, use the class as an independent wrapping element.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Example
Click the buttons below to show and hide another element via class changes:
.collapse
hides content
.collapsing
is applied during transitions
.collapse.show
shows content
Generally, we recommend using a
<button>
with the
data-bs-target
attribute. While not recommended from a semantic point of view, you can also use an
link with the
href
attribute (and a
role="button"
). In both cases, the
data-bs-toggle="collapse"
is required.
Link with href
Button with data-bs-target
Some placeholder content for the collapse component. This panel is hidden by default but revealed when the user activates the relevant trigger.
html
class
d-inline-flex gap-1
class
btn btn-primary
data-bs-toggle
collapse
href
#collapseExample
role
button
aria-expanded
false
aria-controls
collapseExample
Link with href
button
class
btn btn-primary
type
button
data-bs-toggle
collapse
data-bs-target
#collapseExample
aria-expanded
false
aria-controls
collapseExample
Button with data-bs-target
button
class
collapse
collapseExample
class
card card-body
Some placeholder content for the collapse component. This panel is hidden by default but revealed when the user activates the relevant trigger.
Horizontal
The collapse plugin supports horizontal collapsing. Add the
.collapse-horizontal
modifier class to transition the
width
instead of
height
and set a
width
on the immediate child element. Feel free to write your own custom Sass, use inline styles, or use our
width utilities
Please note that while the example below has a
min-height
set to avoid excessive repaints in our docs, this is not explicitly required.
Only the
width
on the child element is required.
Toggle width collapse
This is some placeholder content for a horizontal collapse. It’s hidden by default and shown when triggered.
html
button
class
btn btn-primary
type
button
data-bs-toggle
collapse
data-bs-target
#collapseWidthExample
aria-expanded
false
aria-controls
collapseWidthExample
Toggle width collapse
button
style
min-height
120px
class
collapse collapse-horizontal
collapseWidthExample
class
card card-body
style
width
300px
This is some placeholder content for a horizontal collapse. It’s hidden by default and shown when triggered.
Multiple toggles and targets
<button>
element can show and hide multiple elements by referencing them with a selector in its
data-bs-target
href
attribute.
Conversely, multiple
<button>
elements can show and hide the same element if they each reference it with their
data-bs-target
href
attribute.
Toggle first element
Toggle second element
Toggle both elements
Some placeholder content for the first collapse component of this multi-collapse example. This panel is hidden by default but revealed when the user activates the relevant trigger.
Some placeholder content for the second collapse component of this multi-collapse example. This panel is hidden by default but revealed when the user activates the relevant trigger.
html
class
d-inline-flex gap-1
class
btn btn-primary
data-bs-toggle
collapse
href
#multiCollapseExample1
role
button
aria-expanded
false
aria-controls
multiCollapseExample1
Toggle first element
button
class
btn btn-primary
type
button
data-bs-toggle
collapse
data-bs-target
#multiCollapseExample2
aria-expanded
false
aria-controls
multiCollapseExample2
Toggle second element
button
button
class
btn btn-primary
type
button
data-bs-toggle
collapse
data-bs-target
.multi-collapse
aria-expanded
false
aria-controls
multiCollapseExample1 multiCollapseExample2
Toggle both elements
button
class
class
class
collapse multi-collapse
multiCollapseExample1
class
card card-body
Some placeholder content for the first collapse component of this multi-collapse example. This panel is hidden by default but revealed when the user activates the relevant trigger.
class
class
collapse multi-collapse
multiCollapseExample2
class
card card-body
Some placeholder content for the second collapse component of this multi-collapse example. This panel is hidden by default but revealed when the user activates the relevant trigger.
Accessibility
Be sure to add
aria-expanded
to the control element. This attribute explicitly conveys the current state of the collapsible element tied to the control to screen readers and similar assistive technologies. If the collapsible element is closed by default, the attribute on the control element should have a value of
aria-expanded="false"
. If you’ve set the collapsible element to be open by default using the
show
class, set
aria-expanded="true"
on the control instead. The plugin will automatically toggle this attribute on the control based on whether or not the collapsible element has been opened or closed (via JavaScript, or because the user triggered another control element also tied to the same collapsible element). If the control element’s HTML element is not a button (e.g., an
<div>
), the attribute
role="button"
should be added to the element.
If your control element is targeting a single collapsible element – i.e. the
data-bs-target
attribute is pointing to an
selector – you should add the
aria-controls
attribute to the control element, containing the
of the collapsible element. Modern screen readers and similar assistive technologies make use of this attribute to provide users with additional shortcuts to navigate directly to the collapsible element itself.
Note that Bootstrap’s current implementation does not cover the various
optional
keyboard interactions described in the
ARIA Authoring Practices Guide accordion pattern
- you will need to include these yourself with custom JavaScript.
Sass variables
scss/_variables.scss
$transition-collapse
height .35s ease
$transition-collapse-width
width .35s ease
Classes
Collapse transition classes can be found in
scss/_transitions.scss
as these are shared across multiple components (collapse and accordion).
scss/_transitions.scss
.collapse
show
display
none
.collapsing
height
overflow
hidden
@include
transition
$transition-collapse
.collapse-horizontal
width
height
auto
@include
transition
$transition-collapse-width
Usage
The collapse plugin utilizes a few classes to handle the heavy lifting:
.collapse
hides the content
.collapse.show
shows the content
.collapsing
is added when the transition starts, and removed when it finishes
These classes can be found in
_transitions.scss
Via data attributes
Just add
data-bs-toggle="collapse"
and a
data-bs-target
to the element to automatically assign control of one or more collapsible elements. The
data-bs-target
attribute accepts a CSS selector to apply the collapse to. Be sure to add the class
collapse
to the collapsible element. If you’d like it to default open, add the additional class
show
To add accordion-like group management to a collapsible area, add the data attribute
data-bs-parent="#selector"
. Refer to the
accordion page
for more information.
Via JavaScript
Enable manually with:
const
collapseElementList
document
querySelectorAll
'.collapse'
const
collapseList
collapseElementList
collapseEl
Collapse
collapseEl
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
parent
selector, DOM element
null
If parent is provided, then all collapsible elements under the specified parent will be closed when this collapsible item is shown. (similar to traditional accordion behavior - this is dependent on the
card
class). The attribute has to be set on the target collapsible area.
toggle
boolean
true
Toggles the collapsible element on invocation.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Activates your content as a collapsible element. Accepts an optional options
object
You can create a collapse instance with the constructor, for example:
const
bsCollapse
Collapse
'#myCollapse'
toggle
false
Method
Description
dispose
Destroys an element’s collapse. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the collapse instance associated to a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a collapse instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
hide
Hides a collapsible element.
Returns to the caller before the collapsible element has actually been hidden
(e.g., before the
hidden.bs.collapse
event occurs).
show
Shows a collapsible element.
Returns to the caller before the collapsible element has actually been shown
(e.g., before the
shown.bs.collapse
event occurs).
toggle
Toggles a collapsible element to shown or hidden.
Returns to the caller before the collapsible element has actually been shown or hidden
(i.e. before the
shown.bs.collapse
hidden.bs.collapse
event occurs).
Events
Event type
Description
hide.bs.collapse
This event is fired immediately when the
hide
method has been called.
hidden.bs.collapse
This event is fired when a collapse element has been hidden from the user (will wait for CSS transitions to complete).
show.bs.collapse
This event fires immediately when the
show
instance method is called.
shown.bs.collapse
This event is fired when a collapse element has been made visible to the user (will wait for CSS transitions to complete).
const
myCollapsible
document
getElementById
'myCollapsible'
myCollapsible
addEventListener
'hidden.bs.collapse'
event
// do something...


--- 118_components_tooltips.txt ---
URL: https://getbootstrap.com/docs/5.3/components/tooltips
--------------------------------------------------
Overview
Things to know when using the tooltip plugin:
Tooltips rely on the third party library
Popper
for positioning. You must include
popper.min.js
before
, or use one
which contains Popper.
Tooltips are opt-in for performance reasons, so
you must initialize them yourself
Tooltips with zero-length titles are never displayed.
Specify
container: 'body'
to avoid rendering problems in more complex components (like our input groups, button groups, etc).
Triggering tooltips on hidden elements will not work.
Tooltips for
.disabled
disabled
elements must be triggered on a wrapper element.
When triggered from hyperlinks that span multiple lines, tooltips will be centered. Use
white-space: nowrap;
on your
s to avoid this behavior.
Tooltips must be hidden before their corresponding elements have been removed from the DOM.
Tooltips can be triggered thanks to an element inside a shadow DOM.
Got all that? Great, let’s see how they work with some examples.
By default, this component uses the built-in content sanitizer, which strips out any HTML elements that are not explicitly allowed. See the
sanitizer section in our JavaScript documentation
for more details.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Examples
Enable tooltips
As mentioned above, you must initialize tooltips before they can be used. One way to initialize all tooltips on a page would be to select them by their
data-bs-toggle
attribute, like so:
const
tooltipTriggerList
document
querySelectorAll
'[data-bs-toggle="tooltip"]'
const
tooltipList
tooltipTriggerList
tooltipTriggerEl
Tooltip
tooltipTriggerEl
Tooltips on links
Hover over the links below to see tooltips:
Placeholder text to demonstrate some
inline links
with tooltips. This is now just filler, no killer. Content placed here just to mimic the presence of
real text
. And all that just to give you an idea of how tooltips would look when used in real-world situations. So hopefully you’ve now seen how
these tooltips on links
can work in practice, once you use them on
your own
site or project.
html
class
muted
Placeholder text to demonstrate some
href
data-bs-toggle
tooltip
data-bs-title
Default tooltip
inline links
with tooltips. This is now just filler, no killer. Content placed here just to mimic the presence of
href
data-bs-toggle
tooltip
data-bs-title
Another tooltip
real text
. And all that just to give you an idea of how tooltips would look when used in real-world situations. So hopefully you’ve now seen how
href
data-bs-toggle
tooltip
data-bs-title
Another one here too
these tooltips on links
can work in practice, once you use them on
href
data-bs-toggle
tooltip
data-bs-title
The last tip!
your own
site or project.
Feel free to use either
title
data-bs-title
in your HTML. When
title
is used, Popper will replace it automatically with
data-bs-title
when the element is rendered.
Custom tooltips
Added in v5.2.0
You can customize the appearance of tooltips using
CSS variables
. We set a custom class with
data-bs-custom-class="custom-tooltip"
to scope our custom appearance and use it to override a local CSS variable.
site/src/scss/_component-examples.scss
.custom-tooltip
--bs-tooltip-bg
--bd-violet-bg
--bs-tooltip-color
--bs-white
Custom tooltip
html
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-placement
data-bs-custom-class
custom-tooltip
data-bs-title
This top tooltip is themed via CSS variables.
Custom tooltip
button
Directions
Hover over the buttons below to see the four tooltips directions: top, right, bottom, and left. Directions are mirrored when using Bootstrap in RTL.
Tooltip on top
Tooltip on right
Tooltip on bottom
Tooltip on left
Tooltip with HTML
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-placement
data-bs-title
Tooltip on top
Tooltip on top
button
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-placement
right
data-bs-title
Tooltip on right
Tooltip on right
button
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-placement
bottom
data-bs-title
Tooltip on bottom
Tooltip on bottom
button
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-placement
left
data-bs-title
Tooltip on left
Tooltip on left
button
And with custom HTML added:
button
type
button
class
btn btn-secondary
data-bs-toggle
tooltip
data-bs-html
true
data-bs-title
<em>Tooltip</em> <u>with</u> <b>HTML</b>
Tooltip with HTML
button
With an SVG:
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, tooltips now use local CSS variables on
.tooltip
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_tooltip.scss
#{$prefix}
tooltip-zindex
#{$zindex-tooltip}
#{$prefix}
tooltip-max-width
#{$tooltip-max-width}
#{$prefix}
tooltip-padding-x
#{$tooltip-padding-x}
#{$prefix}
tooltip-padding-y
#{$tooltip-padding-y}
#{$prefix}
tooltip-margin
#{$tooltip-margin}
@include
$tooltip-font-size
#{$prefix}
tooltip-font-size
#{$prefix}
tooltip-color
#{$tooltip-color}
#{$prefix}
tooltip-bg
#{$tooltip-bg}
#{$prefix}
tooltip-border-radius
#{$tooltip-border-radius}
#{$prefix}
tooltip-opacity
#{$tooltip-opacity}
#{$prefix}
tooltip-arrow-width
#{$tooltip-arrow-width}
#{$prefix}
tooltip-arrow-height
#{$tooltip-arrow-height}
Sass variables
scss/_variables.scss
$tooltip-font-size
$font-size-sm
$tooltip-max-width
200px
$tooltip-color
#{$prefix}
body-bg
$tooltip-bg
#{$prefix}
emphasis-color
$tooltip-border-radius
#{$prefix}
border-radius
$tooltip-opacity
$tooltip-padding-y
$spacer
$tooltip-padding-x
$spacer
$tooltip-margin
null
// TODO: remove this in v6
$tooltip-arrow-width
.8rem
$tooltip-arrow-height
.4rem
// fusv-disable
$tooltip-arrow-color
null
// Deprecated in Bootstrap 5.2.0 for CSS variables
// fusv-enable
Usage
The tooltip plugin generates content and markup on demand, and by default places tooltips after their trigger element. Trigger the tooltip via JavaScript:
const
exampleEl
document
getElementById
'example'
const
tooltip
Tooltip
exampleEl
options
Tooltips automatically attempt to change positions when a parent container has
overflow: auto
overflow: scroll
, but still keeps the original placement’s positioning. Set the
boundary
option
(for the flip modifier using the
popperConfig
option) to any HTMLElement to override the default value,
'clippingParents'
, such as
document.body
const
tooltip
Tooltip
'#example'
boundary
document
body
// or document.querySelector('#boundary')
Markup
The required markup for a tooltip is only a
data
attribute and
title
on the HTML element you wish to have a tooltip. The generated markup of a tooltip is rather simple, though it does require a position (by default, set to
by the plugin).
Keep tooltips accessible to keyboard and assistive technology users
by only adding them to HTML elements that are traditionally keyboard-focusable and interactive (such as links or form controls). While other HTML elements can be made focusable by adding
tabindex="0"
, this can create annoying and confusing tab stops on non-interactive elements for keyboard users, and most assistive technologies currently do not announce tooltips in this situation. Additionally, do not rely solely on
hover
as the trigger for your tooltips as this will make them impossible to trigger for keyboard users.
<!-- HTML to write -->
href
data-bs-toggle
tooltip
data-bs-title
Some tooltip text!
Hover over me
<!-- Generated markup by the plugin -->
class
tooltip bs-tooltip-auto
role
tooltip
class
tooltip-arrow
class
tooltip-inner
Some tooltip text!
Disabled elements
Elements with the
disabled
attribute aren’t interactive, meaning users cannot focus, hover, or click them to trigger a tooltip (or popover). As a workaround, you’ll want to trigger the tooltip from a wrapper
<div>
<span>
, ideally made keyboard-focusable using
tabindex="0"
Disabled button
html
span
class
d-inline-block
tabindex
data-bs-toggle
tooltip
data-bs-title
Disabled tooltip
button
class
btn btn-primary
type
button
disabled
Disabled button
button
span
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Note that for security reasons the
sanitize
sanitizeFn
, and
allowList
options cannot be supplied using data attributes.
Name
Type
Default
Description
allowList
object
Default value
An object containing allowed tags and attributes. Those not explicitly allowed will be removed by
the content sanitizer
Exercise caution when adding to this list.
Refer to
OWASP’s Cross Site Scripting Prevention Cheat Sheet
for more information.
animation
boolean
true
Apply a CSS fade transition to the tooltip.
boundary
string, element
'clippingParents'
Overflow constraint boundary of the tooltip (applies only to Popper’s preventOverflow modifier). By default, it’s
'clippingParents'
and can accept an HTMLElement reference (via JavaScript only). For more information refer to Popper’s
detectOverflow docs
container
string, element, false
false
Appends the tooltip to a specific element. Example:
container: 'body'
. This option is particularly useful in that it allows you to position the tooltip in the flow of the document near the triggering element - which will prevent the tooltip from floating away from the triggering element during a window resize.
customClass
string, function
Add classes to the tooltip when it is shown. Note that these classes will be added in addition to any classes specified in the template. To add multiple classes, separate them with spaces:
'class-1 class-2'
. You can also pass a function that should return a single string containing additional class names.
delay
number, object
Delay showing and hiding the tooltip (ms)—doesn’t apply to manual trigger type. If a number is supplied, delay is applied to both hide/show. Object structure is:
delay: { "show": 500, "hide": 100 }
fallbackPlacements
array
['top', 'right', 'bottom', 'left']
Define fallback placements by providing a list of placements in array (in order of preference). For more information refer to Popper’s
behavior docs
html
boolean
false
Allow HTML in the tooltip. If true, HTML tags in the tooltip’s
title
will be rendered in the tooltip. If false,
innerText
property will be used to insert content into the DOM. Prefer text when dealing with user-generated input to
prevent XSS attacks
offset
array, string, function
[0, 6]
Offset of the tooltip relative to its target. You can pass a string in data attributes with comma separated values like:
data-bs-offset="10,20"
. When a function is used to determine the offset, it is called with an object containing the popper placement, the reference, and popper rects as its first argument. The triggering element DOM node is passed as the second argument. The function must return an array with two numbers:
skidding
distance
. For more information refer to Popper’s
offset docs
placement
string, function
'top'
How to position the tooltip: auto, top, bottom, left, right. When
auto
is specified, it will dynamically reorient the tooltip. When a function is used to determine the placement, it is called with the tooltip DOM node as its first argument and the triggering element DOM node as its second. The
this
context is set to the tooltip instance.
popperConfig
null, object, function
null
To change Bootstrap’s default Popper config, see
Popper’s configuration
. When a function is used to create the Popper configuration, it’s called with an object that contains the Bootstrap’s default Popper configuration. It helps you use and merge the default with your own configuration. The function must return a configuration object for Popper.
sanitize
boolean
true
Enable
content sanitization
. If true, the
template
content
title
options will be sanitized.
Exercise caution when disabling content sanitization.
Refer to
OWASP’s Cross Site Scripting Prevention Cheat Sheet
for more information. Vulnerabilities caused solely by disabling content sanitization are not considered within scope for Bootstrap’s security model.
sanitizeFn
null, function
null
Provide an alternative
content sanitization
function. This can be useful if you prefer to use a dedicated library to perform sanitization.
selector
string, false
false
If a selector is provided, tooltip objects will be delegated to the specified targets. In practice, this is used to also apply tooltips to dynamically added DOM elements (
jQuery.on
support). See
this issue
an informative example
Note
title
attribute must not be used as a selector.
template
string
'<div class="tooltip" role="tooltip"><div class="tooltip-arrow"></div><div class="tooltip-inner"></div></div>'
Base HTML to use when creating the tooltip. The tooltip’s
title
will be injected into the
.tooltip-inner
.tooltip-arrow
will become the tooltip’s arrow. The outermost wrapper element should have the
.tooltip
class and
role="tooltip"
title
string, element, function
The tooltip title. If a function is given, it will be called with its
this
reference set to the element that the popover is attached to.
trigger
string
'hover focus'
How tooltip is triggered: click, hover, focus, manual. You may pass multiple triggers; separate them with a space.
'manual'
indicates that the tooltip will be triggered programmatically via the
.tooltip('show')
.tooltip('hide')
.tooltip('toggle')
methods; this value cannot be combined with any other trigger.
'hover'
on its own will result in tooltips that cannot be triggered via the keyboard, and should only be used if alternative methods for conveying the same information for keyboard users is present.
Data attributes for individual tooltips
Options for individual tooltips can alternatively be specified through the use of data attributes, as explained above.
Using function with
popperConfig
const
tooltip
Tooltip
element
popperConfig
defaultBsPopperConfig
// const newPopperConfig = {...}
// use defaultBsPopperConfig if needed...
// return newPopperConfig
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Method
Description
disable
Removes the ability for an element’s tooltip to be shown. The tooltip will only be able to be shown if it is re-enabled.
dispose
Hides and destroys an element’s tooltip (Removes stored data on the DOM element). Tooltips that use delegation (which are created using
selector
option
) cannot be individually destroyed on descendant trigger elements.
enable
Gives an element’s tooltip the ability to be shown.
Tooltips are enabled by default.
getInstance
Static
method which allows you to get the tooltip instance associated with a DOM element.
getOrCreateInstance
Static
method which allows you to get the tooltip instance associated with a DOM element, or create a new one in case it wasn’t initialized.
hide
Hides an element’s tooltip.
Returns to the caller before the tooltip has actually been hidden
(i.e. before the
hidden.bs.tooltip
event occurs). This is considered a “manual” triggering of the tooltip.
setContent
Gives a way to change the tooltip’s content after its initialization.
show
Reveals an element’s tooltip.
Returns to the caller before the tooltip has actually been shown
(i.e. before the
shown.bs.tooltip
event occurs). This is considered a “manual” triggering of the tooltip. Tooltips with zero-length titles are never displayed.
toggle
Toggles an element’s tooltip.
Returns to the caller before the tooltip has actually been shown or hidden
(i.e. before the
shown.bs.tooltip
hidden.bs.tooltip
event occurs). This is considered a “manual” triggering of the tooltip.
toggleEnabled
Toggles the ability for an element’s tooltip to be shown or hidden.
update
Updates the position of an element’s tooltip.
const
tooltip
Tooltip
getInstance
'#example'
// Returns a Bootstrap tooltip instance
// setContent example
tooltip
setContent
'.tooltip-inner'
'another title'
setContent
method accepts an
object
argument, where each property-key is a valid
string
selector within the tooltip template, and each related property-value can be
string
element
function
null
Events
Event
Description
hide.bs.tooltip
This event is fired immediately when the
hide
instance method has been called.
hidden.bs.tooltip
This event is fired when the tooltip has finished being hidden from the user (will wait for CSS transitions to complete).
inserted.bs.tooltip
This event is fired after the
show.bs.tooltip
event when the tooltip template has been added to the DOM.
show.bs.tooltip
This event fires immediately when the
show
instance method is called.
shown.bs.tooltip
This event is fired when the tooltip has been made visible to the user (will wait for CSS transitions to complete).
const
myTooltipEl
document
getElementById
'myTooltip'
const
tooltip
Tooltip
getOrCreateInstance
myTooltipEl
myTooltipEl
addEventListener
'hidden.bs.tooltip'
// do something...
tooltip
hide


--- 121_components_button-group.txt ---
URL: https://getbootstrap.com/docs/5.3/components/button-group
--------------------------------------------------
Basic example
Wrap a series of buttons with
.btn
.btn-group
Left
Middle
Right
html
class
btn-group
role
group
aria-label
Basic example
button
type
button
class
btn btn-primary
Left
button
button
type
button
class
btn btn-primary
Middle
button
button
type
button
class
btn btn-primary
Right
button
Button groups require an appropriate
role
attribute and explicit label to ensure assistive technologies like screen readers identify buttons as grouped and announce them. Use
role="group"
for button groups or
role="toolbar"
for button toolbars. Then use
aria-label
aria-labelledby
to label them.
These classes can also be added to groups of links, as an alternative to the
.nav
navigation components
Active link
Link
Link
html
class
btn-group
href
class
btn btn-primary active
aria-current
page
Active link
href
class
btn btn-primary
Link
href
class
btn btn-primary
Link
Mixed styles
Left
Middle
Right
html
class
btn-group
role
group
aria-label
Basic mixed styles example
button
type
button
class
btn btn-danger
Left
button
button
type
button
class
btn btn-warning
Middle
button
button
type
button
class
btn btn-success
Right
button
Outlined styles
Left
Middle
Right
html
class
btn-group
role
group
aria-label
Basic outlined example
button
type
button
class
btn btn-outline-primary
Left
button
button
type
button
class
btn btn-outline-primary
Middle
button
button
type
button
class
btn btn-outline-primary
Right
button
Checkbox and radio button groups
Combine button-like checkbox and radio
toggle buttons
into a seamless looking button group.
Checkbox 1
Checkbox 2
Checkbox 3
html
class
btn-group
role
group
aria-label
Basic checkbox toggle button group
input
type
checkbox
class
btn-check
btncheck1
autocomplete
label
class
btn btn-outline-primary
btncheck1
Checkbox 1
label
input
type
checkbox
class
btn-check
btncheck2
autocomplete
label
class
btn btn-outline-primary
btncheck2
Checkbox 2
label
input
type
checkbox
class
btn-check
btncheck3
autocomplete
label
class
btn btn-outline-primary
btncheck3
Checkbox 3
label
Radio 1
Radio 2
Radio 3
html
class
btn-group
role
group
aria-label
Basic radio toggle button group
input
type
radio
class
btn-check
name
btnradio
btnradio1
autocomplete
checked
label
class
btn btn-outline-primary
btnradio1
Radio 1
label
input
type
radio
class
btn-check
name
btnradio
btnradio2
autocomplete
label
class
btn btn-outline-primary
btnradio2
Radio 2
label
input
type
radio
class
btn-check
name
btnradio
btnradio3
autocomplete
label
class
btn btn-outline-primary
btnradio3
Radio 3
label
Button toolbar
Combine sets of button groups into button toolbars for more complex components. Use utility classes as needed to space out groups, buttons, and more.
html
class
btn-toolbar
role
toolbar
aria-label
Toolbar with button groups
class
btn-group me-2
role
group
aria-label
First group
button
type
button
class
btn btn-primary
button
button
type
button
class
btn btn-primary
button
button
type
button
class
btn btn-primary
button
button
type
button
class
btn btn-primary
button
class
btn-group me-2
role
group
aria-label
Second group
button
type
button
class
btn btn-secondary
button
button
type
button
class
btn btn-secondary
button
button
type
button
class
btn btn-secondary
button
class
btn-group
role
group
aria-label
Third group
button
type
button
class
btn btn-info
button
Feel free to mix input groups with button groups in your toolbars. Similar to the example above, you’ll likely need some utilities though to space things properly.
html
class
btn-toolbar mb-3
role
toolbar
aria-label
Toolbar with button groups
class
btn-group me-2
role
group
aria-label
First group
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
class
input-group
class
input-group-text
btnGroupAddon
input
type
text
class
form-control
placeholder
Input group example
aria-label
Input group example
aria-describedby
btnGroupAddon
class
btn-toolbar justify-content-between
role
toolbar
aria-label
Toolbar with button groups
class
btn-group
role
group
aria-label
First group
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
button
type
button
class
btn btn-outline-secondary
button
class
input-group
class
input-group-text
btnGroupAddon2
input
type
text
class
form-control
placeholder
Input group example
aria-label
Input group example
aria-describedby
btnGroupAddon2
Sizing
Instead of applying button sizing classes to every button in a group, just add
.btn-group-*
to each
.btn-group
, including each one when nesting multiple groups.
Left
Middle
Right
Left
Middle
Right
Left
Middle
Right
html
class
btn-group btn-group-lg
role
group
aria-label
Large button group
button
type
button
class
btn btn-outline-primary
Left
button
button
type
button
class
btn btn-outline-primary
Middle
button
button
type
button
class
btn btn-outline-primary
Right
button
class
btn-group
role
group
aria-label
Default button group
button
type
button
class
btn btn-outline-primary
Left
button
button
type
button
class
btn btn-outline-primary
Middle
button
button
type
button
class
btn btn-outline-primary
Right
button
class
btn-group btn-group-sm
role
group
aria-label
Small button group
button
type
button
class
btn btn-outline-primary
Left
button
button
type
button
class
btn btn-outline-primary
Middle
button
button
type
button
class
btn btn-outline-primary
Right
button
Nesting
Place a
.btn-group
within another
.btn-group
when you want dropdown menus mixed with a series of buttons.
Dropdown
Dropdown link
Dropdown link
html
class
btn-group
role
group
aria-label
Button group with nested dropdown
button
type
button
class
btn btn-primary
button
button
type
button
class
btn btn-primary
button
class
btn-group
role
group
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Dropdown link
class
dropdown-item
href
Dropdown link
Vertical variation
Make a set of buttons appear vertically stacked rather than horizontally.
Split button dropdowns are not supported here.
Button
Button
Button
Button
html
class
btn-group-vertical
role
group
aria-label
Vertical button group
button
type
button
class
btn btn-primary
Button
button
button
type
button
class
btn btn-primary
Button
button
button
type
button
class
btn btn-primary
Button
button
button
type
button
class
btn btn-primary
Button
button
Dropdown
Dropdown link
Dropdown link
Button
Button
Dropdown
Dropdown link
Dropdown link
Dropdown
Dropdown link
Dropdown link
Dropdown
Dropdown link
Dropdown link
html
class
btn-group-vertical
role
group
aria-label
Vertical button group
class
btn-group
role
group
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Dropdown link
class
dropdown-item
href
Dropdown link
button
type
button
class
btn btn-primary
Button
button
button
type
button
class
btn btn-primary
Button
button
class
btn-group dropstart
role
group
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Dropdown link
class
dropdown-item
href
Dropdown link
class
btn-group dropend
role
group
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Dropdown link
class
dropdown-item
href
Dropdown link
class
btn-group dropup
role
group
button
type
button
class
btn btn-primary dropdown-toggle
data-bs-toggle
dropdown
aria-expanded
false
Dropdown
button
class
dropdown-menu
class
dropdown-item
href
Dropdown link
class
dropdown-item
href
Dropdown link
Radio 1
Radio 2
Radio 3
html
class
btn-group-vertical
role
group
aria-label
Vertical radio toggle button group
input
type
radio
class
btn-check
name
vbtn-radio
vbtn-radio1
autocomplete
checked
label
class
btn btn-outline-danger
vbtn-radio1
Radio 1
label
input
type
radio
class
btn-check
name
vbtn-radio
vbtn-radio2
autocomplete
label
class
btn btn-outline-danger
vbtn-radio2
Radio 2
label
input
type
radio
class
btn-check
name
vbtn-radio
vbtn-radio3
autocomplete
label
class
btn btn-outline-danger
vbtn-radio3
Radio 3
label


--- 130_examples_badges.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/badges
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Primary 1
Primary 2
Primary 3
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark


--- 134_components_toasts.txt ---
URL: https://getbootstrap.com/docs/5.3/components/toasts
--------------------------------------------------
Toasts are lightweight notifications designed to mimic the push notifications that have been popularized by mobile and desktop operating systems. They’re built with flexbox, so they’re easy to align and position.
Overview
Things to know when using the toast plugin:
Toasts are opt-in for performance reasons, so
you must initialize them yourself
Toasts will automatically hide if you do not specify
autohide: false
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Examples
Basic
To encourage extensible and predictable toasts, we recommend a header and body. Toast headers use
display: flex
, allowing easy alignment of content thanks to our margin and flexbox utilities.
Toasts are as flexible as you need and have very little required markup. At a minimum, we require a single element to contain your “toasted” content and strongly encourage a dismiss button.
11 mins ago
Hello, world! This is a toast message.
html
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
11 mins ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Hello, world! This is a toast message.
Previously, our scripts dynamically added the
.hide
class to completely hide a toast (with
display:none
, rather than just with
opacity:0
). This is now not necessary anymore. However, for backwards compatibility, our script will continue to toggle the class (even though there is no practical need for it) until the next major version.
Live example
Click the button below to show a toast (positioned with our utilities in the lower right corner) that has been hidden by default.
11 mins ago
Hello, world! This is a toast message.
Show live toast
button
type
button
class
btn btn-primary
liveToastBtn
Show live toast
button
class
toast-container position-fixed bottom-0 end-0 p-3
liveToast
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
11 mins ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Hello, world! This is a toast message.
We use the following JavaScript to trigger our live toast demo:
site/src/assets/partials/snippets.js
const
toastTrigger
document
getElementById
'liveToastBtn'
const
toastLiveExample
document
getElementById
'liveToast'
toastTrigger
const
toastBootstrap
Toast
getOrCreateInstance
toastLiveExample
toastTrigger
addEventListener
'click'
toastBootstrap
show
Translucent
Toasts are slightly translucent to blend in with what’s below them.
11 mins ago
Hello, world! This is a toast message.
html
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
class
text-body-secondary
11 mins ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Hello, world! This is a toast message.
Stacking
You can stack toasts by wrapping them in a toast container, which will vertically add some spacing.
just now
See? Just like this.
2 seconds ago
Heads up, toasts will stack automatically
html
class
toast-container position-static
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
class
text-body-secondary
just now
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
See? Just like this.
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
class
text-body-secondary
2 seconds ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Heads up, toasts will stack automatically
Custom content
Customize your toasts by removing sub-components, tweaking them with
utilities
, or by adding your own markup. Here we’ve created a simpler toast by removing the default
.toast-header
, adding a custom hide icon from
, and using some
flexbox utilities
to adjust the layout.
Hello, world! This is a toast message.
html
class
toast align-items-center
role
alert
aria-live
assertive
aria-atomic
true
class
d-flex
class
toast-body
Hello, world! This is a toast message.
button
type
button
class
btn-close me-2 m-auto
data-bs-dismiss
toast
aria-label
Close
button
Alternatively, you can also add additional controls and components to toasts.
Hello, world! This is a toast message.
Take action
Close
html
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-body
Hello, world! This is a toast message.
class
mt-2 pt-2 border-top
button
type
button
class
btn btn-primary btn-sm
Take action
button
button
type
button
class
btn btn-secondary btn-sm
data-bs-dismiss
toast
Close
button
Color schemes
Building on the above example, you can create different toast color schemes with our
color
background
utilities. Here we’ve added
.text-bg-primary
to the
.toast
, and then added
.btn-close-white
to our close button. For a crisp edge, we remove the default border with
.border-0
Hello, world! This is a toast message.
html
class
toast align-items-center text-bg-primary border-0
role
alert
aria-live
assertive
aria-atomic
true
class
d-flex
class
toast-body
Hello, world! This is a toast message.
button
type
button
class
btn-close btn-close-white me-2 m-auto
data-bs-dismiss
toast
aria-label
Close
button
Placement
Place toasts with custom CSS as you need them. The top right is often used for notifications, as is the top middle. If you’re only ever going to show one toast at a time, put the positioning styles right on the
.toast
Toast placement
Select a position...
Top left
Top center
Top right
Middle left
Middle center
Middle right
Bottom left
Bottom center
Bottom right
11 mins ago
Hello, world! This is a toast message.
html
form
class
mb-3
label
selectToastPlacement
Toast placement
label
select
class
form-select mt-2
selectToastPlacement
option
value
selected
Select a position...
option
option
value
top-0 start-0
Top left
option
option
value
top-0 start-50 translate-middle-x
Top center
option
option
value
top-0 end-0
Top right
option
option
value
top-50 start-0 translate-middle-y
Middle left
option
option
value
top-50 start-50 translate-middle
Middle center
option
option
value
top-50 end-0 translate-middle-y
Middle right
option
option
value
bottom-0 start-0
Bottom left
option
option
value
bottom-0 start-50 translate-middle-x
Bottom center
option
option
value
bottom-0 end-0
Bottom right
option
select
form
aria-live
polite
aria-atomic
true
class
bg-body-secondary position-relative bd-example-toasts rounded-3
class
toast-container p-3
toastPlacement
class
toast
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
11 mins ago
small
class
toast-body
Hello, world! This is a toast message.
For systems that generate more notifications, consider using a wrapping element so they can easily stack.
just now
See? Just like this.
2 seconds ago
Heads up, toasts will stack automatically
html
aria-live
polite
aria-atomic
true
class
position-relative
<!-- Position it: -->
<!-- - `.toast-container` for spacing between toasts -->
<!-- - `top-0` & `end-0` to position the toasts in the upper right corner -->
<!-- - `.p-3` to prevent the toasts from sticking to the edge of the container  -->
class
toast-container top-0 end-0 p-3
<!-- Then put toasts within -->
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
class
text-body-secondary
just now
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
See? Just like this.
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
class
text-body-secondary
2 seconds ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Heads up, toasts will stack automatically
You can also get fancy with flexbox utilities to align toasts horizontally and/or vertically.
11 mins ago
Hello, world! This is a toast message.
html
<!-- Flexbox container for aligning the toasts -->
aria-live
polite
aria-atomic
true
class
d-flex justify-content-center align-items-center w-100
<!-- Then put toasts within -->
class
toast
role
alert
aria-live
assertive
aria-atomic
true
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
11 mins ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Hello, world! This is a toast message.
Accessibility
Toasts are intended to be small interruptions to your visitors or users, so to help those with screen readers and similar assistive technologies, you should wrap your toasts in an
aria-live
region
. Changes to live regions (such as injecting/updating a toast component) are automatically announced by screen readers without needing to move the user’s focus or otherwise interrupt the user. Additionally, include
aria-atomic="true"
to ensure that the entire toast is always announced as a single (atomic) unit, rather than just announcing what was changed (which could lead to problems if you only update part of the toast’s content, or if displaying the same toast content at a later point in time). If the information needed is important for the process, e.g. for a list of errors in a form, then use the
alert component
instead of toast.
Note that the live region needs to be present in the markup
before
the toast is generated or updated. If you dynamically generate both at the same time and inject them into the page, they will generally not be announced by assistive technologies.
You also need to adapt the
role
aria-live
level depending on the content. If it’s an important message like an error, use
role="alert" aria-live="assertive"
, otherwise use
role="status" aria-live="polite"
attributes.
As the content you’re displaying changes, be sure to update the
delay
timeout
so that users have enough time to read the toast.
class
toast
role
alert
aria-live
polite
aria-atomic
true
data-bs-delay
10000
role
alert
aria-live
assertive
aria-atomic
true
When using
autohide: false
, you must add a close button to allow users to dismiss the toast.
11 mins ago
Hello, world! This is a toast message.
html
role
alert
aria-live
assertive
aria-atomic
true
class
toast
data-bs-autohide
false
class
toast-header
class
rounded me-2
strong
class
me-auto
strong
small
11 mins ago
small
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
class
toast-body
Hello, world! This is a toast message.
While technically it’s possible to add focusable/actionable controls (such as additional buttons or links) in your toast, you should avoid doing this for autohiding toasts. Even if you give the toast a long
delay
timeout
, keyboard and assistive technology users may find it difficult to reach the toast in time to take action (since toasts don’t receive focus when they are displayed). If you absolutely must have further controls, we recommend using a toast with
autohide: false
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, toasts now use local CSS variables on
.toast
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_toasts.scss
#{$prefix}
toast-zindex
#{$zindex-toast}
#{$prefix}
toast-padding-x
#{$toast-padding-x}
#{$prefix}
toast-padding-y
#{$toast-padding-y}
#{$prefix}
toast-spacing
#{$toast-spacing}
#{$prefix}
toast-max-width
#{$toast-max-width}
@include
$toast-font-size
#{$prefix}
toast-font-size
#{$prefix}
toast-color
#{$toast-color}
#{$prefix}
toast-bg
#{$toast-background-color}
#{$prefix}
toast-border-width
#{$toast-border-width}
#{$prefix}
toast-border-color
#{$toast-border-color}
#{$prefix}
toast-border-radius
#{$toast-border-radius}
#{$prefix}
toast-box-shadow
#{$toast-box-shadow}
#{$prefix}
toast-header-color
#{$toast-header-color}
#{$prefix}
toast-header-bg
#{$toast-header-background-color}
#{$prefix}
toast-header-border-color
#{$toast-header-border-color}
Sass variables
scss/_variables.scss
$toast-max-width
350px
$toast-padding-x
.75rem
$toast-padding-y
.5rem
$toast-font-size
.875rem
$toast-color
null
$toast-background-color
rgba
#{$prefix}
body-bg-rgb
$toast-border-width
#{$prefix}
border-width
$toast-border-color
#{$prefix}
border-color-translucent
$toast-border-radius
#{$prefix}
border-radius
$toast-box-shadow
#{$prefix}
box-shadow
$toast-spacing
$container-padding-x
$toast-header-color
#{$prefix}
secondary-color
$toast-header-background-color
rgba
#{$prefix}
body-bg-rgb
$toast-header-border-color
$toast-border-color
Usage
Initialize toasts via JavaScript:
const
toastElList
document
querySelectorAll
'.toast'
const
toastList
toastElList
toastEl
Toast
toastEl
option
Triggers
Dismissal can be achieved with the
data-bs-dismiss
attribute on a button
within the toast
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
toast
aria-label
Close
button
or on a button
outside the toast
using the additional
data-bs-target
as demonstrated below:
button
type
button
class
btn-close
data-bs-dismiss
toast
data-bs-target
#my-toast
aria-label
Close
button
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
animation
boolean
true
Apply a CSS fade transition to the toast.
autohide
boolean
true
Automatically hide the toast after the delay.
delay
number
5000
Delay in milliseconds before hiding the toast.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Method
Description
dispose
Hides an element’s toast. Your toast will remain on the DOM but won’t show anymore.
getInstance
Static
method which allows you to get the toast instance associated with a DOM element.
For example:
const myToastEl = document.getElementById('myToastEl')
const myToast = bootstrap.Toast.getInstance(myToastEl)
Returns a Bootstrap toast instance.
getOrCreateInstance
Static
method which allows you to get the toast instance associated with a DOM element, or create a new one, in case it wasn’t initialized.
const myToastEl = document.getElementById('myToastEl')
const myToast = bootstrap.Toast.getOrCreateInstance(myToastEl)
Returns a Bootstrap toast instance.
hide
Hides an element’s toast.
Returns to the caller before the toast has actually been hidden
(i.e. before the
hidden.bs.toast
event occurs). You have to manually call this method if you made
autohide
false
isShown
Returns a boolean according to toast’s visibility state.
show
Reveals an element’s toast.
Returns to the caller before the toast has actually been shown
(i.e. before the
shown.bs.toast
event occurs). You have to manually call this method, instead your toast won’t show.
Events
Event
Description
hide.bs.toast
This event is fired immediately when the
hide
instance method has been called.
hidden.bs.toast
This event is fired when the toast has finished being hidden from the user.
show.bs.toast
This event fires immediately when the
show
instance method is called.
shown.bs.toast
This event is fired when the toast has been made visible to the user.
const
myToastEl
document
getElementById
'myToast'
myToastEl
addEventListener
'hidden.bs.toast'
// do something...


--- 135_components_accordion.txt ---
URL: https://getbootstrap.com/docs/5.3/components/accordion
--------------------------------------------------
How it works
The accordion uses
collapse
internally to make it collapsible.
The animation effect of this component is dependent on the
prefers-reduced-motion
media query. See the
reduced motion section of our accessibility documentation
Example
Click the accordions below to expand/collapse the accordion content.
To render an accordion that’s expanded by default:
add the
.show
class on the
.accordion-collapse
element.
drop the
.collapsed
class from the
.accordion-button
element and set its
aria-expanded
attribute to
true
Accordion Item #1
This is the first item’s accordion body.
It is shown by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #2
This is the second item’s accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #3
This is the third item’s accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
html
class
accordion
accordionExample
class
accordion-item
class
accordion-header
button
class
accordion-button
type
button
data-bs-toggle
collapse
data-bs-target
#collapseOne
aria-expanded
true
aria-controls
collapseOne
Accordion Item #1
button
collapseOne
class
accordion-collapse collapse show
data-bs-parent
#accordionExample
class
accordion-body
strong
This is the first item’s accordion body.
strong
It is shown by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#collapseTwo
aria-expanded
false
aria-controls
collapseTwo
Accordion Item #2
button
collapseTwo
class
accordion-collapse collapse
data-bs-parent
#accordionExample
class
accordion-body
strong
This is the second item’s accordion body.
strong
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#collapseThree
aria-expanded
false
aria-controls
collapseThree
Accordion Item #3
button
collapseThree
class
accordion-collapse collapse
data-bs-parent
#accordionExample
class
accordion-body
strong
This is the third item’s accordion body.
strong
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
Flush
.accordion-flush
to remove some borders and rounded corners to render accordions edge-to-edge with their parent container.
Accordion Item #1
Placeholder content for this accordion, which is intended to demonstrate the
.accordion-flush
class. This is the first item’s accordion body.
Accordion Item #2
Placeholder content for this accordion, which is intended to demonstrate the
.accordion-flush
class. This is the second item’s accordion body. Let’s imagine this being filled with some actual content.
Accordion Item #3
Placeholder content for this accordion, which is intended to demonstrate the
.accordion-flush
class. This is the third item’s accordion body. Nothing more exciting happening here in terms of content, but just filling up the space to make it look, at least at first glance, a bit more representative of how this would look in a real-world application.
html
class
accordion accordion-flush
accordionFlushExample
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#flush-collapseOne
aria-expanded
false
aria-controls
flush-collapseOne
Accordion Item #1
button
flush-collapseOne
class
accordion-collapse collapse
data-bs-parent
#accordionFlushExample
class
accordion-body
Placeholder content for this accordion, which is intended to demonstrate the
code
.accordion-flush
code
class. This is the first item’s accordion body.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#flush-collapseTwo
aria-expanded
false
aria-controls
flush-collapseTwo
Accordion Item #2
button
flush-collapseTwo
class
accordion-collapse collapse
data-bs-parent
#accordionFlushExample
class
accordion-body
Placeholder content for this accordion, which is intended to demonstrate the
code
.accordion-flush
code
class. This is the second item’s accordion body. Let’s imagine this being filled with some actual content.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#flush-collapseThree
aria-expanded
false
aria-controls
flush-collapseThree
Accordion Item #3
button
flush-collapseThree
class
accordion-collapse collapse
data-bs-parent
#accordionFlushExample
class
accordion-body
Placeholder content for this accordion, which is intended to demonstrate the
code
.accordion-flush
code
class. This is the third item’s accordion body. Nothing more exciting happening here in terms of content, but just filling up the space to make it look, at least at first glance, a bit more representative of how this would look in a real-world application.
Always open
Omit the
data-bs-parent
attribute on each
.accordion-collapse
to make accordion items stay open when another item is opened.
Accordion Item #1
This is the first item’s accordion body.
It is shown by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #2
This is the second item’s accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #3
This is the third item’s accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
html
class
accordion
accordionPanelsStayOpenExample
class
accordion-item
class
accordion-header
button
class
accordion-button
type
button
data-bs-toggle
collapse
data-bs-target
#panelsStayOpen-collapseOne
aria-expanded
true
aria-controls
panelsStayOpen-collapseOne
Accordion Item #1
button
panelsStayOpen-collapseOne
class
accordion-collapse collapse show
class
accordion-body
strong
This is the first item’s accordion body.
strong
It is shown by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#panelsStayOpen-collapseTwo
aria-expanded
false
aria-controls
panelsStayOpen-collapseTwo
Accordion Item #2
button
panelsStayOpen-collapseTwo
class
accordion-collapse collapse
class
accordion-body
strong
This is the second item’s accordion body.
strong
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
class
accordion-item
class
accordion-header
button
class
accordion-button collapsed
type
button
data-bs-toggle
collapse
data-bs-target
#panelsStayOpen-collapseThree
aria-expanded
false
aria-controls
panelsStayOpen-collapseThree
Accordion Item #3
button
panelsStayOpen-collapseThree
class
accordion-collapse collapse
class
accordion-body
strong
This is the third item’s accordion body.
strong
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It’s also worth noting that just about any HTML can go within the
code
.accordion-body
code
, though the transition does limit overflow.
Accessibility
Please read the
collapse accessibility section
for more information.
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, accordions now use local CSS variables on
.accordion
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_accordion.scss
#{$prefix}
accordion-color
#{$accordion-color}
#{$prefix}
accordion-bg
#{$accordion-bg}
#{$prefix}
accordion-transition
#{$accordion-transition}
#{$prefix}
accordion-border-color
#{$accordion-border-color}
#{$prefix}
accordion-border-width
#{$accordion-border-width}
#{$prefix}
accordion-border-radius
#{$accordion-border-radius}
#{$prefix}
accordion-inner-border-radius
#{$accordion-inner-border-radius}
#{$prefix}
accordion-btn-padding-x
#{$accordion-button-padding-x}
#{$prefix}
accordion-btn-padding-y
#{$accordion-button-padding-y}
#{$prefix}
accordion-btn-color
#{$accordion-button-color}
#{$prefix}
accordion-btn-bg
#{$accordion-button-bg}
#{$prefix}
accordion-btn-icon
escape-svg
$accordion-button-icon
#{$prefix}
accordion-btn-icon-width
#{$accordion-icon-width}
#{$prefix}
accordion-btn-icon-transform
#{$accordion-icon-transform}
#{$prefix}
accordion-btn-icon-transition
#{$accordion-icon-transition}
#{$prefix}
accordion-btn-active-icon
escape-svg
$accordion-button-active-icon
#{$prefix}
accordion-btn-focus-box-shadow
#{$accordion-button-focus-box-shadow}
#{$prefix}
accordion-body-padding-x
#{$accordion-body-padding-x}
#{$prefix}
accordion-body-padding-y
#{$accordion-body-padding-y}
#{$prefix}
accordion-active-color
#{$accordion-button-active-color}
#{$prefix}
accordion-active-bg
#{$accordion-button-active-bg}
Sass variables
scss/_variables.scss
$accordion-padding-y
1rem
$accordion-padding-x
1.25rem
$accordion-color
#{$prefix}
body-color
$accordion-bg
#{$prefix}
body-bg
$accordion-border-width
#{$prefix}
border-width
$accordion-border-color
#{$prefix}
border-color
$accordion-border-radius
#{$prefix}
border-radius
$accordion-inner-border-radius
subtract
$accordion-border-radius
$accordion-border-width
$accordion-body-padding-y
$accordion-padding-y
$accordion-body-padding-x
$accordion-padding-x
$accordion-button-padding-y
$accordion-padding-y
$accordion-button-padding-x
$accordion-padding-x
$accordion-button-color
#{$prefix}
body-color
$accordion-button-bg
#{$prefix}
accordion-bg
$accordion-transition
$btn-transition
border-radius .15s ease
$accordion-button-active-bg
#{$prefix}
primary-bg-subtle
$accordion-button-active-color
#{$prefix}
primary-text-emphasis
// fusv-disable
$accordion-button-focus-border-color
$input-focus-border-color
// Deprecated in v5.3.3
// fusv-enable
$accordion-button-focus-box-shadow
$btn-focus-box-shadow
$accordion-icon-width
1.25rem
$accordion-icon-color
$body-color
$accordion-icon-active-color
$primary-text-emphasis
$accordion-icon-transition
transform .2s ease-in-out
$accordion-icon-transform
rotate
-180deg
$accordion-button-icon
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='none' stroke='#{$accordion-icon-color}' stroke-linecap='round' stroke-linejoin='round'><path d='m2 5 6 6 6-6'/></svg>"
$accordion-button-active-icon
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='none' stroke='#{$accordion-icon-active-color}' stroke-linecap='round' stroke-linejoin='round'><path d='m2 5 6 6 6-6'/></svg>"
Usage
The collapse plugin utilizes a few classes to handle the heavy lifting:
.collapse
hides the content
.collapse.show
shows the content
.collapsing
is added when the transition starts, and removed when it finishes
These classes can be found in
_transitions.scss
Via data attributes
Just add
data-bs-toggle="collapse"
and a
data-bs-target
to the element to automatically assign control of one or more collapsible elements. The
data-bs-target
attribute accepts a CSS selector to apply the collapse to. Be sure to add the class
collapse
to the collapsible element. If you’d like it to default open, add the additional class
show
To add accordion group management to a collapsible area, add the data attribute
data-bs-parent="#selector"
Via JavaScript
Enable manually with:
const
accordionCollapseElementList
document
querySelectorAll
'#myAccordion .collapse'
const
accordionCollapseList
accordionCollapseElementList
accordionCollapseEl
Collapse
accordionCollapseEl
Options
As options can be passed via data attributes or JavaScript, you can append an option name to
data-bs-
, as in
data-bs-animation="{value}"
. Make sure to change the case type of the option name from “
camelCase
” to “
kebab-case
” when passing the options via data attributes. For example, use
data-bs-custom-class="beautifier"
instead of
data-bs-customClass="beautifier"
As of Bootstrap 5.2.0, all components support an
experimental
reserved data attribute
data-bs-config
that can house simple component configuration as a JSON string. When an element has
data-bs-config='{"delay":0, "title":123}'
data-bs-title="456"
attributes, the final
title
value will be
and the separate data attributes will override values given on
data-bs-config
. In addition, existing data attributes are able to house JSON values like
data-bs-delay='{"show":0,"hide":150}'
The final configuration object is the merged result of
data-bs-config
data-bs-
, and
js object
where the latest given key-value overrides the others.
Name
Type
Default
Description
parent
selector, DOM element
null
If parent is provided, then all collapsible elements under the specified parent will be closed when this collapsible item is shown. (similar to traditional accordion behavior - this is dependent on the
card
class). The attribute has to be set on the target collapsible area.
toggle
boolean
true
Toggles the collapsible element on invocation.
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Activates your content as a collapsible element. Accepts an optional options
object
You can create a collapse instance with the constructor, for example:
const
bsCollapse
Collapse
'#myCollapse'
toggle
false
Method
Description
dispose
Destroys an element’s collapse. (Removes stored data on the DOM element)
getInstance
Static method which allows you to get the collapse instance associated to a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a collapse instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
hide
Hides a collapsible element.
Returns to the caller before the collapsible element has actually been hidden
(e.g., before the
hidden.bs.collapse
event occurs).
show
Shows a collapsible element.
Returns to the caller before the collapsible element has actually been shown
(e.g., before the
shown.bs.collapse
event occurs).
toggle
Toggles a collapsible element to shown or hidden.
Returns to the caller before the collapsible element has actually been shown or hidden
(i.e. before the
shown.bs.collapse
hidden.bs.collapse
event occurs).
Events
Event type
Description
hide.bs.collapse
This event is fired immediately when the
hide
method has been called.
hidden.bs.collapse
This event is fired when a collapse element has been hidden from the user (will wait for CSS transitions to complete).
show.bs.collapse
This event fires immediately when the
show
instance method is called.
shown.bs.collapse
This event is fired when a collapse element has been made visible to the user (will wait for CSS transitions to complete).
const
myCollapsible
document
getElementById
'myCollapsible'
myCollapsible
addEventListener
'hidden.bs.collapse'
event
// do something...


--- 136_examples_navbars.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/navbars
--------------------------------------------------
Matching .container-xl...
Navbar examples
This example is a quick exercise to illustrate how the navbar and its contents work. Some navbars extend the width of the viewport, others are confined within a
.container
. For positioning of navbars, checkout the
fixed top
examples.
At the smallest breakpoint, the collapse plugin is used to hide the links and show a menu button to toggle the collapsed content.
View navbar docs »


--- 137_examples_navbar-bottom.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/navbar-bottom
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Bottom Navbar example
This example is a quick exercise to illustrate how the bottom navbar works.
View navbar docs »


--- 145_components_list-group.txt ---
URL: https://getbootstrap.com/docs/5.3/components/list-group
--------------------------------------------------
Basic example
The most basic list group is an unordered list with list items and the proper classes. Build upon it with the options that follow, or with your own CSS as needed.
An item
A second item
A third item
A fourth item
And a fifth one
html
class
list-group
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group-item
A fourth item
class
list-group-item
And a fifth one
Active items
.active
to a
.list-group-item
to indicate the current active selection.
An active item
A second item
A third item
A fourth item
And a fifth one
html
class
list-group
class
list-group-item active
aria-current
true
An active item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group-item
A fourth item
class
list-group-item
And a fifth one
Links and buttons
s or
<button>
s to create
actionable
list group items with hover, disabled, and active states by adding
.list-group-item-action
. We separate these pseudo-classes to ensure list groups made of non-interactive elements (like
<li>
s or
<div>
s) don’t provide a click or tap affordance.
Make
.list-group-item-action
instances
appear
disabled by adding
.disabled
, and
aria-disabled="true"
to inform assistive technologies that the element is disabled. You may require additional JavaScript to fully disable links and buttons.
Be sure to
not use the standard
.btn
classes here
The current link item
A second link item
A third link item
A fourth link item
A disabled link item
html
class
list-group
href
class
list-group-item list-group-item-action active
aria-current
true
The current link item
href
class
list-group-item list-group-item-action
A second link item
href
class
list-group-item list-group-item-action
A third link item
href
class
list-group-item list-group-item-action
A fourth link item
href
class
list-group-item list-group-item-action disabled
aria-disabled
true
A disabled link item
With
<button>
s, you can also make use of the
disabled
attribute instead of the
.disabled
class. Sadly,
s don’t support the disabled attribute.
The current button
A second button item
A third button item
A fourth button item
A disabled button item
html
class
list-group
button
type
button
class
list-group-item list-group-item-action active
aria-current
true
The current button
button
button
type
button
class
list-group-item list-group-item-action
A second button item
button
button
type
button
class
list-group-item list-group-item-action
A third button item
button
button
type
button
class
list-group-item list-group-item-action
A fourth button item
button
button
type
button
class
list-group-item list-group-item-action
disabled
A disabled button item
button
Flush
.list-group-flush
to remove some borders and rounded corners to render list group items edge-to-edge in a parent container (e.g., cards).
An item
A second item
A third item
A fourth item
And a fifth one
html
class
list-group list-group-flush
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group-item
A fourth item
class
list-group-item
And a fifth one
Numbered
Add the
.list-group-numbered
modifier class (and optionally use an
<ol>
element) to opt into numbered list group items. Numbers are generated via CSS (as opposed to a
<ol>
s default browser styling) for better placement inside list group items and to allow for better customization.
Numbers are generated by
counter-reset
on the
<ol>
, and then styled and placed with a
::before
pseudo-element on the
<li>
with
counter-increment
content
A list item
A list item
A list item
html
class
list-group list-group-numbered
class
list-group-item
A list item
class
list-group-item
A list item
class
list-group-item
A list item
These work great with custom content as well.
Subheading
Content for list item
Subheading
Content for list item
Subheading
Content for list item
html
class
list-group list-group-numbered
class
list-group-item d-flex justify-content-between align-items-start
class
ms-2 me-auto
class
fw-bold
Subheading
Content for list item
span
class
badge text-bg-primary rounded-pill
span
class
list-group-item d-flex justify-content-between align-items-start
class
ms-2 me-auto
class
fw-bold
Subheading
Content for list item
span
class
badge text-bg-primary rounded-pill
span
class
list-group-item d-flex justify-content-between align-items-start
class
ms-2 me-auto
class
fw-bold
Subheading
Content for list item
span
class
badge text-bg-primary rounded-pill
span
Horizontal
.list-group-horizontal
to change the layout of list group items from vertical to horizontal across all breakpoints. Alternatively, choose a responsive variant
.list-group-horizontal-{sm|md|lg|xl|xxl}
to make a list group horizontal starting at that breakpoint’s
min-width
. Currently
horizontal list groups cannot be combined with flush list groups.
ProTip:
Want equal-width list group items when horizontal? Add
.flex-fill
to each list group item.
An item
A second item
A third item
An item
A second item
A third item
An item
A second item
A third item
An item
A second item
A third item
An item
A second item
A third item
An item
A second item
A third item
html
class
list-group list-group-horizontal
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group list-group-horizontal-sm
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group list-group-horizontal-md
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group list-group-horizontal-lg
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group list-group-horizontal-xl
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
class
list-group list-group-horizontal-xxl
class
list-group-item
An item
class
list-group-item
A second item
class
list-group-item
A third item
Variants
Heads up!
As of v5.3.0, the
list-group-item-variant()
Sass mixin is deprecated. List group item variants now have their CSS variables overridden in
a Sass loop
Use contextual classes to style list items with a stateful background and color.
A simple default list group item
A simple primary list group item
A simple secondary list group item
A simple success list group item
A simple danger list group item
A simple warning list group item
A simple info list group item
A simple light list group item
A simple dark list group item
html
class
list-group
class
list-group-item
A simple default list group item
class
list-group-item list-group-item-primary
A simple primary list group item
class
list-group-item list-group-item-secondary
A simple secondary list group item
class
list-group-item list-group-item-success
A simple success list group item
class
list-group-item list-group-item-danger
A simple danger list group item
class
list-group-item list-group-item-warning
A simple warning list group item
class
list-group-item list-group-item-info
A simple info list group item
class
list-group-item list-group-item-light
A simple light list group item
class
list-group-item list-group-item-dark
A simple dark list group item
For links and buttons
Contextual classes also work with
.list-group-item-action
<button>
elements. Note the addition of the hover styles here not present in the previous example. Also supported is the
.active
state; apply it to indicate an active selection on a contextual list group item.
A simple default list group item
A simple primary list group item
A simple secondary list group item
A simple success list group item
A simple danger list group item
A simple warning list group item
A simple info list group item
A simple light list group item
A simple dark list group item
html
class
list-group
href
class
list-group-item list-group-item-action
A simple default list group item
href
class
list-group-item list-group-item-action list-group-item-primary
A simple primary list group item
href
class
list-group-item list-group-item-action list-group-item-secondary
A simple secondary list group item
href
class
list-group-item list-group-item-action list-group-item-success
A simple success list group item
href
class
list-group-item list-group-item-action list-group-item-danger
A simple danger list group item
href
class
list-group-item list-group-item-action list-group-item-warning
A simple warning list group item
href
class
list-group-item list-group-item-action list-group-item-info
A simple info list group item
href
class
list-group-item list-group-item-action list-group-item-light
A simple light list group item
href
class
list-group-item list-group-item-action list-group-item-dark
A simple dark list group item
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
With badges
Add badges to any list group item to show unread counts, activity, and more with the help of some
utilities
A list item
A second list item
A third list item
html
class
list-group
class
list-group-item d-flex justify-content-between align-items-center
A list item
span
class
badge text-bg-primary rounded-pill
span
class
list-group-item d-flex justify-content-between align-items-center
A second list item
span
class
badge text-bg-primary rounded-pill
span
class
list-group-item d-flex justify-content-between align-items-center
A third list item
span
class
badge text-bg-primary rounded-pill
span
Custom content
Add nearly any HTML within, even for linked list groups like the one below, with the help of
flexbox utilities
List group item heading
3 days ago
Some placeholder content in a paragraph.
And some small print.
List group item heading
3 days ago
Some placeholder content in a paragraph.
And some muted small print.
List group item heading
3 days ago
Some placeholder content in a paragraph.
And some muted small print.
html
class
list-group
href
class
list-group-item list-group-item-action active
aria-current
true
class
d-flex w-100 justify-content-between
class
mb-1
List group item heading
small
3 days ago
small
class
mb-1
Some placeholder content in a paragraph.
small
And some small print.
small
href
class
list-group-item list-group-item-action
class
d-flex w-100 justify-content-between
class
mb-1
List group item heading
small
class
text-body-secondary
3 days ago
small
class
mb-1
Some placeholder content in a paragraph.
small
class
text-body-secondary
And some muted small print.
small
href
class
list-group-item list-group-item-action
class
d-flex w-100 justify-content-between
class
mb-1
List group item heading
small
class
text-body-secondary
3 days ago
small
class
mb-1
Some placeholder content in a paragraph.
small
class
text-body-secondary
And some muted small print.
small
Checkboxes and radios
Place Bootstrap’s checkboxes and radios within list group items and customize as needed. You can use them without
<label>
s, but please remember to include an
aria-label
attribute and value for accessibility.
First checkbox
Second checkbox
Third checkbox
html
class
list-group
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
firstCheckbox
label
class
form-check-label
firstCheckbox
First checkbox
label
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
secondCheckbox
label
class
form-check-label
secondCheckbox
Second checkbox
label
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
thirdCheckbox
label
class
form-check-label
thirdCheckbox
Third checkbox
label
First radio
Second radio
Third radio
html
class
list-group
class
list-group-item
input
class
form-check-input me-1
type
radio
name
listGroupRadio
value
firstRadio
checked
label
class
form-check-label
firstRadio
First radio
label
class
list-group-item
input
class
form-check-input me-1
type
radio
name
listGroupRadio
value
secondRadio
label
class
form-check-label
secondRadio
Second radio
label
class
list-group-item
input
class
form-check-input me-1
type
radio
name
listGroupRadio
value
thirdRadio
label
class
form-check-label
thirdRadio
Third radio
label
You can use
.stretched-link
<label>
s to make the whole list group item clickable.
First checkbox
Second checkbox
Third checkbox
html
class
list-group
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
firstCheckboxStretched
label
class
form-check-label stretched-link
firstCheckboxStretched
First checkbox
label
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
secondCheckboxStretched
label
class
form-check-label stretched-link
secondCheckboxStretched
Second checkbox
label
class
list-group-item
input
class
form-check-input me-1
type
checkbox
value
thirdCheckboxStretched
label
class
form-check-label stretched-link
thirdCheckboxStretched
Third checkbox
label
Variables
Added in v5.2.0
As part of Bootstrap’s evolving CSS variables approach, list groups now use local CSS variables on
.list-group
for enhanced real-time customization. Values for the CSS variables are set via Sass, so Sass customization is still supported, too.
scss/_list-group.scss
#{$prefix}
list-group-color
#{$list-group-color}
#{$prefix}
list-group-bg
#{$list-group-bg}
#{$prefix}
list-group-border-color
#{$list-group-border-color}
#{$prefix}
list-group-border-width
#{$list-group-border-width}
#{$prefix}
list-group-border-radius
#{$list-group-border-radius}
#{$prefix}
list-group-item-padding-x
#{$list-group-item-padding-x}
#{$prefix}
list-group-item-padding-y
#{$list-group-item-padding-y}
#{$prefix}
list-group-action-color
#{$list-group-action-color}
#{$prefix}
list-group-action-hover-color
#{$list-group-action-hover-color}
#{$prefix}
list-group-action-hover-bg
#{$list-group-hover-bg}
#{$prefix}
list-group-action-active-color
#{$list-group-action-active-color}
#{$prefix}
list-group-action-active-bg
#{$list-group-action-active-bg}
#{$prefix}
list-group-disabled-color
#{$list-group-disabled-color}
#{$prefix}
list-group-disabled-bg
#{$list-group-disabled-bg}
#{$prefix}
list-group-active-color
#{$list-group-active-color}
#{$prefix}
list-group-active-bg
#{$list-group-active-bg}
#{$prefix}
list-group-active-border-color
#{$list-group-active-border-color}
Sass variables
scss/_variables.scss
$list-group-color
#{$prefix}
body-color
$list-group-bg
#{$prefix}
body-bg
$list-group-border-color
#{$prefix}
border-color
$list-group-border-width
#{$prefix}
border-width
$list-group-border-radius
#{$prefix}
border-radius
$list-group-item-padding-y
$spacer
$list-group-item-padding-x
$spacer
// fusv-disable
$list-group-item-bg-scale
-80%
// Deprecated in v5.3.0
$list-group-item-color-scale
// Deprecated in v5.3.0
// fusv-enable
$list-group-hover-bg
#{$prefix}
tertiary-bg
$list-group-active-color
$component-active-color
$list-group-active-bg
$component-active-bg
$list-group-active-border-color
$list-group-active-bg
$list-group-disabled-color
#{$prefix}
secondary-color
$list-group-disabled-bg
$list-group-bg
$list-group-action-color
#{$prefix}
secondary-color
$list-group-action-hover-color
#{$prefix}
emphasis-color
$list-group-action-active-color
#{$prefix}
body-color
$list-group-action-active-bg
#{$prefix}
secondary-bg
Sass mixins
Deprecated in v5.3.0
scss/mixins/_list-group.scss
@mixin
list-group-item-variant
$state
$background
$color
.list-group-item-
#{$state}
color
$color
background-color
$background
.list-group-item-action
:hover,
:focus
color
$color
background-color
shade-color
$background
.active
color
$white
background-color
$color
border-color
$color
Sass loops
Loop that generates the modifier classes with an overriding of CSS variables.
scss/_list-group.scss
// List group contextual variants
// Add modifier classes to change text and background color on individual items.
// Organizationally, this must come after the `:hover` states.
@each
$state
map-keys
$theme-colors
.list-group-item-
#{$state}
#{$prefix}
list-group-color
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
list-group-bg
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
list-group-border-color
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-action-hover-color
#{$prefix}
emphasis-color
#{$prefix}
list-group-action-hover-bg
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-action-active-color
#{$prefix}
emphasis-color
#{$prefix}
list-group-action-active-bg
#{$prefix}
#{$state}
-border-subtle
#{$prefix}
list-group-active-color
#{$prefix}
#{$state}
-bg-subtle
#{$prefix}
list-group-active-bg
#{$prefix}
#{$state}
-text-emphasis
#{$prefix}
list-group-active-border-color
#{$prefix}
#{$state}
-text-emphasis
JavaScript behavior
Use the tab JavaScript plugin—include it individually or through the compiled
file—to extend our list group to create tabbable panes of local content.
Home
Profile
Messages
Settings
Some placeholder content in a paragraph relating to "Home". And some more content, used here just to pad out and fill this tab panel. In production, you would obviously have more real content here. And not just text. It could be anything, really. Text, images, forms.
Some placeholder content in a paragraph relating to "Profile". And some more content, used here just to pad out and fill this tab panel. In production, you would obviously have more real content here. And not just text. It could be anything, really. Text, images, forms.
Some placeholder content in a paragraph relating to "Messages". And some more content, used here just to pad out and fill this tab panel. In production, you would obviously have more real content here. And not just text. It could be anything, really. Text, images, forms.
Some placeholder content in a paragraph relating to "Settings". And some more content, used here just to pad out and fill this tab panel. In production, you would obviously have more real content here. And not just text. It could be anything, really. Text, images, forms.
class
class
col-4
class
list-group
list-tab
role
tablist
class
list-group-item list-group-item-action active
list-home-list
data-bs-toggle
list
href
#list-home
role
aria-controls
list-home
Home
class
list-group-item list-group-item-action
list-profile-list
data-bs-toggle
list
href
#list-profile
role
aria-controls
list-profile
Profile
class
list-group-item list-group-item-action
list-messages-list
data-bs-toggle
list
href
#list-messages
role
aria-controls
list-messages
Messages
class
list-group-item list-group-item-action
list-settings-list
data-bs-toggle
list
href
#list-settings
role
aria-controls
list-settings
Settings
class
col-8
class
tab-content
nav-tabContent
class
tab-pane fade show active
list-home
role
tabpanel
aria-labelledby
list-home-list
class
tab-pane fade
list-profile
role
tabpanel
aria-labelledby
list-profile-list
class
tab-pane fade
list-messages
role
tabpanel
aria-labelledby
list-messages-list
class
tab-pane fade
list-settings
role
tabpanel
aria-labelledby
list-settings-list
Using data attributes
You can activate a list group navigation without writing any JavaScript by simply specifying
data-bs-toggle="list"
or on an element. Use these data attributes on
.list-group-item
role
tabpanel
<!-- List group -->
class
list-group
myList
role
tablist
class
list-group-item list-group-item-action active
data-bs-toggle
list
href
#home
role
Home
class
list-group-item list-group-item-action
data-bs-toggle
list
href
#profile
role
Profile
class
list-group-item list-group-item-action
data-bs-toggle
list
href
#messages
role
Messages
class
list-group-item list-group-item-action
data-bs-toggle
list
href
#settings
role
Settings
<!-- Tab panes -->
class
tab-content
class
tab-pane active
home
role
tabpanel
class
tab-pane
profile
role
tabpanel
class
tab-pane
messages
role
tabpanel
class
tab-pane
settings
role
tabpanel
Via JavaScript
Enable tabbable list item via JavaScript (each list item needs to be activated individually):
const
triggerTabList
document
querySelectorAll
'#myTab a'
triggerTabList
forEach
triggerEl
const
tabTrigger
triggerEl
triggerEl
addEventListener
'click'
event
event
preventDefault
tabTrigger
show
You can activate individual list item in several ways:
const
triggerEl
document
querySelector
'#myTab a[href="#profile"]'
getInstance
triggerEl
show
// Select tab by name
const
triggerFirstTabEl
document
querySelector
'#myTab li:first-child a'
getInstance
triggerFirstTabEl
show
// Select first tab
Fade effect
To make tabs panel fade in, add
.fade
to each
.tab-pane
. The first tab pane must also have
.show
to make the initial content visible.
class
tab-content
class
tab-pane fade show active
home
role
tabpanel
class
tab-pane fade
profile
role
tabpanel
class
tab-pane fade
messages
role
tabpanel
class
tab-pane fade
settings
role
tabpanel
Methods
All API methods are asynchronous and start a transition.
They return to the caller as soon as the transition is started, but before it ends. In addition, a method call on a transitioning component will be ignored.
Learn more in our JavaScript docs.
Activates your content as a tab element.
You can create a tab instance with the constructor, for example:
const
bsTab
'#myTab'
Method
Description
dispose
Destroys an element’s tab.
getInstance
Static method which allows you to get the tab instance associated with a DOM element, you can use it like this:
getOrCreateInstance
Static method which returns a tab instance associated to a DOM element or create a new one in case it wasn’t initialized. You can use it like this:
show
Selects the given tab and shows its associated pane. Any other tab that was previously selected becomes unselected and its associated pane is hidden.
Returns to the caller before the tab pane has actually been shown
(i.e. before the
shown.bs.tab
event occurs).
Events
When showing a new tab, the events fire in the following order:
hide.bs.tab
(on the current active tab)
show.bs.tab
(on the to-be-shown tab)
hidden.bs.tab
(on the previous active tab, the same one as for the
hide.bs.tab
event)
shown.bs.tab
(on the newly-active just-shown tab, the same one as for the
show.bs.tab
event)
If no tab was already active, then the
hide.bs.tab
hidden.bs.tab
events will not be fired.
Event type
Description
hide.bs.tab
This event fires when a new tab is to be shown (and thus the previous active tab is to be hidden). Use
event.target
event.relatedTarget
to target the current active tab and the new soon-to-be-active tab, respectively.
hidden.bs.tab
This event fires after a new tab is shown (and thus the previous active tab is hidden). Use
event.target
event.relatedTarget
to target the previous active tab and the new active tab, respectively.
show.bs.tab
This event fires on tab show, but before the new tab has been shown. Use
event.target
event.relatedTarget
to target the active tab and the previous active tab (if available) respectively.
shown.bs.tab
This event fires on tab show after a tab has been shown. Use
event.target
event.relatedTarget
to target the active tab and the previous active tab (if available) respectively.
const
tabElms
document
querySelectorAll
'a[data-bs-toggle="list"]'
tabElms
forEach
tabElm
tabElm
addEventListener
'shown.bs.tab'
event
event
target
// newly activated tab
event
relatedTarget
// previous active tab


--- 147_examples_sticky-footer-navbar.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/sticky-footer-navbar
--------------------------------------------------
Sticky footer with fixed navbar
Pin a footer to the bottom of the viewport in desktop browsers with this custom HTML and CSS. A fixed navbar has been added with
padding-top: 60px;
on the
main > .container
Back to
the default sticky footer
minus the navbar.


--- 149_examples_modals.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/modals
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Modal title
This is a modal sheet, a variation of the modal that docs itself to the bottom of the viewport like the newer share sheets in iOS.
Save changes
Close
Enable this setting?
You can always change your mind in your account settings.
Yes, enable
No thanks
What's new
Grid view
Not into lists? Try the new grid view.
Bookmarks
Save items you love for easy access later.
Video embeds
Share videos wherever you go.
Great, thanks!
Sign up for free
Email address
Password
Sign up
By clicking Sign up, you agree to the terms of use.
Or use a third-party
Sign up with Google
Sign up with Facebook
Sign up with GitHub


-------------------- End of Components (38 pages) --------------------


========================= HELPERS =========================
Section: Helpers
Files: 14
======================================================================

--- 003_helpers_icon-link.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/icon-link
--------------------------------------------------
The icon link helper component modifies our default link styles to enhance their appearance and quickly align any pairing of icon and text. Alignment is set via inline flexbox styling and a default
value. We stylize the underline with a custom offset and color. Icons are automatically sized to
to best match their associated text’s
font-size
Icon links assume
are being used, but you can use any icon or image you like.
When icons are purely decorative, they should be hidden from assistive technologies using
aria-hidden="true"
, as we’ve done in our examples. For icons that convey meaning, provide an appropriate text alternative by adding
role="img"
and an appropriate
aria-label="..."
to the SVGs.
Example
Take a regular
element, add
.icon-link
, and insert an icon on either the left or right of your link text. The icon is automatically sized, placed, and colored.
Icon link
html
class
icon-link
href
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M8.186 1.113a.5.5 0 0 0-.372 0L1.846 3.5l2.404.961L10.404 2l-2.218-.887zm3.564 1.426L5.596 5 8 5.961 14.154 3.5l-2.404-.961zm3.25 1.7-6.5 2.6v7.922l6.5-2.6V4.24zM7.5 14.762V6.838L1 4.239v7.923l6.5 2.6zM7.443.184a1.5 1.5 0 0 1 1.114 0l7.129 2.852A.5.5 0 0 1 16 3.5v8.662a1 1 0 0 1-.629.928l-7.185 2.874a.5.5 0 0 1-.372 0L.63 13.09a1 1 0 0 1-.63-.928V3.5a.5.5 0 0 1 .314-.464L7.443.184z
Icon link
Icon link
html
class
icon-link
href
Icon link
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z
Style on hover
.icon-link-hover
to move the icon to the right on hover.
Icon link
html
class
icon-link icon-link-hover
href
Icon link
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z
Customize
Modify the styling of an icon link with our link CSS variables, Sass variables, utilities, or custom styles.
CSS variables
Modify the
--bs-link-*
--bs-icon-link-*
CSS variables as needed to change the default appearance.
Customize the hover
transform
by overriding the
--bs-icon-link-transform
CSS variable:
Icon link
html
class
icon-link icon-link-hover
style
--bs-icon-link-transform
translate3d
-.125rem
href
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z
path
M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z
Icon link
Customize the color by overriding the
--bs-link-*
CSS variable:
Icon link
html
class
icon-link icon-link-hover
style
--bs-link-hover-color-rgb
href
Icon link
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z
Sass variables
Customize the icon link Sass variables to modify all icon link styles across your Bootstrap-powered project.
scss/_variables.scss
$icon-link-gap
.375rem
$icon-link-underline-offset
.25em
$icon-link-icon-size
$icon-link-icon-transition
.2s ease-in-out transform
$icon-link-icon-transform
translate3d
.25em
Sass utilities API
Modify icon links with any of
our link utilities
for modifying underline color and offset.
Icon link
html
class
icon-link icon-link-hover link-success link-underline-success link-underline-opacity-25
href
Icon link
xmlns
http://www.w3.org/2000/svg
class
viewBox
0 0 16 16
aria-hidden
true
path
M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z


--- 026_migration.txt ---
URL: https://getbootstrap.com/docs/5.3/migration
--------------------------------------------------
Dependencies
Migrated from Hugo to Astro for building our documentation
If you’re migrating from our previous alpha releases of v5.3.0, please review their changes in addition to this section.
Helpers
Colored links
once again have
!important
so they work better with our newly added link utilities.
Utilities
Added new
.d-inline-grid
display utility
If you’re migrating from our previous alpha release of v5.3.0, please review the changes listed below.
CSS variables
Removed several duplicate and unused root CSS variables.
Color modes
Dark mode colors are now derived from our theme colors (e.g.,
$primary
) in Sass, rather than color specific tints or shades (e.g.,
$blue-300
). This allows for a more automated dark mode when customizing the default theme colors.
Added Sass maps for generating theme colors for dark mode text, subtle background, and subtle border.
Snippet examples
are now ready for dark mode with updated markup and reduced custom styles.
Added
color-scheme: dark
to dark mode CSS to change OS level controls like scrollbars
Form validation
border-color
and text
color
states now respond to dark mode, thanks to new Sass and CSS variables.
Dropped recently added form control background CSS variables and reassigned the Sass variables to use CSS variables instead. This simplifies the styling across color modes and avoids an issue where form controls in dark mode wouldn’t update properly.
box-shadow
s will once again always stay dark instead of inverting to white when in dark mode.
Improved HTML and JavaScript for our color mode toggle script. The selector for changing the active SVG has been improved, and the markup made more accessible with ARIA attributes.
Improved docs code syntax colors and more across light and dark modes.
Typography
We no longer set a color for
$headings-color-dark
--bs-heading-color
for dark mode. To avoid several problems of headings within components appearing the wrong color, we’ve set the Sass variable to
null
and added a
null
check like we use on the default light mode.
Components
Cards now have a
color
set on them to improve rendering across color modes.
Added new
.nav-underline
variant for our navigation with a simpler bottom border under the active nav link.
See the docs for an example.
Navs now have new
:focus-visible
styles that better match our custom button focus styles.
Helpers
Added new
.icon-link
helper to quickly place and align Bootstrap Icons alongside a textual link. Icon links support our new link utilities, too.
Added new focus ring helper for removing the default
outline
and setting a custom
box-shadow
focus ring.
Utilities
Renamed Sass and CSS variables
${color}-text
${color}-text-emphasis
to match their associated utilities.
Added new
.link-body-emphasis
helper alongside our
colored links
. This creates a colored link using our color mode responsive emphasis color.
Added new link utilities for link color opacity, underline offset, underline color, and underline opacity.
Explore the new links utilities.
CSS variable based
border-width
utilities have been reverted to set their property directly (as was done prior to v5.2.0). This avoids inheritance issues across nested elements, including tables.
Added new
.border-black
utility to match our
.text-black
.bg-black
utilities.
Deprecated
.text-muted
utility and
$text-muted
Sass variable have been deprecated and replaced with
.text-body-secondary
$body-secondary-color
Docs
Examples are now displayed with the appropriate light or dark color mode as dictated by the setting in our docs. Each example has an individual color mode picker.
Improved included JavaScript for live Toast demo.
Added
twbs/examples
repo contents to the top of the Examples page.
Tooling
Added SCSS testing via True to help test our utilities API and other customizations.
Replaced instances of our bootstrap-npm-starter project with the newer and more complete
twbs/examples repo
For a complete list of changes,
see the v5.3.0-alpha2 project on GitHub
Color modes!
Learn more by reading the new
color modes documentation
Global support for light (default) and dark color modes.
Set color mode globally on the
:root
element, on groups of elements and components with a wrapper class, or directly on components, with
data-bs-theme="light|dark"
. Also included is a new
color-mode()
mixin that can output a ruleset with the
data-bs-theme
selector or a media query, depending on your preference.
Deprecated
Color modes replace dark variants for components, so
.btn-close-white
.carousel-dark
.dropdown-menu-dark
, and
.navbar-dark
are deprecated.
New extended color system.
We’ve added new theme colors (but not in
$theme-colors
) for a more nuanced, system-wide color palette with new secondary, tertiary, and emphasis colors for
color
background-color
. These new colors are available as Sass variables, CSS variables, and utilities.
We’ve also expanded our theme color Sass variables, CSS variables, and utilities to include text emphasis, subtle background colors, and subtle border colors. These are available as Sass variables, CSS variables, and utilities.
Adds new
_variables-dark.scss
stylesheet to house dark-mode specific overrides. This stylesheet should be imported immediately after the existing
_variables.scss
file in your import stack.
diff --git a/scss/bootstrap.scss b/scss/bootstrap.scss
index 8f8296def..449d70487 100644
--- a/scss/bootstrap.scss
+++ b/scss/bootstrap.scss
@@ -6,6 +6,7 @@
// Configuration
@import "functions";
@import "variables";
@import "variables-dark";
@import "maps";
@import "mixins";
@import "utilities";
CSS variables
Restores CSS variables for breakpoints, though we don’t use them in our media queries as they’re not supported. However, these can be useful in JS-specific contexts.
Per the color modes update, we’ve added new utilities for new Sass CSS variables
secondary
tertiary
text and background colors, plus
{color}-bg-subtle
{color}-border-subtle
, and
{color}-text-emphasis
for our theme colors. These new colors are available through Sass and CSS variables (but not our color maps) with the express goal of making it easier to customize across multiple colors modes like light and dark.
Adds additional variables for alerts,
.btn-close
, and
.offcanvas
--bs-heading-color
variable is back with an update and dark mode support. First, we now check for a
null
value on the associated Sass variable,
$headings-color
, before trying to output the CSS variable, so by default it’s not present in our compiled CSS. Second, we use the CSS variable with a fallback value,
inherit
, allowing the original behavior to persist, but also allowing for overrides.
Converts links to use CSS variables for styling
color
, but not
text-decoration
. Colors are now set with
--bs-link-color-rgb
--bs-link-opacity
rgba()
color, allowing you to customize the translucency with ease. The
a:hover
pseudo-class now overrides
--bs-link-color-rgb
instead of explicitly setting the
color
property.
--bs-border-width
is now being used in more components for greater control over default global styling.
Adds new root CSS variables for our
box-shadow
s, including
--bs-box-shadow
--bs-box-shadow-sm
--bs-box-shadow-lg
, and
--bs-box-shadow-inset
Components
Alert
Alert variants are now styled via CSS variables.
Deprecated
alert-variant()
mixin is now deprecated. We now
use a Sass loop
directly to modify the component’s default CSS variables for each variant.
List group
List group item variants are now styled via CSS variables.
Deprecated
list-group-item-variant()
mixin is now deprecated. We now
use a Sass loop
directly to modify the component’s default CSS variables for each variant.
Dropdowns
Deprecated
.dropdown-menu-dark
class has been deprecated and replaced with
data-bs-theme="dark"
on the dropdown or any parent element.
See the docs for an example.
Close button
Deprecated
.btn-close-white
class has been deprecated and replaced with
data-bs-theme="dark"
on the close button or any parent element.
See the docs for an example.
Navbar
Deprecated
.navbar-dark
class has been deprecated and replaced with
data-bs-theme="dark"
on the navbar or any parent element.
See the docs for updated examples.
Progress bars
The markup for
progress bars
has been updated in v5.3.0. Due to the placement of
role
and various
aria-
attributes on the inner
.progress-bar
element,
some screen readers were not announcing zero value progress bars
. Now,
role="progressbar"
and the relevant
aria-*
attributes are on the outer
.progress
element, leaving the
.progress-bar
purely for the visual presentation of the bar and optional label.
While we recommend adopting the new markup for improved compatibility with all screen readers, note that the legacy progress bar structure will continue to work as before.
<!-- Previous markup -->
class
progress
class
progress-bar
role
progressbar
aria-label
Basic example
style
width
aria-valuenow
aria-valuemin
aria-valuemax
<!-- New markup -->
class
progress
role
progressbar
aria-label
Basic example
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar
style
width
We’ve also introduced a new
.progress-stacked
class to more logically wrap
multiple progress bars
into a single stacked progress bar.
<!-- Previous markup -->
class
progress
class
progress-bar
role
progressbar
aria-label
Segment one
style
width
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-success
role
progressbar
aria-label
Segment two
style
width
aria-valuenow
aria-valuemin
aria-valuemax
class
progress-bar bg-info
role
progressbar
aria-label
Segment three
style
width
aria-valuenow
aria-valuemin
aria-valuemax
<!-- New markup -->
class
progress-stacked
class
progress
role
progressbar
aria-label
Segment one
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar
class
progress
role
progressbar
aria-label
Segment two
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar bg-success
class
progress
role
progressbar
aria-label
Segment three
aria-valuenow
aria-valuemin
aria-valuemax
style
width
class
progress-bar bg-info
Forms
.form-control
is now styled with CSS variables to support color modes. This includes the addition of two new root CSS variables for the default and disabled form control backgrounds.
.form-check
.form-switch
components are now built with CSS variables for setting the
background-image
. The usage here differs from other components in that the various focus, active, etc states for each component aren’t set on the base class. Instead, the states override one variable (e.g.,
--bs-form-switch-bg
Floating form labels now have a
background-color
to fix support for
<textarea>
elements. Additional changes have been made to also support disabled states and more.
Fixed display of date and time inputs in WebKit based browsers.
Utilities
Deprecated
.text-muted
will be replaced by
.text-body-secondary
in v6.
With the addition of the expanded theme colors and variables, the
.text-muted
variables and utility have been deprecated with v5.3.0. Its default value has also been reassigned to the new
--bs-secondary-color
CSS variable to better support color modes. It will be removed in v6.0.0.
Adds new
.overflow-x
.overflow-y
, and several
.object-fit-*
utilities.
The object-fit property is used to specify how an
<img>
<video>
should be resized to fit its container, giving us a responsive alternative to using
background-image
for a resizable fill/fit image.
Adds new
.fw-medium
utility.
Added new
.z-*
utilities
z-index
Box shadow utilities
(and Sass variables) have been updated for dark mode. They now use
--bs-body-color-rgb
to generate the
rgba()
color values, allowing them to easily adapt to color modes based on the specified foreground color.
For a complete list of changes,
see the v5.3.0 project on GitHub
Refreshed design
most notably through refined
border-radius
values on buttons and form controls
. Our documentation also has been updated with a new homepage, simpler docs layout that no longer collapses sections of the sidebar, and more prominent examples of
More CSS variables
We’ve updated all our components to use CSS variables.
While Sass still underpins everything, each component has been updated to include CSS variables on the component base classes (e.g.,
.btn
), allowing for more real-time customization of Bootstrap. In subsequent releases, we'll continue to expand our use of CSS variables into our layout, forms, helpers, and utilities. Read more about CSS variables in each component on their respective documentation pages.
Our CSS variable usage will be somewhat incomplete until Bootstrap 6. While we’d love to fully implement these across the board, they do run the risk of causing breaking changes. For example, setting
$alert-border-width: var(--bs-border-width)
in our source code breaks potential Sass in your own code if you were doing
$alert-border-width * 2
for some reason.
As such, wherever possible, we will continue to push towards more CSS variables, but please recognize our implementation may be slightly limited in v5.
_maps.scss
_maps.scss
It pulls out several Sass maps from
_variables.scss
to fix an issue where updates to an original map were not applied to secondary maps that extend them. For example, updates to
$theme-colors
were not being applied to other theme maps that relied on
$theme-colors
, breaking key customization workflows. In short, Sass has a limitation where once a default variable or map has been
used
, it cannot be updated.
There’s a similar shortcoming with CSS variables when they’re used to compose other CSS variables.
This is why variable customizations in Bootstrap have to come after
@import "functions"
, but before
@import "variables"
and the rest of our import stack. The same applies to Sass maps—you must override the defaults before they get used. The following maps have been moved to the new
_maps.scss
$theme-colors-rgb
$utilities-colors
$utilities-text
$utilities-text-colors
$utilities-bg
$utilities-bg-colors
$negative-spacers
$gutters
Your custom Bootstrap CSS builds should now look something like this with a separate maps import.
// Functions come first
@import "functions";
// Optional variable overrides here
$custom-color: #df711b;
$custom-theme-colors: (
"custom": $custom-color
// Variables come next
@import "variables";
// Optional Sass map overrides here
$theme-colors: map-merge($theme-colors, $custom-theme-colors);
// Followed by our default maps
@import "maps";
// Rest of our imports
@import "mixins";
@import "utilities";
@import "root";
@import "reboot";
// etc
New utilities
Expanded
font-weight
utilities
to include
.fw-semibold
for semibold fonts.
Expanded
border-radius
utilities
to include two new sizes,
.rounded-4
.rounded-5
, for more options.
Additional changes
Introduced new
$enable-container-classes
option. —
Now when opting into the experimental CSS Grid layout,
.container-*
classes will still be compiled, unless this option is set to
false
. Containers also now keep their gutter values.
Offcanvas component now has
responsive variations
The original
.offcanvas
class remains unchanged—it hides content across all viewports. To make it responsive, change that
.offcanvas
class to any
.offcanvas-{sm|md|lg|xl|xxl}
class.
Thicker table dividers are now opt-in. —
We’ve removed the thicker and more difficult to override border between table groups and moved it to an optional class you can apply,
.table-group-divider
See the table docs for an example.
Scrollspy has been rewritten
to use the Intersection Observer API
, which means you no longer need relative parent wrappers, deprecates
offset
config, and more. Look for your Scrollspy implementations to be more accurate and consistent in their nav highlighting.
Popovers and tooltips now use CSS variables.
Some CSS variables have been updated from their Sass counterparts to reduce the number of variables. As a result, three variables have been deprecated in this release:
$popover-arrow-color
$popover-arrow-outer-color
, and
$tooltip-arrow-color
Added new
.text-bg-{color}
helpers.
Instead of setting individual
.text-*
.bg-*
utilities, you can now use
.text-bg-*
helpers
to set a
background-color
with contrasting foreground
color
Added
.form-check-reverse
modifier to flip the order of labels and associated checkboxes/radios.
Added
striped columns
support to tables via the new
.table-striped-columns
class.
For a complete list of changes,
see the v5.2.0 project on GitHub
Added experimental support for
CSS Grid layout
This is a work in progress, and is not yet ready for production use, but you can opt into the new feature via Sass. To enable it, disable the default grid, by setting
$enable-grid-classes: false
and enable the CSS Grid by setting
$enable-cssgrid: true
Updated navbars to support offcanvas. —
offcanvas drawers in any navbar
with the responsive
.navbar-expand-*
classes and some offcanvas markup.
Added new
placeholder component
Our newest component, a way to provide temporary blocks in lieu of real content to help indicate that something is still loading in your site or app.
Collapse plugin now supports
horizontal collapsing
.collapse-horizontal
to your
.collapse
to collapse the
width
instead of the
height
. Avoid browser repainting by setting a
min-height
height
Added new stack and vertical rule helpers. —
Quickly apply multiple flexbox properties to quickly create custom layouts with
stacks
. Choose from horizontal (
.hstack
) and vertical (
.vstack
) stacks. Add vertical dividers similar to
<hr>
elements with the
helpers
Added new global
:root
CSS variables. —
Added several new CSS variables to the
:root
level for controlling
<body>
styles. More are in the works, including across our utilities and components, but for now read up
CSS variables in the Customize section
Overhauled color and background utilities to use CSS variables, and added new
text opacity
background opacity
utilities. —
.text-*
.bg-*
utilities are now built with CSS variables and
rgba()
color values, allowing you to easily customize any utility with new opacity utilities.
Added new snippet examples based to show how to customize our components. —
Pull ready to use customized components and other common design patterns with our new
Snippets examples
. Includes
footers
dropdowns
list groups
, and
modals
Removed unused positioning styles from popovers and tooltips
as these are handled solely by Popper.
$tooltip-margin
has been deprecated and set to
null
in the process.
Want more information?
Read the v5.1.0 blog post.
Hey there!
Changes to our first major release of Bootstrap 5, v5.0.0, are documented below. They don’t reflect the additional changes shown above.
Dependencies
Dropped jQuery.
Upgraded from Popper v1.x to Popper v2.x.
Replaced Libsass with Dart Sass as our Sass compiler given Libsass was deprecated.
Migrated from Jekyll to Hugo for building our documentation
Browser support
Dropped Internet Explorer 10 and 11
Dropped Microsoft Edge < 16 (Legacy Edge)
Dropped Firefox < 60
Dropped Safari < 12
Dropped iOS Safari < 12
Dropped Chrome < 60
Documentation changes
Redesigned homepage, docs layout, and footer.
Added
new Parcel guide
Added
new Customize section
, replacing
v4’s Theming page
, with new details on Sass, global configuration options, color schemes, CSS variables, and more.
Reorganized all form documentation into
new Forms section
, breaking apart the content into more focused pages.
Similarly, updated
the Layout section
, to flesh out grid content more clearly.
Renamed “Navs” component page to "Navs & Tabs".
Renamed “Checks” page to "Checks & radios".
Redesigned the navbar and added a new subnav to make it easier to get around our sites and docs versions.
Added new keyboard shortcut for the search field:
Ctrl
Sass
We’ve ditched the default Sass map merges to make it easier to remove redundant values. Keep in mind you now have to define all values in the Sass maps like
$theme-colors
. Check out how to deal with
Sass maps
Breaking
Renamed
color-yiq()
function and related variables to
color-contrast()
as it’s no longer related to YIQ color space.
See #30168.
$yiq-contrasted-threshold
is renamed to
$min-contrast-ratio
$yiq-text-dark
$yiq-text-light
are respectively renamed to
$color-contrast-dark
$color-contrast-light
Breaking
Media query mixins parameters have changed for a more logical approach.
media-breakpoint-down()
uses the breakpoint itself instead of the next breakpoint (e.g.,
media-breakpoint-down(lg)
instead of
media-breakpoint-down(md)
targets viewports smaller than
Similarly, the second parameter in
media-breakpoint-between()
also uses the breakpoint itself instead of the next breakpoint (e.g.,
media-breakpoint-between(sm, lg)
instead of
media-breakpoint-between(sm, md)
targets viewports between
Breaking
Removed print styles and
$enable-print-styles
variable. Print display classes are still around.
See #28339
Breaking
Dropped
color()
theme-color()
, and
gray()
functions in favor of variables.
See #29083
Breaking
Renamed
theme-color-level()
function to
color-level()
and now accepts any color you want instead of only
$theme-color
colors.
See #29083
Watch out:
color-level()
was later on dropped in
Breaking
Renamed
$enable-prefers-reduced-motion-media-query
$enable-pointer-cursor-for-buttons
$enable-reduced-motion
$enable-button-pointers
for brevity.
Breaking
Removed the
bg-gradient-variant()
mixin. Use the
.bg-gradient
class to add gradients to elements instead of the generated
.bg-gradient-*
classes.
Breaking
Removed previously deprecated mixins:
hover
hover-focus
plain-hover-focus
, and
hover-focus-active
float()
form-control-mixin()
nav-divider()
retina-img()
text-hide()
(also dropped the associated utility class,
.text-hide
visibility()
form-control-focus()
Breaking
Renamed
scale-color()
function to
shift-color()
to avoid collision with Sass’s own color scaling function.
box-shadow
mixins now allow
null
values and drop
none
from multiple arguments.
See #30394
border-radius()
mixin now has a default value.
Color system
The color system which worked with
color-level()
$theme-color-interval
was removed in favor of a new color system. All
lighten()
darken()
functions in our codebase are replaced by
tint-color()
shade-color()
. These functions will mix the color with either white or black instead of changing its lightness by a fixed amount. The
shift-color()
will either tint or shade a color depending on whether its weight parameter is positive or negative.
See #30622
for more details.
Added new tints and shades for every color, providing nine separate colors for each base color, as new Sass variables.
Improved color contrast. Bumped color contrast ratio from 3:1 to 4.5:1 and updated blue, green, cyan, and pink colors to ensure WCAG 2.2 AA contrast. Also changed our color contrast color from
$gray-900
$black
To support our color system, we’ve added new custom
tint-color()
shade-color()
functions to mix our colors appropriately.
Grid updates
New breakpoint!
Added new
breakpoint for
1400px
and up. No changes to all other breakpoints.
Improved gutters.
Gutters are now set in rems, and are narrower than v4 (
1.5rem
, or about
24px
, down from
30px
). This aligns our grid system’s gutters with our spacing utilities.
Added new
gutter class
.g-*
.gx-*
, and
.gy-*
) to control horizontal/vertical gutters, horizontal gutters, and vertical gutters.
Breaking
Renamed
.no-gutters
.g-0
to match new gutter utilities.
Columns no longer have
position: relative
applied, so you may have to add
.position-relative
to some elements to restore that behavior.
Breaking
Dropped several
.order-*
classes that often went unused. We now only provide
.order-0
.order-5
out of the box.
Breaking
Dropped the
.media
component as it can be easily replicated with utilities.
See #28265
and the
flex utilities page for an example
Breaking
now only applies
box-sizing: border-box
to the column instead of resetting the global box-sizing. This way, our grid styles can be used in more places without interference.
$enable-grid-classes
no longer disables the generation of container classes anymore.
See #29146.
Updated the
make-col
mixin to default to equal columns without a specified size.
Content, Reboot, etc
is now enabled by default.
Headings using the
font-size()
mixin will automatically adjust their
font-size
to scale with the viewport.
This feature was previously opt-in with v4.
Breaking
Overhauled our display typography to replace our
$display-*
variables and with a
$display-font-sizes
Sass map. Also removed the individual
$display-*-weight
variables for a single
$display-font-weight
and adjusted
font-size
Added two new
.display-*
heading sizes,
.display-5
.display-6
Links are underlined by default
(not just on hover), unless they’re part of specific components.
Redesigned tables
to refresh their styles and rebuild them with CSS variables for more control over styling.
Breaking
Nested tables do not inherit styles anymore.
Breaking
.thead-light
.thead-dark
are dropped in favor of the
.table-*
variant classes which can be used for all table elements (
thead
tbody
tfoot
Breaking
table-row-variant()
mixin is renamed to
table-variant()
and accepts only 2 parameters:
$color
(color name) and
$value
(color code). The border color and accent colors are automatically calculated based on the table factor variables.
Split table cell padding variables into
Breaking
Dropped
.pre-scrollable
class.
See #29135
Breaking
.text-*
utilities do not add hover and focus states to links anymore.
.link-*
helper classes can be used instead.
See #29267
Breaking
Dropped
.text-justify
class.
See #29793
Breaking
<hr>
elements now use
height
instead of
border
to better support the
size
attribute. This also enables use of padding utilities to create thicker dividers (e.g.,
<hr class="py-1">
Reset default horizontal
padding-left
<ul>
<ol>
elements from browser default
40px
2rem
Added
$enable-smooth-scroll
, which applies
scroll-behavior: smooth
globally—except for users asking for reduced motion through
prefers-reduced-motion
media query.
See #31877
Horizontal direction specific variables, utilities, and mixins have all been renamed to use logical properties like those found in flexbox layouts—e.g.,
start
in lieu of
left
right
Forms
Added new floating forms!
We’ve promoted the Floating labels example to fully supported form components.
See the new Floating labels page.
Breaking
Consolidated native and custom form elements.
Checkboxes, radios, selects, and other inputs that had native and custom classes in v4 have been consolidated. Now nearly all our form elements are entirely custom, most without the need for custom HTML.
.custom-control.custom-checkbox
is now
.form-check
.custom-control.custom-radio
is now
.form-check
.custom-control.custom-switch
is now
.form-check.form-switch
.custom-select
is now
.form-select
.custom-file
.form-control-file
have been replaced by custom styles on top of
.form-control
.custom-range
is now
.form-range
Dropped native
.form-control-file
.form-control-range
Breaking
Dropped
.input-group-append
.input-group-prepend
. You can now just add buttons and
.input-group-text
as direct children of the input groups.
The longstanding
Missing border radius on input group with validation feedback bug
is finally fixed by adding an additional
.has-validation
class to input groups with validation.
Breaking
Dropped form-specific layout classes for our grid system.
Use our grid and utilities instead of
.form-group
.form-row
, or
.form-inline
Breaking
Form labels now require
.form-label
Breaking
.form-text
no longer sets
display
, allowing you to create inline or block help text as you wish just by changing the HTML element.
Form controls no longer used fixed
height
when possible, instead deferring to
min-height
to improve customization and compatibility with other components.
Validation icons are no longer applied to
<select>
s with
multiple
Rearranged source Sass files under
scss/forms/
, including input group styles.
Components
Unified
padding
values for alerts, breadcrumbs, cards, dropdowns, list groups, modals, popovers, and tooltips to be based on our
$spacer
variable.
See #30564
Accordion
Added
new accordion component
Alerts
Alerts now have
examples with icons
Removed custom styles for
<hr>
s in each alert since they already use
currentColor
Badges
Breaking
Dropped all
.badge-*
color classes for background utilities (e.g., use
.bg-primary
instead of
.badge-primary
Breaking
Dropped
.badge-pill
—use the
.rounded-pill
utility instead.
Breaking
Removed hover and focus styles for
<button>
elements.
Increased default padding for badges from
.25em
.5em
.35em
.65em
Breadcrumbs
Simplified the default appearance of breadcrumbs by removing
padding
background-color
, and
border-radius
Added new CSS custom property
--bs-breadcrumb-divider
for easy customization without needing to recompile CSS.
Buttons
Breaking
Toggle buttons
, with checkboxes or radios, no longer require JavaScript and have new markup.
We no longer require a wrapping element, add
.btn-check
to the
<input>
, and pair it with any
.btn
classes on the
<label>
See #30650
The docs for this has moved from our Buttons page to the new Forms section.
Breaking
Dropped
.btn-block
for utilities.
Instead of using
.btn-block
on the
.btn
, wrap your buttons with
.d-grid
and a
.gap-*
utility to space them as needed. Switch to responsive classes for even more control over them.
Read the docs for some examples.
Updated our
button-variant()
button-outline-variant()
mixins to support additional parameters.
Updated buttons to ensure increased contrast on hover and active states.
Disabled buttons now have
pointer-events: none;
Card
Breaking
Dropped
.card-deck
in favor of our grid. Wrap your cards in column classes and add a parent
.row-cols-*
container to recreate card decks (but with more control over responsive alignment).
Breaking
Dropped
.card-columns
in favor of Masonry.
See #28922
Breaking
Replaced the
.card
based accordion with a
new Accordion component
Carousel
Added new
.carousel-dark
variant
for dark text, controls, and indicators (great for lighter backgrounds).
Replaced chevron icons for carousel controls with new SVGs from
Close button
Breaking
Renamed
.close
.btn-close
for a less generic name.
Close buttons now use a
background-image
(embedded SVG) instead of a
&times;
in the HTML, allowing for easier customization without the need to touch your markup.
Added new
.btn-close-white
variant that uses
filter: invert(1)
to enable higher contrast dismiss icons against darker backgrounds.
Collapse
Removed scroll anchoring for accordions.
Dropdowns
Added new
.dropdown-menu-dark
variant and associated variables for on-demand dark dropdowns.
Added new variable for
$dropdown-padding-x
Darkened the dropdown divider for improved contrast.
Breaking
All the events for the dropdown are now triggered on the dropdown toggle button and then bubbled up to the parent element.
Dropdown menus now have a
data-bs-popper="static"
attribute set when the positioning of the dropdown is static, or dropdown is in the navbar. This is added by our JavaScript and helps us use custom position styles without interfering with Popper’s positioning.
Breaking
Dropped
flip
option for dropdown plugin in favor of native Popper configuration. You can now disable the flipping behavior by passing an empty array for
fallbackPlacements
option in
flip
modifier.
Dropdown menus can now be clickable with a new
autoClose
option to handle the
auto close behavior
. You can use this option to accept the click inside or outside the dropdown menu to make it interactive.
Dropdowns now support
.dropdown-item
s wrapped in
<li>
Jumbotron
Breaking
Dropped the jumbotron component as it can be replicated with utilities.
See our new Jumbotron example for a demo.
List group
Added new
.list-group-numbered
modifier
to list groups.
Navs and tabs
Added new
null
variables for
font-size
font-weight
color
, and
:hover
color
to the
.nav-link
class.
Navbars
Breaking
Navbars now require a container within (to drastically simplify spacing requirements and CSS required).
Breaking
.active
class can no longer be applied to
.nav-item
s, it must be applied directly on
.nav-link
Offcanvas
Added the new
offcanvas component
Pagination
Pagination links now have customizable
margin-left
that are dynamically rounded on all corners when separated from one another.
Added
transition
s to pagination links.
Popovers
Breaking
Renamed
.arrow
.popover-arrow
in our default popover template.
Renamed
whiteList
option to
allowList
Spinners
Spinners now honor
prefers-reduced-motion: reduce
by slowing down animations.
See #31882
Improved spinner vertical alignment.
Toasts
Toasts can now be
positioned
in a
.toast-container
with the help of
positioning utilities
Changed default toast duration to 5 seconds.
Removed
overflow: hidden
from toasts and replaced with proper
border-radius
s with
calc()
functions.
Tooltips
Breaking
Renamed
.arrow
.tooltip-arrow
in our default tooltip template.
Breaking
The default value for the
fallbackPlacements
is changed to
['top', 'right', 'bottom', 'left']
for better placement of popper elements.
Breaking
Renamed
whiteList
option to
allowList
Utilities
Breaking
Renamed several utilities to use logical property names instead of directional names with the addition of RTL support:
Renamed
.float-left
.float-right
.float-start
.float-end
Renamed
.border-left
.border-right
.border-start
.border-end
Renamed
.rounded-left
.rounded-right
.rounded-start
.rounded-end
Renamed
.ml-*
.mr-*
.ms-*
.me-*
Renamed
.pl-*
.pr-*
.ps-*
.pe-*
Renamed
.text-*-left
.text-*-right
.text-*-start
.text-*-end
Breaking
Disabled negative margins by default.
Added new
.bg-body
class for quickly setting the
<body>
’s background to additional elements.
Added new
position utilities
right
bottom
, and
left
. Values include
, and
100%
for each property.
Added new
.translate-middle-x
.translate-middle-y
utilities to horizontally or vertically center absolute/fixed positioned elements.
Added new
border-width
utilities
Breaking
Renamed
.text-monospace
.font-monospace
Breaking
Removed
.text-hide
as it’s an antiquated method for hiding text that shouldn’t be used anymore.
Added
.fs-*
utilities for
font-size
utilities (with RFS enabled). These use the same scale as HTML’s default headings (1-6, large to small), and can be modified via Sass map.
Breaking
Renamed
.font-weight-*
utilities as
.fw-*
for brevity and consistency.
Breaking
Renamed
.font-italic
utility to
.fst-italic
for brevity and consistency with new
.fst-normal
utility.
Added
.d-grid
to display utilities and new
utilities (
.gap
) for CSS Grid and flexbox layouts.
Breaking
Removed
.rounded-sm
rounded-lg
, and introduced a new scale of classes,
.rounded-0
.rounded-3
See #31687
Added new
line-height
utilities:
.lh-1
.lh-sm
.lh-base
.lh-lg
. See
here
Moved the
.d-none
utility in our CSS to give it more weight over other display utilities.
Extended the
.visually-hidden-focusable
helper to also work on containers, using
:focus-within
Helpers
Breaking
Responsive embed helpers have been renamed to
ratio helpers
with new class names and improved behaviors, as well as a helpful CSS variable.
Classes have been renamed to change
in the aspect ratio. For example,
.ratio-16by9
is now
.ratio-16x9
We’ve dropped the
.embed-responsive-item
and element group selector in favor of a simpler
.ratio > *
selector. No more class is needed, and the ratio helper now works with any HTML element.
$embed-responsive-aspect-ratios
Sass map has been renamed to
$aspect-ratios
and its values have been simplified to include the class name and the percentage as the
key: value
pair.
CSS variables are now generated and included for each value in the Sass map. Modify the
--bs-aspect-ratio
variable on the
.ratio
to create any
custom aspect ratio
Breaking
"Screen reader" classes are now
"visually hidden" classes
Changed the Sass file from
scss/helpers/_screenreaders.scss
scss/helpers/_visually-hidden.scss
Renamed
.sr-only
.sr-only-focusable
.visually-hidden
.visually-hidden-focusable
Renamed
sr-only()
sr-only-focusable()
mixins to
visually-hidden()
visually-hidden-focusable()
now also includes our helpers. Helpers don’t need to be imported in custom builds anymore.
JavaScript
Dropped jQuery dependency
and rewrote plugins to be in regular JavaScript.
Breaking
Data attributes for all JavaScript plugins are now namespaced to help distinguish Bootstrap functionality from third parties and your own code. For example, we use
data-bs-toggle
instead of
data-toggle
All plugins can now accept a CSS selector as the first argument.
You can either pass a DOM element or any valid CSS selector to create a new instance of the plugin:
const
modal
Modal
'#myModal'
const
dropdown
Dropdown
'[data-bs-toggle="dropdown"]'
popperConfig
can be passed as a function that accepts the Bootstrap’s default Popper config as an argument, so that you can merge this default configuration in your way.
Applies to dropdowns, popovers, and tooltips.
The default value for the
fallbackPlacements
is changed to
['top', 'right', 'bottom', 'left']
for better placement of Popper elements.
Applies to dropdowns, popovers, and tooltips.
Removed underscore from public static methods like
_getInstance()
getInstance()
Removed
util.js
, with its functionality now integrated into individual plugins. If you previously included
util.js
manually, you can safely remove it, as it is no longer needed. Each plugin now contains only the utilities it requires, enhancing modularity and reducing dependencies.


--- 065_helpers_stacks.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/stacks
--------------------------------------------------
Stacks offer a shortcut for applying a number of flexbox properties to quickly and easily create layouts in Bootstrap. All credit for the concept and implementation goes to the open source
Pylon project
Heads up!
Support for gap utilities with flexbox isn’t available in Safari prior to 14.5, so consider verifying your intended browser support. Grid layout should have no issues.
Read more
Vertical
.vstack
to create vertical layouts. Stacked items are full-width by default. Use
.gap-*
utilities to add space between items.
First item
Second item
Third item
html
class
vstack gap-3
class
First item
class
Second item
class
Third item
Horizontal
.hstack
for horizontal layouts. Stacked items are vertically centered by default and only take up their necessary width. Use
.gap-*
utilities to add space between items.
First item
Second item
Third item
html
class
hstack gap-3
class
First item
class
Second item
class
Third item
Using horizontal margin utilities like
.ms-auto
as spacers:
First item
Second item
Third item
html
class
hstack gap-3
class
First item
class
p-2 ms-auto
Second item
class
Third item
And with
vertical rules
First item
Second item
Third item
html
class
hstack gap-3
class
First item
class
p-2 ms-auto
Second item
class
class
Third item
Examples
.vstack
to stack buttons and other elements:
Save changes
Cancel
html
class
vstack gap-2 col-md-5 mx-auto
button
type
button
class
btn btn-secondary
Save changes
button
button
type
button
class
btn btn-outline-secondary
Cancel
button
Create an inline form with
.hstack
Submit
Reset
html
class
hstack gap-3
input
class
form-control me-auto
type
text
placeholder
Add your item here...
aria-label
Add your item here...
button
type
button
class
btn btn-secondary
Submit
button
class
button
type
button
class
btn btn-outline-danger
Reset
button
scss/helpers/_stacks.scss
.hstack
display
flex
flex-direction
align-items
center
align-self
stretch
.vstack
display
flex
flex
1 1 auto
flex-direction
column
align-self
stretch


--- 072_helpers_colored-links.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/colored-links
--------------------------------------------------
Link colors
You can use the
.link-*
classes to colorize links. Unlike the
.text-*
classes
, these classes have a
:hover
:focus
state. Some of the link styles use a relatively light foreground color, and should only be used on a dark background in order to have sufficient contrast.
Heads up!
.link-body-emphasis
is currently the only colored link that adapts to color modes. It’s treated as a special case until v6 arrives and we can more thoroughly rebuild our theme colors for color modes. Until then, it’s a unique, high-contrast link color with custom
:hover
:focus
styles. However, it still responds to the new link utilities.
Primary link
Secondary link
Success link
Danger link
Warning link
Info link
Light link
Dark link
Emphasis link
html
href
class
link-primary
Primary link
href
class
link-secondary
Secondary link
href
class
link-success
Success link
href
class
link-danger
Danger link
href
class
link-warning
Warning link
href
class
link-info
Info link
href
class
link-light
Light link
href
class
link-dark
Dark link
href
class
link-body-emphasis
Emphasis link
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Link utilities
Added in v5.3.0
Colored links can also be modified by our
link utilities
Primary link
Secondary link
Success link
Danger link
Warning link
Info link
Light link
Dark link
Emphasis link
html
href
class
link-primary link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Primary link
href
class
link-secondary link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Secondary link
href
class
link-success link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Success link
href
class
link-danger link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Danger link
href
class
link-warning link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Warning link
href
class
link-info link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Info link
href
class
link-light link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Light link
href
class
link-dark link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Dark link
href
class
link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover
Emphasis link


--- 075_helpers_ratio.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/ratio
--------------------------------------------------
About
Use the ratio helper to manage the aspect ratios of external content like
<iframe>
<embed>
<video>
s, and
<object>
s. These helpers also can be used on any standard HTML child element (e.g., a
<div>
<img>
). Styles are applied from the parent
.ratio
class directly to the child.
Aspect ratios are declared in a Sass map and included in each class via CSS variable, which also allows
custom aspect ratios
Pro-Tip!
You don’t need
frameborder="0"
on your
<iframe>
s as we override that for you in
Reboot
Example
Wrap any embed, like an
<iframe>
, in a parent element with
.ratio
and an aspect ratio class. The immediate child element is automatically sized thanks to our universal selector
.ratio > *
html
class
ratio ratio-16x9
iframe
https://www.youtube.com/embed/zpOULjyy-n8?rel=0
title
YouTube video
allowfullscreen
iframe
Aspect ratios
Aspect ratios can be customized with modifier classes. By default the following ratio classes are provided:
16x9
21x9
html
class
ratio ratio-1x1
class
ratio ratio-4x3
class
ratio ratio-16x9
16x9
class
ratio ratio-21x9
21x9
Custom ratios
Each
.ratio-*
class includes a CSS custom property (or CSS variable) in the selector. You can override this CSS variable to create custom aspect ratios on the fly with some quick math on your part.
For example, to create a 2x1 aspect ratio, set
--bs-aspect-ratio: 50%
on the
.ratio
html
class
ratio
style
--bs-aspect-ratio
This CSS variable makes it easy to modify the aspect ratio across breakpoints. The following is 4x3 to start, but changes to a custom 2x1 at the medium breakpoint.
.ratio-4x3
@include
media-breakpoint-up
--bs-aspect-ratio
// 2x1
4x3, then 2x1
html
class
ratio ratio-4x3
4x3, then 2x1
Sass maps
Within
_variables.scss
, you can change the aspect ratios you want to use. Here’s our default
$ratio-aspect-ratios
map. Modify the map as you like and recompile your Sass to put them to use.
scss/_variables.scss
$aspect-ratios
"1x1"
100%
"4x3"
calc
100%
"16x9"
calc
100%
"21x9"
calc
100%


--- 076_helpers_color-background.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/color-background
--------------------------------------------------
Overview
Color and background helpers combine the power of our
.text-*
utilities
.bg-*
utilities
in one class. Using our Sass
color-contrast()
function, we automatically determine a contrasting
color
for a particular
background-color
Heads up!
There’s currently no support for a CSS-native
color-contrast
function, so we use our own via Sass. This means that customizing our theme colors via CSS variables may cause color contrast issues with these utilities.
Primary with contrasting color
Secondary with contrasting color
Success with contrasting color
Danger with contrasting color
Warning with contrasting color
Info with contrasting color
Light with contrasting color
Dark with contrasting color
html
class
text-bg-primary p-3
Primary with contrasting color
class
text-bg-secondary p-3
Secondary with contrasting color
class
text-bg-success p-3
Success with contrasting color
class
text-bg-danger p-3
Danger with contrasting color
class
text-bg-warning p-3
Warning with contrasting color
class
text-bg-info p-3
Info with contrasting color
class
text-bg-light p-3
Light with contrasting color
class
text-bg-dark p-3
Dark with contrasting color
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
With components
Use them in place of combined
.text-*
.bg-*
classes, like on
badges
Primary
Info
html
span
class
badge text-bg-primary
Primary
span
span
class
badge text-bg-info
Info
span
Or on
cards
Header
Some quick example text to build on the card title and make up the bulk of the card’s content.
Header
Some quick example text to build on the card title and make up the bulk of the card’s content.
html
class
card text-bg-primary mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card text-bg-info mb-3
style
max-width
18rem
class
card-header
Header
class
card-body
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.


--- 077_helpers_position.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/position
--------------------------------------------------
Fixed top
Position an element at the top of the viewport, from edge to edge. Be sure you understand the ramifications of fixed position in your project; you may need to add additional CSS.
class
fixed-top
Fixed bottom
Position an element at the bottom of the viewport, from edge to edge. Be sure you understand the ramifications of fixed position in your project; you may need to add additional CSS.
class
fixed-bottom
Sticky top
Position an element at the top of the viewport, from edge to edge, but only after you scroll past it.
class
sticky-top
Responsive sticky top
Responsive variations also exist for
.sticky-top
utility.
class
sticky-sm-top
Stick to the top on viewports sized SM (small) or wider
class
sticky-md-top
Stick to the top on viewports sized MD (medium) or wider
class
sticky-lg-top
Stick to the top on viewports sized LG (large) or wider
class
sticky-xl-top
Stick to the top on viewports sized XL (extra-large) or wider
class
sticky-xxl-top
Stick to the top on viewports sized XXL (extra-extra-large) or wider
Sticky bottom
Position an element at the bottom of the viewport, from edge to edge, but only after you scroll past it.
class
sticky-bottom
Responsive sticky bottom
Responsive variations also exist for
.sticky-bottom
utility.
class
sticky-sm-bottom
Stick to the bottom on viewports sized SM (small) or wider
class
sticky-md-bottom
Stick to the bottom on viewports sized MD (medium) or wider
class
sticky-lg-bottom
Stick to the bottom on viewports sized LG (large) or wider
class
sticky-xl-bottom
Stick to the bottom on viewports sized XL (extra-large) or wider
class
sticky-xxl-bottom
Stick to the bottom on viewports sized XXL (extra-extra-large) or wider


--- 084_helpers_text-truncation.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/text-truncation
--------------------------------------------------
For longer content, you can add a
.text-truncate
class to truncate the text with an ellipsis.
Requires
display: inline-block
display: block
This text is quite long, and will be truncated once displayed.
This text is quite long, and will be truncated once displayed.
html
<!-- Block level -->
class
class
col-2 text-truncate
This text is quite long, and will be truncated once displayed.
<!-- Inline level -->
span
class
d-inline-block text-truncate
style
max-width
150px
This text is quite long, and will be truncated once displayed.
span


--- 096_utilities_position.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/position
--------------------------------------------------
Position values
Quick positioning classes are available, though they are not responsive.
class
position-static
class
position-relative
class
position-absolute
class
position-fixed
class
position-sticky
Arrange elements
Arrange elements easily with the edge positioning utilities. The format is
{property}-{position}
Where
property
is one of:
- for the vertical
position
start
- for the horizontal
left
position (in LTR)
bottom
- for the vertical
bottom
position
- for the horizontal
right
position (in LTR)
Where
position
is one of:
- for
edge position
- for
edge position
- for
100%
edge position
(You can add more position values by adding entries to the
$position-values
Sass map variable.)
html
class
position-relative
class
position-absolute top-0 start-0
class
position-absolute top-0 end-0
class
position-absolute top-50 start-50
class
position-absolute bottom-50 end-50
class
position-absolute bottom-0 start-0
class
position-absolute bottom-0 end-0
Center elements
In addition, you can also center the elements with the transform utility class
.translate-middle
This class applies the transformations
translateX(-50%)
translateY(-50%)
to the element which, in combination with the edge positioning utilities, allows you to absolute center an element.
html
class
position-relative
class
position-absolute top-0 start-0 translate-middle
class
position-absolute top-0 start-50 translate-middle
class
position-absolute top-0 start-100 translate-middle
class
position-absolute top-50 start-0 translate-middle
class
position-absolute top-50 start-50 translate-middle
class
position-absolute top-50 start-100 translate-middle
class
position-absolute top-100 start-0 translate-middle
class
position-absolute top-100 start-50 translate-middle
class
position-absolute top-100 start-100 translate-middle
By adding
.translate-middle-x
.translate-middle-y
classes, elements can be positioned only in horizontal or vertical direction.
html
class
position-relative
class
position-absolute top-0 start-0
class
position-absolute top-0 start-50 translate-middle-x
class
position-absolute top-0 end-0
class
position-absolute top-50 start-0 translate-middle-y
class
position-absolute top-50 start-50 translate-middle
class
position-absolute top-50 end-0 translate-middle-y
class
position-absolute bottom-0 start-0
class
position-absolute bottom-0 start-50 translate-middle-x
class
position-absolute bottom-0 end-0
Examples
Here are some real life examples of these classes:
Mails
unread messages
Marker
Alerts
unread messages
html
button
type
button
class
btn btn-primary position-relative
Mails
span
class
position-absolute top-0 start-100 translate-middle badge rounded-pill text-bg-secondary
span
class
visually-hidden
unread messages
span
span
button
class
position-relative py-2 px-4 text-bg-secondary border border-secondary rounded-pill
Marker
width
height
viewBox
0 0 16 16
class
position-absolute top-100 start-50 translate-middle mt-1
fill
var(--bs-secondary)
xmlns
http://www.w3.org/2000/svg
aria-hidden
true
path
M7.247 11.14L2.451 5.658C1.885 5.013 2.345 4 3.204 4h9.592a1 1 0 0 1 .753 1.659l-4.796 5.48a1 1 0 0 1-1.506 0z
button
type
button
class
btn btn-primary position-relative
Alerts
span
class
position-absolute top-0 start-100 translate-middle badge border border-light rounded-circle bg-danger p-2
span
class
visually-hidden
unread messages
span
span
button
You can use these classes with existing components to create new ones. Remember that you can extend its functionality by adding entries to the
$position-values
variable.
html
class
position-relative m-4
class
progress
role
progressbar
aria-label
Progress
aria-valuenow
aria-valuemin
aria-valuemax
style
height
class
progress-bar
style
width
button
type
button
class
position-absolute top-0 start-0 translate-middle btn btn-sm btn-primary rounded-pill
style
width
2rem
height
2rem
button
button
type
button
class
position-absolute top-0 start-50 translate-middle btn btn-sm btn-primary rounded-pill
style
width
2rem
height
2rem
button
button
type
button
class
position-absolute top-0 start-100 translate-middle btn btn-sm btn-secondary rounded-pill
style
width
2rem
height
2rem
button
Sass maps
Default position utility values are declared in a Sass map, then used to generate our utilities.
scss/_variables.scss
$position-values
100%
Sass utilities API
Position utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"position"
property
position
values
static relative absolute fixed sticky
"top"
property
values
$position-values
"bottom"
property
bottom
values
$position-values
"start"
property
left
class
start
values
$position-values
"end"
property
right
class
values
$position-values
"translate-middle"
property
transform
class
translate-middle
values
null
translate
-50%
-50%
translateX
-50%
translateY
-50%


--- 102_helpers_stretched-link.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/stretched-link
--------------------------------------------------
.stretched-link
to a link to make its
containing block
clickable via a
::after
pseudo element. In most cases, this means that an element with
position: relative;
that contains a link with the
.stretched-link
class is clickable. Please note given
how CSS
position
works
.stretched-link
cannot be mixed with most table elements.
Cards have
position: relative
by default in Bootstrap, so in this case you can safely add the
.stretched-link
class to a link in the card without any other HTML changes.
Multiple links and tap targets are not recommended with stretched links. However, some
position
z-index
styles can help should this be required.
Card image cap
Card with stretched link
Some quick example text to build on the card title and make up the bulk of the card’s content.
Go somewhere
html
class
card
style
width
18rem
class
card-img-top
class
card-body
class
card-title
Card with stretched link
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
href
class
btn btn-primary stretched-link
Go somewhere
Most custom components do not have
position: relative
by default, so we need to add the
.position-relative
here to prevent the link from stretching outside the parent element.
Generic placeholder image22222
Custom component with stretched link
This is some placeholder content for the custom component. It is intended to mimic what some real-world content would look like, and we’re using it here to give the component a bit of body and size.
Go somewhere
html
class
d-flex position-relative
class
flex-shrink-0 me-3
class
mt-0
Custom component with stretched link
This is some placeholder content for the custom component. It is intended to mimic what some real-world content would look like, and we’re using it here to give the component a bit of body and size.
href
class
stretched-link
Go somewhere
Generic placeholder image
Columns with stretched link
Another instance of placeholder content for this other custom component. It is intended to mimic what some real-world content would look like, and we’re using it here to give the component a bit of body and size.
Go somewhere
html
class
row g-0 bg-body-secondary position-relative
class
col-md-6 mb-md-0 p-md-4
class
w-100
class
col-md-6 p-4 ps-md-0
class
mt-0
Columns with stretched link
Another instance of placeholder content for this other custom component. It is intended to mimic what some real-world content would look like, and we’re using it here to give the component a bit of body and size.
href
class
stretched-link
Go somewhere
Identifying the containing block
If the stretched link doesn’t seem to work, the
containing block
will probably be the cause. The following CSS properties will make an element the containing block:
position
value other than
static
transform
perspective
value other than
none
will-change
value of
transform
perspective
filter
value other than
none
or a
will-change
value of
filter
(only works on Firefox)
Card image cap
Card with stretched links
Some quick example text to build on the card title and make up the bulk of the card’s content.
Stretched link will not work here, because
position: relative
is added to the link
This
stretched link
will only be spread over the
-tag, because a transform is applied to it.
html
class
card
style
width
18rem
class
card-img-top
class
card-body
class
card-title
Card with stretched links
class
card-text
Some quick example text to build on the card title and make up the bulk of the card’s content.
class
card-text
href
class
stretched-link text-danger
style
position
relative
Stretched link will not work here, because
code
position: relative
code
is added to the link
class
card-text bg-body-tertiary
style
transform
rotate
This
href
class
text-warning stretched-link
stretched link
will only be spread over the
code
code
-tag, because a transform is applied to it.


--- 111_helpers_vertical-rule.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/vertical-rule
--------------------------------------------------
How it works
Vertical rules are inspired by the
<hr>
element, allowing you to create vertical dividers in common layouts. They’re styled just like
<hr>
elements:
They’re
wide
They have
min-height
Their color is set via
currentColor
opacity
Customize them with additional styles as needed.
Example
html
class
Vertical rules scale their height in flex layouts:
html
class
d-flex
style
height
200px
class
With stacks
They can also be used in
stacks
First item
Second item
Third item
html
class
hstack gap-3
class
First item
class
p-2 ms-auto
Second item
class
class
Third item
Sass variables
Customize the vertical rule Sass variable to change its width.
scss/_variables.scss
$vr-border-width
#{$prefix}
border-width


--- 124_helpers_clearfix.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/clearfix
--------------------------------------------------
Easily clear
float
s by adding
.clearfix
to the parent element
. Can also be used as a mixin.
Use in HTML:
class
clearfix
The mixin source code:
scss/mixins/_clearfix.scss
@mixin
clearfix
::after
display
block
clear
both
content
Use the mixin in SCSS:
.element
@include
clearfix
The following example shows how the clearfix can be used. Without the clearfix the wrapping div would not span around the buttons which would cause a broken layout.
Example Button floated left
Example Button floated right
html
class
bg-info clearfix
button
type
button
class
btn btn-secondary float-start
Example Button floated left
button
button
type
button
class
btn btn-secondary float-end
Example Button floated right
button


--- 133_helpers_focus-ring.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/focus-ring
--------------------------------------------------
.focus-ring
helper removes the default
outline
:focus
, replacing it with a
box-shadow
that can be more broadly customized. The new shadow is made up of a series of CSS variables, inherited from the
:root
level, that can be modified for any element or component.
Example
Click directly on the link below to see the focus ring in action, or into the example below and then press
Custom focus ring
html
href
class
d-inline-flex focus-ring py-1 px-2 text-decoration-none border rounded-2
Custom focus ring
Customize
Modify the styling of a focus ring with our CSS variables, Sass variables, utilities, or custom styles.
CSS variables
Modify the
--bs-focus-ring-*
CSS variables as needed to change the default appearance.
Green focus ring
html
href
class
d-inline-flex focus-ring py-1 px-2 text-decoration-none border rounded-2
style
--bs-focus-ring-color
rgba
--bs-success-rgb
Green focus ring
.focus-ring
sets styles via global CSS variables that can be overridden on any parent element, as shown above. These variables are generated from their Sass variable counterparts.
scss/_root.scss
#{$prefix}
focus-ring-width
#{$focus-ring-width}
#{$prefix}
focus-ring-opacity
#{$focus-ring-opacity}
#{$prefix}
focus-ring-color
#{$focus-ring-color}
By default, there is no
--bs-focus-ring-x
--bs-focus-ring-y
, or
--bs-focus-ring-blur
, but we provide CSS variables with fallbacks to initial
values. Modify them to change the default appearance.
Blurry offset focus ring
html
href
class
d-inline-flex focus-ring py-1 px-2 text-decoration-none border rounded-2
style
--bs-focus-ring-x
10px
--bs-focus-ring-y
10px
--bs-focus-ring-blur
Blurry offset focus ring
Sass variables
Customize the focus ring Sass variables to modify all usage of the focus ring styles across your Bootstrap-powered project.
scss/_variables.scss
$focus-ring-width
.25rem
$focus-ring-opacity
$focus-ring-color
rgba
$primary
$focus-ring-opacity
$focus-ring-blur
$focus-ring-box-shadow
$focus-ring-blur
$focus-ring-width
$focus-ring-color
Sass utilities API
In addition to
.focus-ring
, we have several
.focus-ring-*
utilities to modify the helper class defaults. Modify the color with any of our
theme colors
. Note that the light and dark variants may not be visible on all background colors given current color mode support.
Primary focus
Secondary focus
Success focus
Danger focus
Warning focus
Info focus
Light focus
Dark focus
html
href
class
d-inline-flex focus-ring focus-ring-primary py-1 px-2 text-decoration-none border rounded-2
Primary focus
href
class
d-inline-flex focus-ring focus-ring-secondary py-1 px-2 text-decoration-none border rounded-2
Secondary focus
href
class
d-inline-flex focus-ring focus-ring-success py-1 px-2 text-decoration-none border rounded-2
Success focus
href
class
d-inline-flex focus-ring focus-ring-danger py-1 px-2 text-decoration-none border rounded-2
Danger focus
href
class
d-inline-flex focus-ring focus-ring-warning py-1 px-2 text-decoration-none border rounded-2
Warning focus
href
class
d-inline-flex focus-ring focus-ring-info py-1 px-2 text-decoration-none border rounded-2
Info focus
href
class
d-inline-flex focus-ring focus-ring-light py-1 px-2 text-decoration-none border rounded-2
Light focus
href
class
d-inline-flex focus-ring focus-ring-dark py-1 px-2 text-decoration-none border rounded-2
Dark focus
Focus ring utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"focus-ring"
css-var
true
css-variable-name
focus-ring-color
class
focus-ring
values
map-loop
$theme-colors-rgb
rgba-css-var
"$key"
"focus-ring"


--- 151_helpers_visually-hidden.txt ---
URL: https://getbootstrap.com/docs/5.3/helpers/visually-hidden
--------------------------------------------------
Visually hide an element while still allowing it to be exposed to assistive technologies (such as screen readers) with
.visually-hidden
. Use
.visually-hidden-focusable
to visually hide an element by default, but to display it when it’s focused (e.g. by a keyboard-only user).
.visually-hidden-focusable
can also be applied to a container–thanks to
:focus-within
, the container will be displayed when any child element of the container receives focus.
Title for screen readers
A container with a
focusable element
html
class
visually-hidden
Title for screen readers
class
visually-hidden-focusable
href
#content
class
visually-hidden-focusable
A container with a
href
focusable element
Both
visually-hidden
visually-hidden-focusable
can also be used as mixins.
// Usage as a mixin
.visually-hidden-title
@include
visually-hidden
.skip-navigation
@include
visually-hidden-focusable


-------------------- End of Helpers (14 pages) --------------------


========================= UTILITIES =========================
Section: Utilities
Files: 18
======================================================================

--- 012_utilities_overflow.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/overflow
--------------------------------------------------
Overflow
Adjust the
overflow
property on the fly with four default values and classes. These classes are not responsive by default.
This is an example of using
.overflow-auto
on an element with set width and height dimensions. By design, this content will vertically scroll.
This is an example of using
.overflow-hidden
on an element with set width and height dimensions.
This is an example of using
.overflow-visible
on an element with set width and height dimensions.
This is an example of using
.overflow-scroll
on an element with set width and height dimensions.
class
overflow-auto
class
overflow-hidden
class
overflow-visible
class
overflow-scroll
overflow-x
Adjust the
overflow-x
property to affect the overflow of content horizontally.
.overflow-x-auto
example on an element
with set width and height dimensions.
.overflow-x-hidden
example
on an element with set width and height dimensions.
.overflow-x-visible
example
on an element with set width and height dimensions.
.overflow-x-scroll
example on an element
with set width and height dimensions.
class
overflow-x-auto
class
overflow-x-hidden
class
overflow-x-visible
class
overflow-x-scroll
overflow-y
Adjust the
overflow-y
property to affect the overflow of content vertically.
.overflow-y-auto
example on an element with set width and height dimensions.
.overflow-y-hidden
example on an element with set width and height dimensions.
.overflow-y-visible
example on an element with set width and height dimensions.
.overflow-y-scroll
example on an element with set width and height dimensions.
class
overflow-y-auto
class
overflow-y-hidden
class
overflow-y-visible
class
overflow-y-scroll
Using Sass variables, you may customize the overflow utilities by changing the
$overflows
variable in
_variables.scss
Sass utilities API
Overflow utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"overflow"
property
overflow
values
auto hidden visible scroll
"overflow-x"
property
overflow-x
values
auto hidden visible scroll
"overflow-y"
property
overflow-y
values
auto hidden visible scroll


--- 031_utilities_sizing.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/sizing
--------------------------------------------------
Relative to the parent
Width and height utilities are generated from the utility API in
_utilities.scss
. Includes support for
100%
, and
auto
by default. Modify those values as you need to generate different utilities here.
Width 25%
Width 50%
Width 75%
Width 100%
Width auto
html
class
w-25 p-3
Width 25%
class
w-50 p-3
Width 50%
class
w-75 p-3
Width 75%
class
w-100 p-3
Width 100%
class
w-auto p-3
Width auto
Height 25%
Height 50%
Height 75%
Height 100%
Height auto
html
style
height
100px
class
h-25 d-inline-block
style
width
120px
Height 25%
class
h-50 d-inline-block
style
width
120px
Height 50%
class
h-75 d-inline-block
style
width
120px
Height 75%
class
h-100 d-inline-block
style
width
120px
Height 100%
class
h-auto d-inline-block
style
width
120px
Height auto
You can also use
max-width: 100%;
max-height: 100%;
utilities as needed.
Max-width 100%
html
style
width
height
100px
class
mw-100
style
width
200%
Max-width 100%
Max-height 100%
html
style
height
100px
class
mh-100
style
width
100px
height
200px
Max-height 100%
Relative to the viewport
You can also use utilities to set the width and height relative to the viewport.
class
min-vw-100
Min-width 100vw
class
min-vh-100
Min-height 100vh
class
vw-100
Width 100vw
class
vh-100
Height 100vh
Sass utilities API
Sizing utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"width"
property
width
class
values
100%
auto
auto
"max-width"
property
max-width
class
values
100%
"viewport-width"
property
width
class
values
100vw
"min-viewport-width"
property
min-width
class
min-vw
values
100vw
"height"
property
height
class
values
100%
auto
auto
"max-height"
property
max-height
class
values
100%
"viewport-height"
property
height
class
values
100vh
"min-viewport-height"
property
min-height
class
min-vh
values
100vh


--- 032_utilities_spacing.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/spacing
--------------------------------------------------
Margin and padding
Assign responsive-friendly
margin
padding
values to an element or a subset of its sides with shorthand classes. Includes support for individual properties, all properties, and vertical and horizontal properties. Classes are built from a default Sass map ranging from
.25rem
3rem
Using the CSS Grid layout module?
Consider using
the gap utility
instead.
Notation
Spacing utilities that apply to all breakpoints, from
, have no breakpoint abbreviation in them. This is because those classes are applied from
min-width: 0
and up, and thus are not bound by a media query. The remaining breakpoints, however, do include a breakpoint abbreviation.
The classes are named using the format
{property}{sides}-{size}
{property}{sides}-{breakpoint}-{size}
, and
Where
property
is one of:
- for classes that set
margin
- for classes that set
padding
Where
sides
is one of:
- for classes that set
margin-top
padding-top
- for classes that set
margin-bottom
padding-bottom
- (start) for classes that set
margin-left
padding-left
in LTR,
margin-right
padding-right
in RTL
- (end) for classes that set
margin-right
padding-right
in LTR,
margin-left
padding-left
in RTL
- for classes that set both
*-left
*-right
- for classes that set both
*-top
*-bottom
blank - for classes that set a
margin
padding
on all 4 sides of the element
Where
size
is one of:
- for classes that eliminate the
margin
padding
by setting it to
- (by default) for classes that set the
margin
padding
$spacer * .25
- (by default) for classes that set the
margin
padding
$spacer * .5
- (by default) for classes that set the
margin
padding
$spacer
- (by default) for classes that set the
margin
padding
$spacer * 1.5
- (by default) for classes that set the
margin
padding
$spacer * 3
auto
- for classes that set the
margin
to auto
(You can add more sizes by adding entries to the
$spacers
Sass map variable.)
Examples
Here are some representative examples of these classes:
.mt-0
margin-top
!important
.ms-1
margin-left
$spacer
!important
.px-2
padding-left
$spacer
!important
padding-right
$spacer
!important
.p-3
padding
$spacer
!important
Horizontal centering
Additionally, Bootstrap also includes an
.mx-auto
class for horizontally centering fixed-width block level content—that is, content that has
display: block
and a
width
set—by setting the horizontal margins to
auto
Centered element
class
mx-auto p-2
style
width
200px
Centered element
Negative margin
In CSS,
margin
properties can utilize negative values (
padding
cannot). These negative margins are
disabled by default
, but can be enabled in Sass by setting
$enable-negative-margins: true
The syntax is nearly the same as the default, positive margin utilities, but with the addition of
before the requested size. Here’s an example class that’s the opposite of
.mt-1
.mt-n1
margin-top
-0.25rem
!important
When using
display: grid
display: flex
, you can make use of
utilities on the parent element. This can save on having to add margin utilities to individual children of a grid or flex container. Gap utilities are responsive by default, and are generated via our utilities API, based on the
$spacers
Sass map.
Grid item 1
Grid item 2
Grid item 3
Grid item 4
html
style
grid-template-columns
1fr 1fr
class
d-grid gap-3
class
Grid item 1
class
Grid item 2
class
Grid item 3
class
Grid item 4
Support includes responsive options for all of Bootstrap’s grid breakpoints, as well as six sizes from the
$spacers
map (
). There is no
.gap-auto
utility class as it’s effectively the same as
.gap-0
row-gap
row-gap
sets the vertical space between children items in the specified container.
Grid item 1
Grid item 2
Grid item 3
Grid item 4
html
style
grid-template-columns
1fr 1fr
class
d-grid gap-0 row-gap-3
class
Grid item 1
class
Grid item 2
class
Grid item 3
class
Grid item 4
column-gap
column-gap
sets the horizontal space between children items in the specified container.
Grid item 1
Grid item 2
Grid item 3
Grid item 4
html
style
grid-template-columns
1fr 1fr
class
d-grid gap-0 column-gap-3
class
Grid item 1
class
Grid item 2
class
Grid item 3
class
Grid item 4
Sass maps
Spacing utilities are declared via Sass map and then generated with our utilities API.
scss/_variables.scss
$spacer
1rem
$spacers
$spacer
$spacer
$spacer
$spacer
$spacer
Sass utilities API
Spacing utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"margin"
responsive
true
property
margin
class
values
map-merge
$spacers
auto
auto
"margin-x"
responsive
true
property
margin-right margin-left
class
values
map-merge
$spacers
auto
auto
"margin-y"
responsive
true
property
margin-top margin-bottom
class
values
map-merge
$spacers
auto
auto
"margin-top"
responsive
true
property
margin-top
class
values
map-merge
$spacers
auto
auto
"margin-end"
responsive
true
property
margin-right
class
values
map-merge
$spacers
auto
auto
"margin-bottom"
responsive
true
property
margin-bottom
class
values
map-merge
$spacers
auto
auto
"margin-start"
responsive
true
property
margin-left
class
values
map-merge
$spacers
auto
auto
// Negative margin utilities
"negative-margin"
responsive
true
property
margin
class
values
$negative-spacers
"negative-margin-x"
responsive
true
property
margin-right margin-left
class
values
$negative-spacers
"negative-margin-y"
responsive
true
property
margin-top margin-bottom
class
values
$negative-spacers
"negative-margin-top"
responsive
true
property
margin-top
class
values
$negative-spacers
"negative-margin-end"
responsive
true
property
margin-right
class
values
$negative-spacers
"negative-margin-bottom"
responsive
true
property
margin-bottom
class
values
$negative-spacers
"negative-margin-start"
responsive
true
property
margin-left
class
values
$negative-spacers
// Padding utilities
"padding"
responsive
true
property
padding
class
values
$spacers
"padding-x"
responsive
true
property
padding-right padding-left
class
values
$spacers
"padding-y"
responsive
true
property
padding-top padding-bottom
class
values
$spacers
"padding-top"
responsive
true
property
padding-top
class
values
$spacers
"padding-end"
responsive
true
property
padding-right
class
values
$spacers
"padding-bottom"
responsive
true
property
padding-bottom
class
values
$spacers
"padding-start"
responsive
true
property
padding-left
class
values
$spacers
// Gap utility
"gap"
responsive
true
property
class
values
$spacers
"row-gap"
responsive
true
property
row-gap
class
row-gap
values
$spacers
"column-gap"
responsive
true
property
column-gap
class
column-gap
values
$spacers


--- 033_utilities_shadows.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/shadows
--------------------------------------------------
Examples
While shadows on components are disabled by default in Bootstrap and can be enabled via
$enable-shadows
, you can also quickly add or remove a shadow with our
box-shadow
utility classes. Includes support for
.shadow-none
and three default sizes (which have associated variables to match).
No shadow
Small shadow
Regular shadow
Larger shadow
html
class
shadow-none p-3 mb-5 bg-body-tertiary rounded
No shadow
class
shadow-sm p-3 mb-5 bg-body-tertiary rounded
Small shadow
class
shadow p-3 mb-5 bg-body-tertiary rounded
Regular shadow
class
shadow-lg p-3 mb-5 bg-body-tertiary rounded
Larger shadow
Sass variables
scss/_variables.scss
$box-shadow
0 .5rem 1rem
rgba
$black
$box-shadow-sm
0 .125rem .25rem
rgba
$black
.075
$box-shadow-lg
0 1rem 3rem
rgba
$black
.175
$box-shadow-inset
inset 0 1px 2px
rgba
$black
.075
Sass utilities API
Shadow utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"shadow"
property
box-shadow
class
shadow
values
null
#{$prefix}
box-shadow
#{$prefix}
box-shadow-sm
#{$prefix}
box-shadow-lg
none
none


--- 042_utilities_borders.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/borders
--------------------------------------------------
Border
Use border utilities to add or remove an element’s borders. Choose from all borders or one at a time.
Additive
Add borders to custom elements:
html
span
class
border
span
span
class
border-top
span
span
class
border-end
span
span
class
border-bottom
span
span
class
border-start
span
Subtractive
Or remove borders:
html
span
class
border border-0
span
span
class
border border-top-0
span
span
class
border border-end-0
span
span
class
border border-bottom-0
span
span
class
border border-start-0
span
Color
Border utilities like
.border-*
that generated from our original
$theme-colors
Sass map don’t yet respond to color modes, however, any
.border-*-subtle
utility will. This will be resolved in v6.
Change the border color using utilities built on our theme colors.
html
span
class
border border-primary
span
span
class
border border-primary-subtle
span
span
class
border border-secondary
span
span
class
border border-secondary-subtle
span
span
class
border border-success
span
span
class
border border-success-subtle
span
span
class
border border-danger
span
span
class
border border-danger-subtle
span
span
class
border border-warning
span
span
class
border border-warning-subtle
span
span
class
border border-info
span
span
class
border border-info-subtle
span
span
class
border border-light
span
span
class
border border-light-subtle
span
span
class
border border-dark
span
span
class
border border-dark-subtle
span
span
class
border border-black
span
span
class
border border-white
span
Or modify the default
border-color
of a component:
Email address
Dangerous heading
Changing border color and width
html
class
mb-4
label
exampleFormControlInput1
class
form-label
Email address
label
input
type
email
class
form-control border-success
exampleFormControlInput1
placeholder
name@example.com
class
h4 pb-2 mb-4 text-danger border-bottom border-danger
Dangerous heading
class
p-3 bg-info bg-opacity-10 border border-info border-start-0 rounded-end
Changing border color and width
Opacity
Added in v5.2.0
border-{color}
utilities are generated with Sass using CSS variables. This allows for real-time color changes without compilation and dynamic alpha transparency changes.
How it works
Consider our default
.border-success
utility.
.border-success
--bs-border-opacity
border-color
rgba
--bs-success-rgb
--bs-border-opacity
!important
We use an RGB version of our
--bs-success
(with the value of
25, 135, 84
) CSS variable and attached a second CSS variable,
--bs-border-opacity
, for the alpha transparency (with a default value
thanks to a local CSS variable). That means anytime you use
.border-success
now, your computed
color
value is
rgba(25, 135, 84, 1)
. The local CSS variable inside each
.border-*
class avoids inheritance issues so nested instances of the utilities don’t automatically have a modified alpha transparency.
Example
To change that opacity, override
--bs-border-opacity
via custom styles or inline styles.
This is default success border
This is 50% opacity success border
html
class
border border-success p-2 mb-2
This is default success border
class
border border-success p-2
style
--bs-border-opacity
This is 50% opacity success border
Or, choose from any of the
.border-opacity
utilities:
This is default success border
This is 75% opacity success border
This is 50% opacity success border
This is 25% opacity success border
This is 10% opacity success border
html
class
border border-success p-2 mb-2
This is default success border
class
border border-success p-2 mb-2 border-opacity-75
This is 75% opacity success border
class
border border-success p-2 mb-2 border-opacity-50
This is 50% opacity success border
class
border border-success p-2 mb-2 border-opacity-25
This is 25% opacity success border
class
border border-success p-2 border-opacity-10
This is 10% opacity success border
Width
html
span
class
border border-1
span
span
class
border border-2
span
span
class
border border-3
span
span
class
border border-4
span
span
class
border border-5
span
Radius
Add classes to an element to easily round its corners.
Example rounded image
75x75
Example top rounded image
75x75
Example right rounded image
75x75
Example bottom rounded image
75x75
Example left rounded image
75x75
html
class
rounded
class
rounded-top
class
rounded-end
class
rounded-bottom
class
rounded-start
Sizes
Use the scaling classes for larger or smaller rounded corners. Sizes range from
including
circle
pill
, and can be configured by modifying the utilities API.
Example non-rounded image
75x75
Example small rounded image
75x75
Example default rounded image
75x75
Example large rounded image
75x75
Example larger rounded image
75x75
Example extra large rounded image
75x75
Completely round image
75x75
Rounded pill image
150x75
html
class
rounded-0
class
rounded-1
class
rounded-2
class
rounded-3
class
rounded-4
class
rounded-5
class
rounded-circle
class
rounded-pill
Example small rounded image
75x75
Example default left rounded image
75x75
Example right completely round image
75x75
Example left rounded pill image
75x75
Example extra large bottom rounded image
75x75
html
class
rounded-bottom-1
class
rounded-start-2
class
rounded-end-circle
class
rounded-start-pill
class
rounded-5 rounded-top-0
Variables
Added in v5.2.0
scss/_root.scss
#{$prefix}
border-width
#{$border-width}
#{$prefix}
border-style
#{$border-style}
#{$prefix}
border-color
#{$border-color}
#{$prefix}
border-color-translucent
#{$border-color-translucent}
#{$prefix}
border-radius
#{$border-radius}
#{$prefix}
border-radius-sm
#{$border-radius-sm}
#{$prefix}
border-radius-lg
#{$border-radius-lg}
#{$prefix}
border-radius-xl
#{$border-radius-xl}
#{$prefix}
border-radius-xxl
#{$border-radius-xxl}
#{$prefix}
border-radius-2xl
#{$prefix}
border-radius-xxl
// Deprecated in v5.3.0 for consistency
#{$prefix}
border-radius-pill
#{$border-radius-pill}
Sass variables
scss/_variables.scss
$border-width
$border-widths
$border-style
solid
$border-color
$gray-300
$border-color-translucent
rgba
$black
.175
scss/_variables.scss
$border-radius
.375rem
$border-radius-sm
.25rem
$border-radius-lg
.5rem
$border-radius-xl
1rem
$border-radius-xxl
2rem
$border-radius-pill
50rem
Variables for setting
border-color
.border-*-subtle
utilities in light and dark mode:
scss/_variables.scss
$primary-border-subtle
tint-color
$primary
$secondary-border-subtle
tint-color
$secondary
$success-border-subtle
tint-color
$success
$info-border-subtle
tint-color
$info
$warning-border-subtle
tint-color
$warning
$danger-border-subtle
tint-color
$danger
$light-border-subtle
$gray-200
$dark-border-subtle
$gray-500
scss/_variables-dark.scss
$primary-border-subtle-dark
shade-color
$primary
$secondary-border-subtle-dark
shade-color
$secondary
$success-border-subtle-dark
shade-color
$success
$info-border-subtle-dark
shade-color
$info
$warning-border-subtle-dark
shade-color
$warning
$danger-border-subtle-dark
shade-color
$danger
$light-border-subtle-dark
$gray-700
$dark-border-subtle-dark
$gray-800
Sass maps
Color mode adaptive border colors are also available as a Sass map:
scss/_maps.scss
$theme-colors-border-subtle
"primary"
$primary-border-subtle
"secondary"
$secondary-border-subtle
"success"
$success-border-subtle
"info"
$info-border-subtle
"warning"
$warning-border-subtle
"danger"
$danger-border-subtle
"light"
$light-border-subtle
"dark"
$dark-border-subtle
scss/_maps.scss
$theme-colors-border-subtle-dark
"primary"
$primary-border-subtle-dark
"secondary"
$secondary-border-subtle-dark
"success"
$success-border-subtle-dark
"info"
$info-border-subtle-dark
"warning"
$warning-border-subtle-dark
"danger"
$danger-border-subtle-dark
"light"
$light-border-subtle-dark
"dark"
$dark-border-subtle-dark
Sass mixins
scss/mixins/_border-radius.scss
@mixin
border-radius
$radius
$border-radius
$fallback-border-radius
false
$enable-rounded
border-radius
valid-radius
$radius
@else if
$fallback-border-radius
!= false
border-radius
$fallback-border-radius
@mixin
border-top-radius
$radius
$border-radius
$enable-rounded
border-top-left-radius
valid-radius
$radius
border-top-right-radius
valid-radius
$radius
@mixin
border-end-radius
$radius
$border-radius
$enable-rounded
border-top-right-radius
valid-radius
$radius
border-bottom-right-radius
valid-radius
$radius
@mixin
border-bottom-radius
$radius
$border-radius
$enable-rounded
border-bottom-right-radius
valid-radius
$radius
border-bottom-left-radius
valid-radius
$radius
@mixin
border-start-radius
$radius
$border-radius
$enable-rounded
border-top-left-radius
valid-radius
$radius
border-bottom-left-radius
valid-radius
$radius
@mixin
border-top-start-radius
$radius
$border-radius
$enable-rounded
border-top-left-radius
valid-radius
$radius
@mixin
border-top-end-radius
$radius
$border-radius
$enable-rounded
border-top-right-radius
valid-radius
$radius
@mixin
border-bottom-end-radius
$radius
$border-radius
$enable-rounded
border-bottom-right-radius
valid-radius
$radius
@mixin
border-bottom-start-radius
$radius
$border-radius
$enable-rounded
border-bottom-left-radius
valid-radius
$radius
Sass utilities API
Border utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"border"
property
border
values
null
#{$prefix}
border-width
#{$prefix}
border-style
#{$prefix}
border-color
"border-top"
property
border-top
values
null
#{$prefix}
border-width
#{$prefix}
border-style
#{$prefix}
border-color
"border-end"
property
border-right
class
border-end
values
null
#{$prefix}
border-width
#{$prefix}
border-style
#{$prefix}
border-color
"border-bottom"
property
border-bottom
values
null
#{$prefix}
border-width
#{$prefix}
border-style
#{$prefix}
border-color
"border-start"
property
border-left
class
border-start
values
null
#{$prefix}
border-width
#{$prefix}
border-style
#{$prefix}
border-color
"border-color"
property
border-color
class
border
local-vars
"border-opacity"
values
$utilities-border-colors
"subtle-border-color"
property
border-color
class
border
values
$utilities-border-subtle
"border-width"
property
border-width
class
border
values
$border-widths
"border-opacity"
css-var
true
class
border-opacity
values
scss/_utilities.scss
"rounded"
property
border-radius
class
rounded
values
null
#{$prefix}
border-radius
#{$prefix}
border-radius-sm
#{$prefix}
border-radius
#{$prefix}
border-radius-lg
#{$prefix}
border-radius-xl
#{$prefix}
border-radius-xxl
circle
pill
#{$prefix}
border-radius-pill
"rounded-top"
property
border-top-left-radius border-top-right-radius
class
rounded-top
values
null
#{$prefix}
border-radius
#{$prefix}
border-radius-sm
#{$prefix}
border-radius
#{$prefix}
border-radius-lg
#{$prefix}
border-radius-xl
#{$prefix}
border-radius-xxl
circle
pill
#{$prefix}
border-radius-pill
"rounded-end"
property
border-top-right-radius border-bottom-right-radius
class
rounded-end
values
null
#{$prefix}
border-radius
#{$prefix}
border-radius-sm
#{$prefix}
border-radius
#{$prefix}
border-radius-lg
#{$prefix}
border-radius-xl
#{$prefix}
border-radius-xxl
circle
pill
#{$prefix}
border-radius-pill
"rounded-bottom"
property
border-bottom-right-radius border-bottom-left-radius
class
rounded-bottom
values
null
#{$prefix}
border-radius
#{$prefix}
border-radius-sm
#{$prefix}
border-radius
#{$prefix}
border-radius-lg
#{$prefix}
border-radius-xl
#{$prefix}
border-radius-xxl
circle
pill
#{$prefix}
border-radius-pill
"rounded-start"
property
border-bottom-left-radius border-top-left-radius
class
rounded-start
values
null
#{$prefix}
border-radius
#{$prefix}
border-radius-sm
#{$prefix}
border-radius
#{$prefix}
border-radius-lg
#{$prefix}
border-radius-xl
#{$prefix}
border-radius-xxl
circle
pill
#{$prefix}
border-radius-pill


--- 056_utilities_text.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/text
--------------------------------------------------
Text alignment
Easily realign text to components with text alignment classes. For start, end, and center alignment, responsive classes are available that use the same viewport width breakpoints as the grid system.
Start aligned text on all viewport sizes.
Center aligned text on all viewport sizes.
End aligned text on all viewport sizes.
End aligned text on viewports sized SM (small) or wider.
End aligned text on viewports sized MD (medium) or wider.
End aligned text on viewports sized LG (large) or wider.
End aligned text on viewports sized XL (extra large) or wider.
End aligned text on viewports sized XXL (extra extra large) or wider.
html
class
text-start
Start aligned text on all viewport sizes.
class
text-center
Center aligned text on all viewport sizes.
class
text-end
End aligned text on all viewport sizes.
class
text-sm-end
End aligned text on viewports sized SM (small) or wider.
class
text-md-end
End aligned text on viewports sized MD (medium) or wider.
class
text-lg-end
End aligned text on viewports sized LG (large) or wider.
class
text-xl-end
End aligned text on viewports sized XL (extra large) or wider.
class
text-xxl-end
End aligned text on viewports sized XXL (extra extra large) or wider.
Note that we don’t provide utility classes for justified text. While, aesthetically, justified text might look more appealing, it does make word-spacing more random and therefore harder to read.
Text wrapping and overflow
Wrap text with a
.text-wrap
class.
This text should wrap.
html
class
badge text-bg-primary text-wrap
style
width
6rem
This text should wrap.
Prevent text from wrapping with a
.text-nowrap
class.
This text should overflow the parent.
html
class
text-nowrap bg-body-secondary border
style
width
8rem
This text should overflow the parent.
Word break
Prevent long strings of text from breaking your components’ layout by using
.text-break
to set
word-wrap: break-word
word-break: break-word
. We use
word-wrap
instead of the more common
overflow-wrap
for wider browser support, and add the deprecated
word-break: break-word
to avoid issues with flex containers.
mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
html
class
text-break
mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
Note that
breaking words isn’t possible in Arabic
, which is the most used RTL language. Therefore
.text-break
is removed from our RTL compiled CSS.
Text transform
Transform text in components with our text capitalization classes:
text-lowercase
text-uppercase
text-capitalize
Lowercased text.
Uppercased text.
CapiTaliZed text.
html
class
text-lowercase
Lowercased text.
class
text-uppercase
Uppercased text.
class
text-capitalize
CapiTaliZed text.
Note how
.text-capitalize
only changes the first letter of each word, leaving the case of any other letters unaffected.
Font size
Quickly change the
font-size
of text. While our heading classes (e.g.,
) apply
font-size
font-weight
, and
line-height
, these utilities
only
apply
font-size
. Sizing for these utilities matches HTML’s heading elements, so as the number increases, their size decreases.
.fs-1 text
.fs-2 text
.fs-3 text
.fs-4 text
.fs-5 text
.fs-6 text
html
class
fs-1
.fs-1 text
class
fs-2
.fs-2 text
class
fs-3
.fs-3 text
class
fs-4
.fs-4 text
class
fs-5
.fs-5 text
class
fs-6
.fs-6 text
Customize your available
font-size
s by modifying the
$font-sizes
Sass map.
Font weight and italics
Quickly change the
font-weight
font-style
of text with these utilities.
font-style
utilities are abbreviated as
.fst-*
font-weight
utilities are abbreviated as
.fw-*
Bold text.
Bolder weight text (relative to the parent element).
Semibold weight text.
Medium weight text.
Normal weight text.
Light weight text.
Lighter weight text (relative to the parent element).
Italic text.
Text with normal font style
html
class
fw-bold
Bold text.
class
fw-bolder
Bolder weight text (relative to the parent element).
class
fw-semibold
Semibold weight text.
class
fw-medium
Medium weight text.
class
fw-normal
Normal weight text.
class
fw-light
Light weight text.
class
fw-lighter
Lighter weight text (relative to the parent element).
class
fst-italic
Italic text.
class
fst-normal
Text with normal font style
Line height
Change the line height with
.lh-*
utilities.
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
html
class
lh-1
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
class
lh-sm
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
class
lh-base
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
class
lh-lg
This is a long paragraph written to show how the line-height of an element is affected by our utilities. Classes are applied to the element itself or sometimes the parent element. These classes can be customized as needed with our utility API.
Monospace
Change a selection to our monospace font stack with
.font-monospace
This is in monospace
html
class
font-monospace
This is in monospace
Reset color
Reset a text or link’s color with
.text-reset
, so that it inherits the color from its parent.
Secondary body text with a
reset link
html
class
text-body-secondary
Secondary body text with a
href
class
text-reset
reset link
Text decoration
Decorate text in components with text decoration classes.
This text has a line underneath it.
This text has a line going through it.
This link has its text decoration removed
html
class
text-decoration-underline
This text has a line underneath it.
class
text-decoration-line-through
This text has a line going through it.
href
class
text-decoration-none
This link has its text decoration removed
Sass variables
Default type and font related Sass variables:
scss/_variables.scss
// stylelint-disable value-keyword-case
$font-family-sans-serif
system-ui
-apple-system
"Segoe UI"
Roboto
"Helvetica Neue"
"Noto Sans"
"Liberation Sans"
Arial
sans-serif
"Apple Color Emoji"
"Segoe UI Emoji"
"Segoe UI Symbol"
"Noto Color Emoji"
$font-family-monospace
SFMono-Regular
Menlo
Monaco
Consolas
"Liberation Mono"
"Courier New"
monospace
// stylelint-enable value-keyword-case
$font-family-base
#{$prefix}
font-sans-serif
$font-family-code
#{$prefix}
font-monospace
// $font-size-root affects the value of `rem`, which is used for as well font sizes, paddings, and margins
// $font-size-base affects the font size of the body text
$font-size-root
null
$font-size-base
1rem
// Assumes the browser default, typically `16px`
$font-size-sm
$font-size-base
.875
$font-size-lg
$font-size-base
1.25
$font-weight-lighter
lighter
$font-weight-light
$font-weight-normal
$font-weight-medium
$font-weight-semibold
$font-weight-bold
$font-weight-bolder
bolder
$font-weight-base
$font-weight-normal
$line-height-base
$line-height-sm
1.25
$line-height-lg
$h1-font-size
$font-size-base
$h2-font-size
$font-size-base
$h3-font-size
$font-size-base
1.75
$h4-font-size
$font-size-base
$h5-font-size
$font-size-base
1.25
$h6-font-size
$font-size-base
Sass maps
Font-size utilities are generated from this map, in combination with our utilities API.
scss/_variables.scss
$font-sizes
$h1-font-size
$h2-font-size
$h3-font-size
$h4-font-size
$h5-font-size
$h6-font-size
scss/_maps.scss
$theme-colors-text
"primary"
$primary-text-emphasis
"secondary"
$secondary-text-emphasis
"success"
$success-text-emphasis
"info"
$info-text-emphasis
"warning"
$warning-text-emphasis
"danger"
$danger-text-emphasis
"light"
$light-text-emphasis
"dark"
$dark-text-emphasis
Sass utilities API
Font and text utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"font-family"
property
font-family
class
font
values
monospace
#{$prefix}
font-monospace
"font-size"
true
property
font-size
class
values
$font-sizes
"font-style"
property
font-style
class
values
italic normal
"font-weight"
property
font-weight
class
values
lighter
$font-weight-lighter
light
$font-weight-light
normal
$font-weight-normal
medium
$font-weight-medium
semibold
$font-weight-semibold
bold
$font-weight-bold
bolder
$font-weight-bolder
"line-height"
property
line-height
class
values
$line-height-sm
base
$line-height-base
$line-height-lg
"text-align"
responsive
true
property
text-align
class
text
values
start
left
right
center
center
"text-decoration"
property
text-decoration
values
none underline line-through
"text-transform"
property
text-transform
class
text
values
lowercase uppercase capitalize
"white-space"
property
white-space
class
text
values
wrap
normal
nowrap
nowrap
"word-wrap"
property
word-wrap word-break
class
text
values
break
break-word
false


--- 062_utilities_object-fit.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/object-fit
--------------------------------------------------
How it works
Change the value of the
object-fit
property
with our responsive
object-fit
utility classes. This property tells the content to fill the parent container in a variety of ways, such as preserving the aspect ratio or stretching to take up as much space as possible.
Classes for the value of
object-fit
are named using the format
.object-fit-{value}
. Choose from the following values:
contain
cover
fill
scale
(for scale-down)
none
Examples
Add the
object-fit-{value}
class to the
replaced element
html
class
object-fit-contain border rounded
class
object-fit-cover border rounded
class
object-fit-fill border rounded
class
object-fit-scale border rounded
class
object-fit-none border rounded
Responsive
Responsive variations also exist for each
object-fit
value using the format
.object-fit-{breakpoint}-{value}
, for the following breakpoint abbreviations:
, and
. Classes can be combined for various effects as you need.
html
class
object-fit-sm-contain border rounded
class
object-fit-md-contain border rounded
class
object-fit-lg-contain border rounded
class
object-fit-xl-contain border rounded
class
object-fit-xxl-contain border rounded
Video
.object-fit-{value}
and responsive
.object-fit-{breakpoint}-{value}
utilities also work on
<video>
elements.
video
class
object-fit-contain
autoplay
video
video
class
object-fit-cover
autoplay
video
video
class
object-fit-fill
autoplay
video
video
class
object-fit-scale
autoplay
video
video
class
object-fit-none
autoplay
video
Sass utilities API
Object fit utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"object-fit"
responsive
true
property
object-fit
values
contain
contain
cover
cover
fill
fill
scale
scale-down
none
none


--- 069_utilities_api.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/api
--------------------------------------------------
official Sass docs
to get started.
$utilities
map contains all our utilities and is later merged with your custom
$utilities
map, if present. The utility map contains a keyed list of utility groups which accept the following options:
Option
Type
Default value
Description
property
Required
Name of the property, this can be a string or an array of strings (e.g., horizontal paddings or margins).
values
Required
List of values, or a map if you don’t want the class name to be the same as the value. If
null
is used as map key,
class
is not prepended to the class name.
class
Optional
null
Name of the generated class. If not provided and
property
is an array of strings,
class
will default to the first element of the
property
array. If not provided and
property
is a string, the
values
keys are used for the
class
names.
css-var
Optional
false
Boolean to generate CSS variables instead of CSS rules.
css-variable-name
Optional
null
Custom un-prefixed name for the CSS variable inside the ruleset.
local-vars
Optional
null
Map of local CSS variables to generate in addition to the CSS rules.
state
Optional
null
List of pseudo-class variants (e.g.,
:hover
:focus
) to generate.
responsive
Optional
false
Boolean indicating if responsive classes should be generated.
Optional
false
Boolean to enable
fluid rescaling with RFS
print
Optional
false
Boolean indicating if print classes need to be generated.
Optional
true
Boolean indicating if utility should be kept in RTL.
API explained
All utility variables are added to the
$utilities
variable within our
_utilities.scss
stylesheet. Each group of utilities looks something like this:
$utilities
"opacity"
property
opacity
values
Which outputs the following:
.opacity-0
opacity
.opacity-25
opacity
.opacity-50
opacity
.opacity-75
opacity
.opacity-100
opacity
Property
The required
property
key must be set for any utility, and it must contain a valid CSS property. This property is used in the generated utility’s ruleset. When the
class
key is omitted, it also serves as the default class name. Consider the
text-decoration
utility:
$utilities
"text-decoration"
property
text-decoration
values
none underline line-through
Output:
.text-decoration-none
text-decoration
none
!important
.text-decoration-underline
text-decoration
underline
!important
.text-decoration-line-through
text-decoration
line-through
!important
Values
Use the
values
key to specify which values for the specified
property
should be used in the generated class names and rules. Can be a list or map (set in the utilities or in a Sass variable).
As a list, like with
text-decoration
utilities
values
none underline line-through
As a map, like with
opacity
utilities
values
As a Sass variable that sets the list or map, as in our
position
utilities
values
$position-values
Class
Use the
class
option to change the class prefix used in the compiled CSS. For example, to change from
.opacity-*
.o-*
$utilities
"opacity"
property
opacity
class
values
Output:
.o-0
opacity
!important
.o-25
opacity
!important
.o-50
opacity
!important
.o-75
opacity
!important
.o-100
opacity
!important
class: null
, generates classes for each of the
values
keys:
$utilities
"visibility"
property
visibility
class
null
values
visible
visible
invisible
hidden
Output:
.visible
visibility
visible
!important
.invisible
visibility
hidden
!important
CSS variable utilities
Set the
css-var
boolean option to
true
and the API will generate local CSS variables for the given selector instead of the usual
property: value
rules. Add an optional
css-variable-name
to set a different CSS variable name than the class name.
Consider our
.text-opacity-*
utilities. If we add the
css-variable-name
option, we'll get a custom output.
$utilities
"text-opacity"
css-var
true
css-variable-name
text-alpha
class
text-opacity
values
Output:
.text-opacity-25
--bs-text-alpha
.text-opacity-50
--bs-text-alpha
.text-opacity-75
--bs-text-alpha
.text-opacity-100
--bs-text-alpha
Local CSS variables
Use the
local-vars
option to specify a Sass map that will generate local CSS variables within the utility class’s ruleset. Please note that it may require additional work to consume those local CSS variables in the generated CSS rules. For example, consider our
.bg-*
utilities:
$utilities
"background-color"
property
background-color
class
local-vars
"bg-opacity"
values
map-merge
$utilities-bg-colors
"transparent"
transparent
Output:
.bg-primary
--bs-bg-opacity
background-color
rgba
--bs-primary-rgb
--bs-bg-opacity
!important
States
Use the
state
option to generate pseudo-class variations. Example pseudo-classes are
:hover
:focus
. When a list of states are provided, classnames are created for that pseudo-class. For example, to change opacity on hover, add
state: hover
and you’ll get
.opacity-hover:hover
in your compiled CSS.
Need multiple pseudo-classes? Use a space-separated list of states:
state: hover focus
$utilities
"opacity"
property
opacity
class
opacity
state
hover
values
Output:
.opacity-0-hover:hover
opacity
!important
.opacity-25-hover:hover
opacity
!important
.opacity-50-hover:hover
opacity
!important
.opacity-75-hover:hover
opacity
!important
.opacity-100-hover:hover
opacity
!important
Responsive
Add the
responsive
boolean to generate responsive utilities (e.g.,
.opacity-md-25
) across
all breakpoints
$utilities
"opacity"
property
opacity
responsive
true
values
Output:
.opacity-0
opacity
!important
.opacity-25
opacity
!important
.opacity-50
opacity
!important
.opacity-75
opacity
!important
.opacity-100
opacity
!important
@media
min-width
576px
.opacity-sm-0
opacity
!important
.opacity-sm-25
opacity
!important
.opacity-sm-50
opacity
!important
.opacity-sm-75
opacity
!important
.opacity-sm-100
opacity
!important
@media
min-width
768px
.opacity-md-0
opacity
!important
.opacity-md-25
opacity
!important
.opacity-md-50
opacity
!important
.opacity-md-75
opacity
!important
.opacity-md-100
opacity
!important
@media
min-width
992px
.opacity-lg-0
opacity
!important
.opacity-lg-25
opacity
!important
.opacity-lg-50
opacity
!important
.opacity-lg-75
opacity
!important
.opacity-lg-100
opacity
!important
@media
min-width
1200px
.opacity-xl-0
opacity
!important
.opacity-xl-25
opacity
!important
.opacity-xl-50
opacity
!important
.opacity-xl-75
opacity
!important
.opacity-xl-100
opacity
!important
@media
min-width
1400px
.opacity-xxl-0
opacity
!important
.opacity-xxl-25
opacity
!important
.opacity-xxl-50
opacity
!important
.opacity-xxl-75
opacity
!important
.opacity-xxl-100
opacity
!important
Print
Enabling the
print
option will
also
generate utility classes for print, which are only applied within the
@media print { ... }
media query.
$utilities
"opacity"
property
opacity
print
true
values
Output:
.opacity-0
opacity
!important
.opacity-25
opacity
!important
.opacity-50
opacity
!important
.opacity-75
opacity
!important
.opacity-100
opacity
!important
@media
print
.opacity-print-0
opacity
!important
.opacity-print-25
opacity
!important
.opacity-print-50
opacity
!important
.opacity-print-75
opacity
!important
.opacity-print-100
opacity
!important
Importance
All utilities generated by the API include
!important
to ensure they override components and modifier classes as intended. You can toggle this setting globally with the
$enable-important-utilities
variable (defaults to
true
Using the API
Now that you’re familiar with how the utilities API works, learn how to add your own custom classes and modify our default utilities.
Override utilities
Override existing utilities by using the same key. For example, if you want additional responsive overflow utility classes, you can do this:
$utilities
"overflow"
responsive
true
property
overflow
values
visible hidden scroll auto
Add utilities
New utilities can be added to the default
$utilities
map with a
map-merge
. Make sure our required Sass files and
_utilities.scss
are imported first, then use the
map-merge
to add your additional utilities. For example, here’s how to add a responsive
cursor
utility with three values.
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
"cursor"
property
cursor
class
cursor
responsive
true
values
auto pointer grab
@import
"bootstrap/scss/utilities/api"
Modify utilities
Modify existing utilities in the default
$utilities
map with
map-get
map-merge
functions. In the example below, we’re adding an additional value to the
width
utilities. Start with an initial
map-merge
and then specify which utility you want to modify. From there, fetch the nested
"width"
map with
map-get
to access and modify the utility’s options and values.
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
"width"
map-merge
map-get
$utilities
"width"
values
map-merge
map-get
map-get
$utilities
"width"
"values"
@import
"bootstrap/scss/utilities/api"
Enable responsive
You can enable responsive classes for an existing set of utilities that are not currently responsive by default. For example, to make the
border
classes responsive:
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
"border"
map-merge
map-get
$utilities
"border"
responsive
true
@import
"bootstrap/scss/utilities/api"
This will now generate responsive variations of
.border
.border-0
for each breakpoint. Your generated CSS will look like this:
.border
.border-0
@media
min-width
576px
.border-sm
.border-sm-0
@media
min-width
768px
.border-md
.border-md-0
@media
min-width
992px
.border-lg
.border-lg-0
@media
min-width
1200px
.border-xl
.border-xl-0
@media
min-width
1400px
.border-xxl
.border-xxl-0
Rename utilities
Missing v4 utilities, or used to another naming convention? The utilities API can be used to override the resulting
class
of a given utility—for example, to rename
.ms-*
utilities to oldish
.ml-*
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
"margin-start"
map-merge
map-get
$utilities
"margin-start"
class
@import
"bootstrap/scss/utilities/api"
Remove utilities
Remove any of the default utilities with the
map-remove()
Sass function
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
// Remove multiple utilities with a comma-separated list
$utilities
map-remove
$utilities
"width"
"float"
@import
"bootstrap/scss/utilities/api"
You can also use the
map-merge()
Sass function
and set the group key to
null
to remove the utility.
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
"width"
null
@import
"bootstrap/scss/utilities/api"
Add, remove, modify
You can add, remove, and modify many utilities all at once with the
map-merge()
Sass function
. Here’s how you can combine the previous examples into one larger map.
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$utilities
map-merge
$utilities
// Remove the `width` utility
"width"
null
// Make an existing utility responsive
"border"
map-merge
map-get
$utilities
"border"
responsive
true
// Add new utilities
"cursor"
property
cursor
class
cursor
responsive
true
values
auto pointer grab
@import
"bootstrap/scss/utilities/api"
Remove utility in RTL
Some edge cases make
RTL styling difficult
, such as line breaks in Arabic. Thus utilities can be dropped from RTL output by setting the
option to
false
$utilities
"word-wrap"
property
word-wrap word-break
class
text
values
break
break-word
false
Output:
/* rtl:begin:remove */
.text-break
word-wrap
break-word
!important
word-break
break-word
!important
/* rtl:end:remove */
This doesn’t output anything in RTL, thanks to
the RTLCSS
remove
control directive


--- 083_utilities_colors.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/colors
--------------------------------------------------
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Colors
Colorize text with color utilities. If you want to colorize links, you can use the
.link-*
helper classes
which have
:hover
:focus
states.
Color utilities like
.text-*
that generated from our original
$theme-colors
Sass map don’t yet respond to color modes, however, any
.text-*-emphasis
utility will. This will be resolved in v6.
.text-primary
.text-primary-emphasis
.text-secondary
.text-secondary-emphasis
.text-success
.text-success-emphasis
.text-danger
.text-danger-emphasis
.text-warning
.text-warning-emphasis
.text-info
.text-info-emphasis
.text-light
.text-light-emphasis
.text-dark
.text-dark-emphasis
.text-body
.text-body-emphasis
.text-body-secondary
.text-body-tertiary
.text-black
.text-white
.text-black-50
.text-white-50
html
class
text-primary
.text-primary
class
text-primary-emphasis
.text-primary-emphasis
class
text-secondary
.text-secondary
class
text-secondary-emphasis
.text-secondary-emphasis
class
text-success
.text-success
class
text-success-emphasis
.text-success-emphasis
class
text-danger
.text-danger
class
text-danger-emphasis
.text-danger-emphasis
class
text-warning bg-dark
.text-warning
class
text-warning-emphasis
.text-warning-emphasis
class
text-info bg-dark
.text-info
class
text-info-emphasis
.text-info-emphasis
class
text-light bg-dark
.text-light
class
text-light-emphasis
.text-light-emphasis
class
text-dark bg-white
.text-dark
class
text-dark-emphasis
.text-dark-emphasis
class
text-body
.text-body
class
text-body-emphasis
.text-body-emphasis
class
text-body-secondary
.text-body-secondary
class
text-body-tertiary
.text-body-tertiary
class
text-black bg-white
.text-black
class
text-white bg-dark
.text-white
class
text-black-50 bg-white
.text-black-50
class
text-white-50 bg-dark
.text-white-50
Deprecation:
With the addition of
.text-opacity-*
utilities and CSS variables for text utilities,
.text-black-50
.text-white-50
are deprecated as of v5.1.0. They’ll be removed in v6.0.0.
Deprecation:
With the addition of the expanded theme colors and variables, the
.text-muted
utility has been deprecated as of v5.3.0. Its default value has also been reassigned to the new
--bs-secondary-color
CSS variable to better support color modes. It will be removed in v6.0.0.
Opacity
Added in v5.1.0
As of v5.1.0, text color utilities are generated with Sass using CSS variables. This allows for real-time color changes without compilation and dynamic alpha transparency changes.
How it works
Consider our default
.text-primary
utility.
.text-primary
--bs-text-opacity
color
rgba
--bs-primary-rgb
--bs-text-opacity
!important
We use an RGB version of our
--bs-primary
(with the value of
13, 110, 253
) CSS variable and attached a second CSS variable,
--bs-text-opacity
, for the alpha transparency (with a default value
thanks to a local CSS variable). That means anytime you use
.text-primary
now, your computed
color
value is
rgba(13, 110, 253, 1)
. The local CSS variable inside each
.text-*
class avoids inheritance issues so nested instances of the utilities don’t automatically have a modified alpha transparency.
Example
To change that opacity, override
--bs-text-opacity
via custom styles or inline styles.
This is default primary text
This is 50% opacity primary text
html
class
text-primary
This is default primary text
class
text-primary
style
--bs-text-opacity
This is 50% opacity primary text
Or, choose from any of the
.text-opacity
utilities:
This is default primary text
This is 75% opacity primary text
This is 50% opacity primary text
This is 25% opacity primary text
html
class
text-primary
This is default primary text
class
text-primary text-opacity-75
This is 75% opacity primary text
class
text-primary text-opacity-50
This is 50% opacity primary text
class
text-primary text-opacity-25
This is 25% opacity primary text
Specificity
Sometimes contextual classes cannot be applied due to the specificity of another selector. In some cases, a sufficient workaround is to wrap your element’s content in a
<div>
or more semantic element with the desired class.
In addition to the following Sass functionality, consider reading about our included
CSS custom properties
(aka CSS variables) for colors and more.
Sass variables
Most
color
utilities are generated by our theme colors, reassigned from our generic color palette variables.
scss/_variables.scss
$blue
#0d6efd
$indigo
#6610f2
$purple
#6f42c1
$pink
#d63384
$red
#dc3545
$orange
#fd7e14
$yellow
#ffc107
$green
#198754
$teal
#20c997
$cyan
#0dcaf0
scss/_variables.scss
$primary
$blue
$secondary
$gray-600
$success
$green
$info
$cyan
$warning
$yellow
$danger
$red
$light
$gray-100
$dark
$gray-900
Grayscale colors are also available, but only a subset are used to generate any utilities.
scss/_variables.scss
$white
#fff
$gray-100
#f8f9fa
$gray-200
#e9ecef
$gray-300
#dee2e6
$gray-400
#ced4da
$gray-500
#adb5bd
$gray-600
#6c757d
$gray-700
#495057
$gray-800
#343a40
$gray-900
#212529
$black
#000
scss/_maps.scss
$theme-colors-text
"primary"
$primary-text-emphasis
"secondary"
$secondary-text-emphasis
"success"
$success-text-emphasis
"info"
$info-text-emphasis
"warning"
$warning-text-emphasis
"danger"
$danger-text-emphasis
"light"
$light-text-emphasis
"dark"
$dark-text-emphasis
Variables for setting colors in
.text-*-emphasis
utilities in light and dark mode:
scss/_variables.scss
$primary-text-emphasis
shade-color
$primary
$secondary-text-emphasis
shade-color
$secondary
$success-text-emphasis
shade-color
$success
$info-text-emphasis
shade-color
$info
$warning-text-emphasis
shade-color
$warning
$danger-text-emphasis
shade-color
$danger
$light-text-emphasis
$gray-700
$dark-text-emphasis
$gray-700
scss/_variables-dark.scss
$primary-text-emphasis-dark
tint-color
$primary
$secondary-text-emphasis-dark
tint-color
$secondary
$success-text-emphasis-dark
tint-color
$success
$info-text-emphasis-dark
tint-color
$info
$warning-text-emphasis-dark
tint-color
$warning
$danger-text-emphasis-dark
tint-color
$danger
$light-text-emphasis-dark
$gray-100
$dark-text-emphasis-dark
$gray-300
Sass maps
Theme colors are then put into a Sass map so we can loop over them to generate our utilities, component modifiers, and more.
scss/_variables.scss
$theme-colors
"primary"
$primary
"secondary"
$secondary
"success"
$success
"info"
$info
"warning"
$warning
"danger"
$danger
"light"
$light
"dark"
$dark
Grayscale colors are also available as a Sass map.
This map is not used to generate any utilities.
scss/_variables.scss
$grays
"100"
$gray-100
"200"
$gray-200
"300"
$gray-300
"400"
$gray-400
"500"
$gray-500
"600"
$gray-600
"700"
$gray-700
"800"
$gray-800
"900"
$gray-900
RGB colors are generated from a separate Sass map:
scss/_maps.scss
$theme-colors-rgb
map-loop
$theme-colors
to-rgb
"$value"
Color opacities build on that with their own map that’s consumed by the utilities API:
scss/_maps.scss
$utilities-text
map-merge
$utilities-colors
"black"
to-rgb
$black
"white"
to-rgb
$white
"body"
to-rgb
$body-color
$utilities-text-colors
map-loop
$utilities-text
rgba-css-var
"$key"
"text"
$utilities-text-emphasis-colors
"primary-emphasis"
#{$prefix}
primary-text-emphasis
"secondary-emphasis"
#{$prefix}
secondary-text-emphasis
"success-emphasis"
#{$prefix}
success-text-emphasis
"info-emphasis"
#{$prefix}
info-text-emphasis
"warning-emphasis"
#{$prefix}
warning-text-emphasis
"danger-emphasis"
#{$prefix}
danger-text-emphasis
"light-emphasis"
#{$prefix}
light-text-emphasis
"dark-emphasis"
#{$prefix}
dark-text-emphasis
Color mode adaptive text colors are also available as a Sass map:
scss/_maps.scss
$theme-colors-text
"primary"
$primary-text-emphasis
"secondary"
$secondary-text-emphasis
"success"
$success-text-emphasis
"info"
$info-text-emphasis
"warning"
$warning-text-emphasis
"danger"
$danger-text-emphasis
"light"
$light-text-emphasis
"dark"
$dark-text-emphasis
scss/_maps.scss
$theme-colors-text-dark
"primary"
$primary-text-emphasis-dark
"secondary"
$secondary-text-emphasis-dark
"success"
$success-text-emphasis-dark
"info"
$info-text-emphasis-dark
"warning"
$warning-text-emphasis-dark
"danger"
$danger-text-emphasis-dark
"light"
$light-text-emphasis-dark
"dark"
$dark-text-emphasis-dark
Sass utilities API
Color utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"color"
property
color
class
text
local-vars
"text-opacity"
values
map-merge
$utilities-text-colors
"muted"
#{$prefix}
secondary-color
// deprecated
"black-50"
rgba
$black
// deprecated
"white-50"
rgba
$white
// deprecated
"body-secondary"
#{$prefix}
secondary-color
"body-tertiary"
#{$prefix}
tertiary-color
"body-emphasis"
#{$prefix}
emphasis-color
"reset"
inherit
"text-opacity"
css-var
true
class
text-opacity
values
"text-color"
property
color
class
text
values
$utilities-text-emphasis-colors


--- 087_utilities_link.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/link
--------------------------------------------------
Link opacity
Change the alpha opacity of the link
rgba()
color value with utilities. Please be aware that changes to a color’s opacity can lead to links with
insufficient
contrast
Link opacity 10
Link opacity 25
Link opacity 50
Link opacity 75
Link opacity 100
html
class
link-opacity-10
href
Link opacity 10
class
link-opacity-25
href
Link opacity 25
class
link-opacity-50
href
Link opacity 50
class
link-opacity-75
href
Link opacity 75
class
link-opacity-100
href
Link opacity 100
You can even change the opacity level on hover.
Link hover opacity 10
Link hover opacity 25
Link hover opacity 50
Link hover opacity 75
Link hover opacity 100
html
class
link-opacity-10-hover
href
Link hover opacity 10
class
link-opacity-25-hover
href
Link hover opacity 25
class
link-opacity-50-hover
href
Link hover opacity 50
class
link-opacity-75-hover
href
Link hover opacity 75
class
link-opacity-100-hover
href
Link hover opacity 100
Link underlines
Underline color
Change the underline’s color independent of the link text color.
Primary underline
Secondary underline
Success underline
Danger underline
Warning underline
Info underline
Light underline
Dark underline
html
href
class
link-underline-primary
Primary underline
href
class
link-underline-secondary
Secondary underline
href
class
link-underline-success
Success underline
href
class
link-underline-danger
Danger underline
href
class
link-underline-warning
Warning underline
href
class
link-underline-info
Info underline
href
class
link-underline-light
Light underline
href
class
link-underline-dark
Dark underline
Underline offset
Change the underline’s distance from your text. Offset is set in
units to automatically scale with the element’s current
font-size
Default link
Offset 1 link
Offset 2 link
Offset 3 link
html
href
Default link
class
link-offset-1
href
Offset 1 link
class
link-offset-2
href
Offset 2 link
class
link-offset-3
href
Offset 3 link
Underline opacity
Change the underline’s opacity. Requires adding
.link-underline
to first set an
rgba()
color we use to then modify the alpha opacity.
Underline opacity 0
Underline opacity 10
Underline opacity 25
Underline opacity 50
Underline opacity 75
Underline opacity 100
html
class
link-offset-2 link-underline link-underline-opacity-0
href
Underline opacity 0
class
link-offset-2 link-underline link-underline-opacity-10
href
Underline opacity 10
class
link-offset-2 link-underline link-underline-opacity-25
href
Underline opacity 25
class
link-offset-2 link-underline link-underline-opacity-50
href
Underline opacity 50
class
link-offset-2 link-underline link-underline-opacity-75
href
Underline opacity 75
class
link-offset-2 link-underline link-underline-opacity-100
href
Underline opacity 100
Hover variants
Just like the
.link-opacity-*-hover
utilities,
.link-offset
.link-underline-opacity
utilities include
:hover
variants by default. Mix and match to create unique link styles.
Underline opacity 0
html
class
link-offset-2 link-offset-3-hover link-underline link-underline-opacity-0 link-underline-opacity-75-hover
href
Underline opacity 0
Colored links
Colored link helpers
have been updated to pair with our link utilities. Use the new utilities to modify the link opacity, underline opacity, and underline offset.
Primary link
Secondary link
Success link
Danger link
Warning link
Info link
Light link
Dark link
Emphasis link
html
href
class
link-primary link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Primary link
href
class
link-secondary link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Secondary link
href
class
link-success link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Success link
href
class
link-danger link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Danger link
href
class
link-warning link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Warning link
href
class
link-info link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Info link
href
class
link-light link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Light link
href
class
link-dark link-offset-2 link-underline-opacity-25 link-underline-opacity-100-hover
Dark link
href
class
link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover
Emphasis link
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
In addition to the following Sass functionality, consider reading about our included
CSS custom properties
(aka CSS variables) for colors and more.
Sass utilities API
Link utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"link-opacity"
css-var
true
class
link-opacity
state
hover
values
"link-offset"
property
text-underline-offset
class
link-offset
state
hover
values
.125em
.25em
.375em
"link-underline"
property
text-decoration-color
class
link-underline
local-vars
"link-underline-opacity"
values
map-merge
$utilities-links-underline
null
rgba
#{$prefix}
link-color-rgb
#{$prefix}
link-underline-opacity
"link-underline-opacity"
css-var
true
class
link-underline-opacity
state
hover
values


--- 091_utilities_interactions.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/interactions
--------------------------------------------------
Text selection
Change the way in which the content is selected when the user interacts with it.
This paragraph will be entirely selected when clicked by the user.
This paragraph has default select behavior.
This paragraph will not be selectable when clicked by the user.
html
class
user-select-all
This paragraph will be entirely selected when clicked by the user.
class
user-select-auto
This paragraph has default select behavior.
class
user-select-none
This paragraph will not be selectable when clicked by the user.
Pointer events
.pe-none
.pe-auto
classes to prevent or add element interactions.
This link
can not be clicked.
This link
can be clicked (this is default behavior).
This link
can not be clicked because the
pointer-events
property is inherited from its parent. However,
this link
has a
pe-auto
class and can be clicked.
html
href
class
pe-none
tabindex
aria-disabled
true
This link
can not be clicked.
href
class
pe-auto
This link
can be clicked (this is default behavior).
class
pe-none
href
tabindex
aria-disabled
true
This link
can not be clicked because the
code
pointer-events
code
property is inherited from its parent. However,
href
class
pe-auto
this link
has a
code
pe-auto
code
class and can be clicked.
.pe-none
class (and the
pointer-events
CSS property it sets) only prevents interactions with a pointer (mouse, stylus, touch). Links and controls with
.pe-none
are, by default, still focusable and actionable for keyboard users. To ensure that they are completely neutralized even for keyboard users, you may need to add further attributes such as
tabindex="-1"
(to prevent them from receiving keyboard focus) and
aria-disabled="true"
(to convey the fact they are effectively disabled to assistive technologies), and possibly use JavaScript to completely prevent them from being actionable.
If possible, the simpler solution is:
For form controls, add the
disabled
HTML attribute.
For links, remove the
href
attribute, making it a non-interactive anchor or placeholder link.
Sass utilities API
Interaction utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"user-select"
property
user-select
values
all auto none
"pointer-events"
property
pointer-events
class
values
none auto


--- 098_utilities_flex.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/flex
--------------------------------------------------
Enable flex behaviors
Apply
display
utilities to create a flexbox container and transform
direct children elements
into flex items. Flex containers and items are able to be modified further with additional flex properties.
I'm a flexbox container!
html
class
d-flex p-2
I'm a flexbox container!
I'm an inline flexbox container!
html
class
d-inline-flex p-2
I'm an inline flexbox container!
Responsive variations also exist for
.d-flex
.d-inline-flex
.d-flex
.d-inline-flex
.d-sm-flex
.d-sm-inline-flex
.d-md-flex
.d-md-inline-flex
.d-lg-flex
.d-lg-inline-flex
.d-xl-flex
.d-xl-inline-flex
.d-xxl-flex
.d-xxl-inline-flex
Direction
Set the direction of flex items in a flex container with direction utilities. In most cases you can omit the horizontal class here as the browser default is
. However, you may encounter situations where you needed to explicitly set this value (like responsive layouts).
.flex-row
to set a horizontal direction (the browser default), or
.flex-row-reverse
to start the horizontal direction from the opposite side.
Flex item 1
Flex item 2
Flex item 3
Flex item 1
Flex item 2
Flex item 3
html
class
d-flex flex-row mb-3
class
Flex item 1
class
Flex item 2
class
Flex item 3
class
d-flex flex-row-reverse
class
Flex item 1
class
Flex item 2
class
Flex item 3
.flex-column
to set a vertical direction, or
.flex-column-reverse
to start the vertical direction from the opposite side.
Flex item 1
Flex item 2
Flex item 3
Flex item 1
Flex item 2
Flex item 3
html
class
d-flex flex-column mb-3
class
Flex item 1
class
Flex item 2
class
Flex item 3
class
d-flex flex-column-reverse
class
Flex item 1
class
Flex item 2
class
Flex item 3
Responsive variations also exist for
flex-direction
.flex-row
.flex-row-reverse
.flex-column
.flex-column-reverse
.flex-sm-row
.flex-sm-row-reverse
.flex-sm-column
.flex-sm-column-reverse
.flex-md-row
.flex-md-row-reverse
.flex-md-column
.flex-md-column-reverse
.flex-lg-row
.flex-lg-row-reverse
.flex-lg-column
.flex-lg-column-reverse
.flex-xl-row
.flex-xl-row-reverse
.flex-xl-column
.flex-xl-column-reverse
.flex-xxl-row
.flex-xxl-row-reverse
.flex-xxl-column
.flex-xxl-column-reverse
Justify content
justify-content
utilities on flexbox containers to change the alignment of flex items on the main axis (the x-axis to start, y-axis if
flex-direction: column
). Choose from
start
(browser default),
center
between
around
, or
evenly
Justify
Content
Start
Justify
Content
Justify
Content
Center
Justify
Content
Between
Justify
Content
Around
Justify
Content
Evenly
class
d-flex justify-content-start
class
d-flex justify-content-end
class
d-flex justify-content-center
class
d-flex justify-content-between
class
d-flex justify-content-around
class
d-flex justify-content-evenly
Responsive variations also exist for
justify-content
.justify-content-start
.justify-content-end
.justify-content-center
.justify-content-between
.justify-content-around
.justify-content-evenly
.justify-content-sm-start
.justify-content-sm-end
.justify-content-sm-center
.justify-content-sm-between
.justify-content-sm-around
.justify-content-sm-evenly
.justify-content-md-start
.justify-content-md-end
.justify-content-md-center
.justify-content-md-between
.justify-content-md-around
.justify-content-md-evenly
.justify-content-lg-start
.justify-content-lg-end
.justify-content-lg-center
.justify-content-lg-between
.justify-content-lg-around
.justify-content-lg-evenly
.justify-content-xl-start
.justify-content-xl-end
.justify-content-xl-center
.justify-content-xl-between
.justify-content-xl-around
.justify-content-xl-evenly
.justify-content-xxl-start
.justify-content-xxl-end
.justify-content-xxl-center
.justify-content-xxl-between
.justify-content-xxl-around
.justify-content-xxl-evenly
Align items
align-items
utilities on flexbox containers to change the alignment of flex items on the cross axis (the y-axis to start, x-axis if
flex-direction: column
). Choose from
start
center
baseline
, or
stretch
(browser default).
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-items-start
class
d-flex align-items-end
class
d-flex align-items-center
class
d-flex align-items-baseline
class
d-flex align-items-stretch
Responsive variations also exist for
align-items
.align-items-start
.align-items-end
.align-items-center
.align-items-baseline
.align-items-stretch
.align-items-sm-start
.align-items-sm-end
.align-items-sm-center
.align-items-sm-baseline
.align-items-sm-stretch
.align-items-md-start
.align-items-md-end
.align-items-md-center
.align-items-md-baseline
.align-items-md-stretch
.align-items-lg-start
.align-items-lg-end
.align-items-lg-center
.align-items-lg-baseline
.align-items-lg-stretch
.align-items-xl-start
.align-items-xl-end
.align-items-xl-center
.align-items-xl-baseline
.align-items-xl-stretch
.align-items-xxl-start
.align-items-xxl-end
.align-items-xxl-center
.align-items-xxl-baseline
.align-items-xxl-stretch
Align self
align-self
utilities on flexbox items to individually change their alignment on the cross axis (the y-axis to start, x-axis if
flex-direction: column
). Choose from the same options as
align-items
start
center
baseline
, or
stretch
(browser default).
Flex item
Aligned flex item
Flex item
Flex item
Aligned flex item
Flex item
Flex item
Aligned flex item
Flex item
Flex item
Aligned flex item
Flex item
Flex item
Aligned flex item
Flex item
class
align-self-start
Aligned flex item
class
align-self-end
Aligned flex item
class
align-self-center
Aligned flex item
class
align-self-baseline
Aligned flex item
class
align-self-stretch
Aligned flex item
Responsive variations also exist for
align-self
.align-self-start
.align-self-end
.align-self-center
.align-self-baseline
.align-self-stretch
.align-self-sm-start
.align-self-sm-end
.align-self-sm-center
.align-self-sm-baseline
.align-self-sm-stretch
.align-self-md-start
.align-self-md-end
.align-self-md-center
.align-self-md-baseline
.align-self-md-stretch
.align-self-lg-start
.align-self-lg-end
.align-self-lg-center
.align-self-lg-baseline
.align-self-lg-stretch
.align-self-xl-start
.align-self-xl-end
.align-self-xl-center
.align-self-xl-baseline
.align-self-xl-stretch
.align-self-xxl-start
.align-self-xxl-end
.align-self-xxl-center
.align-self-xxl-baseline
.align-self-xxl-stretch
Fill
Use the
.flex-fill
class on a series of sibling elements to force them into widths equal to their content (or equal widths if their content does not surpass their border-boxes) while taking up all available horizontal space.
Flex item with a lot of content
Flex item
Flex item
html
class
d-flex
class
p-2 flex-fill
Flex item with a lot of content
class
p-2 flex-fill
Flex item
class
p-2 flex-fill
Flex item
Responsive variations also exist for
flex-fill
.flex-fill
.flex-sm-fill
.flex-md-fill
.flex-lg-fill
.flex-xl-fill
.flex-xxl-fill
Grow and shrink
.flex-grow-*
utilities to toggle a flex item’s ability to grow to fill available space. In the example below, the
.flex-grow-1
elements uses all available space it can, while allowing the remaining two flex items their necessary space.
Flex item
Flex item
Third flex item
html
class
d-flex
class
p-2 flex-grow-1
Flex item
class
Flex item
class
Third flex item
.flex-shrink-*
utilities to toggle a flex item’s ability to shrink if necessary. In the example below, the second flex item with
.flex-shrink-1
is forced to wrap its contents to a new line, “shrinking” to allow more space for the previous flex item with
.w-100
Flex item
Flex item
html
class
d-flex
class
p-2 w-100
Flex item
class
p-2 flex-shrink-1
Flex item
Responsive variations also exist for
flex-grow
flex-shrink
.flex-{grow|shrink}-0
.flex-{grow|shrink}-1
.flex-sm-{grow|shrink}-0
.flex-sm-{grow|shrink}-1
.flex-md-{grow|shrink}-0
.flex-md-{grow|shrink}-1
.flex-lg-{grow|shrink}-0
.flex-lg-{grow|shrink}-1
.flex-xl-{grow|shrink}-0
.flex-xl-{grow|shrink}-1
.flex-xxl-{grow|shrink}-0
.flex-xxl-{grow|shrink}-1
Auto margins
Flexbox can do some pretty awesome things when you mix flex alignments with auto margins. Shown below are three examples of controlling flex items via auto margins: default (no auto margin), pushing two items to the right (
.me-auto
), and pushing two items to the left (
.ms-auto
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
html
class
d-flex mb-3
class
Flex item
class
Flex item
class
Flex item
class
d-flex mb-3
class
me-auto p-2
Flex item
class
Flex item
class
Flex item
class
d-flex mb-3
class
Flex item
class
Flex item
class
ms-auto p-2
Flex item
With align-items
Vertically move one flex item to the top or bottom of a container by mixing
align-items
flex-direction: column
, and
margin-top: auto
margin-bottom: auto
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
html
class
d-flex align-items-start flex-column mb-3
style
height
200px
class
mb-auto p-2
Flex item
class
Flex item
class
Flex item
class
d-flex align-items-end flex-column mb-3
style
height
200px
class
Flex item
class
Flex item
class
mt-auto p-2
Flex item
Wrap
Change how flex items wrap in a flex container. Choose from no wrapping at all (the browser default) with
.flex-nowrap
, wrapping with
.flex-wrap
, or reverse wrapping with
.flex-wrap-reverse
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex flex-nowrap
Flex item 1
Flex item 2
Flex item 3
Flex item 4
Flex item 5
Flex item 6
Flex item 7
Flex item 8
Flex item 9
Flex item 10
Flex item 11
Flex item 12
Flex item 13
Flex item 14
class
d-flex flex-wrap
Flex item 1
Flex item 2
Flex item 3
Flex item 4
Flex item 5
Flex item 6
Flex item 7
Flex item 8
Flex item 9
Flex item 10
Flex item 11
Flex item 12
Flex item 13
Flex item 14
class
d-flex flex-wrap-reverse
Responsive variations also exist for
flex-wrap
.flex-nowrap
.flex-wrap
.flex-wrap-reverse
.flex-sm-nowrap
.flex-sm-wrap
.flex-sm-wrap-reverse
.flex-md-nowrap
.flex-md-wrap
.flex-md-wrap-reverse
.flex-lg-nowrap
.flex-lg-wrap
.flex-lg-wrap-reverse
.flex-xl-nowrap
.flex-xl-wrap
.flex-xl-wrap-reverse
.flex-xxl-nowrap
.flex-xxl-wrap
.flex-xxl-wrap-reverse
Order
Change the
visual
order of specific flex items with a handful of
order
utilities. We only provide options for making an item first or last, as well as a reset to use the DOM order. As
order
takes any integer value from 0 to 5, add custom CSS for any additional values needed.
First flex item
Second flex item
Third flex item
html
class
d-flex flex-nowrap
class
order-3 p-2
First flex item
class
order-2 p-2
Second flex item
class
order-1 p-2
Third flex item
Responsive variations also exist for
order
.order-0
.order-1
.order-2
.order-3
.order-4
.order-5
.order-sm-0
.order-sm-1
.order-sm-2
.order-sm-3
.order-sm-4
.order-sm-5
.order-md-0
.order-md-1
.order-md-2
.order-md-3
.order-md-4
.order-md-5
.order-lg-0
.order-lg-1
.order-lg-2
.order-lg-3
.order-lg-4
.order-lg-5
.order-xl-0
.order-xl-1
.order-xl-2
.order-xl-3
.order-xl-4
.order-xl-5
.order-xxl-0
.order-xxl-1
.order-xxl-2
.order-xxl-3
.order-xxl-4
.order-xxl-5
Additionally there are also responsive
.order-first
.order-last
classes that change the
order
of an element by applying
order: -1
order: 6
, respectively.
.order-first
.order-last
.order-sm-first
.order-sm-last
.order-md-first
.order-md-last
.order-lg-first
.order-lg-last
.order-xl-first
.order-xl-last
.order-xxl-first
.order-xxl-last
Align content
align-content
utilities on flexbox containers to align flex items
together
on the cross axis. Choose from
start
(browser default),
center
between
around
, or
stretch
. To demonstrate these utilities, we’ve enforced
flex-wrap: wrap
and increased the number of flex items.
Heads up!
This property has no effect on single rows of flex items.
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-start flex-wrap
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-end flex-wrap
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-center flex-wrap
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-between flex-wrap
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-around flex-wrap
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
Flex item
class
d-flex align-content-stretch flex-wrap
Responsive variations also exist for
align-content
.align-content-start
.align-content-end
.align-content-center
.align-content-between
.align-content-around
.align-content-stretch
.align-content-sm-start
.align-content-sm-end
.align-content-sm-center
.align-content-sm-between
.align-content-sm-around
.align-content-sm-stretch
.align-content-md-start
.align-content-md-end
.align-content-md-center
.align-content-md-between
.align-content-md-around
.align-content-md-stretch
.align-content-lg-start
.align-content-lg-end
.align-content-lg-center
.align-content-lg-between
.align-content-lg-around
.align-content-lg-stretch
.align-content-xl-start
.align-content-xl-end
.align-content-xl-center
.align-content-xl-between
.align-content-xl-around
.align-content-xl-stretch
.align-content-xxl-start
.align-content-xxl-end
.align-content-xxl-center
.align-content-xxl-between
.align-content-xxl-around
.align-content-xxl-stretch
Media object
Looking to replicate the
media object component
from Bootstrap 4? Recreate it in no time with a few flex utilities that allow even more flexibility and customization than before.
Placeholder
Image
This is some content from a media component. You can replace this with any content and adjust it as needed.
html
class
d-flex
class
flex-shrink-0
class
flex-grow-1 ms-3
This is some content from a media component. You can replace this with any content and adjust it as needed.
And say you want to vertically center the content next to the image:
Placeholder
Image
This is some content from a media component. You can replace this with any content and adjust it as needed.
html
class
d-flex align-items-center
class
flex-shrink-0
class
flex-grow-1 ms-3
This is some content from a media component. You can replace this with any content and adjust it as needed.
Sass utilities API
Flexbox utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"flex"
responsive
true
property
flex
values
fill
1 1 auto
"flex-direction"
responsive
true
property
flex-direction
class
flex
values
row column row-reverse column-reverse
"flex-grow"
responsive
true
property
flex-grow
class
flex
values
grow-0
grow-1
"flex-shrink"
responsive
true
property
flex-shrink
class
flex
values
shrink-0
shrink-1
"flex-wrap"
responsive
true
property
flex-wrap
class
flex
values
wrap nowrap wrap-reverse
"justify-content"
responsive
true
property
justify-content
values
start
flex-start
flex-end
center
center
between
space-between
around
space-around
evenly
space-evenly
"align-items"
responsive
true
property
align-items
values
start
flex-start
flex-end
center
center
baseline
baseline
stretch
stretch
"align-content"
responsive
true
property
align-content
values
start
flex-start
flex-end
center
center
between
space-between
around
space-around
stretch
stretch
"align-self"
responsive
true
property
align-self
values
auto
auto
start
flex-start
flex-end
center
center
baseline
baseline
stretch
stretch
"order"
responsive
true
property
order
values
first
last


--- 101_utilities_background.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/background
--------------------------------------------------
Accessibility tip:
Using color to add meaning only provides a visual indication, which will not be conveyed to users of assistive technologies like screen readers. Please ensure the meaning is obvious from the content itself (e.g., the visible text with a
sufficient
color contrast
) or is included through alternative means, such as additional text hidden with the
.visually-hidden
class.
Background color
Similar to the contextual text color classes, set the background of an element to any contextual class. Background utilities
do not set
color
, so in some cases you’ll want to use
.text-*
color utilities
Background utilities like
.bg-*
that generated from our original
$theme-colors
Sass map don’t yet respond to color modes, however, any
.bg-*-subtle
utility will. This will be resolved in v6.
.bg-primary
.bg-primary-subtle
.bg-secondary
.bg-secondary-subtle
.bg-success
.bg-success-subtle
.bg-danger
.bg-danger-subtle
.bg-warning
.bg-warning-subtle
.bg-info
.bg-info-subtle
.bg-light
.bg-light-subtle
.bg-dark
.bg-dark-subtle
.bg-body-secondary
.bg-body-tertiary
.bg-body
.bg-black
.bg-white
.bg-transparent
html
class
p-3 mb-2 bg-primary text-white
.bg-primary
class
p-3 mb-2 bg-primary-subtle text-primary-emphasis
.bg-primary-subtle
class
p-3 mb-2 bg-secondary text-white
.bg-secondary
class
p-3 mb-2 bg-secondary-subtle text-secondary-emphasis
.bg-secondary-subtle
class
p-3 mb-2 bg-success text-white
.bg-success
class
p-3 mb-2 bg-success-subtle text-success-emphasis
.bg-success-subtle
class
p-3 mb-2 bg-danger text-white
.bg-danger
class
p-3 mb-2 bg-danger-subtle text-danger-emphasis
.bg-danger-subtle
class
p-3 mb-2 bg-warning text-dark
.bg-warning
class
p-3 mb-2 bg-warning-subtle text-warning-emphasis
.bg-warning-subtle
class
p-3 mb-2 bg-info text-dark
.bg-info
class
p-3 mb-2 bg-info-subtle text-info-emphasis
.bg-info-subtle
class
p-3 mb-2 bg-light text-dark
.bg-light
class
p-3 mb-2 bg-light-subtle text-light-emphasis
.bg-light-subtle
class
p-3 mb-2 bg-dark text-white
.bg-dark
class
p-3 mb-2 bg-dark-subtle text-dark-emphasis
.bg-dark-subtle
class
p-3 mb-2 bg-body-secondary
.bg-body-secondary
class
p-3 mb-2 bg-body-tertiary
.bg-body-tertiary
class
p-3 mb-2 bg-body text-body
.bg-body
class
p-3 mb-2 bg-black text-white
.bg-black
class
p-3 mb-2 bg-white text-dark
.bg-white
class
p-3 mb-2 bg-transparent text-body
.bg-transparent
Background gradient
By adding a
.bg-gradient
class, a linear gradient is added as background image to the backgrounds. This gradient starts with a semi-transparent white which fades out to the bottom.
Do you need a gradient in your custom CSS? Just add
background-image: var(--bs-gradient);
.bg-primary.bg-gradient
.bg-secondary.bg-gradient
.bg-success.bg-gradient
.bg-danger.bg-gradient
.bg-warning.bg-gradient
.bg-info.bg-gradient
.bg-light.bg-gradient
.bg-dark.bg-gradient
.bg-black.bg-gradient
Opacity
Added in v5.1.0
As of v5.1.0,
background-color
utilities are generated with Sass using CSS variables. This allows for real-time color changes without compilation and dynamic alpha transparency changes.
How it works
Consider our default
.bg-success
utility.
.bg-success
--bs-bg-opacity
background-color
rgba
--bs-success-rgb
--bs-bg-opacity
!important
We use an RGB version of our
--bs-success
(with the value of
25, 135, 84
) CSS variable and attached a second CSS variable,
--bs-bg-opacity
, for the alpha transparency (with a default value
thanks to a local CSS variable). That means anytime you use
.bg-success
now, your computed
color
value is
rgba(25, 135, 84, 1)
. The local CSS variable inside each
.bg-*
class avoids inheritance issues so nested instances of the utilities don’t automatically have a modified alpha transparency.
Example
To change that opacity, override
--bs-bg-opacity
via custom styles or inline styles.
This is default success background
This is 50% opacity success background
html
class
bg-success p-2 text-white
This is default success background
class
bg-success p-2
style
--bs-bg-opacity
This is 50% opacity success background
Or, choose from any of the
.bg-opacity
utilities:
This is default success background
This is 75% opacity success background
This is 50% opacity success background
This is 25% opacity success background
This is 10% opacity success background
html
class
bg-success p-2 text-white
This is default success background
class
bg-success p-2 text-white bg-opacity-75
This is 75% opacity success background
class
bg-success p-2 text-dark bg-opacity-50
This is 50% opacity success background
class
bg-success p-2 text-dark bg-opacity-25
This is 25% opacity success background
class
bg-success p-2 text-dark bg-opacity-10
This is 10% opacity success background
In addition to the following Sass functionality, consider reading about our included
CSS custom properties
(aka CSS variables) for colors and more.
Sass variables
Most
background-color
utilities are generated by our theme colors, reassigned from our generic color palette variables.
scss/_variables.scss
$blue
#0d6efd
$indigo
#6610f2
$purple
#6f42c1
$pink
#d63384
$red
#dc3545
$orange
#fd7e14
$yellow
#ffc107
$green
#198754
$teal
#20c997
$cyan
#0dcaf0
scss/_variables.scss
$primary
$blue
$secondary
$gray-600
$success
$green
$info
$cyan
$warning
$yellow
$danger
$red
$light
$gray-100
$dark
$gray-900
scss/_variables.scss
$gradient
linear-gradient
180deg
rgba
$white
rgba
$white
Grayscale colors are also available, but only a subset are used to generate any utilities.
scss/_variables.scss
$white
#fff
$gray-100
#f8f9fa
$gray-200
#e9ecef
$gray-300
#dee2e6
$gray-400
#ced4da
$gray-500
#adb5bd
$gray-600
#6c757d
$gray-700
#495057
$gray-800
#343a40
$gray-900
#212529
$black
#000
Variables for setting
background-color
.bg-*-subtle
utilities in light and dark mode:
scss/_variables.scss
$primary-bg-subtle
tint-color
$primary
$secondary-bg-subtle
tint-color
$secondary
$success-bg-subtle
tint-color
$success
$info-bg-subtle
tint-color
$info
$warning-bg-subtle
tint-color
$warning
$danger-bg-subtle
tint-color
$danger
$light-bg-subtle
$gray-100
$white
$dark-bg-subtle
$gray-400
scss/_variables-dark.scss
$primary-bg-subtle-dark
shade-color
$primary
$secondary-bg-subtle-dark
shade-color
$secondary
$success-bg-subtle-dark
shade-color
$success
$info-bg-subtle-dark
shade-color
$info
$warning-bg-subtle-dark
shade-color
$warning
$danger-bg-subtle-dark
shade-color
$danger
$light-bg-subtle-dark
$gray-800
$dark-bg-subtle-dark
$gray-800
$black
Sass maps
Theme colors are then put into a Sass map so we can loop over them to generate our utilities, component modifiers, and more.
scss/_variables.scss
$theme-colors
"primary"
$primary
"secondary"
$secondary
"success"
$success
"info"
$info
"warning"
$warning
"danger"
$danger
"light"
$light
"dark"
$dark
Grayscale colors are also available as a Sass map.
This map is not used to generate any utilities.
scss/_variables.scss
$grays
"100"
$gray-100
"200"
$gray-200
"300"
$gray-300
"400"
$gray-400
"500"
$gray-500
"600"
$gray-600
"700"
$gray-700
"800"
$gray-800
"900"
$gray-900
RGB colors are generated from a separate Sass map:
scss/_maps.scss
$theme-colors-rgb
map-loop
$theme-colors
to-rgb
"$value"
Background color opacities build on that with their own map that’s consumed by the utilities API:
scss/_maps.scss
$utilities-bg
map-merge
$utilities-colors
"black"
to-rgb
$black
"white"
to-rgb
$white
"body"
to-rgb
$body-bg
$utilities-bg-colors
map-loop
$utilities-bg
rgba-css-var
"$key"
"bg"
$utilities-bg-subtle
"primary-subtle"
#{$prefix}
primary-bg-subtle
"secondary-subtle"
#{$prefix}
secondary-bg-subtle
"success-subtle"
#{$prefix}
success-bg-subtle
"info-subtle"
#{$prefix}
info-bg-subtle
"warning-subtle"
#{$prefix}
warning-bg-subtle
"danger-subtle"
#{$prefix}
danger-bg-subtle
"light-subtle"
#{$prefix}
light-bg-subtle
"dark-subtle"
#{$prefix}
dark-bg-subtle
Color mode background colors are also available as a Sass map:
scss/_maps.scss
$theme-colors-bg-subtle
"primary"
$primary-bg-subtle
"secondary"
$secondary-bg-subtle
"success"
$success-bg-subtle
"info"
$info-bg-subtle
"warning"
$warning-bg-subtle
"danger"
$danger-bg-subtle
"light"
$light-bg-subtle
"dark"
$dark-bg-subtle
scss/_maps.scss
$theme-colors-bg-subtle-dark
"primary"
$primary-bg-subtle-dark
"secondary"
$secondary-bg-subtle-dark
"success"
$success-bg-subtle-dark
"info"
$info-bg-subtle-dark
"warning"
$warning-bg-subtle-dark
"danger"
$danger-bg-subtle-dark
"light"
$light-bg-subtle-dark
"dark"
$dark-bg-subtle-dark
Sass mixins
No mixins are used to generate our background utilities
, but we do have some additional mixins for other situations where you’d like to create your own gradients.
scss/mixins/_gradients.scss
@mixin
gradient-bg
$color
null
background-color
$color
$enable-gradients
background-image
#{$prefix}
gradient
scss/mixins/_gradients.scss
// Horizontal gradient, from left to right
// Creates two color stops, start and end, by specifying a color and position for each color stop.
@mixin
gradient-x
$start-color
$gray-700
$end-color
$gray-800
$start-percent
$end-percent
100%
background-image
linear-gradient
to right
$start-color
$start-percent
$end-color
$end-percent
// Vertical gradient, from top to bottom
// Creates two color stops, start and end, by specifying a color and position for each color stop.
@mixin
gradient-y
$start-color
$gray-700
$end-color
$gray-800
$start-percent
null
$end-percent
null
background-image
linear-gradient
to bottom
$start-color
$start-percent
$end-color
$end-percent
@mixin
gradient-directional
$start-color
$gray-700
$end-color
$gray-800
$deg
45deg
background-image
linear-gradient
$deg
$start-color
$end-color
@mixin
gradient-x-three-colors
$start-color
$blue
$mid-color
$purple
$color-stop
$end-color
$red
background-image
linear-gradient
to right
$start-color
$mid-color
$color-stop
$end-color
@mixin
gradient-y-three-colors
$start-color
$blue
$mid-color
$purple
$color-stop
$end-color
$red
background-image
linear-gradient
$start-color
$mid-color
$color-stop
$end-color
@mixin
gradient-radial
$inner-color
$gray-700
$outer-color
$gray-800
background-image
radial-gradient
circle
$inner-color
$outer-color
@mixin
gradient-striped
$color
rgba
$white
$angle
45deg
background-image
linear-gradient
$angle
$color
transparent 25%
transparent 50%
$color
$color
transparent 75%
transparent
Sass utilities API
Background utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"background-color"
property
background-color
class
local-vars
"bg-opacity"
values
map-merge
$utilities-bg-colors
"transparent"
transparent
"body-secondary"
rgba
#{$prefix}
secondary-bg-rgb
#{$prefix}
bg-opacity
"body-tertiary"
rgba
#{$prefix}
tertiary-bg-rgb
#{$prefix}
bg-opacity
"bg-opacity"
css-var
true
class
bg-opacity
values
"subtle-background-color"
property
background-color
class
values
$utilities-bg-subtle


--- 104_utilities_visibility.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/visibility
--------------------------------------------------
Set the
visibility
of elements with our visibility utilities. These utility classes do not modify the
display
value at all and do not affect layout –
.invisible
elements still take up space in the page.
Elements with the
.invisible
class will be hidden
both
visually and for assistive technology/screen reader users.
Apply
.visible
.invisible
as needed.
class
visible
class
invisible
// Class
.visible
visibility
visible
!important
.invisible
visibility
hidden
!important
Sass utilities API
Visibility utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"visibility"
property
visibility
class
null
values
visible
visible
invisible
hidden


--- 107_utilities_vertical-align.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/vertical-align
--------------------------------------------------
Change the alignment of elements with the
vertical-alignment
utilities. Please note that vertical-align only affects inline, inline-block, inline-table, and table cell elements.
Choose from
.align-baseline
.align-top
.align-middle
.align-bottom
.align-text-bottom
, and
.align-text-top
as needed.
To vertically center non-inline content (like
<div>
s and more), use our
flex box utilities
With inline elements:
baseline
middle
bottom
text-top
text-bottom
html
span
class
align-baseline
baseline
span
span
class
align-top
span
span
class
align-middle
middle
span
span
class
align-bottom
bottom
span
span
class
align-text-top
text-top
span
span
class
align-text-bottom
text-bottom
span
With table cells:
baseline
middle
bottom
text-top
text-bottom
html
table
style
height
100px
tbody
class
align-baseline
baseline
class
align-top
class
align-middle
middle
class
align-bottom
bottom
class
align-text-top
text-top
class
align-text-bottom
text-bottom
tbody
table
Sass utilities API
Vertical align utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"align"
property
vertical-align
class
align
values
baseline top middle bottom text-bottom text-top


--- 110_utilities_opacity.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/opacity
--------------------------------------------------
opacity
property sets the opacity level for an element. The opacity level describes the transparency level, where
is not transparent at all,
is 50% visible, and
is completely transparent.
Set the
opacity
of an element using
.opacity-{value}
utilities.
100%
class
opacity-100
class
opacity-75
class
opacity-50
class
opacity-25
class
opacity-0
Sass utilities API
Opacity utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"opacity"
property
opacity
values


--- 122_utilities_display.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/display
--------------------------------------------------
How it works
Change the value of the
display
property
with our responsive display utility classes. We purposely support only a subset of all possible values for
display
. Classes can be combined for various effects as you need.
Notation
Display utility classes that apply to all
breakpoints
, from
, have no breakpoint abbreviation in them. This is because those classes are applied from
min-width: 0;
and up, and thus are not bound by a media query. The remaining breakpoints, however, do include a breakpoint abbreviation.
As such, the classes are named using the format:
.d-{value}
.d-{breakpoint}-{value}
, and
Where
value
is one of:
none
inline
inline-block
block
grid
inline-grid
table
table-cell
table-row
flex
inline-flex
The display values can be altered by changing the
display
values defined in
$utilities
and recompiling the SCSS.
The media queries affect screen widths with the given breakpoint
or larger
. For example,
.d-lg-none
sets
display: none;
, and
screens.
Examples
d-inline
d-inline
html
class
d-inline p-2 text-bg-primary
d-inline
class
d-inline p-2 text-bg-dark
d-inline
d-block
d-block
html
span
class
d-block p-2 text-bg-primary
d-block
span
span
class
d-block p-2 text-bg-dark
d-block
span
Hiding elements
For faster mobile-friendly development, use responsive display classes for showing and hiding elements by device. Avoid creating entirely different versions of the same site, instead hide elements responsively for each screen size.
To hide elements simply use the
.d-none
class or one of the
.d-{sm,md,lg,xl,xxl}-none
classes for any responsive screen variation.
To show an element only on a given interval of screen sizes you can combine one
.d-*-none
class with a
.d-*-*
class, for example
.d-none .d-md-block .d-xl-none
will hide the element for all screen sizes except on medium and large devices.
Screen size
Class
Hidden on all
.d-none
Hidden only on xs
.d-none .d-sm-block
Hidden only on sm
.d-sm-none .d-md-block
Hidden only on md
.d-md-none .d-lg-block
Hidden only on lg
.d-lg-none .d-xl-block
Hidden only on xl
.d-xl-none .d-xxl-block
Hidden only on xxl
.d-xxl-none
Visible on all
.d-block
Visible only on xs
.d-block .d-sm-none
Visible only on sm
.d-none .d-sm-block .d-md-none
Visible only on md
.d-none .d-md-block .d-lg-none
Visible only on lg
.d-none .d-lg-block .d-xl-none
Visible only on xl
.d-none .d-xl-block .d-xxl-none
Visible only on xxl
.d-none .d-xxl-block
hide on lg and wider screens
hide on screens smaller than lg
html
class
d-lg-none
hide on lg and wider screens
class
d-none d-lg-block
hide on screens smaller than lg
Display in print
Change the
display
value of elements when printing with our print display utility classes. Includes support for the same
display
values as our responsive
.d-*
utilities.
.d-print-none
.d-print-inline
.d-print-inline-block
.d-print-block
.d-print-grid
.d-print-inline-grid
.d-print-table
.d-print-table-row
.d-print-table-cell
.d-print-flex
.d-print-inline-flex
The print and display classes can be combined.
Screen Only (Hide on print only)
Print Only (Hide on screen only)
Hide up to large on screen, but always show on print
html
class
d-print-none
Screen Only (Hide on print only)
class
d-none d-print-block
Print Only (Hide on screen only)
class
d-none d-lg-block d-print-block
Hide up to large on screen, but always show on print
Sass utilities API
Display utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"display"
responsive
true
print
true
property
display
class
values
inline inline-block block grid inline-grid table table-row table-cell flex inline-flex none


--- 125_utilities_float.txt ---
URL: https://getbootstrap.com/docs/5.3/utilities/float
--------------------------------------------------
Overview
These utility classes float an element to the left or right, or disable floating, based on the current viewport size using the
float
property
!important
is included to avoid specificity issues. These use the same viewport breakpoints as our grid system. Please be aware float utilities have no effect on flex items.
Float start on all viewport sizes
Float end on all viewport sizes
Don’t float on all viewport sizes
html
class
float-start
Float start on all viewport sizes
class
float-end
Float end on all viewport sizes
class
float-none
Don’t float on all viewport sizes
Use the
clearfix helper
on a parent element to clear floats.
Responsive
Responsive variations also exist for each
float
value.
Float end on viewports sized SM (small) or wider
Float end on viewports sized MD (medium) or wider
Float end on viewports sized LG (large) or wider
Float end on viewports sized XL (extra large) or wider
Float end on viewports sized XXL (extra extra large) or wider
html
class
float-sm-end
Float end on viewports sized SM (small) or wider
class
float-md-end
Float end on viewports sized MD (medium) or wider
class
float-lg-end
Float end on viewports sized LG (large) or wider
class
float-xl-end
Float end on viewports sized XL (extra large) or wider
class
float-xxl-end
Float end on viewports sized XXL (extra extra large) or wider
Here are all the support classes:
.float-start
.float-end
.float-none
.float-sm-start
.float-sm-end
.float-sm-none
.float-md-start
.float-md-end
.float-md-none
.float-lg-start
.float-lg-end
.float-lg-none
.float-xl-start
.float-xl-end
.float-xl-none
.float-xxl-start
.float-xxl-end
.float-xxl-none
Sass utilities API
Float utilities are declared in our utilities API in
scss/_utilities.scss
Learn how to use the utilities API.
scss/_utilities.scss
"float"
responsive
true
property
float
values
start
left
right
none
none


-------------------- End of Utilities (18 pages) --------------------


========================= EXTEND =========================
Section: Extend
Files: 2
======================================================================

--- 010_extend_approach.txt ---
URL: https://getbootstrap.com/docs/5.3/extend/approach
--------------------------------------------------
While the getting started pages provide an introductory tour of the project and what it offers, this document focuses on
we do the things we do in Bootstrap. It explains our philosophy to building on the web so that others can learn from us, contribute with us, and help us improve.
See something that doesn’t sound right, or perhaps could be done better?
Open an issue
—we’d love to discuss it with you.
Summary
We'll dive into each of these more throughout, but at a high level, here’s what guides our approach.
Components should be responsive and mobile-first
Components should be built with a base class and extended via modifier classes
Component states should obey a common z-index scale
Whenever possible, prefer an HTML and CSS implementation over JavaScript
Whenever possible, use utilities over custom styles
Whenever possible, avoid enforcing strict HTML requirements (children selectors)
Responsive
mobile-first
. We use this term in our docs and largely agree with it, but at times it can be too broad. While not every component
must
be entirely responsive in Bootstrap, this responsive approach is about reducing CSS overrides by pushing you to add styles as the viewport becomes larger.
Across Bootstrap, you’ll see this most clearly in our media queries. In most cases, we use
min-width
queries that begin to apply at a specific breakpoint and carry up through the higher breakpoints. For example, a
.d-none
applies from
min-width: 0
to infinity. On the other hand, a
.d-md-none
applies from the medium breakpoint and up.
At times we'll use
max-width
when a component’s inherent complexity requires it. At times, these overrides are functionally and mentally clearer to implement and support than rewriting core functionality from our components. We strive to limit this approach, but will use it from time to time.
Classes
Aside from our Reboot, a cross-browser normalization stylesheet, all our styles aim to use classes as selectors. This means steering clear of type selectors (e.g.,
input[type="text"]
) and extraneous parent classes (e.g.,
.parent .child
) that make styles too specific to easily override.
As such, components should be built with a base class that houses common, not-to-be overridden property-value pairs. For example,
.btn
.btn-primary
. We use
.btn
for all the common styles like
display
padding
, and
border-width
. We then use modifiers like
.btn-primary
to add the color, background-color, border-color, etc.
Modifier classes should only be used when there are multiple properties or values to be changed across multiple variants. Modifiers are not always necessary, so be sure you’re actually saving lines of code and preventing unnecessary overrides when creating them. Good examples of modifiers are our theme color classes and size variants.
z-index scales
There are two
z-index
scales in Bootstrap—elements within a component and overlay components.
Component elements
Some components in Bootstrap are built with overlapping elements to prevent double borders without modifying the
border
property. For example, button groups, input groups, and pagination.
These components share a standard
z-index
scale of
through
is default (initial),
:hover
:active
.active
, and
:focus
This approach matches our expectations of highest user priority. If an element is focused, it’s in view and at the user’s attention. Active elements are second highest because they indicate state. Hover is third highest because it indicates user intent, but nearly
anything
can be hovered.
Overlay components
z-index
, dropdowns, fixed and sticky navbars, modals, tooltips, and popovers. These components have their own
z-index
scale that begins at
1000
. This starting number was chosen arbitrarily and serves as a small buffer between our styles and your project’s custom styles.
Each overlay component increases its
z-index
value slightly in such a way that common UI principles allow user focused or hovered elements to remain in view at all times. For example, a modal is document blocking (e.g., you cannot take any other action save for the modal’s action), so we put that above our navbars.
Learn more about this in our
z-index
layout page
HTML and CSS over JS
Whenever possible, we prefer to write HTML and CSS over JavaScript. In general, HTML and CSS are more prolific and accessible to more people of all different experience levels. HTML and CSS are also faster in your browser than JavaScript, and your browser generally provides a great deal of functionality for you.
This principle is our first-class JavaScript API using
data
attributes. You don’t need to write nearly any JavaScript to use our JavaScript plugins; instead, write HTML. Read more about this in
our JavaScript overview page
Lastly, our styles build on the fundamental behaviors of common web elements. Whenever possible, we prefer to use what the browser provides. For example, you can put a
.btn
class on nearly any element, but most elements don’t provide any semantic value or browser functionality. So instead, we use
<button>
s and
The same goes for more complex components. While we
could
write our own form validation plugin to add classes to a parent element based on an input’s state, thereby allowing us to style the text say red, we prefer using the
:valid
:invalid
pseudo-elements every browser provides us.
Utilities
Utility classes—formerly helpers in Bootstrap 3—are a powerful ally in combating CSS bloat and poor page performance. A utility class is typically a single, immutable property-value pairing expressed as a class (e.g.,
.d-block
represents
display: block;
). Their primary appeal is speed of use while writing HTML and limiting the amount of custom CSS you have to write.
Specifically regarding custom CSS, utilities can help combat increasing file size by reducing your most commonly repeated property-value pairs into single classes. This can have a dramatic effect at scale in your projects.
Flexible HTML
While not always possible, we strive to avoid being overly dogmatic in our HTML requirements for components. Thus, we focus on single classes in our CSS selectors and try to avoid immediate children selectors (
). This gives you more flexibility in your implementation and helps keep our CSS simpler and less specific.
Code conventions
Code Guide
(from Bootstrap co-creator, @mdo) documents how we write our HTML and CSS across Bootstrap. It specifies guidelines for general formatting, common sense defaults, property and attribute orders, and more.
We use
Stylelint
to enforce these standards and more in our Sass/CSS.
Our custom Stylelint config
is open source and available for others to use and extend.
We use
vnu-jar
to enforce standard and semantic HTML, as well as detecting common errors.


--- 028_extend_icons.txt ---
URL: https://getbootstrap.com/docs/5.3/extend/icons
--------------------------------------------------
While Bootstrap doesn’t include an icon set by default, we do have our own comprehensive icon library called Bootstrap Icons. Feel free to use them or any other icon set in your project. We’ve included details for Bootstrap Icons and other preferred icon sets below.
While most icon sets include multiple file formats, we prefer SVG implementations for their improved accessibility and vector support.
@mdo
and maintained by
the Bootstrap Team
. The beginnings of this icon set come from Bootstrap’s very own components—our forms, carousels, and more. Bootstrap has very few icon needs out of the box, so we didn’t need much. However, once we got going, we couldn’t stop making more.
Oh, and did we mention they’re completely open source? Licensed under MIT, just like Bootstrap, our icon set is available to everyone.
Learn more about Bootstrap Icons
, including how to install them and recommended usage.
Alternatives
We’ve tested and used these icon sets ourselves as preferred alternatives to Bootstrap Icons.
Font Awesome
Feather
Octicons
More options
While we haven’t tried these out ourselves, they do look promising and provide multiple formats, including SVG.
Bytesize
CoreUI Icons
Google Material icons
Ionicons
Dripicons
Ikons
Icons8
icofont
Tabler Icons


-------------------- End of Extend (2 pages) --------------------


========================= CUSTOMIZE =========================
Section: Customize
Files: 7
======================================================================

--- 035_customize_sass.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/sass
--------------------------------------------------
Utilize our source Sass files to take advantage of variables, maps, mixins, and more.
Sass deprecation warnings are shown when compiling source Sass files with the latest versions of Dart Sass. This does not prevent compilation or usage of Bootstrap. We’re
working on a long-term fix
, but in the meantime these deprecation notices can be ignored.
File structure
Whenever possible, avoid modifying Bootstrap’s core files. For Sass, that means creating your own stylesheet that imports Bootstrap so you can modify and extend it. Assuming you’re using a package manager like npm, you’ll have a file structure that looks like this:
your-project/
├── scss/
│   └── custom.scss
└── node_modules/
│   └── bootstrap/
│       ├── js/
│       └── scss/
└── index.html
If you’ve downloaded our source files and aren’t using a package manager, you’ll want to manually create something similar to that structure, keeping Bootstrap’s source files separate from your own.
your-project/
├── scss/
│   └── custom.scss
├── bootstrap/
│   ├── js/
│   └── scss/
└── index.html
Importing
In your
custom.scss
, you’ll import Bootstrap’s source Sass files. You have two options: include all of Bootstrap, or pick the parts you need. We encourage the latter, though be aware there are some requirements and dependencies across our components. You also will need to include some JavaScript for our plugins.
// Custom.scss
// Option A: Include all of Bootstrap
// Include any default variable overrides here (though functions won’t be available)
@import
"../node_modules/bootstrap/scss/bootstrap"
// Then add additional custom code here
// Custom.scss
// Option B: Include parts of Bootstrap
// 1. Include functions first (so you can manipulate colors, SVGs, calc, etc)
@import
"../node_modules/bootstrap/scss/functions"
// 2. Include any default variable overrides here
// 3. Include remainder of required Bootstrap stylesheets (including any separate color mode stylesheets)
@import
"../node_modules/bootstrap/scss/variables"
@import
"../node_modules/bootstrap/scss/variables-dark"
// 4. Include any default map overrides here
// 5. Include remainder of required parts
@import
"../node_modules/bootstrap/scss/maps"
@import
"../node_modules/bootstrap/scss/mixins"
@import
"../node_modules/bootstrap/scss/root"
// 6. Include any other optional stylesheet partials as desired; list below is not inclusive of all available stylesheets
@import
"../node_modules/bootstrap/scss/utilities"
@import
"../node_modules/bootstrap/scss/reboot"
@import
"../node_modules/bootstrap/scss/type"
@import
"../node_modules/bootstrap/scss/images"
@import
"../node_modules/bootstrap/scss/containers"
@import
"../node_modules/bootstrap/scss/grid"
@import
"../node_modules/bootstrap/scss/helpers"
// ...
// 7. Optionally include utilities API last to generate classes based on the Sass map in `_utilities.scss`
@import
"../node_modules/bootstrap/scss/utilities/api"
// 8. Add additional custom code here
With that setup in place, you can begin to modify any of the Sass variables and maps in your
custom.scss
. You can also start to add parts of Bootstrap under the
// Optional
section as needed. We suggest using the full import stack from our
file as your starting point.
Compiling
In order to use your custom Sass code as CSS in the browser, you need a Sass compiler. Sass ships as a CLI package, but you can also compile it with other build tools like
Gulp
Webpack
, or with GUI applications. Some IDEs also have Sass compilers built in or as downloadable extensions.
We like to use the CLI to compile our Sass, but you can use whichever method you prefer. From the command line, run the following:
# Install Sass globally
install
sass
# Watch your custom Sass for changes and compile it to CSS
sass
--watch
./scss/custom.scss ./css/custom.css
Learn more about your options at
sass-lang.com/install
compiling with VS Code
Using Bootstrap with another build tool?
Consider reading our guides for compiling with
Webpack
Parcel
, or
Vite
. We also have production-ready demos in
our examples repository on GitHub
Including
Once your CSS is compiled, you can include it in your HTML files. Inside your
index.html
you’ll want to include your compiled CSS file. Be sure to update the path to your compiled CSS file if you’ve changed it.
doctype
html
html
lang
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
Custom Bootstrap
title
link
href
/css/custom.css
stylesheet
head
body
Hello, world!
body
html
Variable defaults
Every Sass variable in Bootstrap includes the
!default
flag allowing you to override the variable’s default value in your own Sass without modifying Bootstrap’s source code. Copy and paste variables as needed, modify their values, and remove the
!default
flag. If a variable has already been assigned, then it won’t be re-assigned by the default values in Bootstrap.
You will find the complete list of Bootstrap’s variables in
scss/_variables.scss
. Some variables are set to
null
, these variables don’t output the property unless they are overridden in your configuration.
Variable overrides must come after our functions are imported, but before the rest of the imports.
Here’s an example that changes the
background-color
color
for the
<body>
when importing and compiling Bootstrap via npm:
// Required
@import
"../node_modules/bootstrap/scss/functions"
// Default variable overrides
$body-bg
#000
$body-color
#111
// Required
@import
"../node_modules/bootstrap/scss/variables"
@import
"../node_modules/bootstrap/scss/variables-dark"
@import
"../node_modules/bootstrap/scss/maps"
@import
"../node_modules/bootstrap/scss/mixins"
@import
"../node_modules/bootstrap/scss/root"
// Optional Bootstrap components here
@import
"../node_modules/bootstrap/scss/reboot"
@import
"../node_modules/bootstrap/scss/type"
// etc
Repeat as necessary for any variable in Bootstrap, including the global options below.
Get started with Bootstrap via npm with our starter project!
Head to the
Sass & JS example
template repository to see how to build and customize Bootstrap in your own npm project. Includes Sass compiler, Autoprefixer, Stylelint, PurgeCSS, and Bootstrap Icons.
Maps and loops
!default
flag and can be overridden and extended.
Some of our Sass maps are merged into empty ones by default. This is done to allow easy expansion of a given Sass map, but comes at the cost of making
removing
items from a map slightly more difficult.
Modify map
All variables in the
$theme-colors
map are defined as standalone variables. To modify an existing color in our
$theme-colors
map, add the following to your custom Sass file:
$primary
#0074d9
$danger
#ff4136
Later on, these variables are set in Bootstrap’s
$theme-colors
map:
$theme-colors
"primary"
$primary
"danger"
$danger
Add to map
Add new colors to
$theme-colors
, or any other map, by creating a new Sass map with your custom values and merging it with the original map. In this case, we'll create a new
$custom-colors
map and merge it with
$theme-colors
// Create your own map
$custom-colors
"custom-color"
#900
// Merge the maps
$theme-colors
map-merge
$theme-colors
$custom-colors
Remove from map
To remove colors from
$theme-colors
, or any other map, use
map-remove
. Be aware you must insert
$theme-colors
between our requirements just after its definition in
variables
and before its usage in
maps
// Required
@import
"../node_modules/bootstrap/scss/functions"
@import
"../node_modules/bootstrap/scss/variables"
@import
"../node_modules/bootstrap/scss/variables-dark"
$theme-colors
map-remove
$theme-colors
"info"
"light"
"dark"
@import
"../node_modules/bootstrap/scss/maps"
@import
"../node_modules/bootstrap/scss/mixins"
@import
"../node_modules/bootstrap/scss/root"
// Optional
@import
"../node_modules/bootstrap/scss/reboot"
@import
"../node_modules/bootstrap/scss/type"
// etc
Required keys
For example, we use the
primary
success
, and
danger
keys from
$theme-colors
for links, buttons, and form states. Replacing the values of these keys should present no issues, but removing them may cause Sass compilation issues. In these instances, you’ll need to modify the Sass code that makes use of those values.
Functions
Colors
Next to the
Sass maps
we have, theme colors can also be used as standalone variables, like
$primary
.custom-element
color
$gray-100
background-color
$dark
You can lighten or darken colors with Bootstrap’s
tint-color()
shade-color()
functions. These functions will mix colors with black or white, unlike Sass’ native
lighten()
darken()
functions which will change the lightness by a fixed amount, which often doesn’t lead to the desired effect.
shift-color()
combines these two functions by shading the color if the weight is positive and tinting the color if the weight is negative.
scss/_functions.scss
// Tint a color: mix a color with white
@function
tint-color
$color
$weight
@return
white
$color
$weight
// Shade a color: mix a color with black
@function
shade-color
$color
$weight
@return
black
$color
$weight
// Shade the color if the weight is positive, else tint it
@function
shift-color
$color
$weight
@return
$weight
shade-color
$color
$weight
tint-color
$color
$weight
In practice, you’d call the function and pass in the color and weight parameters.
.custom-element
color
tint-color
$primary
.custom-element-2
color
shade-color
$danger
.custom-element-3
color
shift-color
$success
background-color
shift-color
$success
-60%
Color contrast
In order to meet the
Web Content Accessibility Guidelines (WCAG)
contrast requirements, authors
must
provide a minimum
text color contrast of 4.5:1
and a minimum
non-text color contrast of 3:1
, with very few exceptions.
To help with this, we included the
color-contrast
function in Bootstrap. It uses the
WCAG contrast ratio algorithm
for calculating contrast thresholds based on
relative luminance
in an
sRGB
color space to automatically return a light (
#fff
), dark (
#212529
) or black (
#000
) contrast color based on the specified base color. This function is especially useful for mixins or loops where you’re generating multiple classes.
For example, to generate color swatches from our
$theme-colors
map:
@each
$color
$value
$theme-colors
.swatch-
#{$color}
color
color-contrast
$value
It can also be used for one-off contrast needs:
.custom-element
color
color-contrast
#000
// returns `color: #fff`
You can also specify a base color with our color map functions:
.custom-element
color
color-contrast
$dark
// returns `color: #fff`
Escape SVG
We use the
escape-svg
function to escape the
characters for SVG background images. When using the
escape-svg
function, data URIs must be quoted.
Add and Subtract functions
We use the
subtract
functions to wrap the CSS
calc
function. The primary purpose of these functions is to avoid errors when a “unitless”
value is passed into a
calc
expression. Expressions like
calc(10px - 0)
will return an error in all browsers, despite being mathematically correct.
Example where the calc is valid:
$border-radius
.25rem
$border-width
.element
// Output calc(.25rem - 1px) is valid
border-radius
calc
$border-radius
$border-width
.element
// Output the same calc(.25rem - 1px) as above
border-radius
subtract
$border-radius
$border-width
Example where the calc is invalid:
$border-radius
.25rem
$border-width
.element
// Output calc(.25rem - 0) is invalid
border-radius
calc
$border-radius
$border-width
.element
// Output .25rem
border-radius
subtract
$border-radius
$border-width
Mixins
scss/mixins/
directory has a ton of mixins that power parts of Bootstrap and can also be used across your own project.
Color schemes
A shorthand mixin for the
prefers-color-scheme
media query is available with support for
light
dark
color schemes. See
the color modes documentation
for information on our color mode mixin.
scss/mixins/_color-scheme.scss
@mixin
color-scheme
$name
@media
prefers-color-scheme
#{$name}
@content
.custom-element
@include
color-scheme
light
// Insert light mode styles here
@include
color-scheme
dark
// Insert dark mode styles here


--- 052_customize_overview.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/overview
--------------------------------------------------
Sass
Utilize our source Sass files to take advantage of variables, maps, mixins, and functions.
Options
Customize Bootstrap with built-in variables to easily toggle global CSS preferences.
Color
Learn about and customize the color systems that support the entire toolkit.
Color modes
Explore our default light mode and the new dark mode, or create custom color modes yourself.
Components
Learn how we build nearly all our components responsively and with base and modifier classes.
CSS variables
Use Bootstrap’s CSS custom properties for fast and forward-looking design and development.
Optimize
Keep your projects lean, responsive, and maintainable so you can deliver the best experience.
Overview
There are multiple ways to customize Bootstrap. Your best path can depend on your project, the complexity of your build tools, the version of Bootstrap you’re using, browser support, and more.
Our two preferred methods are:
Using Bootstrap
via package manager
so you can use and extend our source files.
Using Bootstrap’s compiled distribution files or
jsDelivr
so you can add onto or override Bootstrap’s styles.
While we cannot go into details here on how to use every package manager, we can give some guidance on
using Bootstrap with your own Sass compiler
For those who want to use the distribution files, review the
getting started page
for how to include those files and an example HTML page. From there, consult the docs for the layout, components, and behaviors you’d like to use.
As you familiarize yourself with Bootstrap, continue exploring this section for more details on how to utilize our global options, making use of and changing our color system, how we build our components, how to use our growing list of CSS custom properties, and how to optimize your code when building with Bootstrap.
CSPs and embedded SVGs
Several Bootstrap components include embedded SVGs in our CSS to style components consistently and easily across browsers and devices.
For organizations with more strict
configurations
, we’ve documented all instances of our embedded SVGs (all of which are applied via
background-image
) so you can more thoroughly review your options.
Accordion
Carousel controls
Close button
(used in alerts and modals)
Form checkboxes and radio buttons
Form switches
Form validation icons
Navbar toggle buttons
Select menus
Based on
community conversation
, some options for addressing this in your own codebase include
replacing the URLs with locally hosted assets
, removing the images and using inline images (not possible in all components), and modifying your CSP. Our recommendation is to carefully review your own security policies and decide on the best path forward, if necessary.


--- 053_customize_optimize.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/optimize
--------------------------------------------------
Lean Sass imports
When using Sass in your asset pipeline, make sure you optimize Bootstrap by only
@import
ing the components you need. Your largest optimizations will likely come from the
Layout & Components
section of our
scss/bootstrap.scss
// Configuration
@import
"functions"
@import
"variables"
@import
"variables-dark"
@import
"maps"
@import
"mixins"
@import
"utilities"
// Layout & components
@import
"root"
@import
"reboot"
@import
"type"
@import
"images"
@import
"containers"
@import
"grid"
@import
"tables"
@import
"forms"
@import
"buttons"
@import
"transitions"
@import
"dropdown"
@import
"button-group"
@import
"nav"
@import
"navbar"
@import
"card"
@import
"accordion"
@import
"breadcrumb"
@import
"pagination"
@import
"badge"
@import
"alert"
@import
"progress"
@import
"list-group"
@import
"close"
@import
"toasts"
@import
"modal"
@import
"tooltip"
@import
"popover"
@import
"carousel"
@import
"spinners"
@import
"offcanvas"
@import
"placeholders"
// Helpers
@import
"helpers"
// Utilities
@import
"utilities/api"
If you’re not using a component, comment it out or delete it entirely. For example, if you’re not using the carousel, remove that import to save some file size in your compiled CSS. Keep in mind there are some dependencies across Sass imports that may make it more difficult to omit a file.
Lean JavaScript
), and even our primary dependency (Popper) with our bundle files (
). While you’re customizing via Sass, be sure to remove related JavaScript.
For instance, assuming you’re using your own JavaScript bundler like Webpack, Parcel, or Vite, you’d only import the JavaScript you plan on using. In the example below, we show how to just include our modal JavaScript:
// Import just what we need
// import 'bootstrap/js/dist/alert';
// import 'bootstrap/js/dist/button';
// import 'bootstrap/js/dist/carousel';
// import 'bootstrap/js/dist/collapse';
// import 'bootstrap/js/dist/dropdown';
import
'bootstrap/js/dist/modal'
// import 'bootstrap/js/dist/offcanvas';
// import 'bootstrap/js/dist/popover';
// import 'bootstrap/js/dist/scrollspy';
// import 'bootstrap/js/dist/tab';
// import 'bootstrap/js/dist/toast';
// import 'bootstrap/js/dist/tooltip';
This way, you’re not including any JavaScript you don’t intend to use for components like buttons, carousels, and tooltips. If you’re importing dropdowns, tooltips or popovers, be sure to list the Popper dependency in your
package.json
file.
Heads up!
Files in
use the
default export
. To use them, do the following:
import
Modal
from
'bootstrap/js/dist/modal'
const
modal
Modal
document
getElementById
'myModal'
Autoprefixer .browserslistrc
.browserslistrc
file, found in the root of the Bootstrap repo. Customizing this list of browsers and recompiling the Sass will automatically remove some CSS from your compiled CSS, if there are vendor prefixes unique to that browser or version.
Unused CSS
Help wanted with this section, please consider opening a PR. Thanks!
While we don’t have a prebuilt example for using
PurgeCSS
with Bootstrap, there are some helpful articles and walkthroughs that the community has written. Here are some options:
https://medium.com/dwarves-foundation/remove-unused-css-styles-from-bootstrap-using-purgecss-88395a2c5772
https://lukelowrey.com/automatically-removeunused-css-from-bootstrap-or-other-frameworks/
Lastly, this
CSS Tricks article on unused CSS
shows how to use PurgeCSS and other similar tools.
Minify and gzip
Whenever possible, be sure to compress all the code you serve to your visitors. If you’re using Bootstrap dist files, try to stick to the minified versions (indicated by the
.min.css
.min.js
extensions). If you’re building Bootstrap from the source with your own build system, be sure to implement your own minifiers for HTML, CSS, and JS.
Non-blocking files
While minifying and using compression might seem like enough, making your files non-blocking ones is also a big step in making your site well-optimized and fast enough.
If you are using a
Lighthouse
plugin in Google Chrome, you may have stumbled over FCP.
The First Contentful Paint
metric measures the time from when the page starts loading to when any part of the page’s content is rendered on the screen.
You can improve FCP by deferring non-critical JavaScript or CSS. What does that mean? Simply, JavaScript or stylesheets that don’t need to be present on the first paint of your page should be marked with
async
defer
attributes.
This ensures that the less important resources are loaded later and not blocking the first paint. On the other hand, critical resources can be included as inline scripts or styles.
If you want to learn more about this, there are already a lot of great articles about it:
https://developer.chrome.com/docs/lighthouse/performance/render-blocking-resources/
https://web.dev/articles/defer-non-critical-css
Always use HTTPS
Your website should only be available over HTTPS connections in production. HTTPS improves the security, privacy, and availability of all sites, and
there is no such thing as non-sensitive web traffic
. The steps to configure your website to be served exclusively over HTTPS vary widely depending on your architecture and web hosting provider, and thus are beyond the scope of these docs.
Sites served over HTTPS should also access all stylesheets, scripts, and other assets over HTTPS connections. Otherwise, you’ll be sending users
mixed active content
, leading to potential vulnerabilities where a site can be compromised by altering a dependency. This can lead to security issues and in-browser warnings displayed to users. Whether you’re getting Bootstrap from a CDN or serving it yourself, ensure that you only access it over HTTPS connections.


--- 060_customize_options.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/options
--------------------------------------------------
Customize Bootstrap with our built-in custom variables file and easily toggle global CSS preferences with new
$enable-*
Sass variables. Override a variable’s value and recompile with
npm run test
as needed.
You can find and customize these variables for key global options in Bootstrap’s
scss/_variables.scss
file.
Variable
Values
Description
$spacer
1rem
(default), or any value > 0
Specifies the default spacer value to programmatically generate our
spacer utilities
$enable-dark-mode
true
(default) or
false
Enables built-in
dark mode support
across the project and its components.
$enable-rounded
true
(default) or
false
Enables predefined
border-radius
styles on various components.
$enable-shadows
true
false
(default)
Enables predefined decorative
box-shadow
styles on various components. Does not affect
box-shadow
s used for focus states.
$enable-gradients
true
false
(default)
Enables predefined gradients via
background-image
styles on various components.
$enable-transitions
true
(default) or
false
Enables predefined
transition
s on various components.
$enable-reduced-motion
true
(default) or
false
Enables the
prefers-reduced-motion
media query
, which suppresses certain animations/transitions based on the users’ browser/operating system preferences.
$enable-grid-classes
true
(default) or
false
Enables the generation of CSS classes for the grid system (e.g.
.row
.col-md-1
, etc.).
$enable-cssgrid
true
false
(default)
Enables the experimental CSS Grid system (e.g.
.grid
.g-col-md-1
, etc.).
$enable-container-classes
true
(default) or
false
Enables the generation of CSS classes for layout containers. (New in v5.2.0)
$enable-caret
true
(default) or
false
Enables pseudo element caret on
.dropdown-toggle
$enable-button-pointers
true
(default) or
false
Add “hand” cursor to non-disabled button elements.
$enable-rfs
true
(default) or
false
Globally enables
$enable-validation-icons
true
(default) or
false
Enables
background-image
icons within textual inputs and some custom forms for validation states.
$enable-negative-margins
true
false
(default)
Enables the generation of
negative margin utilities
$enable-deprecation-messages
true
(default) or
false
Set to
false
to hide warnings when using any of the deprecated mixins and functions that are planned to be removed in
$enable-important-utilities
true
(default) or
false
Enables the
!important
suffix in utility classes.
$enable-smooth-scroll
true
(default) or
false
Applies
scroll-behavior: smooth
globally, except for users asking for reduced motion through
prefers-reduced-motion
media query


--- 105_customize_css-variables.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/css-variables
--------------------------------------------------
CSS custom properties (variables)
in its compiled CSS for real-time customization without the need to recompile Sass. These provide easy access to commonly used values like our theme colors, breakpoints, and primary font stacks when working in your browser’s inspector, a code sandbox, or general prototyping.
All our custom properties are prefixed with
to avoid conflicts with third party CSS.
Root variables
Here are the variables we include (note that the
:root
is required) that can be accessed anywhere Bootstrap’s CSS is loaded. They’re located in our
_root.scss
file and included in our compiled dist files.
Default
These CSS variables are available everywhere, regardless of color mode.
:root,
[data-bs-theme=light]
--bs-blue
#0d6efd
--bs-indigo
#6610f2
--bs-purple
#6f42c1
--bs-pink
#d63384
--bs-red
#dc3545
--bs-orange
#fd7e14
--bs-yellow
#ffc107
--bs-green
#198754
--bs-teal
#20c997
--bs-cyan
#0dcaf0
--bs-black
#000
--bs-white
#fff
--bs-gray
#6c757d
--bs-gray-dark
#343a40
--bs-gray-100
#f8f9fa
--bs-gray-200
#e9ecef
--bs-gray-300
#dee2e6
--bs-gray-400
#ced4da
--bs-gray-500
#adb5bd
--bs-gray-600
#6c757d
--bs-gray-700
#495057
--bs-gray-800
#343a40
--bs-gray-900
#212529
--bs-primary
#0d6efd
--bs-secondary
#6c757d
--bs-success
#198754
--bs-info
#0dcaf0
--bs-warning
#ffc107
--bs-danger
#dc3545
--bs-light
#f8f9fa
--bs-dark
#212529
--bs-primary-rgb
--bs-secondary-rgb
--bs-success-rgb
--bs-info-rgb
--bs-warning-rgb
--bs-danger-rgb
--bs-light-rgb
--bs-dark-rgb
--bs-primary-text-emphasis
#052c65
--bs-secondary-text-emphasis
#2b2f32
--bs-success-text-emphasis
#0a3622
--bs-info-text-emphasis
#055160
--bs-warning-text-emphasis
#664d03
--bs-danger-text-emphasis
#58151c
--bs-light-text-emphasis
#495057
--bs-dark-text-emphasis
#495057
--bs-primary-bg-subtle
#cfe2ff
--bs-secondary-bg-subtle
#e2e3e5
--bs-success-bg-subtle
#d1e7dd
--bs-info-bg-subtle
#cff4fc
--bs-warning-bg-subtle
#fff3cd
--bs-danger-bg-subtle
#f8d7da
--bs-light-bg-subtle
#fcfcfd
--bs-dark-bg-subtle
#ced4da
--bs-primary-border-subtle
#9ec5fe
--bs-secondary-border-subtle
#c4c8cb
--bs-success-border-subtle
#a3cfbb
--bs-info-border-subtle
#9eeaf9
--bs-warning-border-subtle
#ffe69c
--bs-danger-border-subtle
#f1aeb5
--bs-light-border-subtle
#e9ecef
--bs-dark-border-subtle
#adb5bd
--bs-white-rgb
--bs-black-rgb
--bs-font-sans-serif
system-ui
-apple-system
"Segoe UI"
Roboto
"Helvetica Neue"
"Noto Sans"
"Liberation Sans"
Arial
sans-serif
"Apple Color Emoji"
"Segoe UI Emoji"
"Segoe UI Symbol"
"Noto Color Emoji"
--bs-font-monospace
SFMono-Regular
Menlo
Monaco
Consolas
"Liberation Mono"
"Courier New"
monospace
--bs-gradient
linear-gradient
180deg
rgba
0.15
rgba
--bs-body-font-family
--bs-font-sans-serif
--bs-body-font-size
1rem
--bs-body-font-weight
--bs-body-line-height
--bs-body-color
#212529
--bs-body-color-rgb
--bs-body-bg
#fff
--bs-body-bg-rgb
--bs-emphasis-color
#000
--bs-emphasis-color-rgb
--bs-secondary-color
rgba
0.75
--bs-secondary-color-rgb
--bs-secondary-bg
#e9ecef
--bs-secondary-bg-rgb
--bs-tertiary-color
rgba
--bs-tertiary-color-rgb
--bs-tertiary-bg
#f8f9fa
--bs-tertiary-bg-rgb
--bs-heading-color
inherit
--bs-link-color
#0d6efd
--bs-link-color-rgb
--bs-link-decoration
underline
--bs-link-hover-color
#0a58ca
--bs-link-hover-color-rgb
--bs-code-color
#d63384
--bs-highlight-color
#212529
--bs-highlight-bg
#fff3cd
--bs-border-width
--bs-border-style
solid
--bs-border-color
#dee2e6
--bs-border-color-translucent
rgba
0.175
--bs-border-radius
0.375rem
--bs-border-radius-sm
0.25rem
--bs-border-radius-lg
0.5rem
--bs-border-radius-xl
1rem
--bs-border-radius-xxl
2rem
--bs-border-radius-2xl
--bs-border-radius-xxl
--bs-border-radius-pill
50rem
--bs-box-shadow
0 0.5rem 1rem
rgba
0.15
--bs-box-shadow-sm
0 0.125rem 0.25rem
rgba
0.075
--bs-box-shadow-lg
0 1rem 3rem
rgba
0.175
--bs-box-shadow-inset
inset 0 1px 2px
rgba
0.075
--bs-focus-ring-width
0.25rem
--bs-focus-ring-opacity
0.25
--bs-focus-ring-color
rgba
0.25
--bs-form-valid-color
#198754
--bs-form-valid-border-color
#198754
--bs-form-invalid-color
#dc3545
--bs-form-invalid-border-color
#dc3545
Dark mode
These variables are scoped to our built-in dark mode.
[data-bs-theme=dark]
color-scheme
dark
--bs-body-color
#dee2e6
--bs-body-color-rgb
--bs-body-bg
#212529
--bs-body-bg-rgb
--bs-emphasis-color
#fff
--bs-emphasis-color-rgb
--bs-secondary-color
rgba
0.75
--bs-secondary-color-rgb
--bs-secondary-bg
#343a40
--bs-secondary-bg-rgb
--bs-tertiary-color
rgba
--bs-tertiary-color-rgb
--bs-tertiary-bg
#2b3035
--bs-tertiary-bg-rgb
--bs-primary-text-emphasis
#6ea8fe
--bs-secondary-text-emphasis
#a7acb1
--bs-success-text-emphasis
#75b798
--bs-info-text-emphasis
#6edff6
--bs-warning-text-emphasis
#ffda6a
--bs-danger-text-emphasis
#ea868f
--bs-light-text-emphasis
#f8f9fa
--bs-dark-text-emphasis
#dee2e6
--bs-primary-bg-subtle
#031633
--bs-secondary-bg-subtle
#161719
--bs-success-bg-subtle
#051b11
--bs-info-bg-subtle
#032830
--bs-warning-bg-subtle
#332701
--bs-danger-bg-subtle
#2c0b0e
--bs-light-bg-subtle
#343a40
--bs-dark-bg-subtle
#1a1d20
--bs-primary-border-subtle
#084298
--bs-secondary-border-subtle
#41464b
--bs-success-border-subtle
#0f5132
--bs-info-border-subtle
#087990
--bs-warning-border-subtle
#997404
--bs-danger-border-subtle
#842029
--bs-light-border-subtle
#495057
--bs-dark-border-subtle
#343a40
--bs-heading-color
inherit
--bs-link-color
#6ea8fe
--bs-link-hover-color
#8bb9fe
--bs-link-color-rgb
--bs-link-hover-color-rgb
--bs-code-color
#e685b5
--bs-highlight-color
#dee2e6
--bs-highlight-bg
#664d03
--bs-border-color
#495057
--bs-border-color-translucent
rgba
0.15
--bs-form-valid-color
#75b798
--bs-form-valid-border-color
#75b798
--bs-form-invalid-color
#ea868f
--bs-form-invalid-border-color
#ea868f
Component variables
Have a look at our table documentation for some
insight into how we’re using CSS variables
. Our
navbars also use CSS variables
as of v5.2.0. We’re also using CSS variables across our grids—primarily for gutters the
new opt-in CSS grid
—with more component usage coming in the future.
Whenever possible, we'll assign CSS variables at the base component level (e.g.,
.navbar
for navbar and its sub-components). This reduces guessing on where and how to customize, and allows for easy modifications by our team in future updates.
Prefix
Most CSS variables use a prefix to avoid collisions with your own codebase. This prefix is in addition to the
that’s required on every CSS variable.
Customize the prefix via the
$prefix
Sass variable. By default, it’s set to
(note the trailing dash).
Examples
CSS variables offer similar flexibility to Sass’s variables, but without the need for compilation before being served to the browser. For example, here we’re resetting our page’s font and link styles with CSS variables.
body
font
1rem/1.5
--bs-font-sans-serif
color
--bs-blue
Focus variables
Added in v5.3.0
:focus
styles using a combination of Sass and CSS variables that can be optionally added to specific components and elements. We do not yet globally override all
:focus
styles.
In our Sass, we set default values that can be customized before compiling.
scss/_variables.scss
$focus-ring-width
.25rem
$focus-ring-opacity
$focus-ring-color
rgba
$primary
$focus-ring-opacity
$focus-ring-blur
$focus-ring-box-shadow
$focus-ring-blur
$focus-ring-width
$focus-ring-color
Those variables are then reassigned to
:root
level CSS variables that can be customized in real-time, including with options for
offsets (which default to their fallback value of
scss/_root.scss
#{$prefix}
focus-ring-width
#{$focus-ring-width}
#{$prefix}
focus-ring-opacity
#{$focus-ring-opacity}
#{$prefix}
focus-ring-color
#{$focus-ring-color}
Grid breakpoints
While we include our grid breakpoints as CSS variables (except for
), be aware that
CSS variables do not work in media queries
. This is by design in the CSS spec for variables, but may change in coming years with support for
env()
variables. Check out
this Stack Overflow answer
for some helpful links. In the meantime, you can use these variables in other CSS situations, as well as in your JavaScript.


--- 113_customize_color.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/color
--------------------------------------------------
Colors
Added in v5.3.0
secondary
tertiary
text and background colors, plus
{color}-bg-subtle
{color}-border-subtle
, and
{color}-text-emphasis
for our theme colors. These new colors are available through Sass and CSS variables (but not our color maps or utility classes) with the express goal of making it easier to customize across multiple colors modes like light and dark. These new variables are globally set on
:root
and are adapted for our new dark color mode while our original theme colors remain unchanged.
Colors ending in
-rgb
provide the
red, green, blue
values for use in
rgb()
rgba()
color modes. For example,
rgba(var(--bs-secondary-bg-rgb), .5)
Heads up!
There’s some potential confusion with our new secondary and tertiary colors, and our existing secondary theme color, as well as our light and dark theme colors. Expect this to be ironed out in v6.
Description
Swatch
Variables
Body —
Default foreground (color) and background, including components.
--bs-body-color
--bs-body-color-rgb
--bs-body-bg
--bs-body-bg-rgb
Secondary —
Use the
color
option for lighter text. Use the
option for dividers and to indicate disabled component states.
--bs-secondary-color
--bs-secondary-color-rgb
--bs-secondary-bg
--bs-secondary-bg-rgb
Tertiary —
Use the
color
option for even lighter text. Use the
option to style backgrounds for hover states, accents, and wells.
--bs-tertiary-color
--bs-tertiary-color-rgb
--bs-tertiary-bg
--bs-tertiary-bg-rgb
Emphasis —
For higher contrast text. Not applicable for backgrounds.
--bs-emphasis-color
--bs-emphasis-color-rgb
Border —
For component borders, dividers, and rules. Use
--bs-border-color-translucent
to blend with backgrounds with an
rgba()
value.
--bs-border-color
--bs-border-color-rgb
Primary —
Main theme color, used for hyperlinks, focus styles, and component and form active states.
--bs-primary
--bs-primary-rgb
--bs-primary-bg-subtle
--bs-primary-border-subtle
Text
--bs-primary-text-emphasis
Success —
Theme color used for positive or successful actions and information.
--bs-success
--bs-success-rgb
--bs-success-bg-subtle
--bs-success-border-subtle
Text
--bs-success-text-emphasis
Danger —
Theme color used for errors and dangerous actions.
--bs-danger
--bs-danger-rgb
--bs-danger-bg-subtle
--bs-danger-border-subtle
Text
--bs-danger-text-emphasis
Warning —
Theme color used for non-destructive warning messages.
--bs-warning
--bs-warning-rgb
--bs-warning-bg-subtle
--bs-warning-border-subtle
Text
--bs-warning-text-emphasis
Info —
Theme color used for neutral and informative content.
--bs-info
--bs-info-rgb
--bs-info-bg-subtle
--bs-info-border-subtle
Text
--bs-info-text-emphasis
Light —
Additional theme option for less contrasting colors.
--bs-light
--bs-light-rgb
--bs-light-bg-subtle
--bs-light-border-subtle
Text
--bs-light-text-emphasis
Dark —
Additional theme option for higher contrasting colors.
--bs-dark
--bs-dark-rgb
--bs-dark-bg-subtle
--bs-dark-border-subtle
Text
--bs-dark-text-emphasis
Using the new colors
These new colors are accessible via CSS variables and utility classes—like
--bs-primary-bg-subtle
.bg-primary-subtle
—allowing you to compose your own CSS rules with the variables, or to quickly apply styles via classes. The utilities are built with the color’s associated CSS variables, and since we customize those CSS variables for dark mode, they are also adaptive to color mode by default.
Example element with utilities
html
class
p-3 text-primary-emphasis bg-primary-subtle border border-primary-subtle rounded-3
Example element with utilities
Theme colors
We use a subset of all colors to create a smaller color palette for generating color schemes, also available as Sass variables and a Sass map in Bootstrap’s
scss/_variables.scss
file.
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
All these colors are available as a Sass map,
$theme-colors
scss/_variables.scss
$theme-colors
"primary"
$primary
"secondary"
$secondary
"success"
$success
"info"
$info
"warning"
$warning
"danger"
$danger
"light"
$light
"dark"
$dark
Check out
our Sass maps and loops docs
for how to modify these colors.
All colors
All Bootstrap colors are available as Sass variables and a Sass map in
scss/_variables.scss
file. To avoid increased file sizes, we don’t create text or background color classes for each of these variables. Instead, we choose a subset of these colors for a
theme palette
Be sure to monitor contrast ratios as you customize colors. As shown below, we’ve added three contrast ratios to each of the main colors—one for the swatch’s current colors, one for against white, and one for against black.
$blue
#0d6efd
$blue-100
$blue-200
$blue-300
$blue-400
$blue-500
$blue-600
$blue-700
$blue-800
$blue-900
$indigo
#6610f2
$indigo-100
$indigo-200
$indigo-300
$indigo-400
$indigo-500
$indigo-600
$indigo-700
$indigo-800
$indigo-900
$purple
#6f42c1
$purple-100
$purple-200
$purple-300
$purple-400
$purple-500
$purple-600
$purple-700
$purple-800
$purple-900
$pink
#d63384
$pink-100
$pink-200
$pink-300
$pink-400
$pink-500
$pink-600
$pink-700
$pink-800
$pink-900
$red
#dc3545
$red-100
$red-200
$red-300
$red-400
$red-500
$red-600
$red-700
$red-800
$red-900
$orange
#fd7e14
$orange-100
$orange-200
$orange-300
$orange-400
$orange-500
$orange-600
$orange-700
$orange-800
$orange-900
$yellow
#ffc107
$yellow-100
$yellow-200
$yellow-300
$yellow-400
$yellow-500
$yellow-600
$yellow-700
$yellow-800
$yellow-900
$green
#198754
$green-100
$green-200
$green-300
$green-400
$green-500
$green-600
$green-700
$green-800
$green-900
$teal
#20c997
$teal-100
$teal-200
$teal-300
$teal-400
$teal-500
$teal-600
$teal-700
$teal-800
$teal-900
$cyan
#0dcaf0
$cyan-100
$cyan-200
$cyan-300
$cyan-400
$cyan-500
$cyan-600
$cyan-700
$cyan-800
$cyan-900
$gray-500
#adb5bd
$gray-100
$gray-200
$gray-300
$gray-400
$gray-500
$gray-600
$gray-700
$gray-800
$gray-900
$black
#000
$white
#fff
Notes on Sass
Sass cannot programmatically generate variables, so we manually created variables for every tint and shade ourselves. We specify the midpoint value (e.g.,
$blue-500
) and use custom color functions to tint (lighten) or shade (darken) our colors via Sass’s
mix()
color function.
Using
mix()
is not the same as
lighten()
darken()
—the former blends the specified color with white or black, while the latter only adjusts the lightness value of each color. The result is a much more complete suite of colors, as
shown in this CodePen demo
tint-color()
shade-color()
functions use
mix()
alongside our
$theme-color-interval
variable, which specifies a stepped percentage value for each mixed color we produce. See the
scss/_functions.scss
scss/_variables.scss
files for the full source code.
Color Sass maps
$colors
lists all our available base (
) colors
$theme-colors
lists all semantically named theme colors (shown below)
$grays
lists all tints and shades of gray
Within
scss/_variables.scss
, you’ll find Bootstrap’s color variables and Sass map. Here’s an example of the
$colors
Sass map:
scss/_variables.scss
$colors
"blue"
$blue
"indigo"
$indigo
"purple"
$purple
"pink"
$pink
"red"
$red
"orange"
$orange
"yellow"
$yellow
"green"
$green
"teal"
$teal
"cyan"
$cyan
"black"
$black
"white"
$white
"gray"
$gray-600
"gray-dark"
$gray-800
Add, remove, or modify values within the map to update how they’re used in many other components. Unfortunately at this time, not
every
component utilizes this Sass map. Future updates will strive to improve upon this. Until then, plan on making use of the
${color}
variables and this Sass map.
Example
Here’s how you can use these in your Sass:
.alpha
color
$purple
.beta
color
$yellow-300
background-color
$indigo-900
Color
background
utility classes are also available for setting
color
background-color
using the
color values.
Generating utilities
Added in v5.1.0
color
background-color
utilities for every color variable, but you can generate these yourself with our
utility API
and our extended Sass maps added in v5.1.0.
To start, make sure you’ve imported our functions, variables, mixins, and utilities.
Use our
map-merge-multiple()
function to quickly merge multiple Sass maps together in a new map.
Merge this new combined map to extend any utility with a
{color}-{level}
class name.
Here’s an example that generates text color utilities (e.g.,
.text-purple-500
) using the above steps.
@import
"bootstrap/scss/functions"
@import
"bootstrap/scss/variables"
@import
"bootstrap/scss/variables-dark"
@import
"bootstrap/scss/maps"
@import
"bootstrap/scss/mixins"
@import
"bootstrap/scss/utilities"
$all-colors
map-merge-multiple
$blues
$indigos
$purples
$pinks
$reds
$oranges
$yellows
$greens
$teals
$cyans
$utilities
map-merge
$utilities
"color"
map-merge
map-get
$utilities
"color"
values
map-merge
map-get
map-get
$utilities
"color"
"values"
$all-colors
@import
"bootstrap/scss/utilities/api"
This will generate new
.text-{color}-{level}
utilities for every color and level. You can do the same for any other utility and property as well.


--- 142_customize_color-modes.txt ---
URL: https://getbootstrap.com/docs/5.3/customize/color-modes
--------------------------------------------------
Try it yourself!
Download the source code and working demo for using Bootstrap with Stylelint, and the color modes from the
twbs/examples repository
. You can also
open the example in StackBlitz
Dark mode
With v5.3.0 you can implement your own color mode toggler (see below for an example from Bootstrap’s docs) and apply the different color modes as you see fit. We support a light mode (default) and now dark mode. Color modes can be toggled globally on the
<html>
element, or on specific components and elements, thanks to the
data-bs-theme
attribute.
Alternatively, you can also switch to a media query implementation thanks to our color mode mixin—see
the usage section for details
. Heads up though—this eliminates your ability to change themes on a per-component basis as shown below.
Example
For example, to change the color mode of a dropdown menu, add
data-bs-theme="light"
data-bs-theme="dark"
to the parent
.dropdown
. Now, no matter the global color mode, these dropdowns will display with the specified theme value.
Default dropdown
Action
Action
Another action
Something else here
Separated link
Dark dropdown
Action
Action
Another action
Something else here
Separated link
html
class
dropdown
data-bs-theme
light
button
class
btn btn-secondary dropdown-toggle
type
button
dropdownMenuButtonLight
data-bs-toggle
dropdown
aria-expanded
false
Default dropdown
button
class
dropdown-menu
aria-labelledby
dropdownMenuButtonLight
class
dropdown-item active
href
Action
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
class
dropdown
data-bs-theme
dark
button
class
btn btn-secondary dropdown-toggle
type
button
dropdownMenuButtonDark
data-bs-toggle
dropdown
aria-expanded
false
Dark dropdown
button
class
dropdown-menu
aria-labelledby
dropdownMenuButtonDark
class
dropdown-item active
href
Action
class
dropdown-item
href
Action
class
dropdown-item
href
Another action
class
dropdown-item
href
Something else here
class
dropdown-divider
class
dropdown-item
href
Separated link
How it works
As shown above, color mode styles are controlled by the
data-bs-theme
attribute. This attribute can be applied to the
<html>
element, or to any other element or Bootstrap component. If applied to the
<html>
element, it will apply to everything. If applied to a component or element, it will be scoped to that specific component or element.
For each color mode you wish to support, you’ll need to add new overrides for the shared global CSS variables. We do this already in our
_root.scss
stylesheet for dark mode, with light mode being the default values. In writing color mode specific styles, use the mixin:
// Color mode variables in _root.scss
@include
color-mode
dark
// CSS variable overrides here...
We use a custom
_variables-dark.scss
to power those shared global CSS variable overrides for dark mode. This file isn’t required for your own custom color modes, but it’s required for our dark mode for two reasons. First, it’s better to have a single place to reset global colors. Second, some Sass variables had to be overridden for background images embedded in our CSS for accordions, form components, and more.
Usage
Enable dark mode
Enable the built in dark color mode across your entire project by adding the
data-bs-theme="dark"
attribute to the
<html>
element. This will apply the dark color mode to all components and elements, other than those with a specific
data-bs-theme
attribute applied. Building on the
quick start template
doctype
html
html
lang
data-bs-theme
dark
head
meta
charset
utf-8
meta
name
viewport
content
width=device-width, initial-scale=1
title
title
link
href
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/css/bootstrap.min.css
stylesheet
integrity
sha384-LN+7fdVzj6u52u30Kp6M/trliBMCMKTyK833zpbD+pXdCLuTusPj697FH4R/5mcr
crossorigin
anonymous
head
body
Hello, world!
script
https://cdn.jsdelivr.net/npm/bootstrap@5.3.7/dist/js/bootstrap.bundle.min.js
integrity
sha384-ndDqU0Gzau9qJ1lfW4pNLlhNTkCfHzAVBReH9diLvGRem5+R9g2FzA8ZGN954O5Q
crossorigin
anonymous
script
body
html
Learn more in the JavaScript section.
Building with Sass
Our new dark mode option is available to use for all users of Bootstrap, but it’s controlled via data attributes instead of media queries and does not automatically toggle your project’s color mode. You can disable our dark mode entirely via Sass by changing
$enable-dark-mode
false
We use a custom Sass mixin,
color-mode()
, to help you control
color modes are applied. By default, we use a
data
attribute approach, allowing you to create more user-friendly experiences where your visitors can choose to have an automatic dark mode or control their preference (like in our own docs here). This is also an easy and scalable way to add different themes and more custom color modes beyond light and dark.
In case you want to use media queries and only make color modes automatic, you can change the mixin’s default type via Sass variable. Consider the following snippet and its compiled CSS output.
$color-mode-type
data
@include
color-mode
dark
.element
color
--bs-primary-text-emphasis
background-color
--bs-primary-bg-subtle
Outputs to:
[data-bs-theme=dark] .element
color
--bs-primary-text-emphasis
background-color
--bs-primary-bg-subtle
And when setting to
media-query
$color-mode-type
media-query
@include
color-mode
dark
.element
color
--bs-primary-text-emphasis
background-color
--bs-primary-bg-subtle
Outputs to:
@media
prefers-color-scheme
dark
.element
color
--bs-primary-text-emphasis
background-color
--bs-primary-bg-subtle
Custom color modes
While the primary use case for color modes is light and dark mode, custom color modes are also possible. Create your own
data-bs-theme
selector with a custom value as the name of your color mode, then modify our Sass and CSS variables as needed. We opted to create a separate
_variables-dark.scss
stylesheet to house Bootstrap’s dark mode specific Sass variables, but that’s not required for you.
For example, you can create a “blue theme” with the selector
data-bs-theme="blue"
. In your custom Sass or CSS file, add the new selector and override any global or component CSS variables as needed. If you’re using Sass, you can also use Sass’s functions within your CSS variable overrides.
site/src/scss/_content.scss
[data-bs-theme="blue"]
--bs-body-color
--bs-white
--bs-body-color-rgb
to-rgb
$white
--bs-body-bg
--bs-blue
--bs-body-bg-rgb
to-rgb
$blue
--bs-tertiary-bg
#{$blue-600}
.dropdown-menu
--bs-dropdown-bg
$blue-500
$blue-600
--bs-dropdown-link-active-bg
#{$blue-700}
.btn-secondary
--bs-btn-bg
$gray-600
$blue-400
--bs-btn-border-color
rgba
$white
--bs-btn-hover-bg
darken
$gray-600
$blue-400
--bs-btn-hover-border-color
rgba
$white
--bs-btn-active-bg
darken
$gray-600
$blue-400
--bs-btn-active-border-color
rgba
$white
--bs-btn-focus-border-color
rgba
$white
--bs-btn-focus-box-shadow
0 0 0 .25rem
rgba
Example blue theme
Some paragraph text to show how the blue theme might look with written copy.
Dropdown button
Action
Action
Another action
Something else here
Separated link
data-bs-theme
blue
JavaScript
To allow visitors or users to toggle color modes, you’ll need to create a toggle element to control the
data-bs-theme
attribute on the root element,
<html>
. We’ve built a toggler in our documentation that initially defers to a user’s current system color mode, but provides an option to override that and pick a specific color mode.
Here’s a look at the JavaScript that powers it. Feel free to inspect our own documentation navbar to see how it’s implemented using HTML and CSS from our own components. It is suggested to include the JavaScript at the top of your page to reduce potential screen flickering during reloading of your site. Note that if you decide to use media queries for your color modes, your JavaScript may need to be modified or removed if you prefer an implicit control.
* Copyright 2011-2025 The Bootstrap Authors
* Licensed under the Creative Commons Attribution 3.0 Unported License.
'use strict'
const
getStoredTheme
localStorage
getItem
'theme'
const
setStoredTheme
theme
localStorage
setItem
'theme'
theme
const
getPreferredTheme
const
storedTheme
getStoredTheme
storedTheme
return
storedTheme
return
window
matchMedia
'(prefers-color-scheme: dark)'
matches
'dark'
'light'
const
setTheme
theme
theme
'auto'
document
documentElement
setAttribute
'data-bs-theme'
window
matchMedia
'(prefers-color-scheme: dark)'
matches
'dark'
'light'
else
document
documentElement
setAttribute
'data-bs-theme'
theme
setTheme
getPreferredTheme
const
showActiveTheme
theme
focus
false
const
themeSwitcher
document
querySelector
'#bd-theme'
themeSwitcher
return
const
themeSwitcherText
document
querySelector
'#bd-theme-text'
const
activeThemeIcon
document
querySelector
'.theme-icon-active use'
const
btnToActive
document
querySelector
[data-bs-theme-value="
theme
const
svgOfActiveBtn
btnToActive
querySelector
'svg use'
getAttribute
'href'
document
querySelectorAll
'[data-bs-theme-value]'
forEach
element
element
classList
remove
'active'
element
setAttribute
'aria-pressed'
'false'
btnToActive
classList
'active'
btnToActive
setAttribute
'aria-pressed'
'true'
activeThemeIcon
setAttribute
'href'
svgOfActiveBtn
const
themeSwitcherLabel
themeSwitcherText
textContent
btnToActive
dataset
bsThemeValue
themeSwitcher
setAttribute
'aria-label'
themeSwitcherLabel
focus
themeSwitcher
focus
window
matchMedia
'(prefers-color-scheme: dark)'
addEventListener
'change'
const
storedTheme
getStoredTheme
storedTheme
'light'
storedTheme
'dark'
setTheme
getPreferredTheme
window
addEventListener
'DOMContentLoaded'
showActiveTheme
getPreferredTheme
document
querySelectorAll
'[data-bs-theme-value]'
forEach
toggle
toggle
addEventListener
'click'
const
theme
toggle
getAttribute
'data-bs-theme-value'
setStoredTheme
theme
setTheme
theme
showActiveTheme
theme
true
Adding theme colors
Adding a new color in
$theme-colors
is not enough for some of our components like
alerts
list groups
. New colors must also be defined in
$theme-colors-text
$theme-colors-bg-subtle
, and
$theme-colors-border-subtle
for light theme; but also in
$theme-colors-text-dark
$theme-colors-bg-subtle-dark
, and
$theme-colors-border-subtle-dark
for dark theme.
This is a manual process because Sass cannot generate its own Sass variables from an existing variable or map. In future versions of Bootstrap, we'll revisit this setup to reduce the duplication.
// Required
@import
"functions"
@import
"variables"
@import
"variables-dark"
// Add a custom color to $theme-colors
$custom-colors
"custom-color"
#712cf9
$theme-colors
map-merge
$theme-colors
$custom-colors
@import
"maps"
@import
"mixins"
@import
"utilities"
// Add a custom color to new theme maps
// Light mode
$custom-colors-text
"custom-color"
#712cf9
$custom-colors-bg-subtle
"custom-color"
#e1d2fe
$custom-colors-border-subtle
"custom-color"
#bfa1fc
$theme-colors-text
map-merge
$theme-colors-text
$custom-colors-text
$theme-colors-bg-subtle
map-merge
$theme-colors-bg-subtle
$custom-colors-bg-subtle
$theme-colors-border-subtle
map-merge
$theme-colors-border-subtle
$custom-colors-border-subtle
// Dark mode
$custom-colors-text-dark
"custom-color"
#e1d2f2
$custom-colors-bg-subtle-dark
"custom-color"
#8951fa
$custom-colors-border-subtle-dark
"custom-color"
#e1d2f2
$theme-colors-text-dark
map-merge
$theme-colors-text-dark
$custom-colors-text-dark
$theme-colors-bg-subtle-dark
map-merge
$theme-colors-bg-subtle-dark
$custom-colors-bg-subtle-dark
$theme-colors-border-subtle-dark
map-merge
$theme-colors-border-subtle-dark
$custom-colors-border-subtle-dark
// Remainder of Bootstrap imports
@import
"root"
@import
"reboot"
// etc
Variables
Dozens of root level CSS variables are repeated as overrides for dark mode. These are scoped to the color mode selector, which defaults to
data-bs-theme
can be configured
to use a
prefers-color-scheme
media query. Use these variables as a guideline for generating your own new color modes.
scss/_root.scss
#{$prefix}
body-color
#{$body-color-dark}
#{$prefix}
body-color-rgb
to-rgb
$body-color-dark
#{$prefix}
body-bg
#{$body-bg-dark}
#{$prefix}
body-bg-rgb
to-rgb
$body-bg-dark
#{$prefix}
emphasis-color
#{$body-emphasis-color-dark}
#{$prefix}
emphasis-color-rgb
to-rgb
$body-emphasis-color-dark
#{$prefix}
secondary-color
#{$body-secondary-color-dark}
#{$prefix}
secondary-color-rgb
to-rgb
$body-secondary-color-dark
#{$prefix}
secondary-bg
#{$body-secondary-bg-dark}
#{$prefix}
secondary-bg-rgb
to-rgb
$body-secondary-bg-dark
#{$prefix}
tertiary-color
#{$body-tertiary-color-dark}
#{$prefix}
tertiary-color-rgb
to-rgb
$body-tertiary-color-dark
#{$prefix}
tertiary-bg
#{$body-tertiary-bg-dark}
#{$prefix}
tertiary-bg-rgb
to-rgb
$body-tertiary-bg-dark
@each
$color
$value
$theme-colors-text-dark
#{$prefix}
#{$color}
-text-emphasis
#{$value}
@each
$color
$value
$theme-colors-bg-subtle-dark
#{$prefix}
#{$color}
-bg-subtle
#{$value}
@each
$color
$value
$theme-colors-border-subtle-dark
#{$prefix}
#{$color}
-border-subtle
#{$value}
#{$prefix}
heading-color
#{$headings-color-dark}
#{$prefix}
link-color
#{$link-color-dark}
#{$prefix}
link-hover-color
#{$link-hover-color-dark}
#{$prefix}
link-color-rgb
to-rgb
$link-color-dark
#{$prefix}
link-hover-color-rgb
to-rgb
$link-hover-color-dark
#{$prefix}
code-color
#{$code-color-dark}
#{$prefix}
highlight-color
#{$mark-color-dark}
#{$prefix}
highlight-bg
#{$mark-bg-dark}
#{$prefix}
border-color
#{$border-color-dark}
#{$prefix}
border-color-translucent
#{$border-color-translucent-dark}
#{$prefix}
form-valid-color
#{$form-valid-color-dark}
#{$prefix}
form-valid-border-color
#{$form-valid-border-color-dark}
#{$prefix}
form-invalid-color
#{$form-invalid-color-dark}
#{$prefix}
form-invalid-border-color
#{$form-invalid-border-color-dark}
Sass variables
CSS variables for our dark color mode are partially generated from dark mode specific Sass variables in
_variables-dark.scss
. This also includes some custom overrides for changing the colors of embedded SVGs used throughout our components.
scss/_variables-dark.scss
// scss-docs-start theme-text-dark-variables
$primary-text-emphasis-dark
tint-color
$primary
$secondary-text-emphasis-dark
tint-color
$secondary
$success-text-emphasis-dark
tint-color
$success
$info-text-emphasis-dark
tint-color
$info
$warning-text-emphasis-dark
tint-color
$warning
$danger-text-emphasis-dark
tint-color
$danger
$light-text-emphasis-dark
$gray-100
$dark-text-emphasis-dark
$gray-300
// scss-docs-end theme-text-dark-variables
// scss-docs-start theme-bg-subtle-dark-variables
$primary-bg-subtle-dark
shade-color
$primary
$secondary-bg-subtle-dark
shade-color
$secondary
$success-bg-subtle-dark
shade-color
$success
$info-bg-subtle-dark
shade-color
$info
$warning-bg-subtle-dark
shade-color
$warning
$danger-bg-subtle-dark
shade-color
$danger
$light-bg-subtle-dark
$gray-800
$dark-bg-subtle-dark
$gray-800
$black
// scss-docs-end theme-bg-subtle-dark-variables
// scss-docs-start theme-border-subtle-dark-variables
$primary-border-subtle-dark
shade-color
$primary
$secondary-border-subtle-dark
shade-color
$secondary
$success-border-subtle-dark
shade-color
$success
$info-border-subtle-dark
shade-color
$info
$warning-border-subtle-dark
shade-color
$warning
$danger-border-subtle-dark
shade-color
$danger
$light-border-subtle-dark
$gray-700
$dark-border-subtle-dark
$gray-800
// scss-docs-end theme-border-subtle-dark-variables
$body-color-dark
$gray-300
$body-bg-dark
$gray-900
$body-secondary-color-dark
rgba
$body-color-dark
$body-secondary-bg-dark
$gray-800
$body-tertiary-color-dark
rgba
$body-color-dark
$body-tertiary-bg-dark
$gray-800
$gray-900
$body-emphasis-color-dark
$white
$border-color-dark
$gray-700
$border-color-translucent-dark
rgba
$white
$headings-color-dark
inherit
$link-color-dark
tint-color
$primary
$link-hover-color-dark
shift-color
$link-color-dark
$link-shade-percentage
$code-color-dark
tint-color
$code-color
$mark-color-dark
$body-color-dark
$mark-bg-dark
$yellow-800
// Forms
$form-select-indicator-color-dark
$body-color-dark
$form-select-indicator-dark
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'><path fill='none' stroke='#{$form-select-indicator-color-dark}' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='m2 5 6 6 6-6'/></svg>"
$form-switch-color-dark
rgba
$white
$form-switch-bg-image-dark
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'><circle r='3' fill='#{$form-switch-color-dark}'/></svg>"
// scss-docs-start form-validation-colors-dark
$form-valid-color-dark
$green-300
$form-valid-border-color-dark
$green-300
$form-invalid-color-dark
$red-300
$form-invalid-border-color-dark
$red-300
// scss-docs-end form-validation-colors-dark
// Accordion
$accordion-icon-color-dark
$primary-text-emphasis-dark
$accordion-icon-active-color-dark
$primary-text-emphasis-dark
$accordion-button-icon-dark
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='#{$accordion-icon-color-dark}'><path fill-rule='evenodd' d='M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708'/></svg>"
$accordion-button-active-icon-dark
"data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='#{$accordion-icon-active-color-dark}'><path fill-rule='evenodd' d='M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708'/></svg>"
Sass mixins
Styles for dark mode, and any custom color modes you create, can be scoped appropriately to the
data-bs-theme
attribute selector or media query with the customizable
color-mode()
mixin. See the
Sass usage section
for more details.
scss/mixins/_color-mode.scss
@mixin
color-mode
$mode
light
$root
false
$color-mode-type
== "media-query"
$root
== true
@media
prefers-color-scheme
$mode
:root
@content
@else
@media
prefers-color-scheme
$mode
@content
@else
[data-bs-theme="
#{$mode}
@content


-------------------- End of Customize (7 pages) --------------------


========================= ABOUT =========================
Section: About
Files: 5
======================================================================

--- 027_about_team.txt ---
URL: https://getbootstrap.com/docs/5.3/about/team
--------------------------------------------------
Mark Otto
@mdo
Jacob Thornton
@fat
XhmikosR
@xhmikosr
GeoSot
@geosot
Patrick H. Lauke
@patrickhlauke
Julien Déramond
@julien-deramond
Gaël Poupard
@ffoodd
Rohit Sharma
@rohit2sharma95
alpadev
@alpadev
Martijn Cuppens
@martijncuppens
Johann-S
@johann-s
Gleb Mazovetskiy
@glebm
Get involved with Bootstrap development by
opening an issue
or submitting a pull request. Read our
contributing guidelines
for information on how we develop.


--- 071_about_brand.txt ---
URL: https://getbootstrap.com/docs/5.3/about/brand
--------------------------------------------------
Have a need for Bootstrap’s brand resources? Great! We have only a few guidelines we follow, and in turn ask you to follow as well.
Logo
When referencing Bootstrap, use our logo mark. Do not modify our logos in any way. Do not use Bootstrap’s branding for your own open or closed source projects.
Our logo mark is also available in black and white. All rules for our primary logo apply to these as well.
Name
. No capital
Correct
Incorrect


--- 082_about_license.txt ---
URL: https://getbootstrap.com/docs/5.3/about/license
--------------------------------------------------
It requires you to:
Keep the license and copyright notice included in Bootstrap’s CSS and JavaScript files when you use them in your works
It permits you to:
Freely download and use Bootstrap, in whole or in part, for personal, private, company internal, or commercial purposes
Use Bootstrap in packages or distributions that you create
Modify the source code
Grant a sublicense to modify and distribute Bootstrap to third parties not included in the license
It forbids you to:
Hold the authors and license owners liable for damages as Bootstrap is provided without warranty
Hold the creators or copyright holders of Bootstrap liable
Redistribute any piece of Bootstrap without proper attribution
Use any marks owned by Bootstrap in any way that might state or imply that Bootstrap endorses your distribution
Use any marks owned by Bootstrap in any way that might state or imply that you created the Bootstrap software in question
It does not require you to:
Include the source of Bootstrap itself, or of any modifications you may have made to it, in any redistribution you may assemble that includes it
Submit changes that you make to Bootstrap back to the Bootstrap project (though such feedback is encouraged)
The full Bootstrap license is located
in the project repository
for more information.


--- 106_about_translations.txt ---
URL: https://getbootstrap.com/docs/5.3/about/translations
--------------------------------------------------
Community members have translated Bootstrap’s documentation into various languages. None are officially supported and they may not always be up-to-date.
We don’t help organize or host translations, we just link to them.
Finished a new or better translation? Open a pull request to add it to our list.


--- 143_about_overview.txt ---
URL: https://getbootstrap.com/docs/5.3/about/overview
--------------------------------------------------
Team
small team of developers
on GitHub. We’re actively looking to grow this team and would love to hear from you if you’re excited about CSS at scale, writing and maintaining vanilla JavaScript plugins, and improving build tooling processes for frontend code.
History
Originally created by a designer and a developer at Twitter, Bootstrap has become one of the most popular front-end frameworks and open source projects in the world.
@mdo
@fat
. Prior to being an open-sourced framework, Bootstrap was known as
Twitter Blueprint
. A few months into development, Twitter held its
first Hack Week
and the project exploded as developers of all skill levels jumped in without any external guidance. It served as the style guide for internal tools development at the company for over a year before its public release, and continues to do so today.
Originally
released
Friday, August 19, 2011
, we’ve since had over
twenty releases
, including two major rewrites with v2 and v3. With Bootstrap 2, we added responsive functionality to the entire framework as an optional stylesheet. Building on that with Bootstrap 3, we rewrote the library once more to make it responsive by default with a mobile first approach.
With Bootstrap 4, we once again rewrote the project to account for two key architectural changes: a migration to Sass and the move to CSS’s flexbox. Our intention is to help in a small way to move the web development community forward by pushing for newer CSS properties, fewer dependencies, and new technologies across more modern browsers.
Our latest release, Bootstrap 5, focuses on improving v4’s codebase with as few major breaking changes as possible. We improved existing features and components, removed support for older browsers, dropped jQuery for regular JavaScript, and embraced more future-friendly technologies like CSS custom properties as part of our tooling.
Get involved
Get involved with Bootstrap development by
opening an issue
or submitting a pull request. Read our
contributing guidelines
for information on how we develop.


-------------------- End of About (5 pages) --------------------


========================= MIGRATION EXAMPLES =========================
Section: Migration Examples
Files: 17
======================================================================

--- 011_examples_cheatsheet.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/cheatsheet
--------------------------------------------------
Contents
Typography
Documentation
Display 1
Display 2
Display 3
Display 4
Display 5
Display 6
Heading 1
Heading 2
Heading 3
Heading 4
Heading 5
Heading 6
This is a lead paragraph. It stands out from regular paragraphs.
You can use the mark tag to
highlight
text.
This line of text is meant to be treated as deleted text.
This line of text is meant to be treated as no longer accurate.
This line of text is meant to be treated as an addition to the document.
This line of text will render as underlined.
This line of text is meant to be treated as fine print.
This line rendered as bold text.
This line rendered as italicized text.
A well-known quote, contained in a blockquote element.
This is a list.
It appears completely unstyled.
Structurally, it's still a list.
However, this style only applies to immediate child elements.
Nested lists:
are unaffected by this style
will still show a bullet
and have appropriate left margin
This may still come in handy in some situations.
This is a list item.
And another one.
But they're displayed inline.
Images
Documentation
Placeholder
Responsive image
A generic square placeholder image with a white border around it, making it resemble a photograph taken with an old instant camera
200x200
Tables
Documentation
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
Class
Heading
Heading
Default
Cell
Cell
Primary
Cell
Cell
Secondary
Cell
Cell
Success
Cell
Cell
Danger
Cell
Cell
Warning
Cell
Cell
Info
Cell
Cell
Light
Cell
Cell
Dark
Cell
Cell
First
Last
Handle
Mark
Otto
@mdo
Jacob
Thornton
@fat
John
@social
Figures
Documentation
Placeholder
400x300
A caption for the above image.
Forms
Overview
Documentation
Email address
We'll never share your email with anyone else.
Password
Select menu
Open this select menu
Three
Check me out
Radios buttons
Default radio
Another radio
Upload
Checked switch checkbox input
Example range
Submit
Disabled forms
Documentation
Disabled input
Disabled select menu
Disabled select
Can't check this
Disabled radios buttons
Disabled radio
Another radio
Upload
Disabled checked switch checkbox input
Disabled range
Submit
Sizing
Documentation
Open this select menu
Three
Open this select menu
Three
Input group
Documentation
@example.com
Your vanity URL
https://example.com/users/
With textarea
Floating labels
Documentation
Email address
Password
Validation
Documentation
First name
Looks good!
Last name
Looks good!
Username
Please choose a username.
City
Please provide a valid city.
State
Choose...
Please select a valid state.
Please provide a valid zip.
Agree to terms and conditions
You must agree before submitting.
Submit form
Components
Accordion
Documentation
Accordion Item #1
This is the first item's accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It's also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #2
This is the second item's accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It's also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Accordion Item #3
This is the third item's accordion body.
It is hidden by default, until the collapse plugin adds the appropriate classes that we use to style each element. These classes control the overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this with custom CSS or overriding our default variables. It's also worth noting that just about any HTML can go within the
.accordion-body
, though the transition does limit overflow.
Alerts
Documentation
A simple primary alert with
an example link
. Give it a click if you like.
A simple secondary alert with
an example link
. Give it a click if you like.
A simple success alert with
an example link
. Give it a click if you like.
A simple danger alert with
an example link
. Give it a click if you like.
A simple warning alert with
an example link
. Give it a click if you like.
A simple info alert with
an example link
. Give it a click if you like.
A simple light alert with
an example link
. Give it a click if you like.
A simple dark alert with
an example link
. Give it a click if you like.
Well done!
Aww yeah, you successfully read this important alert message. This example text is going to run a bit longer so that you can see how spacing within an alert works with this kind of content.
Whenever you need to, be sure to use margin utilities to keep things nice and tidy.
Badge
Documentation
Example heading
Example heading
Example heading
Example heading
Example heading
Example heading
Example heading
Example heading
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Breadcrumb
Documentation
Buttons
Documentation
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Link
Primary
Secondary
Success
Danger
Warning
Info
Light
Dark
Small button
Standard button
Large button
Button group
Documentation
Card
Documentation
Placeholder
Image cap
Card title
Some quick example text to build on the card title and make up the bulk of the card's content.
Go somewhere
Featured
Card title
Some quick example text to build on the card title and make up the bulk of the card's content.
Go somewhere
2 days ago
Card title
Some quick example text to build on the card title and make up the bulk of the card's content.
An item
A second item
A third item
Card link
Another link
Placeholder
Image
Card title
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
Last updated 3 mins ago
Carousel
Documentation
Placeholder
First slide
First slide label
Some representative placeholder content for the first slide.
Placeholder
Second slide
Second slide label
Some representative placeholder content for the second slide.
Placeholder
Third slide
Third slide label
Some representative placeholder content for the third slide.
Previous
Next
Dropdowns
Documentation
Dropdown button
Dropdown header
Action
Another action
Something else here
Separated link
Dropdown button
Dropdown header
Action
Another action
Something else here
Separated link
Dropdown button
Dropdown header
Action
Another action
Something else here
Separated link
Primary
Toggle Dropdown
Action
Another action
Something else here
Secondary
Toggle Dropdown
Action
Another action
Something else here
Success
Toggle Dropdown
Action
Another action
Something else here
Info
Toggle Dropdown
Action
Another action
Something else here
Warning
Toggle Dropdown
Action
Another action
Something else here
Danger
Toggle Dropdown
Action
Another action
Something else here
Dropend button
Dropdown header
Action
Another action
Something else here
Separated link
Dropup button
Dropdown header
Action
Another action
Something else here
Separated link
Dropstart button
Dropdown header
Action
Another action
Something else here
Separated link
End-aligned menu
Dropdown header
Action
Another action
Separated link
List group
Documentation
A disabled item
A second item
A third item
A fourth item
And a fifth one
An item
A second item
A third item
A fourth item
And a fifth one
A simple default list group item
A simple primary list group item
A simple secondary list group item
A simple success list group item
A simple danger list group item
A simple warning list group item
A simple info list group item
A simple light list group item
A simple dark list group item
Modal
Documentation
Launch demo modal
Launch static backdrop modal
Vertically centered scrollable modal
Full screen
Navs
Documentation
This is some placeholder content the
Home tab's
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Profile tab's
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
This is some placeholder content the
Contact tab's
associated content. Clicking another tab will toggle the visibility of this one for the next. The tab JavaScript swaps classes to control the content visibility and styling. You can use it with tabs, pills, and any other
.nav
-powered navigation.
Active
Link
Link
Disabled
Navbar
Documentation
Pagination
Documentation
Popovers
Documentation
Click to toggle popover
Popover on top
Popover on end
Popover on bottom
Popover on start
Progress
Documentation
100%
Scrollspy
Documentation
First heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It's repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Second heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It's repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Third heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It's repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Fourth heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It's repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Fifth heading
This is some placeholder content for the scrollspy page. Note that as you scroll down the page, the appropriate navigation link is highlighted. It's repeated throughout the component example. We keep adding some more example copy here to emphasize the scrolling and highlighting.
Spinners
Documentation
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Toasts
Documentation
11 mins ago
Hello, world! This is a toast message.
Tooltips
Documentation
Tooltip on top
Tooltip on end
Tooltip on bottom
Tooltip on start
Tooltip with HTML


--- 036_examples_jumbotrons.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/jumbotrons
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Jumbotron with icon
This is a custom jumbotron featuring an SVG image at the top, some longer text that wraps early thanks to a responsive
.col-*
class, and a customized call to action.
Call to action
Secondary link
Placeholder jumbotron
This faded back jumbotron is useful for placeholder content. It's also a great way to add a bit of context to a page or section when no content is available and to encourage visitors to take a specific action.
Call to action
Full-width jumbotron
This takes the basic jumbotron above and makes its background edge-to-edge with a
.container
inside to align content. Similar to above, it's been recreated with built-in grid and utility classes.
Basic jumbotron
This is a simple Bootstrap jumbotron that sits within a
.container
, recreated with built-in utility classes.


--- 039_examples_sidebars.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/sidebars
--------------------------------------------------
Sidebars examples
Sidebar
Home
Dashboard
Orders
Products
Customers
New project...
Settings
Profile
Sign out
Sidebar
Home
Dashboard
Orders
Products
Customers
New project...
Settings
Profile
Sign out
Icon-only
New project...
Settings
Profile
Sign out
Collapsible
Home
Overview
Updates
Reports
Dashboard
Overview
Weekly
Monthly
Annually
Orders
Processed
Shipped
Returned
Account
New...
Profile
Settings
Sign out
List group
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Tues
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Tues
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Tues
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.
List group item heading
Tues
Some placeholder content in a paragraph below the heading and date.
List group item heading
Some placeholder content in a paragraph below the heading and date.


--- 059_examples_dashboard.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/dashboard
--------------------------------------------------
Dashboard
Share
Export
This week
Section title
Header
Header
Header
Header
1,001
random
data
placeholder
text
1,002
placeholder
irrelevant
visual
layout
1,003
data
rich
dashboard
tabular
1,003
information
placeholder
illustrative
data
1,004
text
random
layout
dashboard
1,005
dashboard
irrelevant
text
placeholder
1,006
dashboard
illustrative
rich
data
1,007
placeholder
tabular
information
irrelevant
1,008
random
data
placeholder
text
1,009
placeholder
irrelevant
visual
layout
1,010
data
rich
dashboard
tabular
1,011
information
placeholder
illustrative
data
1,012
text
placeholder
layout
dashboard
1,013
dashboard
irrelevant
text
visual
1,014
dashboard
illustrative
rich
data
1,015
random
tabular
information
text


--- 061_examples_starter-template.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/starter-template
--------------------------------------------------
Get started with Bootstrap
Quickly and easily get started with Bootstrap's compiled, production-ready files with this barebones example featuring some basic HTML and helpful links. Download all our examples to get started.
Download examples
Starter projects
Ready to go beyond the starter template? Check out these open source projects that you can quickly duplicate to a new GitHub repository.
Guides
Read more detailed instructions and documentation on using or contributing to Bootstrap.
Contributing to Bootstrap


--- 063_examples_cover.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/cover
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Cover your page.
Cover is a one-page template for building simple and beautiful home pages. Download, edit the text, and add your own fullscreen background photo to make it your own.
Learn more


--- 080_examples_sticky-footer.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/sticky-footer
--------------------------------------------------
Toggle theme
Light
Dark
Auto
Sticky footer
Pin a footer to the bottom of the viewport in desktop browsers with this custom HTML and CSS.
the sticky footer with a fixed navbar
if need be, too.


--- 088_examples_blog.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/blog
--------------------------------------------------
Title of a longer featured blog post
Multiple lines of text that form the lede, informing new readers quickly and efficiently about what’s most interesting in this post’s contents.
Continue reading...
World
Featured post
Nov 12
This is a wider card with supporting text below as a natural lead-in to additional content.
Continue reading
Placeholder
Thumbnail
Design
Post title
Nov 11
This is a wider card with supporting text below as a natural lead-in to additional content.
Continue reading
Placeholder
Thumbnail
From the Firehose
Sample blog post
January 1, 2021 by
Mark
This blog post shows a few different types of content that’s supported and styled with Bootstrap. Basic typography, lists, tables, images, code, and more are all supported as expected.
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Blockquotes
This is an example blockquote in action:
Quoted text goes here.
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Example lists
This is some additional paragraph placeholder content. It's a slightly shorter version of the other highly repetitive body text used throughout. This is an example unordered list:
First list item
Second list item with a longer description
Third list item to close it out
And this is an ordered list:
First list item
Second list item with a longer description
Third list item to close it out
And this is a definition list:
HyperText Markup Language (HTML)
The language used to describe and define the content of a Web page
Cascading Style Sheets (CSS)
Used to describe the appearance of Web content
JavaScript (JS)
The programming language used to build advanced Web sites and applications
Inline HTML elements
HTML defines a long list of available inline tags, a complete list of which can be found on the
Mozilla Developer Network
To bold text
, use
<strong>
To italicize text
, use
<em>
Abbreviations, like
HTML
should use
<abbr>
, with an optional
title
attribute for the full phrase.
Citations, like
— Mark Otto
, should use
<cite>
Deleted
text should use
<del>
inserted
text should use
<ins>
Superscript
text
uses
<sup>
and subscript
text
uses
<sub>
Most of these elements are styled by browsers with few modifications on our part.
Heading
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Sub-heading
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Example code block
This is some additional paragraph placeholder content. It's a slightly shorter version of the other highly repetitive body text used throughout.
Another blog post
December 23, 2020 by
Jacob
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Longer quote goes here, maybe with some
emphasized text
in the middle of it.
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
Example table
And don't forget about tables in these posts:
Name
Upvotes
Downvotes
Alice
Charlie
Totals
This is some additional paragraph placeholder content. It's a slightly shorter version of the other highly repetitive body text used throughout.
New feature
December 14, 2020 by
Chris
This is some additional paragraph placeholder content. It has been written to fill the available space and show how a longer snippet of text affects the surrounding content. We'll repeat it often to keep the demonstration flowing, so be on the lookout for this exact same string of text.
First list item
Second list item with a longer description
Third list item to close it out
This is some additional paragraph placeholder content. It's a slightly shorter version of the other highly repetitive body text used throughout.
About
Customize this section to tell your visitors a little bit about your publication, writers, content, or something else entirely. Totally up to you.
Recent posts
Example blog post title
January 15, 2024
This is another blog post title
January 14, 2024
Longer blog post title: This one has multiple lines!
January 13, 2024
Archives
March 2021
February 2021
January 2021
December 2020
November 2020
October 2020
September 2020
August 2020
July 2020
June 2020
May 2020
April 2020
Elsewhere
GitHub
Social
Facebook


--- 094_examples_pricing.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/pricing
--------------------------------------------------
Free
10 users included
2 GB of storage
Email support
Help center access
Sign up for free
20 users included
10 GB of storage
Priority email support
Help center access
Get started
Enterprise
30 users included
15 GB of storage
Phone and email support
Help center access
Contact us
Compare plans
Free
Enterprise
Public
Private
Permissions
Sharing
Unlimited members
Extra security


--- 097_examples_jumbotron.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/jumbotron
--------------------------------------------------
Custom jumbotron
Using a series of utilities, you can create this jumbotron, just like the one in previous versions of Bootstrap. Check out the examples below for how you can remix and restyle it to your liking.
Example button
Change the background
Swap the background-color utility and add a `.text-*` color utility to mix up the jumbotron look. Then, mix and match with additional component themes and more.
Example button
Add borders
Or, keep it light and add a border for some added definition to the boundaries of your content. Be sure to look under the hood at the source HTML here as we've adjusted the alignment and sizing of both column's content for equal-height.
Example button


--- 114_examples_heroes.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/heroes
--------------------------------------------------
Heroes examples
Centered hero
Quickly design and customize responsive mobile-first sites with Bootstrap, the world’s most popular front-end open source toolkit, featuring Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful JavaScript plugins.
Primary button
Secondary
Centered screenshot
Quickly design and customize responsive mobile-first sites with Bootstrap, the world’s most popular front-end open source toolkit, featuring Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful JavaScript plugins.
Primary button
Secondary
Responsive left-aligned hero with image
Quickly design and customize responsive mobile-first sites with Bootstrap, the world’s most popular front-end open source toolkit, featuring Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful JavaScript plugins.
Primary
Default
Vertically centered hero sign-up form
Below is an example form built entirely with Bootstrap’s form controls. Each required form group has a validation state that can be triggered by attempting to submit the form without completing it.
Email address
Password
Remember me
Sign up
By clicking Sign up, you agree to the terms of use.
Border hero with cropped image and shadows
Quickly design and customize responsive mobile-first sites with Bootstrap, the world’s most popular front-end open source toolkit, featuring Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful JavaScript plugins.
Primary
Default
Dark color hero
Quickly design and customize responsive mobile-first sites with Bootstrap, the world’s most popular front-end open source toolkit, featuring Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful JavaScript plugins.
Custom button
Secondary


--- 115_examples.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/
--------------------------------------------------
Starters
Functional examples of using Bootstrap in common JS frameworks like Webpack, Parcel, Vite, and more you can edit in StackBlitz.
CDN starter
Instantly include Bootstrap's compiled CSS and JavaScript via the jsDelivr CDN.
Edit in StackBlitz
Sass & JS
Use npm to import and compile Bootstrap's Sass with Autoprefixer and Stylelint, plus our bundled JavaScript.
Edit in StackBlitz
Sass & ESM JS
Import and compile Bootstrap's Sass with Autoprefixer and Stylelint, and compile our source JavaScript with an ESM shim.
Edit in StackBlitz
Import and compile Bootstrap's Sass with Stylelint, and the Bootstrap color modes.
Edit in StackBlitz
Import and compile Bootstrap's Sass with Stylelint, PurgeCSS, and the Bootstrap Icons web font.
Edit in StackBlitz
Parcel
Import and bundle Bootstrap's source Sass and JavaScript via Parcel.
Edit in StackBlitz
React
Import and bundle Bootstrap's source Sass and JavaScript with React, Next.js, and React Bootstrap.
Edit in StackBlitz
Vite
Import and bundle Bootstrap's source Sass and JavaScript with Vite.
Edit in StackBlitz
Import and bundle Bootstrap's source Sass and JavaScript with Vue and Vite.
Edit in StackBlitz
Webpack
Import and bundle Bootstrap's source Sass and JavaScript with Webpack.
Edit in StackBlitz


--- 128_examples_checkout.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/checkout
--------------------------------------------------
Checkout form
Below is an example form built entirely with Bootstrap’s form controls. Each required form group has a validation state that can be triggered by attempting to submit the form without completing it.
Your cart
Product name
Brief description
Second product
Brief description
Third item
Brief description
Promo code
EXAMPLECODE
Total (USD)
Redeem
Billing address
First name
Valid first name is required.
Last name
Valid last name is required.
Username
Your username is required.
Email
(Optional)
Please enter a valid email address for shipping updates.
Address
Please enter your shipping address.
Address 2
(Optional)
Country
Choose...
United States
Please select a valid country.
State
Choose...
California
Please provide a valid state.
Zip code required.
Shipping address is the same as my billing address
Save this information for next time
Payment
Credit card
Debit card
PayPal
Name on card
Full name as displayed on card
Name on card is required
Credit card number
Credit card number is required
Expiration
Expiration date required
Security code required
Continue to checkout


--- 131_examples_album.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/album
--------------------------------------------------
Album example
Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.
Main call to action
Secondary action
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins
Placeholder
Thumbnail
This is a wider card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
View
Edit
9 mins


--- 132_examples_masonry.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/masonry
--------------------------------------------------
Integrate
Masonry
with the Bootstrap grid system and cards component.
Masonry is not included in Bootstrap. Add it by including the JavaScript plugin manually, or using a CDN like so:
<script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous" async></script>
By adding
data-masonry='&lcub;"percentPosition": true &rcub;'
to the
.row
wrapper, we can combine the powers of Bootstrap's responsive grid and Masonry's positioning.
Placeholder
Image cap
Card title that wraps to a new line
This is a longer card with supporting text below as a natural lead-in to additional content. This content is a little bit longer.
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
Placeholder
Image cap
Card title
This card has supporting text below as a natural lead-in to additional content.
Last updated 3 mins ago
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
Card title
This card has a regular title and short paragraph of text below it.
Last updated 3 mins ago
Placeholder
Card image
A well-known quote, contained in a blockquote element.
Someone famous in
Source Title
Card title
This is another card with title and supporting text below. This card has some additional content to make it slightly taller overall.
Last updated 3 mins ago


--- 141_examples_product.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/product
--------------------------------------------------
Designed for engineers
Build anything you want with Aperture
Learn more
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.
Another headline
And an even wittier subheading.


--- 144_examples_features.txt ---
URL: https://getbootstrap.com/docs/5.3/examples/features
--------------------------------------------------
Features examples
Columns with icons
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Call to action
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Call to action
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Call to action
Hanging icons
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Primary button
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Primary button
Featured title
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Primary button
Custom cards
Short title, long jacket
Earth
Much longer title that wraps to multiple lines
Pakistan
Another longer title belongs here
California
Icon grid
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Features with title
Left-aligned title explaining these awesome features
Paragraph of text beneath the heading to explain the heading. We'll add onto it with another sentence and probably just keep going until we run out of words.
Primary button
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.
Featured title
Paragraph of text beneath the heading to explain the heading.


-------------------- End of Migration Examples (17 pages) --------------------
