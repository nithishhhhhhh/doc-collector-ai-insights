URL: https://modal.com/docs/examples/whisper-transcriber
==================================================

Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
Parallel podcast transcription using Whisper
This example shows how to build a massively parallel application on Modal:
Modal Podcast Transcriber
This example application is more feature-packed than others, and it doesn’t fit in
a single page of code and commentary. So instead of progressing through the
example’s code linearly, this document provides a higher-level walkthrough of how
Modal is used to do fast, on-demand podcast episode transcription for whichever
podcast you’d like.
You can find the code
here
Hour-long episodes transcribed in just 1 minute
The focal point of this demonstration app is that it does serverless CPU
transcription across dozens of containers at the click of a button, completing
hour-long audio files in just 1 minute.
We use a podcast metadata API to allow users to transcribe an arbitrary episode
from whatever niche podcast they desire —
how about
The Pen Addict
, a podcast dedicated to stationery
The video below shows the 45-minute long first episode of
Serial
season 2
transcribed in 62 seconds.
Each transcription segment includes links back to the original audio.
Try it yourself
If you’re itching to see this in action, here are links to begin transcribing
three popular podcasts:
Case 63
by Gimlet Media
The Joe Rogan Experience
The Psychology of your 20s
Tech-stack overview
The entire application is hosted serverlessly on Modal and consists of these
main components:
A React +
Vite
single page application (SPA) deployed
as static files into a Modal web endpoint.
A Python backend running
FastAPI
in a Modal web endpoint.
Podchaser API
provides
podcast search and episode metadata retrieval. It’s hooked into our code with
Modal Secret
A Modal async job queue, described in more detail below.
All of this is deployed with one command and costs
$0.00
when it’s not
transcribing podcasts or serving HTTP requests.
Speed-boosting Whisper with parallelism
Modal’s dead-simple parallelism primitives are the key to doing the
transcription so quickly. Even with a GPU, transcribing a full episode serially
was taking around 10 minutes.
But by pulling in
ffmpeg
with a simple
.pip_install("ffmpeg-python")
addition to our Modal Image, we could exploit the natural silences of the
podcast medium to partition episodes into hundreds of short segments. Each
segment is transcribed by Whisper in its own container task,
and when all are done we stitch the segments back together with only a
minimal loss in transcription quality. This approach actually accords quite well
with Whisper’s model architecture:
“The Whisper architecture is a simple end-to-end approach, implemented as an
encoder-decoder Transformer. Input audio is split into 30-second chunks,
converted into a log-Mel spectrogram, and then passed into an encoder.”
Introducing Whisper
Run this app on Modal
All source code for this example can be
found on GitHub
README.md
includes instructions on setting up the frontend build and
getting authenticated with the Podchaser API. Happy transcribing!
Parallel podcast transcription using Whisper
Hour-long episodes transcribed in just 1 minute
Try it yourself
Tech-stack overview
Speed-boosting Whisper with parallelism
Run this app on Modal