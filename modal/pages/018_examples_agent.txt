URL: https://modal.com/docs/examples/agent
==================================================

Featured
Getting started
Hello, world
Simple web scraper
Serving web endpoints
Large language models (LLMs)
Deploy an OpenAI-compatible LLM service with vLLM
Run DeepSeek-R1 and Phi-4 with llama.cpp
Low-latency, serverless TensorRT-LLM
Run Vision-Language Models with SGLang
Run a multimodal RAG chatbot to answer questions about PDFs
Fine-tune an LLM to replace your CEO
Images, video, & 3D
Fine-tune Wan2.1 video models on your face
Run Flux fast with torch.compile
Fine-tune Flux with LoRA
Animate images with LTX-Video
Generate video clips with LTX-Video
Generate video clips with Mochi
Run Stable Diffusion with a CLI, API, and web UI
Deploy ControlNet demos with Gradio
Audio
Run Text to Speech (TTS) with Chatterbox
Deploy a Moshi voice chatbot
Create music with MusicGen
Real-time communication
Serverless WebRTC
Real-time audio transcription using Parakeet
WebRTC quickstart with FastRTC
Computational biology
Fold proteins with Chai-1
Build a protein-folding dashboard
Fold proteins with Boltz-2
Sandboxed code execution
Run a LangGraph agent's code in a secure GPU sandbox
Build a stateful, sandboxed code interpreter
Run Node.js, Ruby, and more in a Sandbox
Run a sandboxed Jupyter notebook
Embeddings
Embed millions of documents with TEI
Turn satellite images into vectors and store them in MongoDB
Parallel processing and job scheduling
Transcribe podcasts with Whisper
Deploy a Hacker News Slackbot
Run a Document OCR job queue
Serve a Document OCR web app
Training models from scratch
Train an SLM with early-stopping grid search over hyperparameters
Run long, resumable training jobs
Hosting popular libraries
FastHTML: Deploy 100,000 multiplayer checkboxes
YOLO: Fine-tune and serve computer vision models
MultiOn: Create an agent for AI news
Blender: Build a 3D render farm
Streamlit: Run and deploy Streamlit apps
ComfyUI: Run Flux on ComfyUI as an API
SQLite: Publish explorable data with Datasette
Algolia: Build docsearch with a crawler
Connecting to other APIs
Discord: Deploy and run a Discord Bot
Google Sheets: Sync databases and APIs to a Google Sheet
OpenAI: Run a RAG Q&A chatbot
Tailscale: Add Modal Apps to your VPN
Prometheus: Publish custom metrics with Pushgateway
Managing data
Mount S3 buckets in Modal apps
Build your own data warehouse with DuckDB, DBT, and Modal
Create a LoRA Playground with Modal, Gradio, and S3
Miscellaneous
View on GitHub
Build a coding agent with Modal Sandboxes and LangGraph
This example demonstrates how to build an LLM coding â€œagentâ€ that can generate and execute Python code, using
documentation from the web to inform its approach.
Naturally, we use the agent to generate code that runs language models.
The agent is built with
LangGraph
, a library for building
directed graphs of computation popular with AI agent developers,
and uses models from the OpenAI API.
Setup
import
modal
from
.src
import
edges, nodes, retrieval
from
.src.common
import
COLOR, PYTHON_VERSION, image
Copy
You will need two
Modal Secrets
to run this example:
one to access the OpenAI API and another to access the LangSmith API for logging the agentâ€™s behavior.
To create them, head to the
Secrets dashboard
, select â€œCreate new secretâ€,
and use the provided templates for OpenAI and LangSmith.
app = modal.App(
"example-code-langchain"
image
=image,
secrets
modal.Secret.from_name(
"openai-secret"
required_keys
"OPENAI_API_KEY"
modal.Secret.from_name(
"langsmith-secret"
required_keys
"LANGCHAIN_API_KEY"
Copy
Creating a Sandbox
We execute the agentâ€™s code in a Modal
Sandbox
, which allows us to
run arbitrary code in a safe environment. In this example, we will use the
transformers
library to generate text with a pre-trained model. Letâ€™s create a Sandbox with the necessary dependencies.
create_sandbox
) -> modal.Sandbox:
# Change this image (and the retrieval logic in the retrieval module)
# if you want the agent to give coding advice on other libraries!
agent_image = modal.Image.debian_slim(
python_version
=PYTHON_VERSION).pip_install(
"torch==2.5.0"
"transformers==4.46.0"
return
modal.Sandbox.create(
image
=agent_image,
timeout
# 10 minutes
=app,
# Modal sandboxes support GPUs!
"T4"
# you can also pass secrets here -- note that the main app's secrets are not shared
Copy
We also need a way to run our code in the sandbox. For this, weâ€™ll write a simple wrapper
around the Modal Sandox
exec
method. We use
exec
because it allows us to run code without spinning up a
new container. And we can reuse the same container for multiple runs, preserving state.
code
: modal.Sandbox) -> tuple[
print
COLOR[
'HEADER'
ðŸ“¦: Running in sandbox
COLOR[
'ENDC'
COLOR[
'GREEN'
code
COLOR[
'ENDC'
exc = sb.exec(
"python"
"-c"
, code)
exc.wait()
stdout = exc.stdout.read()
stderr = exc.stderr.read()
exc.returncode !=
print
COLOR[
'HEADER'
ðŸ“¦: Failed with exitcode
sb.returncode
COLOR[
'ENDC'
return
stdout, stderr
Copy
Constructing the agentâ€™s graph
Now that we have the sandbox to execute code in, we can construct our agentâ€™s graph. Our graph is
defined in the
edges
nodes
modules
associated with this example
Nodes are actions that change the state. Edges are transitions between nodes.
The idea is simple: we start at the node
generate
, which invokes the LLM to generate code based off documentation.
The generated code is executed (in the sandbox) as part of an edge called
check_code_execution
and then the outputs are passed to the LLM for evaluation (the
evaluate_execution
node).
If the LLM determines that the code has executed correctly â€” which might mean that the code raised an exception! â€”
we pass along the
decide_to_finish
edge and finish.
construct_graph
sandbox
: modal.Sandbox,
debug
bool
False
from
langgraph.graph
import
StateGraph
from
.src.common
import
GraphState
# Crawl the transformers documentation to inform our code generation
context = retrieval.retrieve_docs(
debug
=debug)
graph = StateGraph(GraphState)
# Attach our nodes to the graph
graph_nodes = nodes.Nodes(context, sandbox, run,
debug
=debug)
key, value
graph_nodes.node_map.items():
graph.add_node(key, value)
# Construct the graph by adding edges
graph = edges.enrich(graph)
# Set the starting and ending nodes of the graph
graph.set_entry_point(
"generate"
graph.set_finish_point(
"finish"
return
graph
Copy
We now set up the graph and compile it. See the
module for details
on the content of the graph and the nodes weâ€™ve defined.
DEFAULT_QUESTION =
"How do I generate Python code using a pre-trained model from the transformers library?"
@app.function
question
= DEFAULT_QUESTION,
debug
bool
False
"""Compiles the Python code generation agent graph and runs it, returning the result."""
sb = create_sandbox(app)
graph = construct_graph(sb,
debug
=debug)
runnable = graph.compile()
result = runnable.invoke(
"keys"
"question"
: question,
"iterations"
config
"recursion_limit"
sb.terminate()
return
result[
"keys"
"response"
Copy
Running the Graph
Now letâ€™s call the agent from the command line!
We define a
local_entrypoint
that runs locally and triggers execution on Modal.
You can invoke it by executing following command from a folder that contains the
codelangchain
directory
from our examples repo
modal
codelangchain.agent
--question
"How do I run a pre-trained model from the transformers library?"
Copy
@app.local_entrypoint
main
question
= DEFAULT_QUESTION,
debug
bool
False
"""Sends a question to the Python code generation agent.
Switch to debug mode for shorter context and smaller model."""
debug:
question == DEFAULT_QUESTION:
question =
"hi there, how are you?"
print
(go.remote(question,
debug
=debug))
Copy
If things are working properly, you should see output like the following:
modal
codelangchain.agent
--question
"generate some cool output with transformers"
---DECISION:
FINISH---
---FINISHING---
generate
some
cool
output
using
transformers,
pre-trained
language
model
from
Hugging
Face
Transformers
library.
this
example,
we'll use the GPT-2 model to generate text based on a given prompt. The GPT-2 model is a popular choice for text generation tasks due to its ability to produce coherent and contextually relevant text. We'll
pipeline
from
Transformers
library,
which
simplifies
process
using
pre-trained
models
various
tasks,
including
text
generation.
from
transformers
import
pipeline
# Initialize the text generation pipeline with the GPT-2 model
generator
pipeline
'text-generation'
model='gpt2'
# Define a prompt for the model to generate text from
prompt
"Once upon a time in a land far, far away"
# Generate text using the model
output
generator
prompt,
max_length=50,
num_return_sequences=
# Print the generated text
print
output[0][
'generated_text'
Result
code
execution:
Once
upon
time
land
far,
away,
still
inhabited
even
after
human
race,
there
would
God:
perfect
universal
always
been
will
ever
worshipped.
acts
deeds
immutable,
Copy
Build a coding agent with Modal Sandboxes and LangGraph
Setup
Creating a Sandbox
Constructing the agentâ€™s graph
Running the Graph
Try this on Modal!
You can run this example on Modal in 60 seconds.
Create account to run
After creating a free account, install the Modal Python package, and
create an API token.
install
modal
modal
setup
Copy
Clone the
modal-examples
repository and run:
clone
https://github.com/modal-labs/modal-examples
modal-examples
modal
13_sandboxes.codelangchain.agent
--question
'Use gpt2 and transformers to generate text'
Copy